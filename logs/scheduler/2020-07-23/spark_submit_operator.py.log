[2020-07-23 14:33:26,893] {scheduler_job.py:153} INFO - Started process (PID=202032) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:33:26,895] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:33:26,896] {logging_mixin.py:112} INFO - [2020-07-23 14:33:26,896] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:33:26,981] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:33:27,708] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:33:42,097] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-23 14:33:42,102] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:33:00+00:00: scheduled__2020-07-20T09:33:00+00:00, externally triggered: False>
[2020-07-23 14:33:42,111] {logging_mixin.py:112} INFO - [2020-07-23 14:33:42,111] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:33:00+00:00: scheduled__2020-07-20T09:33:00+00:00, externally triggered: False> successful
[2020-07-23 14:33:43,988] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-23 14:33:44,007] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:33:44,011] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:00:00+00:00 [scheduled]> in ORM
[2020-07-23 14:33:45,784] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 18.891 seconds
[2020-07-23 14:34:24,644] {scheduler_job.py:153} INFO - Started process (PID=202856) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:34:24,647] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:34:24,647] {logging_mixin.py:112} INFO - [2020-07-23 14:34:24,647] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:34:24,656] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:34:25,831] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:34:27,881] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:01:00+00:00: scheduled__2020-07-21T00:01:00+00:00, externally triggered: False>
[2020-07-23 14:34:27,887] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-23 14:34:27,895] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:01:00+00:00: scheduled__2020-07-21T00:01:00+00:00, externally triggered: False>
[2020-07-23 14:34:27,915] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:34:27,920] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:01:00+00:00 [scheduled]> in ORM
[2020-07-23 14:34:29,064] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 4.421 seconds
[2020-07-23 14:35:05,135] {scheduler_job.py:153} INFO - Started process (PID=203554) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:35:05,138] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:35:05,138] {logging_mixin.py:112} INFO - [2020-07-23 14:35:05,138] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:35:05,148] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:35:06,486] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:35:08,384] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:02:00+00:00: scheduled__2020-07-21T00:02:00+00:00, externally triggered: False>
[2020-07-23 14:35:08,388] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-23 14:35:08,399] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:01:00+00:00: scheduled__2020-07-21T00:01:00+00:00, externally triggered: False>
[2020-07-23 14:35:08,408] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:02:00+00:00: scheduled__2020-07-21T00:02:00+00:00, externally triggered: False>
[2020-07-23 14:35:08,426] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:35:08,431] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:02:00+00:00 [scheduled]> in ORM
[2020-07-23 14:35:09,387] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 4.252 seconds
[2020-07-23 14:35:45,710] {scheduler_job.py:153} INFO - Started process (PID=204666) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:35:45,714] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:35:45,715] {logging_mixin.py:112} INFO - [2020-07-23 14:35:45,715] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:35:45,725] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:35:46,473] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:35:48,134] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:03:00+00:00: scheduled__2020-07-21T00:03:00+00:00, externally triggered: False>
[2020-07-23 14:35:48,138] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-23 14:35:48,146] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:01:00+00:00: scheduled__2020-07-21T00:01:00+00:00, externally triggered: False>
[2020-07-23 14:35:48,162] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:02:00+00:00: scheduled__2020-07-21T00:02:00+00:00, externally triggered: False>
[2020-07-23 14:35:48,176] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:03:00+00:00: scheduled__2020-07-21T00:03:00+00:00, externally triggered: False>
[2020-07-23 14:35:48,199] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:35:48,203] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:03:00+00:00 [scheduled]> in ORM
[2020-07-23 14:35:48,953] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 3.243 seconds
[2020-07-23 14:39:15,551] {scheduler_job.py:153} INFO - Started process (PID=208594) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:39:15,592] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:39:15,593] {logging_mixin.py:112} INFO - [2020-07-23 14:39:15,593] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:39:15,602] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:39:16,503] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:39:20,770] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:04:00+00:00: scheduled__2020-07-21T00:04:00+00:00, externally triggered: False>
[2020-07-23 14:39:20,774] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-23 14:39:20,782] {logging_mixin.py:112} INFO - [2020-07-23 14:39:20,782] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False> successful
[2020-07-23 14:39:21,228] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:01:00+00:00: scheduled__2020-07-21T00:01:00+00:00, externally triggered: False>
[2020-07-23 14:39:21,245] {logging_mixin.py:112} INFO - [2020-07-23 14:39:21,245] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:01:00+00:00: scheduled__2020-07-21T00:01:00+00:00, externally triggered: False> successful
[2020-07-23 14:39:21,507] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:02:00+00:00: scheduled__2020-07-21T00:02:00+00:00, externally triggered: False>
[2020-07-23 14:39:21,520] {logging_mixin.py:112} INFO - [2020-07-23 14:39:21,520] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:02:00+00:00: scheduled__2020-07-21T00:02:00+00:00, externally triggered: False> successful
[2020-07-23 14:39:22,251] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:03:00+00:00: scheduled__2020-07-21T00:03:00+00:00, externally triggered: False>
[2020-07-23 14:39:22,274] {logging_mixin.py:112} INFO - [2020-07-23 14:39:22,274] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:03:00+00:00: scheduled__2020-07-21T00:03:00+00:00, externally triggered: False> successful
[2020-07-23 14:39:22,573] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:04:00+00:00: scheduled__2020-07-21T00:04:00+00:00, externally triggered: False>
[2020-07-23 14:39:22,594] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:39:22,598] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:04:00+00:00 [scheduled]> in ORM
[2020-07-23 14:39:22,800] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 7.249 seconds
[2020-07-23 14:43:57,278] {scheduler_job.py:153} INFO - Started process (PID=212506) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:43:57,308] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:43:57,308] {logging_mixin.py:112} INFO - [2020-07-23 14:43:57,308] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:43:57,503] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:43:58,039] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:44:01,304] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:05:00+00:00: scheduled__2020-07-21T00:05:00+00:00, externally triggered: False>
[2020-07-23 14:44:01,311] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:04:00+00:00: scheduled__2020-07-21T00:04:00+00:00, externally triggered: False>
[2020-07-23 14:44:01,322] {logging_mixin.py:112} INFO - [2020-07-23 14:44:01,322] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:04:00+00:00: scheduled__2020-07-21T00:04:00+00:00, externally triggered: False> successful
[2020-07-23 14:44:01,943] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:05:00+00:00: scheduled__2020-07-21T00:05:00+00:00, externally triggered: False>
[2020-07-23 14:44:01,974] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:44:01,978] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:05:00+00:00 [scheduled]> in ORM
[2020-07-23 14:44:02,706] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 5.428 seconds
[2020-07-23 14:44:17,753] {scheduler_job.py:153} INFO - Started process (PID=212920) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:44:17,758] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:44:17,758] {logging_mixin.py:112} INFO - [2020-07-23 14:44:17,758] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:44:17,798] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:44:18,515] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:44:20,009] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:06:00+00:00: scheduled__2020-07-21T00:06:00+00:00, externally triggered: False>
[2020-07-23 14:44:20,024] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:05:00+00:00: scheduled__2020-07-21T00:05:00+00:00, externally triggered: False>
[2020-07-23 14:44:20,040] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:06:00+00:00: scheduled__2020-07-21T00:06:00+00:00, externally triggered: False>
[2020-07-23 14:44:20,070] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:44:20,078] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:06:00+00:00 [scheduled]> in ORM
[2020-07-23 14:44:20,326] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.573 seconds
[2020-07-23 14:44:31,282] {scheduler_job.py:153} INFO - Started process (PID=213195) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:44:31,287] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:44:31,287] {logging_mixin.py:112} INFO - [2020-07-23 14:44:31,287] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:44:31,307] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:44:31,769] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:44:32,654] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:07:00+00:00: scheduled__2020-07-21T00:07:00+00:00, externally triggered: False>
[2020-07-23 14:44:32,660] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:05:00+00:00: scheduled__2020-07-21T00:05:00+00:00, externally triggered: False>
[2020-07-23 14:44:32,668] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:06:00+00:00: scheduled__2020-07-21T00:06:00+00:00, externally triggered: False>
[2020-07-23 14:44:32,680] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:07:00+00:00: scheduled__2020-07-21T00:07:00+00:00, externally triggered: False>
[2020-07-23 14:44:32,700] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:44:32,703] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:07:00+00:00 [scheduled]> in ORM
[2020-07-23 14:44:33,263] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.981 seconds
[2020-07-23 14:44:48,362] {scheduler_job.py:153} INFO - Started process (PID=213639) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:44:48,367] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:44:48,368] {logging_mixin.py:112} INFO - [2020-07-23 14:44:48,368] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:44:48,388] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:44:48,776] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:44:49,650] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:08:00+00:00: scheduled__2020-07-21T00:08:00+00:00, externally triggered: False>
[2020-07-23 14:44:49,656] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:05:00+00:00: scheduled__2020-07-21T00:05:00+00:00, externally triggered: False>
[2020-07-23 14:44:49,672] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:06:00+00:00: scheduled__2020-07-21T00:06:00+00:00, externally triggered: False>
[2020-07-23 14:44:49,688] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:07:00+00:00: scheduled__2020-07-21T00:07:00+00:00, externally triggered: False>
[2020-07-23 14:44:49,704] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:08:00+00:00: scheduled__2020-07-21T00:08:00+00:00, externally triggered: False>
[2020-07-23 14:44:50,092] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:44:50,106] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:08:00+00:00 [scheduled]> in ORM
[2020-07-23 14:44:51,029] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.667 seconds
[2020-07-23 14:48:55,276] {scheduler_job.py:153} INFO - Started process (PID=218041) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:48:55,304] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:48:55,304] {logging_mixin.py:112} INFO - [2020-07-23 14:48:55,304] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:48:55,319] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:48:55,529] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:48:56,653] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:09:00+00:00: scheduled__2020-07-21T00:09:00+00:00, externally triggered: False>
[2020-07-23 14:48:56,658] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:05:00+00:00: scheduled__2020-07-21T00:05:00+00:00, externally triggered: False>
[2020-07-23 14:48:56,668] {logging_mixin.py:112} INFO - [2020-07-23 14:48:56,667] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:05:00+00:00: scheduled__2020-07-21T00:05:00+00:00, externally triggered: False> successful
[2020-07-23 14:48:56,924] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:06:00+00:00: scheduled__2020-07-21T00:06:00+00:00, externally triggered: False>
[2020-07-23 14:48:56,943] {logging_mixin.py:112} INFO - [2020-07-23 14:48:56,942] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:06:00+00:00: scheduled__2020-07-21T00:06:00+00:00, externally triggered: False> successful
[2020-07-23 14:48:57,117] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:07:00+00:00: scheduled__2020-07-21T00:07:00+00:00, externally triggered: False>
[2020-07-23 14:48:57,132] {logging_mixin.py:112} INFO - [2020-07-23 14:48:57,132] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:07:00+00:00: scheduled__2020-07-21T00:07:00+00:00, externally triggered: False> successful
[2020-07-23 14:48:57,368] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:08:00+00:00: scheduled__2020-07-21T00:08:00+00:00, externally triggered: False>
[2020-07-23 14:48:57,385] {logging_mixin.py:112} INFO - [2020-07-23 14:48:57,385] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:08:00+00:00: scheduled__2020-07-21T00:08:00+00:00, externally triggered: False> successful
[2020-07-23 14:48:57,657] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:09:00+00:00: scheduled__2020-07-21T00:09:00+00:00, externally triggered: False>
[2020-07-23 14:48:57,678] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:48:57,682] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:09:00+00:00 [scheduled]> in ORM
[2020-07-23 14:48:57,884] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.608 seconds
[2020-07-23 14:50:15,145] {scheduler_job.py:153} INFO - Started process (PID=219602) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:50:15,287] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:50:15,288] {logging_mixin.py:112} INFO - [2020-07-23 14:50:15,288] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:50:15,308] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:50:15,939] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:50:16,996] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:10:00+00:00: scheduled__2020-07-21T00:10:00+00:00, externally triggered: False>
[2020-07-23 14:50:17,000] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:09:00+00:00: scheduled__2020-07-21T00:09:00+00:00, externally triggered: False>
[2020-07-23 14:50:17,010] {logging_mixin.py:112} INFO - [2020-07-23 14:50:17,010] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:09:00+00:00: scheduled__2020-07-21T00:09:00+00:00, externally triggered: False> successful
[2020-07-23 14:50:17,283] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:10:00+00:00: scheduled__2020-07-21T00:10:00+00:00, externally triggered: False>
[2020-07-23 14:50:17,309] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:50:17,314] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:10:00+00:00 [scheduled]> in ORM
[2020-07-23 14:50:17,675] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.530 seconds
[2020-07-23 14:51:37,461] {scheduler_job.py:153} INFO - Started process (PID=221180) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:51:37,484] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:51:37,485] {logging_mixin.py:112} INFO - [2020-07-23 14:51:37,485] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:51:37,501] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:51:37,657] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:51:38,197] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:11:00+00:00: scheduled__2020-07-21T00:11:00+00:00, externally triggered: False>
[2020-07-23 14:51:38,204] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:10:00+00:00: scheduled__2020-07-21T00:10:00+00:00, externally triggered: False>
[2020-07-23 14:51:38,220] {logging_mixin.py:112} INFO - [2020-07-23 14:51:38,220] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:10:00+00:00: scheduled__2020-07-21T00:10:00+00:00, externally triggered: False> successful
[2020-07-23 14:51:38,380] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:11:00+00:00: scheduled__2020-07-21T00:11:00+00:00, externally triggered: False>
[2020-07-23 14:51:38,417] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:51:38,426] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:11:00+00:00 [scheduled]> in ORM
[2020-07-23 14:51:38,573] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.112 seconds
[2020-07-23 14:51:53,028] {scheduler_job.py:153} INFO - Started process (PID=221600) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:51:53,034] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:51:53,035] {logging_mixin.py:112} INFO - [2020-07-23 14:51:53,035] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:51:53,068] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:51:53,275] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:51:53,753] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:12:00+00:00: scheduled__2020-07-21T00:12:00+00:00, externally triggered: False>
[2020-07-23 14:51:53,758] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:11:00+00:00: scheduled__2020-07-21T00:11:00+00:00, externally triggered: False>
[2020-07-23 14:51:53,773] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:12:00+00:00: scheduled__2020-07-21T00:12:00+00:00, externally triggered: False>
[2020-07-23 14:51:53,804] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:51:53,809] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:12:00+00:00 [scheduled]> in ORM
[2020-07-23 14:51:53,956] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.927 seconds
[2020-07-23 14:53:13,283] {scheduler_job.py:153} INFO - Started process (PID=223175) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:53:13,287] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:53:13,288] {logging_mixin.py:112} INFO - [2020-07-23 14:53:13,288] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:53:13,346] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:53:13,522] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:53:13,971] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:13:00+00:00: scheduled__2020-07-21T00:13:00+00:00, externally triggered: False>
[2020-07-23 14:53:13,984] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:11:00+00:00: scheduled__2020-07-21T00:11:00+00:00, externally triggered: False>
[2020-07-23 14:53:14,027] {logging_mixin.py:112} INFO - [2020-07-23 14:53:14,027] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:11:00+00:00: scheduled__2020-07-21T00:11:00+00:00, externally triggered: False> successful
[2020-07-23 14:53:14,192] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:12:00+00:00: scheduled__2020-07-21T00:12:00+00:00, externally triggered: False>
[2020-07-23 14:53:14,203] {logging_mixin.py:112} INFO - [2020-07-23 14:53:14,203] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:12:00+00:00: scheduled__2020-07-21T00:12:00+00:00, externally triggered: False> successful
[2020-07-23 14:53:14,369] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:13:00+00:00: scheduled__2020-07-21T00:13:00+00:00, externally triggered: False>
[2020-07-23 14:53:14,388] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:53:14,396] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:13:00+00:00 [scheduled]> in ORM
[2020-07-23 14:53:14,550] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.267 seconds
[2020-07-23 14:53:28,200] {scheduler_job.py:153} INFO - Started process (PID=223610) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:53:28,204] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:53:28,205] {logging_mixin.py:112} INFO - [2020-07-23 14:53:28,204] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:53:28,244] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:53:28,492] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:53:28,960] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:14:00+00:00: scheduled__2020-07-21T00:14:00+00:00, externally triggered: False>
[2020-07-23 14:53:28,966] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:13:00+00:00: scheduled__2020-07-21T00:13:00+00:00, externally triggered: False>
[2020-07-23 14:53:28,983] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:14:00+00:00: scheduled__2020-07-21T00:14:00+00:00, externally triggered: False>
[2020-07-23 14:53:29,017] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:53:29,027] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:14:00+00:00 [scheduled]> in ORM
[2020-07-23 14:53:29,243] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.044 seconds
[2020-07-23 14:54:43,195] {scheduler_job.py:153} INFO - Started process (PID=225107) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:54:43,228] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:54:43,231] {logging_mixin.py:112} INFO - [2020-07-23 14:54:43,231] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:54:43,293] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:54:43,559] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:54:44,164] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:15:00+00:00: scheduled__2020-07-21T00:15:00+00:00, externally triggered: False>
[2020-07-23 14:54:44,181] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:13:00+00:00: scheduled__2020-07-21T00:13:00+00:00, externally triggered: False>
[2020-07-23 14:54:44,213] {logging_mixin.py:112} INFO - [2020-07-23 14:54:44,212] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:13:00+00:00: scheduled__2020-07-21T00:13:00+00:00, externally triggered: False> successful
[2020-07-23 14:54:44,351] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:14:00+00:00: scheduled__2020-07-21T00:14:00+00:00, externally triggered: False>
[2020-07-23 14:54:44,429] {logging_mixin.py:112} INFO - [2020-07-23 14:54:44,429] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:14:00+00:00: scheduled__2020-07-21T00:14:00+00:00, externally triggered: False> successful
[2020-07-23 14:54:44,540] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:15:00+00:00: scheduled__2020-07-21T00:15:00+00:00, externally triggered: False>
[2020-07-23 14:54:44,604] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:54:44,613] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:15:00+00:00 [scheduled]> in ORM
[2020-07-23 14:54:44,778] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.583 seconds
[2020-07-23 14:54:59,997] {scheduler_job.py:153} INFO - Started process (PID=225523) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:55:00,002] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:55:00,004] {logging_mixin.py:112} INFO - [2020-07-23 14:55:00,002] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:55:00,024] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:55:00,228] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:55:00,689] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:16:00+00:00: scheduled__2020-07-21T00:16:00+00:00, externally triggered: False>
[2020-07-23 14:55:00,694] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:15:00+00:00: scheduled__2020-07-21T00:15:00+00:00, externally triggered: False>
[2020-07-23 14:55:00,706] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:16:00+00:00: scheduled__2020-07-21T00:16:00+00:00, externally triggered: False>
[2020-07-23 14:55:00,874] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:55:00,883] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:16:00+00:00 [scheduled]> in ORM
[2020-07-23 14:55:01,101] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.105 seconds
[2020-07-23 14:56:19,673] {scheduler_job.py:153} INFO - Started process (PID=227151) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:56:19,696] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:56:19,698] {logging_mixin.py:112} INFO - [2020-07-23 14:56:19,697] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:56:19,739] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:56:19,934] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:56:20,402] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:17:00+00:00: scheduled__2020-07-21T00:17:00+00:00, externally triggered: False>
[2020-07-23 14:56:20,405] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:15:00+00:00: scheduled__2020-07-21T00:15:00+00:00, externally triggered: False>
[2020-07-23 14:56:20,417] {logging_mixin.py:112} INFO - [2020-07-23 14:56:20,417] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:15:00+00:00: scheduled__2020-07-21T00:15:00+00:00, externally triggered: False> successful
[2020-07-23 14:56:20,522] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:16:00+00:00: scheduled__2020-07-21T00:16:00+00:00, externally triggered: False>
[2020-07-23 14:56:20,538] {logging_mixin.py:112} INFO - [2020-07-23 14:56:20,538] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:16:00+00:00: scheduled__2020-07-21T00:16:00+00:00, externally triggered: False> successful
[2020-07-23 14:56:20,700] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:17:00+00:00: scheduled__2020-07-21T00:17:00+00:00, externally triggered: False>
[2020-07-23 14:56:20,740] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:56:20,751] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:17:00+00:00 [scheduled]> in ORM
[2020-07-23 14:56:20,897] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.224 seconds
[2020-07-23 14:56:35,965] {scheduler_job.py:153} INFO - Started process (PID=227538) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:56:35,970] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:56:35,973] {logging_mixin.py:112} INFO - [2020-07-23 14:56:35,970] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:56:36,015] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:56:36,253] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:56:36,956] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:18:00+00:00: scheduled__2020-07-21T00:18:00+00:00, externally triggered: False>
[2020-07-23 14:56:36,963] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:17:00+00:00: scheduled__2020-07-21T00:17:00+00:00, externally triggered: False>
[2020-07-23 14:56:36,980] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:18:00+00:00: scheduled__2020-07-21T00:18:00+00:00, externally triggered: False>
[2020-07-23 14:56:37,006] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:56:37,015] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:18:00+00:00 [scheduled]> in ORM
[2020-07-23 14:56:37,197] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.231 seconds
[2020-07-23 14:57:51,274] {scheduler_job.py:153} INFO - Started process (PID=229074) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:57:51,281] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:57:51,282] {logging_mixin.py:112} INFO - [2020-07-23 14:57:51,282] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:57:51,299] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:57:51,511] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:57:52,095] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:19:00+00:00: scheduled__2020-07-21T00:19:00+00:00, externally triggered: False>
[2020-07-23 14:57:52,101] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:17:00+00:00: scheduled__2020-07-21T00:17:00+00:00, externally triggered: False>
[2020-07-23 14:57:52,121] {logging_mixin.py:112} INFO - [2020-07-23 14:57:52,121] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:17:00+00:00: scheduled__2020-07-21T00:17:00+00:00, externally triggered: False> successful
[2020-07-23 14:57:52,249] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:18:00+00:00: scheduled__2020-07-21T00:18:00+00:00, externally triggered: False>
[2020-07-23 14:57:52,282] {logging_mixin.py:112} INFO - [2020-07-23 14:57:52,282] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:18:00+00:00: scheduled__2020-07-21T00:18:00+00:00, externally triggered: False> successful
[2020-07-23 14:57:52,404] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:19:00+00:00: scheduled__2020-07-21T00:19:00+00:00, externally triggered: False>
[2020-07-23 14:57:52,429] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:57:52,436] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:19:00+00:00 [scheduled]> in ORM
[2020-07-23 14:57:52,711] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.437 seconds
[2020-07-23 14:58:06,258] {scheduler_job.py:153} INFO - Started process (PID=229473) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:58:06,274] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:58:06,286] {logging_mixin.py:112} INFO - [2020-07-23 14:58:06,275] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:58:06,324] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:58:06,633] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:58:07,329] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:20:00+00:00: scheduled__2020-07-21T00:20:00+00:00, externally triggered: False>
[2020-07-23 14:58:07,337] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:19:00+00:00: scheduled__2020-07-21T00:19:00+00:00, externally triggered: False>
[2020-07-23 14:58:07,356] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:20:00+00:00: scheduled__2020-07-21T00:20:00+00:00, externally triggered: False>
[2020-07-23 14:58:07,390] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:58:07,397] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:20:00+00:00 [scheduled]> in ORM
[2020-07-23 14:58:07,566] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.308 seconds
[2020-07-23 14:59:22,251] {scheduler_job.py:153} INFO - Started process (PID=231015) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:59:22,257] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:59:22,258] {logging_mixin.py:112} INFO - [2020-07-23 14:59:22,257] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:59:22,281] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:59:22,533] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:59:23,010] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:21:00+00:00: scheduled__2020-07-21T00:21:00+00:00, externally triggered: False>
[2020-07-23 14:59:23,019] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:19:00+00:00: scheduled__2020-07-21T00:19:00+00:00, externally triggered: False>
[2020-07-23 14:59:23,077] {logging_mixin.py:112} INFO - [2020-07-23 14:59:23,077] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:19:00+00:00: scheduled__2020-07-21T00:19:00+00:00, externally triggered: False> successful
[2020-07-23 14:59:23,197] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:20:00+00:00: scheduled__2020-07-21T00:20:00+00:00, externally triggered: False>
[2020-07-23 14:59:23,216] {logging_mixin.py:112} INFO - [2020-07-23 14:59:23,216] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:20:00+00:00: scheduled__2020-07-21T00:20:00+00:00, externally triggered: False> successful
[2020-07-23 14:59:23,353] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:21:00+00:00: scheduled__2020-07-21T00:21:00+00:00, externally triggered: False>
[2020-07-23 14:59:23,411] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:59:23,419] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:21:00+00:00 [scheduled]> in ORM
[2020-07-23 14:59:23,691] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.441 seconds
[2020-07-23 14:59:37,710] {scheduler_job.py:153} INFO - Started process (PID=231420) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:59:37,715] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 14:59:37,716] {logging_mixin.py:112} INFO - [2020-07-23 14:59:37,716] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:59:37,737] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 14:59:37,934] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 14:59:38,272] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:22:00+00:00: scheduled__2020-07-21T00:22:00+00:00, externally triggered: False>
[2020-07-23 14:59:38,280] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:21:00+00:00: scheduled__2020-07-21T00:21:00+00:00, externally triggered: False>
[2020-07-23 14:59:38,297] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:22:00+00:00: scheduled__2020-07-21T00:22:00+00:00, externally triggered: False>
[2020-07-23 14:59:38,323] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 14:59:38,331] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:22:00+00:00 [scheduled]> in ORM
[2020-07-23 14:59:38,485] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.776 seconds
[2020-07-23 15:00:56,908] {scheduler_job.py:153} INFO - Started process (PID=232984) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:00:56,930] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:00:56,931] {logging_mixin.py:112} INFO - [2020-07-23 15:00:56,930] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:00:56,950] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:00:57,169] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:00:57,651] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:23:00+00:00: scheduled__2020-07-21T00:23:00+00:00, externally triggered: False>
[2020-07-23 15:00:57,658] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:21:00+00:00: scheduled__2020-07-21T00:21:00+00:00, externally triggered: False>
[2020-07-23 15:00:57,680] {logging_mixin.py:112} INFO - [2020-07-23 15:00:57,680] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:21:00+00:00: scheduled__2020-07-21T00:21:00+00:00, externally triggered: False> successful
[2020-07-23 15:00:57,835] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:22:00+00:00: scheduled__2020-07-21T00:22:00+00:00, externally triggered: False>
[2020-07-23 15:00:57,856] {logging_mixin.py:112} INFO - [2020-07-23 15:00:57,855] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:22:00+00:00: scheduled__2020-07-21T00:22:00+00:00, externally triggered: False> successful
[2020-07-23 15:00:57,969] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:23:00+00:00: scheduled__2020-07-21T00:23:00+00:00, externally triggered: False>
[2020-07-23 15:00:58,046] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:00:58,061] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:23:00+00:00 [scheduled]> in ORM
[2020-07-23 15:00:58,308] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.400 seconds
[2020-07-23 15:01:13,096] {scheduler_job.py:153} INFO - Started process (PID=233399) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:01:13,100] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:01:13,113] {logging_mixin.py:112} INFO - [2020-07-23 15:01:13,102] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:01:13,130] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:01:13,452] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:01:13,871] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:24:00+00:00: scheduled__2020-07-21T00:24:00+00:00, externally triggered: False>
[2020-07-23 15:01:13,876] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:23:00+00:00: scheduled__2020-07-21T00:23:00+00:00, externally triggered: False>
[2020-07-23 15:01:13,886] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:24:00+00:00: scheduled__2020-07-21T00:24:00+00:00, externally triggered: False>
[2020-07-23 15:01:13,911] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:01:13,917] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:24:00+00:00 [scheduled]> in ORM
[2020-07-23 15:01:14,096] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.001 seconds
[2020-07-23 15:02:28,401] {scheduler_job.py:153} INFO - Started process (PID=234874) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:02:28,406] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:02:28,407] {logging_mixin.py:112} INFO - [2020-07-23 15:02:28,407] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:02:28,444] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:02:28,710] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:02:29,237] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:25:00+00:00: scheduled__2020-07-21T00:25:00+00:00, externally triggered: False>
[2020-07-23 15:02:29,244] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:23:00+00:00: scheduled__2020-07-21T00:23:00+00:00, externally triggered: False>
[2020-07-23 15:02:29,264] {logging_mixin.py:112} INFO - [2020-07-23 15:02:29,264] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:23:00+00:00: scheduled__2020-07-21T00:23:00+00:00, externally triggered: False> successful
[2020-07-23 15:02:29,354] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:24:00+00:00: scheduled__2020-07-21T00:24:00+00:00, externally triggered: False>
[2020-07-23 15:02:29,377] {logging_mixin.py:112} INFO - [2020-07-23 15:02:29,377] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:24:00+00:00: scheduled__2020-07-21T00:24:00+00:00, externally triggered: False> successful
[2020-07-23 15:02:29,487] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:25:00+00:00: scheduled__2020-07-21T00:25:00+00:00, externally triggered: False>
[2020-07-23 15:02:29,536] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:02:29,547] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:25:00+00:00 [scheduled]> in ORM
[2020-07-23 15:02:29,727] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.327 seconds
[2020-07-23 15:02:45,742] {scheduler_job.py:153} INFO - Started process (PID=235322) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:02:45,755] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:02:45,757] {logging_mixin.py:112} INFO - [2020-07-23 15:02:45,757] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:02:45,776] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:02:45,994] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:02:46,988] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:26:00+00:00: scheduled__2020-07-21T00:26:00+00:00, externally triggered: False>
[2020-07-23 15:02:47,003] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:25:00+00:00: scheduled__2020-07-21T00:25:00+00:00, externally triggered: False>
[2020-07-23 15:02:47,020] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:26:00+00:00: scheduled__2020-07-21T00:26:00+00:00, externally triggered: False>
[2020-07-23 15:02:47,048] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:02:47,057] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:26:00+00:00 [scheduled]> in ORM
[2020-07-23 15:02:47,241] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.502 seconds
[2020-07-23 15:04:03,707] {scheduler_job.py:153} INFO - Started process (PID=236869) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:04:03,734] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:04:03,735] {logging_mixin.py:112} INFO - [2020-07-23 15:04:03,735] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:04:03,801] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:04:04,102] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:04:04,649] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:27:00+00:00: scheduled__2020-07-21T00:27:00+00:00, externally triggered: False>
[2020-07-23 15:04:04,662] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:25:00+00:00: scheduled__2020-07-21T00:25:00+00:00, externally triggered: False>
[2020-07-23 15:04:04,679] {logging_mixin.py:112} INFO - [2020-07-23 15:04:04,679] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:25:00+00:00: scheduled__2020-07-21T00:25:00+00:00, externally triggered: False> successful
[2020-07-23 15:04:04,786] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:26:00+00:00: scheduled__2020-07-21T00:26:00+00:00, externally triggered: False>
[2020-07-23 15:04:04,801] {logging_mixin.py:112} INFO - [2020-07-23 15:04:04,800] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:26:00+00:00: scheduled__2020-07-21T00:26:00+00:00, externally triggered: False> successful
[2020-07-23 15:04:04,977] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:27:00+00:00: scheduled__2020-07-21T00:27:00+00:00, externally triggered: False>
[2020-07-23 15:04:05,000] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:04:05,007] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:27:00+00:00 [scheduled]> in ORM
[2020-07-23 15:04:05,173] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.465 seconds
[2020-07-23 15:04:16,778] {scheduler_job.py:153} INFO - Started process (PID=237240) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:04:16,783] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:04:16,784] {logging_mixin.py:112} INFO - [2020-07-23 15:04:16,784] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:04:16,798] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:04:16,916] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:04:17,251] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:28:00+00:00: scheduled__2020-07-21T00:28:00+00:00, externally triggered: False>
[2020-07-23 15:04:17,255] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:27:00+00:00: scheduled__2020-07-21T00:27:00+00:00, externally triggered: False>
[2020-07-23 15:04:17,265] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:28:00+00:00: scheduled__2020-07-21T00:28:00+00:00, externally triggered: False>
[2020-07-23 15:04:17,284] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:04:17,290] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:28:00+00:00 [scheduled]> in ORM
[2020-07-23 15:04:17,438] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.660 seconds
[2020-07-23 15:05:18,645] {scheduler_job.py:153} INFO - Started process (PID=238517) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:05:18,653] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:05:18,655] {logging_mixin.py:112} INFO - [2020-07-23 15:05:18,653] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:05:18,685] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:05:18,904] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:05:19,226] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:29:00+00:00: scheduled__2020-07-21T00:29:00+00:00, externally triggered: False>
[2020-07-23 15:05:19,232] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:27:00+00:00: scheduled__2020-07-21T00:27:00+00:00, externally triggered: False>
[2020-07-23 15:05:19,243] {logging_mixin.py:112} INFO - [2020-07-23 15:05:19,243] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:27:00+00:00: scheduled__2020-07-21T00:27:00+00:00, externally triggered: False> successful
[2020-07-23 15:05:19,379] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:28:00+00:00: scheduled__2020-07-21T00:28:00+00:00, externally triggered: False>
[2020-07-23 15:05:19,394] {logging_mixin.py:112} INFO - [2020-07-23 15:05:19,393] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:28:00+00:00: scheduled__2020-07-21T00:28:00+00:00, externally triggered: False> successful
[2020-07-23 15:05:19,502] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:29:00+00:00: scheduled__2020-07-21T00:29:00+00:00, externally triggered: False>
[2020-07-23 15:05:19,525] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:05:19,530] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:29:00+00:00 [scheduled]> in ORM
[2020-07-23 15:05:19,706] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.061 seconds
[2020-07-23 15:06:07,398] {scheduler_job.py:153} INFO - Started process (PID=239532) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:06:07,404] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:06:07,404] {logging_mixin.py:112} INFO - [2020-07-23 15:06:07,404] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:06:07,418] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:06:07,585] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:06:08,019] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:30:00+00:00: scheduled__2020-07-21T00:30:00+00:00, externally triggered: False>
[2020-07-23 15:06:08,026] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:29:00+00:00: scheduled__2020-07-21T00:29:00+00:00, externally triggered: False>
[2020-07-23 15:06:08,041] {logging_mixin.py:112} INFO - [2020-07-23 15:06:08,041] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:29:00+00:00: scheduled__2020-07-21T00:29:00+00:00, externally triggered: False> successful
[2020-07-23 15:06:08,233] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:30:00+00:00: scheduled__2020-07-21T00:30:00+00:00, externally triggered: False>
[2020-07-23 15:06:08,256] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:06:08,263] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:30:00+00:00 [scheduled]> in ORM
[2020-07-23 15:06:08,403] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.005 seconds
[2020-07-23 15:06:57,079] {scheduler_job.py:153} INFO - Started process (PID=240541) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:06:57,083] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:06:57,084] {logging_mixin.py:112} INFO - [2020-07-23 15:06:57,084] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:06:57,133] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:06:57,741] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:06:58,265] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:31:00+00:00: scheduled__2020-07-21T00:31:00+00:00, externally triggered: False>
[2020-07-23 15:06:58,271] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:30:00+00:00: scheduled__2020-07-21T00:30:00+00:00, externally triggered: False>
[2020-07-23 15:06:58,282] {logging_mixin.py:112} INFO - [2020-07-23 15:06:58,281] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:30:00+00:00: scheduled__2020-07-21T00:30:00+00:00, externally triggered: False> successful
[2020-07-23 15:06:58,420] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:31:00+00:00: scheduled__2020-07-21T00:31:00+00:00, externally triggered: False>
[2020-07-23 15:06:58,479] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:06:58,494] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:31:00+00:00 [scheduled]> in ORM
[2020-07-23 15:06:58,714] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.635 seconds
[2020-07-23 15:07:58,901] {scheduler_job.py:153} INFO - Started process (PID=241756) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:07:58,918] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:07:58,919] {logging_mixin.py:112} INFO - [2020-07-23 15:07:58,919] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:07:58,943] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:07:59,118] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:07:59,584] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:32:00+00:00: scheduled__2020-07-21T00:32:00+00:00, externally triggered: False>
[2020-07-23 15:07:59,593] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:31:00+00:00: scheduled__2020-07-21T00:31:00+00:00, externally triggered: False>
[2020-07-23 15:07:59,614] {logging_mixin.py:112} INFO - [2020-07-23 15:07:59,614] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:31:00+00:00: scheduled__2020-07-21T00:31:00+00:00, externally triggered: False> successful
[2020-07-23 15:07:59,897] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:32:00+00:00: scheduled__2020-07-21T00:32:00+00:00, externally triggered: False>
[2020-07-23 15:07:59,920] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:07:59,927] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:32:00+00:00 [scheduled]> in ORM
[2020-07-23 15:08:00,390] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.490 seconds
[2020-07-23 15:08:14,273] {scheduler_job.py:153} INFO - Started process (PID=242162) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:08:14,279] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:08:14,280] {logging_mixin.py:112} INFO - [2020-07-23 15:08:14,280] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:08:14,304] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:08:14,503] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:08:15,043] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:33:00+00:00: scheduled__2020-07-21T00:33:00+00:00, externally triggered: False>
[2020-07-23 15:08:15,049] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:32:00+00:00: scheduled__2020-07-21T00:32:00+00:00, externally triggered: False>
[2020-07-23 15:08:15,067] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:33:00+00:00: scheduled__2020-07-21T00:33:00+00:00, externally triggered: False>
[2020-07-23 15:08:15,094] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:08:15,101] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:33:00+00:00 [scheduled]> in ORM
[2020-07-23 15:08:15,282] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.009 seconds
[2020-07-23 15:09:20,358] {scheduler_job.py:153} INFO - Started process (PID=243659) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:09:20,362] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:09:20,363] {logging_mixin.py:112} INFO - [2020-07-23 15:09:20,363] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:09:20,392] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:09:20,557] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:09:21,043] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:34:00+00:00: scheduled__2020-07-21T00:34:00+00:00, externally triggered: False>
[2020-07-23 15:09:21,082] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:32:00+00:00: scheduled__2020-07-21T00:32:00+00:00, externally triggered: False>
[2020-07-23 15:09:21,134] {logging_mixin.py:112} INFO - [2020-07-23 15:09:21,134] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:32:00+00:00: scheduled__2020-07-21T00:32:00+00:00, externally triggered: False> successful
[2020-07-23 15:09:21,233] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:33:00+00:00: scheduled__2020-07-21T00:33:00+00:00, externally triggered: False>
[2020-07-23 15:09:21,258] {logging_mixin.py:112} INFO - [2020-07-23 15:09:21,258] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:33:00+00:00: scheduled__2020-07-21T00:33:00+00:00, externally triggered: False> successful
[2020-07-23 15:09:21,376] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:34:00+00:00: scheduled__2020-07-21T00:34:00+00:00, externally triggered: False>
[2020-07-23 15:09:21,415] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:09:21,430] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:34:00+00:00 [scheduled]> in ORM
[2020-07-23 15:09:21,650] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.292 seconds
[2020-07-23 15:10:20,987] {scheduler_job.py:153} INFO - Started process (PID=244944) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:10:20,990] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:10:20,990] {logging_mixin.py:112} INFO - [2020-07-23 15:10:20,990] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:10:21,000] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:10:21,170] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:10:21,627] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:35:00+00:00: scheduled__2020-07-21T00:35:00+00:00, externally triggered: False>
[2020-07-23 15:10:21,633] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:34:00+00:00: scheduled__2020-07-21T00:34:00+00:00, externally triggered: False>
[2020-07-23 15:10:21,644] {logging_mixin.py:112} INFO - [2020-07-23 15:10:21,644] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:34:00+00:00: scheduled__2020-07-21T00:34:00+00:00, externally triggered: False> successful
[2020-07-23 15:10:21,774] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:35:00+00:00: scheduled__2020-07-21T00:35:00+00:00, externally triggered: False>
[2020-07-23 15:10:21,794] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:10:21,801] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:35:00+00:00 [scheduled]> in ORM
[2020-07-23 15:10:21,994] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.007 seconds
[2020-07-23 15:11:03,786] {scheduler_job.py:153} INFO - Started process (PID=245866) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:11:03,790] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:11:03,790] {logging_mixin.py:112} INFO - [2020-07-23 15:11:03,790] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:11:03,820] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:11:04,338] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:11:04,776] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:36:00+00:00: scheduled__2020-07-21T00:36:00+00:00, externally triggered: False>
[2020-07-23 15:11:04,779] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:35:00+00:00: scheduled__2020-07-21T00:35:00+00:00, externally triggered: False>
[2020-07-23 15:11:04,787] {logging_mixin.py:112} INFO - [2020-07-23 15:11:04,787] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:35:00+00:00: scheduled__2020-07-21T00:35:00+00:00, externally triggered: False> successful
[2020-07-23 15:11:04,980] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:36:00+00:00: scheduled__2020-07-21T00:36:00+00:00, externally triggered: False>
[2020-07-23 15:11:05,003] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:11:05,013] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:36:00+00:00 [scheduled]> in ORM
[2020-07-23 15:11:05,274] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.489 seconds
[2020-07-23 15:11:38,500] {scheduler_job.py:153} INFO - Started process (PID=246733) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:11:38,506] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:11:38,507] {logging_mixin.py:112} INFO - [2020-07-23 15:11:38,506] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:11:38,523] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:11:39,005] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:11:39,923] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:37:00+00:00: scheduled__2020-07-21T00:37:00+00:00, externally triggered: False>
[2020-07-23 15:11:39,929] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:36:00+00:00: scheduled__2020-07-21T00:36:00+00:00, externally triggered: False>
[2020-07-23 15:11:39,961] {logging_mixin.py:112} INFO - [2020-07-23 15:11:39,961] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:36:00+00:00: scheduled__2020-07-21T00:36:00+00:00, externally triggered: False> successful
[2020-07-23 15:11:40,329] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:37:00+00:00: scheduled__2020-07-21T00:37:00+00:00, externally triggered: False>
[2020-07-23 15:11:40,366] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:11:40,373] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:37:00+00:00 [scheduled]> in ORM
[2020-07-23 15:11:40,855] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.355 seconds
[2020-07-23 15:12:22,709] {scheduler_job.py:153} INFO - Started process (PID=247649) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:12:22,715] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:12:22,716] {logging_mixin.py:112} INFO - [2020-07-23 15:12:22,715] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:12:22,732] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:12:23,314] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:12:24,595] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:38:00+00:00: scheduled__2020-07-21T00:38:00+00:00, externally triggered: False>
[2020-07-23 15:12:24,599] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:37:00+00:00: scheduled__2020-07-21T00:37:00+00:00, externally triggered: False>
[2020-07-23 15:12:24,615] {logging_mixin.py:112} INFO - [2020-07-23 15:12:24,615] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:37:00+00:00: scheduled__2020-07-21T00:37:00+00:00, externally triggered: False> successful
[2020-07-23 15:12:24,958] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:38:00+00:00: scheduled__2020-07-21T00:38:00+00:00, externally triggered: False>
[2020-07-23 15:12:24,981] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:12:24,988] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:38:00+00:00 [scheduled]> in ORM
[2020-07-23 15:12:25,731] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 3.022 seconds
[2020-07-23 15:12:57,613] {scheduler_job.py:153} INFO - Started process (PID=248455) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:12:57,618] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:12:57,623] {logging_mixin.py:112} INFO - [2020-07-23 15:12:57,619] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:12:57,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:12:58,146] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:12:59,253] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:39:00+00:00: scheduled__2020-07-21T00:39:00+00:00, externally triggered: False>
[2020-07-23 15:12:59,257] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:38:00+00:00: scheduled__2020-07-21T00:38:00+00:00, externally triggered: False>
[2020-07-23 15:12:59,265] {logging_mixin.py:112} INFO - [2020-07-23 15:12:59,265] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:38:00+00:00: scheduled__2020-07-21T00:38:00+00:00, externally triggered: False> successful
[2020-07-23 15:12:59,595] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:39:00+00:00: scheduled__2020-07-21T00:39:00+00:00, externally triggered: False>
[2020-07-23 15:12:59,614] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:12:59,618] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:39:00+00:00 [scheduled]> in ORM
[2020-07-23 15:12:59,867] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.254 seconds
[2020-07-23 15:13:41,306] {scheduler_job.py:153} INFO - Started process (PID=249389) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:13:41,310] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:13:41,311] {logging_mixin.py:112} INFO - [2020-07-23 15:13:41,311] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:13:41,325] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:13:42,006] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:13:43,968] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:40:00+00:00: scheduled__2020-07-21T00:40:00+00:00, externally triggered: False>
[2020-07-23 15:13:43,974] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:39:00+00:00: scheduled__2020-07-21T00:39:00+00:00, externally triggered: False>
[2020-07-23 15:13:43,990] {logging_mixin.py:112} INFO - [2020-07-23 15:13:43,990] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:39:00+00:00: scheduled__2020-07-21T00:39:00+00:00, externally triggered: False> successful
[2020-07-23 15:13:44,790] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:40:00+00:00: scheduled__2020-07-21T00:40:00+00:00, externally triggered: False>
[2020-07-23 15:13:44,818] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:13:44,826] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:40:00+00:00 [scheduled]> in ORM
[2020-07-23 15:13:45,474] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 4.168 seconds
[2020-07-23 15:14:36,996] {scheduler_job.py:153} INFO - Started process (PID=250530) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:14:37,045] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:14:37,046] {logging_mixin.py:112} INFO - [2020-07-23 15:14:37,046] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:14:37,110] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:14:37,735] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:14:39,257] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:41:00+00:00: scheduled__2020-07-21T00:41:00+00:00, externally triggered: False>
[2020-07-23 15:14:39,264] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:40:00+00:00: scheduled__2020-07-21T00:40:00+00:00, externally triggered: False>
[2020-07-23 15:14:39,275] {logging_mixin.py:112} INFO - [2020-07-23 15:14:39,275] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:40:00+00:00: scheduled__2020-07-21T00:40:00+00:00, externally triggered: False> successful
[2020-07-23 15:14:41,075] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:41:00+00:00: scheduled__2020-07-21T00:41:00+00:00, externally triggered: False>
[2020-07-23 15:14:41,105] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:14:41,121] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:41:00+00:00 [scheduled]> in ORM
[2020-07-23 15:14:42,220] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 5.224 seconds
[2020-07-23 15:14:55,631] {scheduler_job.py:153} INFO - Started process (PID=250969) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:14:55,635] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:14:55,635] {logging_mixin.py:112} INFO - [2020-07-23 15:14:55,635] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:14:55,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:14:56,168] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:14:58,154] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:42:00+00:00: scheduled__2020-07-21T00:42:00+00:00, externally triggered: False>
[2020-07-23 15:14:58,173] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:41:00+00:00: scheduled__2020-07-21T00:41:00+00:00, externally triggered: False>
[2020-07-23 15:14:59,254] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:42:00+00:00: scheduled__2020-07-21T00:42:00+00:00, externally triggered: False>
[2020-07-23 15:14:59,281] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:14:59,287] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:42:00+00:00 [scheduled]> in ORM
[2020-07-23 15:14:59,751] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 4.120 seconds
[2020-07-23 15:15:50,944] {scheduler_job.py:153} INFO - Started process (PID=252200) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:15:50,973] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:15:50,974] {logging_mixin.py:112} INFO - [2020-07-23 15:15:50,974] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:15:51,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:15:51,410] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:15:52,459] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:43:00+00:00: scheduled__2020-07-21T00:43:00+00:00, externally triggered: False>
[2020-07-23 15:15:52,464] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:41:00+00:00: scheduled__2020-07-21T00:41:00+00:00, externally triggered: False>
[2020-07-23 15:15:52,475] {logging_mixin.py:112} INFO - [2020-07-23 15:15:52,475] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:41:00+00:00: scheduled__2020-07-21T00:41:00+00:00, externally triggered: False> successful
[2020-07-23 15:15:53,104] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:42:00+00:00: scheduled__2020-07-21T00:42:00+00:00, externally triggered: False>
[2020-07-23 15:15:53,119] {logging_mixin.py:112} INFO - [2020-07-23 15:15:53,119] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:42:00+00:00: scheduled__2020-07-21T00:42:00+00:00, externally triggered: False> successful
[2020-07-23 15:15:53,515] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:43:00+00:00: scheduled__2020-07-21T00:43:00+00:00, externally triggered: False>
[2020-07-23 15:15:53,536] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:15:53,543] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:43:00+00:00 [scheduled]> in ORM
[2020-07-23 15:15:54,089] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 3.145 seconds
[2020-07-23 15:16:27,152] {scheduler_job.py:153} INFO - Started process (PID=253020) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:16:27,156] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:16:27,157] {logging_mixin.py:112} INFO - [2020-07-23 15:16:27,157] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:16:27,172] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:16:27,316] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:16:27,742] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:44:00+00:00: scheduled__2020-07-21T00:44:00+00:00, externally triggered: False>
[2020-07-23 15:16:27,746] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:43:00+00:00: scheduled__2020-07-21T00:43:00+00:00, externally triggered: False>
[2020-07-23 15:16:27,757] {logging_mixin.py:112} INFO - [2020-07-23 15:16:27,757] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:43:00+00:00: scheduled__2020-07-21T00:43:00+00:00, externally triggered: False> successful
[2020-07-23 15:16:27,865] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:44:00+00:00: scheduled__2020-07-21T00:44:00+00:00, externally triggered: False>
[2020-07-23 15:16:27,881] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:16:27,885] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:44:00+00:00 [scheduled]> in ORM
[2020-07-23 15:16:28,028] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.877 seconds
[2020-07-23 15:17:06,451] {scheduler_job.py:153} INFO - Started process (PID=253908) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:17:06,455] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:17:06,456] {logging_mixin.py:112} INFO - [2020-07-23 15:17:06,456] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:17:06,480] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:17:06,630] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:17:06,943] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:45:00+00:00: scheduled__2020-07-21T00:45:00+00:00, externally triggered: False>
[2020-07-23 15:17:06,947] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:44:00+00:00: scheduled__2020-07-21T00:44:00+00:00, externally triggered: False>
[2020-07-23 15:17:06,955] {logging_mixin.py:112} INFO - [2020-07-23 15:17:06,954] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:44:00+00:00: scheduled__2020-07-21T00:44:00+00:00, externally triggered: False> successful
[2020-07-23 15:17:07,091] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:45:00+00:00: scheduled__2020-07-21T00:45:00+00:00, externally triggered: False>
[2020-07-23 15:17:07,110] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:17:07,114] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:45:00+00:00 [scheduled]> in ORM
[2020-07-23 15:17:07,255] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.804 seconds
[2020-07-23 15:17:45,893] {scheduler_job.py:153} INFO - Started process (PID=254803) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:17:45,898] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:17:45,899] {logging_mixin.py:112} INFO - [2020-07-23 15:17:45,899] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:17:45,916] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:17:46,069] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:17:46,401] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:46:00+00:00: scheduled__2020-07-21T00:46:00+00:00, externally triggered: False>
[2020-07-23 15:17:46,405] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:45:00+00:00: scheduled__2020-07-21T00:45:00+00:00, externally triggered: False>
[2020-07-23 15:17:46,412] {logging_mixin.py:112} INFO - [2020-07-23 15:17:46,412] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:45:00+00:00: scheduled__2020-07-21T00:45:00+00:00, externally triggered: False> successful
[2020-07-23 15:17:46,506] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:46:00+00:00: scheduled__2020-07-21T00:46:00+00:00, externally triggered: False>
[2020-07-23 15:17:46,529] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:17:46,537] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:46:00+00:00 [scheduled]> in ORM
[2020-07-23 15:17:46,712] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.819 seconds
[2020-07-23 15:18:24,599] {scheduler_job.py:153} INFO - Started process (PID=255670) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:18:24,603] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:18:24,603] {logging_mixin.py:112} INFO - [2020-07-23 15:18:24,603] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:18:24,617] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:18:24,773] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:18:25,140] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:47:00+00:00: scheduled__2020-07-21T00:47:00+00:00, externally triggered: False>
[2020-07-23 15:18:25,145] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:46:00+00:00: scheduled__2020-07-21T00:46:00+00:00, externally triggered: False>
[2020-07-23 15:18:25,154] {logging_mixin.py:112} INFO - [2020-07-23 15:18:25,154] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:46:00+00:00: scheduled__2020-07-21T00:46:00+00:00, externally triggered: False> successful
[2020-07-23 15:18:25,299] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:47:00+00:00: scheduled__2020-07-21T00:47:00+00:00, externally triggered: False>
[2020-07-23 15:18:25,312] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:18:25,316] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:47:00+00:00 [scheduled]> in ORM
[2020-07-23 15:18:25,450] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.851 seconds
[2020-07-23 15:19:05,022] {scheduler_job.py:153} INFO - Started process (PID=256600) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:19:05,026] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:19:05,027] {logging_mixin.py:112} INFO - [2020-07-23 15:19:05,027] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:19:05,038] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:19:05,246] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:19:05,638] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:48:00+00:00: scheduled__2020-07-21T00:48:00+00:00, externally triggered: False>
[2020-07-23 15:19:05,643] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:47:00+00:00: scheduled__2020-07-21T00:47:00+00:00, externally triggered: False>
[2020-07-23 15:19:05,650] {logging_mixin.py:112} INFO - [2020-07-23 15:19:05,650] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:47:00+00:00: scheduled__2020-07-21T00:47:00+00:00, externally triggered: False> successful
[2020-07-23 15:19:05,792] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:48:00+00:00: scheduled__2020-07-21T00:48:00+00:00, externally triggered: False>
[2020-07-23 15:19:05,814] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:19:05,822] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:48:00+00:00 [scheduled]> in ORM
[2020-07-23 15:19:05,991] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.970 seconds
[2020-07-23 15:19:45,969] {scheduler_job.py:153} INFO - Started process (PID=257560) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:19:45,972] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:19:45,973] {logging_mixin.py:112} INFO - [2020-07-23 15:19:45,973] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:19:45,981] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:19:46,118] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:19:46,499] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:49:00+00:00: scheduled__2020-07-21T00:49:00+00:00, externally triggered: False>
[2020-07-23 15:19:46,507] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:48:00+00:00: scheduled__2020-07-21T00:48:00+00:00, externally triggered: False>
[2020-07-23 15:19:46,525] {logging_mixin.py:112} INFO - [2020-07-23 15:19:46,524] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:48:00+00:00: scheduled__2020-07-21T00:48:00+00:00, externally triggered: False> successful
[2020-07-23 15:19:46,641] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:49:00+00:00: scheduled__2020-07-21T00:49:00+00:00, externally triggered: False>
[2020-07-23 15:19:46,662] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:19:46,669] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:49:00+00:00 [scheduled]> in ORM
[2020-07-23 15:19:46,829] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.860 seconds
[2020-07-23 15:20:28,838] {scheduler_job.py:153} INFO - Started process (PID=258505) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:20:28,842] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:20:28,843] {logging_mixin.py:112} INFO - [2020-07-23 15:20:28,843] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:20:28,869] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:20:29,054] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:20:29,456] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:50:00+00:00: scheduled__2020-07-21T00:50:00+00:00, externally triggered: False>
[2020-07-23 15:20:29,461] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:49:00+00:00: scheduled__2020-07-21T00:49:00+00:00, externally triggered: False>
[2020-07-23 15:20:29,470] {logging_mixin.py:112} INFO - [2020-07-23 15:20:29,470] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:49:00+00:00: scheduled__2020-07-21T00:49:00+00:00, externally triggered: False> successful
[2020-07-23 15:20:29,612] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:50:00+00:00: scheduled__2020-07-21T00:50:00+00:00, externally triggered: False>
[2020-07-23 15:20:29,631] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:20:29,635] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:50:00+00:00 [scheduled]> in ORM
[2020-07-23 15:20:29,801] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.963 seconds
[2020-07-23 15:21:04,283] {scheduler_job.py:153} INFO - Started process (PID=259329) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:21:04,287] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:21:04,288] {logging_mixin.py:112} INFO - [2020-07-23 15:21:04,288] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:21:04,346] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:21:04,618] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:21:05,116] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:51:00+00:00: scheduled__2020-07-21T00:51:00+00:00, externally triggered: False>
[2020-07-23 15:21:05,130] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:50:00+00:00: scheduled__2020-07-21T00:50:00+00:00, externally triggered: False>
[2020-07-23 15:21:05,331] {logging_mixin.py:112} INFO - [2020-07-23 15:21:05,331] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:50:00+00:00: scheduled__2020-07-21T00:50:00+00:00, externally triggered: False> successful
[2020-07-23 15:21:05,516] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:51:00+00:00: scheduled__2020-07-21T00:51:00+00:00, externally triggered: False>
[2020-07-23 15:21:05,534] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:21:05,538] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:51:00+00:00 [scheduled]> in ORM
[2020-07-23 15:21:05,691] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.408 seconds
[2020-07-23 15:21:43,881] {scheduler_job.py:153} INFO - Started process (PID=260247) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:21:43,885] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:21:43,886] {logging_mixin.py:112} INFO - [2020-07-23 15:21:43,886] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:21:43,900] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:21:44,026] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:21:44,596] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:52:00+00:00: scheduled__2020-07-21T00:52:00+00:00, externally triggered: False>
[2020-07-23 15:21:44,602] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:51:00+00:00: scheduled__2020-07-21T00:51:00+00:00, externally triggered: False>
[2020-07-23 15:21:44,613] {logging_mixin.py:112} INFO - [2020-07-23 15:21:44,613] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:51:00+00:00: scheduled__2020-07-21T00:51:00+00:00, externally triggered: False> successful
[2020-07-23 15:21:44,786] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:52:00+00:00: scheduled__2020-07-21T00:52:00+00:00, externally triggered: False>
[2020-07-23 15:21:44,808] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:21:44,817] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:52:00+00:00 [scheduled]> in ORM
[2020-07-23 15:21:44,965] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.084 seconds
[2020-07-23 15:21:57,590] {scheduler_job.py:153} INFO - Started process (PID=260607) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:21:57,608] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:21:57,612] {logging_mixin.py:112} INFO - [2020-07-23 15:21:57,611] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:21:57,631] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:21:58,072] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:21:58,522] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:53:00+00:00: scheduled__2020-07-21T00:53:00+00:00, externally triggered: False>
[2020-07-23 15:21:58,528] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:52:00+00:00: scheduled__2020-07-21T00:52:00+00:00, externally triggered: False>
[2020-07-23 15:21:58,541] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:53:00+00:00: scheduled__2020-07-21T00:53:00+00:00, externally triggered: False>
[2020-07-23 15:21:58,570] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:21:58,577] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:53:00+00:00 [scheduled]> in ORM
[2020-07-23 15:21:58,731] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.142 seconds
[2020-07-23 15:23:22,673] {scheduler_job.py:153} INFO - Started process (PID=262399) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:23:22,678] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:23:22,679] {logging_mixin.py:112} INFO - [2020-07-23 15:23:22,679] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:23:22,696] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:23:22,847] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:23:23,513] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:54:00+00:00: scheduled__2020-07-21T00:54:00+00:00, externally triggered: False>
[2020-07-23 15:23:23,516] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:52:00+00:00: scheduled__2020-07-21T00:52:00+00:00, externally triggered: False>
[2020-07-23 15:23:23,524] {logging_mixin.py:112} INFO - [2020-07-23 15:23:23,524] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:52:00+00:00: scheduled__2020-07-21T00:52:00+00:00, externally triggered: False> successful
[2020-07-23 15:23:23,618] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:53:00+00:00: scheduled__2020-07-21T00:53:00+00:00, externally triggered: False>
[2020-07-23 15:23:23,628] {logging_mixin.py:112} INFO - [2020-07-23 15:23:23,628] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:53:00+00:00: scheduled__2020-07-21T00:53:00+00:00, externally triggered: False> successful
[2020-07-23 15:23:23,730] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:54:00+00:00: scheduled__2020-07-21T00:54:00+00:00, externally triggered: False>
[2020-07-23 15:23:23,752] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:23:23,760] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:54:00+00:00 [scheduled]> in ORM
[2020-07-23 15:23:23,916] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.243 seconds
[2020-07-23 15:23:34,911] {scheduler_job.py:153} INFO - Started process (PID=262783) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:23:34,915] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:23:34,916] {logging_mixin.py:112} INFO - [2020-07-23 15:23:34,916] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:23:34,929] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:23:35,125] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:23:35,528] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:55:00+00:00: scheduled__2020-07-21T00:55:00+00:00, externally triggered: False>
[2020-07-23 15:23:35,542] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:54:00+00:00: scheduled__2020-07-21T00:54:00+00:00, externally triggered: False>
[2020-07-23 15:23:35,567] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:55:00+00:00: scheduled__2020-07-21T00:55:00+00:00, externally triggered: False>
[2020-07-23 15:23:35,603] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:23:35,611] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:55:00+00:00 [scheduled]> in ORM
[2020-07-23 15:23:35,752] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.840 seconds
[2020-07-23 15:24:41,113] {scheduler_job.py:153} INFO - Started process (PID=264177) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:24:41,123] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:24:41,124] {logging_mixin.py:112} INFO - [2020-07-23 15:24:41,123] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:24:41,154] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:24:41,341] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:24:41,779] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:56:00+00:00: scheduled__2020-07-21T00:56:00+00:00, externally triggered: False>
[2020-07-23 15:24:41,785] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:54:00+00:00: scheduled__2020-07-21T00:54:00+00:00, externally triggered: False>
[2020-07-23 15:24:41,797] {logging_mixin.py:112} INFO - [2020-07-23 15:24:41,797] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:54:00+00:00: scheduled__2020-07-21T00:54:00+00:00, externally triggered: False> successful
[2020-07-23 15:24:41,914] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:55:00+00:00: scheduled__2020-07-21T00:55:00+00:00, externally triggered: False>
[2020-07-23 15:24:41,923] {logging_mixin.py:112} INFO - [2020-07-23 15:24:41,923] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:55:00+00:00: scheduled__2020-07-21T00:55:00+00:00, externally triggered: False> successful
[2020-07-23 15:24:42,036] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:56:00+00:00: scheduled__2020-07-21T00:56:00+00:00, externally triggered: False>
[2020-07-23 15:24:42,053] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:24:42,060] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:56:00+00:00 [scheduled]> in ORM
[2020-07-23 15:24:42,214] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.101 seconds
[2020-07-23 15:25:28,805] {scheduler_job.py:153} INFO - Started process (PID=265207) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:25:28,809] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:25:28,814] {logging_mixin.py:112} INFO - [2020-07-23 15:25:28,814] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:25:28,843] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:25:29,080] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:25:29,534] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:57:00+00:00: scheduled__2020-07-21T00:57:00+00:00, externally triggered: False>
[2020-07-23 15:25:29,540] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:56:00+00:00: scheduled__2020-07-21T00:56:00+00:00, externally triggered: False>
[2020-07-23 15:25:29,554] {logging_mixin.py:112} INFO - [2020-07-23 15:25:29,554] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:56:00+00:00: scheduled__2020-07-21T00:56:00+00:00, externally triggered: False> successful
[2020-07-23 15:25:29,652] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:57:00+00:00: scheduled__2020-07-21T00:57:00+00:00, externally triggered: False>
[2020-07-23 15:25:29,678] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:25:29,685] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:57:00+00:00 [scheduled]> in ORM
[2020-07-23 15:25:29,850] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.045 seconds
[2020-07-23 15:26:14,363] {scheduler_job.py:153} INFO - Started process (PID=266241) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:26:14,367] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:26:14,368] {logging_mixin.py:112} INFO - [2020-07-23 15:26:14,368] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:26:14,382] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:26:14,549] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:26:14,920] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:58:00+00:00: scheduled__2020-07-21T00:58:00+00:00, externally triggered: False>
[2020-07-23 15:26:14,945] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:57:00+00:00: scheduled__2020-07-21T00:57:00+00:00, externally triggered: False>
[2020-07-23 15:26:15,002] {logging_mixin.py:112} INFO - [2020-07-23 15:26:15,001] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:57:00+00:00: scheduled__2020-07-21T00:57:00+00:00, externally triggered: False> successful
[2020-07-23 15:26:15,123] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:58:00+00:00: scheduled__2020-07-21T00:58:00+00:00, externally triggered: False>
[2020-07-23 15:26:15,174] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:26:15,193] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:58:00+00:00 [scheduled]> in ORM
[2020-07-23 15:26:15,387] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.024 seconds
[2020-07-23 15:27:03,150] {scheduler_job.py:153} INFO - Started process (PID=267260) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:27:03,155] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:27:03,156] {logging_mixin.py:112} INFO - [2020-07-23 15:27:03,156] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:27:03,172] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:27:03,340] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:27:03,825] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T00:59:00+00:00: scheduled__2020-07-21T00:59:00+00:00, externally triggered: False>
[2020-07-23 15:27:03,830] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:58:00+00:00: scheduled__2020-07-21T00:58:00+00:00, externally triggered: False>
[2020-07-23 15:27:03,843] {logging_mixin.py:112} INFO - [2020-07-23 15:27:03,842] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:58:00+00:00: scheduled__2020-07-21T00:58:00+00:00, externally triggered: False> successful
[2020-07-23 15:27:04,127] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:59:00+00:00: scheduled__2020-07-21T00:59:00+00:00, externally triggered: False>
[2020-07-23 15:27:04,144] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:27:04,149] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 00:59:00+00:00 [scheduled]> in ORM
[2020-07-23 15:27:04,327] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.177 seconds
[2020-07-23 15:27:34,481] {scheduler_job.py:153} INFO - Started process (PID=267958) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:27:34,485] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:27:34,485] {logging_mixin.py:112} INFO - [2020-07-23 15:27:34,485] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:27:34,498] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:27:34,654] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:27:35,032] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:00:00+00:00: scheduled__2020-07-21T01:00:00+00:00, externally triggered: False>
[2020-07-23 15:27:35,038] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 00:59:00+00:00: scheduled__2020-07-21T00:59:00+00:00, externally triggered: False>
[2020-07-23 15:27:35,050] {logging_mixin.py:112} INFO - [2020-07-23 15:27:35,050] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 00:59:00+00:00: scheduled__2020-07-21T00:59:00+00:00, externally triggered: False> successful
[2020-07-23 15:27:35,174] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:00:00+00:00: scheduled__2020-07-21T01:00:00+00:00, externally triggered: False>
[2020-07-23 15:27:35,191] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:27:35,197] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:00:00+00:00 [scheduled]> in ORM
[2020-07-23 15:27:35,372] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.892 seconds
[2020-07-23 15:28:13,174] {scheduler_job.py:153} INFO - Started process (PID=268836) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:28:13,178] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:28:13,179] {logging_mixin.py:112} INFO - [2020-07-23 15:28:13,178] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:28:13,193] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:28:13,351] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:28:13,699] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:01:00+00:00: scheduled__2020-07-21T01:01:00+00:00, externally triggered: False>
[2020-07-23 15:28:13,703] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:00:00+00:00: scheduled__2020-07-21T01:00:00+00:00, externally triggered: False>
[2020-07-23 15:28:13,710] {logging_mixin.py:112} INFO - [2020-07-23 15:28:13,710] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:00:00+00:00: scheduled__2020-07-21T01:00:00+00:00, externally triggered: False> successful
[2020-07-23 15:28:13,811] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:01:00+00:00: scheduled__2020-07-21T01:01:00+00:00, externally triggered: False>
[2020-07-23 15:28:13,831] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:28:13,834] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:01:00+00:00 [scheduled]> in ORM
[2020-07-23 15:28:13,976] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.802 seconds
[2020-07-23 15:28:48,232] {scheduler_job.py:153} INFO - Started process (PID=269655) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:28:48,239] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:28:48,240] {logging_mixin.py:112} INFO - [2020-07-23 15:28:48,239] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:28:48,261] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:28:48,393] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:28:48,712] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:02:00+00:00: scheduled__2020-07-21T01:02:00+00:00, externally triggered: False>
[2020-07-23 15:28:48,717] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:01:00+00:00: scheduled__2020-07-21T01:01:00+00:00, externally triggered: False>
[2020-07-23 15:28:48,730] {logging_mixin.py:112} INFO - [2020-07-23 15:28:48,730] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:01:00+00:00: scheduled__2020-07-21T01:01:00+00:00, externally triggered: False> successful
[2020-07-23 15:28:48,814] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:02:00+00:00: scheduled__2020-07-21T01:02:00+00:00, externally triggered: False>
[2020-07-23 15:28:48,834] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:28:48,840] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:02:00+00:00 [scheduled]> in ORM
[2020-07-23 15:28:48,992] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.760 seconds
[2020-07-23 15:29:30,645] {scheduler_job.py:153} INFO - Started process (PID=270548) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:29:30,650] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:29:30,651] {logging_mixin.py:112} INFO - [2020-07-23 15:29:30,651] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:29:30,662] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:29:30,826] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:29:31,349] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:03:00+00:00: scheduled__2020-07-21T01:03:00+00:00, externally triggered: False>
[2020-07-23 15:29:31,355] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:02:00+00:00: scheduled__2020-07-21T01:02:00+00:00, externally triggered: False>
[2020-07-23 15:29:31,367] {logging_mixin.py:112} INFO - [2020-07-23 15:29:31,366] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:02:00+00:00: scheduled__2020-07-21T01:02:00+00:00, externally triggered: False> successful
[2020-07-23 15:29:31,484] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:03:00+00:00: scheduled__2020-07-21T01:03:00+00:00, externally triggered: False>
[2020-07-23 15:29:31,496] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:29:31,500] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:03:00+00:00 [scheduled]> in ORM
[2020-07-23 15:29:31,696] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.051 seconds
[2020-07-23 15:30:03,649] {scheduler_job.py:153} INFO - Started process (PID=271369) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:30:03,652] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:30:03,652] {logging_mixin.py:112} INFO - [2020-07-23 15:30:03,652] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:30:03,662] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:30:03,867] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:30:04,276] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:04:00+00:00: scheduled__2020-07-21T01:04:00+00:00, externally triggered: False>
[2020-07-23 15:30:04,279] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:03:00+00:00: scheduled__2020-07-21T01:03:00+00:00, externally triggered: False>
[2020-07-23 15:30:04,287] {logging_mixin.py:112} INFO - [2020-07-23 15:30:04,287] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:03:00+00:00: scheduled__2020-07-21T01:03:00+00:00, externally triggered: False> successful
[2020-07-23 15:30:04,399] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:04:00+00:00: scheduled__2020-07-21T01:04:00+00:00, externally triggered: False>
[2020-07-23 15:30:04,418] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:30:04,422] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:04:00+00:00 [scheduled]> in ORM
[2020-07-23 15:30:04,588] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.939 seconds
[2020-07-23 15:30:43,669] {scheduler_job.py:153} INFO - Started process (PID=272286) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:30:43,673] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:30:43,674] {logging_mixin.py:112} INFO - [2020-07-23 15:30:43,673] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:30:43,685] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:30:43,855] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:30:44,225] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:05:00+00:00: scheduled__2020-07-21T01:05:00+00:00, externally triggered: False>
[2020-07-23 15:30:44,229] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:04:00+00:00: scheduled__2020-07-21T01:04:00+00:00, externally triggered: False>
[2020-07-23 15:30:44,236] {logging_mixin.py:112} INFO - [2020-07-23 15:30:44,236] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:04:00+00:00: scheduled__2020-07-21T01:04:00+00:00, externally triggered: False> successful
[2020-07-23 15:30:44,357] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:05:00+00:00: scheduled__2020-07-21T01:05:00+00:00, externally triggered: False>
[2020-07-23 15:30:44,379] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:30:44,386] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:05:00+00:00 [scheduled]> in ORM
[2020-07-23 15:30:44,534] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.866 seconds
[2020-07-23 15:31:22,739] {scheduler_job.py:153} INFO - Started process (PID=273126) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:31:22,744] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:31:22,745] {logging_mixin.py:112} INFO - [2020-07-23 15:31:22,745] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:31:22,757] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:31:22,967] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:31:23,373] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:06:00+00:00: scheduled__2020-07-21T01:06:00+00:00, externally triggered: False>
[2020-07-23 15:31:23,379] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:05:00+00:00: scheduled__2020-07-21T01:05:00+00:00, externally triggered: False>
[2020-07-23 15:31:23,386] {logging_mixin.py:112} INFO - [2020-07-23 15:31:23,386] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:05:00+00:00: scheduled__2020-07-21T01:05:00+00:00, externally triggered: False> successful
[2020-07-23 15:31:23,494] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:06:00+00:00: scheduled__2020-07-21T01:06:00+00:00, externally triggered: False>
[2020-07-23 15:31:23,514] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:31:23,518] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:06:00+00:00 [scheduled]> in ORM
[2020-07-23 15:31:23,672] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.934 seconds
[2020-07-23 15:31:57,110] {scheduler_job.py:153} INFO - Started process (PID=274204) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:31:57,116] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:31:57,117] {logging_mixin.py:112} INFO - [2020-07-23 15:31:57,117] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:31:57,131] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:31:57,307] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:31:57,847] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:07:00+00:00: scheduled__2020-07-21T01:07:00+00:00, externally triggered: False>
[2020-07-23 15:31:57,851] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:06:00+00:00: scheduled__2020-07-21T01:06:00+00:00, externally triggered: False>
[2020-07-23 15:31:57,859] {logging_mixin.py:112} INFO - [2020-07-23 15:31:57,858] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:06:00+00:00: scheduled__2020-07-21T01:06:00+00:00, externally triggered: False> successful
[2020-07-23 15:31:57,964] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:07:00+00:00: scheduled__2020-07-21T01:07:00+00:00, externally triggered: False>
[2020-07-23 15:31:57,983] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:31:57,987] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:07:00+00:00 [scheduled]> in ORM
[2020-07-23 15:31:58,142] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.032 seconds
[2020-07-23 15:32:33,410] {scheduler_job.py:153} INFO - Started process (PID=275077) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:32:33,413] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:32:33,414] {logging_mixin.py:112} INFO - [2020-07-23 15:32:33,414] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:32:33,427] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:32:33,597] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:32:33,971] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:08:00+00:00: scheduled__2020-07-21T01:08:00+00:00, externally triggered: False>
[2020-07-23 15:32:33,975] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:07:00+00:00: scheduled__2020-07-21T01:07:00+00:00, externally triggered: False>
[2020-07-23 15:32:33,987] {logging_mixin.py:112} INFO - [2020-07-23 15:32:33,987] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:07:00+00:00: scheduled__2020-07-21T01:07:00+00:00, externally triggered: False> successful
[2020-07-23 15:32:34,089] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:08:00+00:00: scheduled__2020-07-21T01:08:00+00:00, externally triggered: False>
[2020-07-23 15:32:34,101] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:32:34,105] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:08:00+00:00 [scheduled]> in ORM
[2020-07-23 15:32:34,265] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.855 seconds
[2020-07-23 15:33:06,070] {scheduler_job.py:153} INFO - Started process (PID=275799) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:33:06,080] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:33:06,081] {logging_mixin.py:112} INFO - [2020-07-23 15:33:06,081] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:33:06,112] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:33:06,325] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:33:06,797] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:09:00+00:00: scheduled__2020-07-21T01:09:00+00:00, externally triggered: False>
[2020-07-23 15:33:06,803] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:08:00+00:00: scheduled__2020-07-21T01:08:00+00:00, externally triggered: False>
[2020-07-23 15:33:06,816] {logging_mixin.py:112} INFO - [2020-07-23 15:33:06,815] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:08:00+00:00: scheduled__2020-07-21T01:08:00+00:00, externally triggered: False> successful
[2020-07-23 15:33:06,914] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:09:00+00:00: scheduled__2020-07-21T01:09:00+00:00, externally triggered: False>
[2020-07-23 15:33:06,933] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:33:06,939] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:09:00+00:00 [scheduled]> in ORM
[2020-07-23 15:33:07,218] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.148 seconds
[2020-07-23 15:33:39,863] {scheduler_job.py:153} INFO - Started process (PID=276598) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:33:39,867] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:33:39,867] {logging_mixin.py:112} INFO - [2020-07-23 15:33:39,867] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:33:39,879] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:33:40,050] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:33:40,535] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:10:00+00:00: scheduled__2020-07-21T01:10:00+00:00, externally triggered: False>
[2020-07-23 15:33:40,540] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:09:00+00:00: scheduled__2020-07-21T01:09:00+00:00, externally triggered: False>
[2020-07-23 15:33:40,547] {logging_mixin.py:112} INFO - [2020-07-23 15:33:40,547] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:09:00+00:00: scheduled__2020-07-21T01:09:00+00:00, externally triggered: False> successful
[2020-07-23 15:33:40,728] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:10:00+00:00: scheduled__2020-07-21T01:10:00+00:00, externally triggered: False>
[2020-07-23 15:33:40,746] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:33:40,750] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:10:00+00:00 [scheduled]> in ORM
[2020-07-23 15:33:40,948] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.085 seconds
[2020-07-23 15:34:20,130] {scheduler_job.py:153} INFO - Started process (PID=277470) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:34:20,135] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:34:20,135] {logging_mixin.py:112} INFO - [2020-07-23 15:34:20,135] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:34:20,150] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:34:20,316] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:34:20,643] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:11:00+00:00: scheduled__2020-07-21T01:11:00+00:00, externally triggered: False>
[2020-07-23 15:34:20,647] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:10:00+00:00: scheduled__2020-07-21T01:10:00+00:00, externally triggered: False>
[2020-07-23 15:34:20,654] {logging_mixin.py:112} INFO - [2020-07-23 15:34:20,654] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:10:00+00:00: scheduled__2020-07-21T01:10:00+00:00, externally triggered: False> successful
[2020-07-23 15:34:20,809] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:11:00+00:00: scheduled__2020-07-21T01:11:00+00:00, externally triggered: False>
[2020-07-23 15:34:20,822] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:34:20,826] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:11:00+00:00 [scheduled]> in ORM
[2020-07-23 15:34:21,021] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.891 seconds
[2020-07-23 15:34:59,695] {scheduler_job.py:153} INFO - Started process (PID=278342) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:34:59,699] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:34:59,700] {logging_mixin.py:112} INFO - [2020-07-23 15:34:59,700] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:34:59,716] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:34:59,901] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:35:00,214] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:12:00+00:00: scheduled__2020-07-21T01:12:00+00:00, externally triggered: False>
[2020-07-23 15:35:00,218] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:11:00+00:00: scheduled__2020-07-21T01:11:00+00:00, externally triggered: False>
[2020-07-23 15:35:00,225] {logging_mixin.py:112} INFO - [2020-07-23 15:35:00,225] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:11:00+00:00: scheduled__2020-07-21T01:11:00+00:00, externally triggered: False> successful
[2020-07-23 15:35:00,413] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:12:00+00:00: scheduled__2020-07-21T01:12:00+00:00, externally triggered: False>
[2020-07-23 15:35:00,431] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:35:00,435] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:12:00+00:00 [scheduled]> in ORM
[2020-07-23 15:35:00,591] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.897 seconds
[2020-07-23 15:35:39,094] {scheduler_job.py:153} INFO - Started process (PID=279187) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:35:39,098] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:35:39,098] {logging_mixin.py:112} INFO - [2020-07-23 15:35:39,098] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:35:39,113] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:35:39,421] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:35:39,987] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:13:00+00:00: scheduled__2020-07-21T01:13:00+00:00, externally triggered: False>
[2020-07-23 15:35:39,991] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:12:00+00:00: scheduled__2020-07-21T01:12:00+00:00, externally triggered: False>
[2020-07-23 15:35:39,999] {logging_mixin.py:112} INFO - [2020-07-23 15:35:39,999] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:12:00+00:00: scheduled__2020-07-21T01:12:00+00:00, externally triggered: False> successful
[2020-07-23 15:35:40,291] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:13:00+00:00: scheduled__2020-07-21T01:13:00+00:00, externally triggered: False>
[2020-07-23 15:35:40,310] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:35:40,314] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:13:00+00:00 [scheduled]> in ORM
[2020-07-23 15:35:40,547] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.454 seconds
[2020-07-23 15:36:19,010] {scheduler_job.py:153} INFO - Started process (PID=280081) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:36:19,015] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:36:19,016] {logging_mixin.py:112} INFO - [2020-07-23 15:36:19,015] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:36:19,032] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:36:19,178] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:36:19,529] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:14:00+00:00: scheduled__2020-07-21T01:14:00+00:00, externally triggered: False>
[2020-07-23 15:36:19,533] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:13:00+00:00: scheduled__2020-07-21T01:13:00+00:00, externally triggered: False>
[2020-07-23 15:36:19,544] {logging_mixin.py:112} INFO - [2020-07-23 15:36:19,544] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:13:00+00:00: scheduled__2020-07-21T01:13:00+00:00, externally triggered: False> successful
[2020-07-23 15:36:19,650] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:14:00+00:00: scheduled__2020-07-21T01:14:00+00:00, externally triggered: False>
[2020-07-23 15:36:19,664] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:36:19,668] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:14:00+00:00 [scheduled]> in ORM
[2020-07-23 15:36:19,873] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.863 seconds
[2020-07-23 15:36:53,749] {scheduler_job.py:153} INFO - Started process (PID=280925) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:36:53,754] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:36:53,755] {logging_mixin.py:112} INFO - [2020-07-23 15:36:53,755] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:36:53,769] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:36:54,211] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:36:54,549] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:15:00+00:00: scheduled__2020-07-21T01:15:00+00:00, externally triggered: False>
[2020-07-23 15:36:54,554] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:14:00+00:00: scheduled__2020-07-21T01:14:00+00:00, externally triggered: False>
[2020-07-23 15:36:54,562] {logging_mixin.py:112} INFO - [2020-07-23 15:36:54,562] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:14:00+00:00: scheduled__2020-07-21T01:14:00+00:00, externally triggered: False> successful
[2020-07-23 15:36:54,667] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:15:00+00:00: scheduled__2020-07-21T01:15:00+00:00, externally triggered: False>
[2020-07-23 15:36:54,686] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:36:54,690] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:15:00+00:00 [scheduled]> in ORM
[2020-07-23 15:36:54,844] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.095 seconds
[2020-07-23 15:37:29,596] {scheduler_job.py:153} INFO - Started process (PID=281698) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:37:29,612] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:37:29,613] {logging_mixin.py:112} INFO - [2020-07-23 15:37:29,612] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:37:29,627] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:37:29,825] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:37:30,167] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:16:00+00:00: scheduled__2020-07-21T01:16:00+00:00, externally triggered: False>
[2020-07-23 15:37:30,173] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:15:00+00:00: scheduled__2020-07-21T01:15:00+00:00, externally triggered: False>
[2020-07-23 15:37:30,181] {logging_mixin.py:112} INFO - [2020-07-23 15:37:30,181] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:15:00+00:00: scheduled__2020-07-21T01:15:00+00:00, externally triggered: False> successful
[2020-07-23 15:37:30,317] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:16:00+00:00: scheduled__2020-07-21T01:16:00+00:00, externally triggered: False>
[2020-07-23 15:37:30,334] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:37:30,338] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:16:00+00:00 [scheduled]> in ORM
[2020-07-23 15:37:30,503] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.908 seconds
[2020-07-23 15:38:01,320] {scheduler_job.py:153} INFO - Started process (PID=282422) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:38:01,324] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:38:01,324] {logging_mixin.py:112} INFO - [2020-07-23 15:38:01,324] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:38:01,359] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:38:01,590] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:38:01,883] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:17:00+00:00: scheduled__2020-07-21T01:17:00+00:00, externally triggered: False>
[2020-07-23 15:38:01,891] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:16:00+00:00: scheduled__2020-07-21T01:16:00+00:00, externally triggered: False>
[2020-07-23 15:38:01,920] {logging_mixin.py:112} INFO - [2020-07-23 15:38:01,920] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:16:00+00:00: scheduled__2020-07-21T01:16:00+00:00, externally triggered: False> successful
[2020-07-23 15:38:02,068] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:17:00+00:00: scheduled__2020-07-21T01:17:00+00:00, externally triggered: False>
[2020-07-23 15:38:02,088] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:38:02,094] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:17:00+00:00 [scheduled]> in ORM
[2020-07-23 15:38:02,244] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.925 seconds
[2020-07-23 15:38:49,018] {scheduler_job.py:153} INFO - Started process (PID=283450) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:38:49,032] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:38:49,033] {logging_mixin.py:112} INFO - [2020-07-23 15:38:49,032] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:38:49,056] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:38:49,282] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:38:49,689] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:18:00+00:00: scheduled__2020-07-21T01:18:00+00:00, externally triggered: False>
[2020-07-23 15:38:49,701] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:17:00+00:00: scheduled__2020-07-21T01:17:00+00:00, externally triggered: False>
[2020-07-23 15:38:49,720] {logging_mixin.py:112} INFO - [2020-07-23 15:38:49,720] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:17:00+00:00: scheduled__2020-07-21T01:17:00+00:00, externally triggered: False> successful
[2020-07-23 15:38:49,851] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:18:00+00:00: scheduled__2020-07-21T01:18:00+00:00, externally triggered: False>
[2020-07-23 15:38:49,878] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:38:49,885] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:18:00+00:00 [scheduled]> in ORM
[2020-07-23 15:38:50,050] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.032 seconds
[2020-07-23 15:39:22,170] {scheduler_job.py:153} INFO - Started process (PID=284182) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:39:22,187] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:39:22,188] {logging_mixin.py:112} INFO - [2020-07-23 15:39:22,188] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:39:22,212] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:39:22,360] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:39:22,842] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:19:00+00:00: scheduled__2020-07-21T01:19:00+00:00, externally triggered: False>
[2020-07-23 15:39:22,847] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:18:00+00:00: scheduled__2020-07-21T01:18:00+00:00, externally triggered: False>
[2020-07-23 15:39:22,855] {logging_mixin.py:112} INFO - [2020-07-23 15:39:22,855] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:18:00+00:00: scheduled__2020-07-21T01:18:00+00:00, externally triggered: False> successful
[2020-07-23 15:39:22,969] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:19:00+00:00: scheduled__2020-07-21T01:19:00+00:00, externally triggered: False>
[2020-07-23 15:39:22,987] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:39:22,991] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:19:00+00:00 [scheduled]> in ORM
[2020-07-23 15:39:23,167] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.997 seconds
[2020-07-23 15:40:03,258] {scheduler_job.py:153} INFO - Started process (PID=285149) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:40:03,263] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:40:03,263] {logging_mixin.py:112} INFO - [2020-07-23 15:40:03,263] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:40:03,274] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:40:03,379] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:40:03,751] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:20:00+00:00: scheduled__2020-07-21T01:20:00+00:00, externally triggered: False>
[2020-07-23 15:40:03,755] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:19:00+00:00: scheduled__2020-07-21T01:19:00+00:00, externally triggered: False>
[2020-07-23 15:40:03,763] {logging_mixin.py:112} INFO - [2020-07-23 15:40:03,762] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:19:00+00:00: scheduled__2020-07-21T01:19:00+00:00, externally triggered: False> successful
[2020-07-23 15:40:03,879] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:20:00+00:00: scheduled__2020-07-21T01:20:00+00:00, externally triggered: False>
[2020-07-23 15:40:03,903] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:40:03,908] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:20:00+00:00 [scheduled]> in ORM
[2020-07-23 15:40:04,122] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.864 seconds
[2020-07-23 15:40:51,295] {scheduler_job.py:153} INFO - Started process (PID=286207) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:40:51,300] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:40:51,301] {logging_mixin.py:112} INFO - [2020-07-23 15:40:51,301] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:40:51,315] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:40:51,491] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:40:51,850] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:21:00+00:00: scheduled__2020-07-21T01:21:00+00:00, externally triggered: False>
[2020-07-23 15:40:51,853] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:20:00+00:00: scheduled__2020-07-21T01:20:00+00:00, externally triggered: False>
[2020-07-23 15:40:51,861] {logging_mixin.py:112} INFO - [2020-07-23 15:40:51,861] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:20:00+00:00: scheduled__2020-07-21T01:20:00+00:00, externally triggered: False> successful
[2020-07-23 15:40:51,971] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:21:00+00:00: scheduled__2020-07-21T01:21:00+00:00, externally triggered: False>
[2020-07-23 15:40:51,989] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:40:51,997] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:21:00+00:00 [scheduled]> in ORM
[2020-07-23 15:40:52,183] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.888 seconds
[2020-07-23 15:41:10,691] {scheduler_job.py:153} INFO - Started process (PID=286734) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:41:10,706] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:41:10,707] {logging_mixin.py:112} INFO - [2020-07-23 15:41:10,707] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:41:10,725] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:41:10,918] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:41:11,352] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:22:00+00:00: scheduled__2020-07-21T01:22:00+00:00, externally triggered: False>
[2020-07-23 15:41:11,371] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:21:00+00:00: scheduled__2020-07-21T01:21:00+00:00, externally triggered: False>
[2020-07-23 15:41:11,417] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:22:00+00:00: scheduled__2020-07-21T01:22:00+00:00, externally triggered: False>
[2020-07-23 15:41:11,499] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:41:11,516] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:22:00+00:00 [scheduled]> in ORM
[2020-07-23 15:41:11,769] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.078 seconds
[2020-07-23 15:42:22,891] {scheduler_job.py:153} INFO - Started process (PID=288159) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:42:22,899] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:42:22,900] {logging_mixin.py:112} INFO - [2020-07-23 15:42:22,900] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:42:22,910] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:42:23,073] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:42:23,627] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:23:00+00:00: scheduled__2020-07-21T01:23:00+00:00, externally triggered: False>
[2020-07-23 15:42:23,631] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:21:00+00:00: scheduled__2020-07-21T01:21:00+00:00, externally triggered: False>
[2020-07-23 15:42:23,638] {logging_mixin.py:112} INFO - [2020-07-23 15:42:23,638] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:21:00+00:00: scheduled__2020-07-21T01:21:00+00:00, externally triggered: False> successful
[2020-07-23 15:42:23,743] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:22:00+00:00: scheduled__2020-07-21T01:22:00+00:00, externally triggered: False>
[2020-07-23 15:42:23,759] {logging_mixin.py:112} INFO - [2020-07-23 15:42:23,758] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:22:00+00:00: scheduled__2020-07-21T01:22:00+00:00, externally triggered: False> successful
[2020-07-23 15:42:23,876] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:23:00+00:00: scheduled__2020-07-21T01:23:00+00:00, externally triggered: False>
[2020-07-23 15:42:23,892] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:42:23,896] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:23:00+00:00 [scheduled]> in ORM
[2020-07-23 15:42:24,242] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.350 seconds
[2020-07-23 15:43:10,552] {scheduler_job.py:153} INFO - Started process (PID=289191) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:43:10,556] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:43:10,557] {logging_mixin.py:112} INFO - [2020-07-23 15:43:10,557] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:43:10,571] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:43:10,900] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:43:11,942] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:24:00+00:00: scheduled__2020-07-21T01:24:00+00:00, externally triggered: False>
[2020-07-23 15:43:11,947] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:23:00+00:00: scheduled__2020-07-21T01:23:00+00:00, externally triggered: False>
[2020-07-23 15:43:11,956] {logging_mixin.py:112} INFO - [2020-07-23 15:43:11,956] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:23:00+00:00: scheduled__2020-07-21T01:23:00+00:00, externally triggered: False> successful
[2020-07-23 15:43:12,328] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:24:00+00:00: scheduled__2020-07-21T01:24:00+00:00, externally triggered: False>
[2020-07-23 15:43:12,345] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:43:12,349] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:24:00+00:00 [scheduled]> in ORM
[2020-07-23 15:43:12,640] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.088 seconds
[2020-07-23 15:43:54,617] {scheduler_job.py:153} INFO - Started process (PID=290120) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:43:54,622] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:43:54,622] {logging_mixin.py:112} INFO - [2020-07-23 15:43:54,622] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:43:54,636] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:43:54,777] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:43:55,076] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:25:00+00:00: scheduled__2020-07-21T01:25:00+00:00, externally triggered: False>
[2020-07-23 15:43:55,080] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:24:00+00:00: scheduled__2020-07-21T01:24:00+00:00, externally triggered: False>
[2020-07-23 15:43:55,089] {logging_mixin.py:112} INFO - [2020-07-23 15:43:55,089] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:24:00+00:00: scheduled__2020-07-21T01:24:00+00:00, externally triggered: False> successful
[2020-07-23 15:43:55,204] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:25:00+00:00: scheduled__2020-07-21T01:25:00+00:00, externally triggered: False>
[2020-07-23 15:43:55,225] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:43:55,230] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:25:00+00:00 [scheduled]> in ORM
[2020-07-23 15:43:55,395] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.778 seconds
[2020-07-23 15:44:33,027] {scheduler_job.py:153} INFO - Started process (PID=290953) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:44:33,035] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:44:33,036] {logging_mixin.py:112} INFO - [2020-07-23 15:44:33,036] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:44:33,051] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:44:33,255] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:44:33,651] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:26:00+00:00: scheduled__2020-07-21T01:26:00+00:00, externally triggered: False>
[2020-07-23 15:44:33,659] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:25:00+00:00: scheduled__2020-07-21T01:25:00+00:00, externally triggered: False>
[2020-07-23 15:44:33,668] {logging_mixin.py:112} INFO - [2020-07-23 15:44:33,668] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:25:00+00:00: scheduled__2020-07-21T01:25:00+00:00, externally triggered: False> successful
[2020-07-23 15:44:33,780] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:26:00+00:00: scheduled__2020-07-21T01:26:00+00:00, externally triggered: False>
[2020-07-23 15:44:33,799] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:44:33,803] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:26:00+00:00 [scheduled]> in ORM
[2020-07-23 15:44:33,969] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.942 seconds
[2020-07-23 15:45:13,653] {scheduler_job.py:153} INFO - Started process (PID=291940) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:45:13,656] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:45:13,657] {logging_mixin.py:112} INFO - [2020-07-23 15:45:13,656] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:45:13,667] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:45:13,849] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:45:14,197] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:27:00+00:00: scheduled__2020-07-21T01:27:00+00:00, externally triggered: False>
[2020-07-23 15:45:14,201] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:26:00+00:00: scheduled__2020-07-21T01:26:00+00:00, externally triggered: False>
[2020-07-23 15:45:14,209] {logging_mixin.py:112} INFO - [2020-07-23 15:45:14,209] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:26:00+00:00: scheduled__2020-07-21T01:26:00+00:00, externally triggered: False> successful
[2020-07-23 15:45:14,379] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:27:00+00:00: scheduled__2020-07-21T01:27:00+00:00, externally triggered: False>
[2020-07-23 15:45:14,585] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:45:14,591] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:27:00+00:00 [scheduled]> in ORM
[2020-07-23 15:45:14,776] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.123 seconds
[2020-07-23 15:45:52,732] {scheduler_job.py:153} INFO - Started process (PID=292815) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:45:52,738] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:45:52,738] {logging_mixin.py:112} INFO - [2020-07-23 15:45:52,738] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:45:52,755] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:45:52,918] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:45:53,249] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:28:00+00:00: scheduled__2020-07-21T01:28:00+00:00, externally triggered: False>
[2020-07-23 15:45:53,256] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:27:00+00:00: scheduled__2020-07-21T01:27:00+00:00, externally triggered: False>
[2020-07-23 15:45:53,263] {logging_mixin.py:112} INFO - [2020-07-23 15:45:53,263] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:27:00+00:00: scheduled__2020-07-21T01:27:00+00:00, externally triggered: False> successful
[2020-07-23 15:45:53,388] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:28:00+00:00: scheduled__2020-07-21T01:28:00+00:00, externally triggered: False>
[2020-07-23 15:45:53,403] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:45:53,408] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:28:00+00:00 [scheduled]> in ORM
[2020-07-23 15:45:53,604] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.872 seconds
[2020-07-23 15:46:31,670] {scheduler_job.py:153} INFO - Started process (PID=293662) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:46:31,673] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:46:31,674] {logging_mixin.py:112} INFO - [2020-07-23 15:46:31,674] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:46:31,692] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:46:31,922] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:46:32,728] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:29:00+00:00: scheduled__2020-07-21T01:29:00+00:00, externally triggered: False>
[2020-07-23 15:46:32,735] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:28:00+00:00: scheduled__2020-07-21T01:28:00+00:00, externally triggered: False>
[2020-07-23 15:46:32,748] {logging_mixin.py:112} INFO - [2020-07-23 15:46:32,748] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:28:00+00:00: scheduled__2020-07-21T01:28:00+00:00, externally triggered: False> successful
[2020-07-23 15:46:33,010] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:29:00+00:00: scheduled__2020-07-21T01:29:00+00:00, externally triggered: False>
[2020-07-23 15:46:33,031] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:46:33,038] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:29:00+00:00 [scheduled]> in ORM
[2020-07-23 15:46:33,279] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.609 seconds
[2020-07-23 15:46:46,308] {scheduler_job.py:153} INFO - Started process (PID=294023) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:46:46,323] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:46:46,324] {logging_mixin.py:112} INFO - [2020-07-23 15:46:46,324] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:46:46,365] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:46:46,608] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:46:47,082] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:30:00+00:00: scheduled__2020-07-21T01:30:00+00:00, externally triggered: False>
[2020-07-23 15:46:47,088] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:29:00+00:00: scheduled__2020-07-21T01:29:00+00:00, externally triggered: False>
[2020-07-23 15:46:47,104] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:30:00+00:00: scheduled__2020-07-21T01:30:00+00:00, externally triggered: False>
[2020-07-23 15:46:47,128] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:46:47,135] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:30:00+00:00 [scheduled]> in ORM
[2020-07-23 15:46:47,298] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.990 seconds
[2020-07-23 15:47:49,585] {scheduler_job.py:153} INFO - Started process (PID=295400) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:47:49,603] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:47:49,604] {logging_mixin.py:112} INFO - [2020-07-23 15:47:49,603] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:47:49,655] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:47:49,842] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:47:50,213] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:31:00+00:00: scheduled__2020-07-21T01:31:00+00:00, externally triggered: False>
[2020-07-23 15:47:50,219] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:29:00+00:00: scheduled__2020-07-21T01:29:00+00:00, externally triggered: False>
[2020-07-23 15:47:50,231] {logging_mixin.py:112} INFO - [2020-07-23 15:47:50,231] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:29:00+00:00: scheduled__2020-07-21T01:29:00+00:00, externally triggered: False> successful
[2020-07-23 15:47:50,352] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:30:00+00:00: scheduled__2020-07-21T01:30:00+00:00, externally triggered: False>
[2020-07-23 15:47:50,371] {logging_mixin.py:112} INFO - [2020-07-23 15:47:50,370] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:30:00+00:00: scheduled__2020-07-21T01:30:00+00:00, externally triggered: False> successful
[2020-07-23 15:47:50,552] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:31:00+00:00: scheduled__2020-07-21T01:31:00+00:00, externally triggered: False>
[2020-07-23 15:47:50,571] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:47:50,576] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:31:00+00:00 [scheduled]> in ORM
[2020-07-23 15:47:50,774] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.189 seconds
[2020-07-23 15:48:02,595] {scheduler_job.py:153} INFO - Started process (PID=295811) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:48:02,602] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:48:02,603] {logging_mixin.py:112} INFO - [2020-07-23 15:48:02,603] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:48:02,634] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:48:02,799] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:48:03,207] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:32:00+00:00: scheduled__2020-07-21T01:32:00+00:00, externally triggered: False>
[2020-07-23 15:48:03,213] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:31:00+00:00: scheduled__2020-07-21T01:31:00+00:00, externally triggered: False>
[2020-07-23 15:48:03,224] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:32:00+00:00: scheduled__2020-07-21T01:32:00+00:00, externally triggered: False>
[2020-07-23 15:48:03,240] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:48:03,245] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:32:00+00:00 [scheduled]> in ORM
[2020-07-23 15:48:03,417] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.822 seconds
[2020-07-23 15:49:12,432] {scheduler_job.py:153} INFO - Started process (PID=297218) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:49:12,437] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:49:12,438] {logging_mixin.py:112} INFO - [2020-07-23 15:49:12,438] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:49:12,451] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:49:12,586] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:49:13,101] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:33:00+00:00: scheduled__2020-07-21T01:33:00+00:00, externally triggered: False>
[2020-07-23 15:49:13,110] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:31:00+00:00: scheduled__2020-07-21T01:31:00+00:00, externally triggered: False>
[2020-07-23 15:49:13,131] {logging_mixin.py:112} INFO - [2020-07-23 15:49:13,131] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:31:00+00:00: scheduled__2020-07-21T01:31:00+00:00, externally triggered: False> successful
[2020-07-23 15:49:13,251] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:32:00+00:00: scheduled__2020-07-21T01:32:00+00:00, externally triggered: False>
[2020-07-23 15:49:13,275] {logging_mixin.py:112} INFO - [2020-07-23 15:49:13,275] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:32:00+00:00: scheduled__2020-07-21T01:32:00+00:00, externally triggered: False> successful
[2020-07-23 15:49:13,396] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:33:00+00:00: scheduled__2020-07-21T01:33:00+00:00, externally triggered: False>
[2020-07-23 15:49:13,419] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:49:13,429] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:33:00+00:00 [scheduled]> in ORM
[2020-07-23 15:49:13,584] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.152 seconds
[2020-07-23 15:50:03,311] {scheduler_job.py:153} INFO - Started process (PID=298197) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:50:03,330] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:50:03,330] {logging_mixin.py:112} INFO - [2020-07-23 15:50:03,330] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:50:03,340] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:50:03,523] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:50:03,913] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:34:00+00:00: scheduled__2020-07-21T01:34:00+00:00, externally triggered: False>
[2020-07-23 15:50:03,916] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:33:00+00:00: scheduled__2020-07-21T01:33:00+00:00, externally triggered: False>
[2020-07-23 15:50:03,926] {logging_mixin.py:112} INFO - [2020-07-23 15:50:03,925] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:33:00+00:00: scheduled__2020-07-21T01:33:00+00:00, externally triggered: False> successful
[2020-07-23 15:50:04,107] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:34:00+00:00: scheduled__2020-07-21T01:34:00+00:00, externally triggered: False>
[2020-07-23 15:50:04,128] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:50:04,132] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:34:00+00:00 [scheduled]> in ORM
[2020-07-23 15:50:04,285] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.974 seconds
[2020-07-23 15:51:00,821] {scheduler_job.py:153} INFO - Started process (PID=299372) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:51:00,843] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:51:00,844] {logging_mixin.py:112} INFO - [2020-07-23 15:51:00,844] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:51:00,890] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:51:01,115] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:51:01,556] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:35:00+00:00: scheduled__2020-07-21T01:35:00+00:00, externally triggered: False>
[2020-07-23 15:51:01,566] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:34:00+00:00: scheduled__2020-07-21T01:34:00+00:00, externally triggered: False>
[2020-07-23 15:51:01,581] {logging_mixin.py:112} INFO - [2020-07-23 15:51:01,581] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:34:00+00:00: scheduled__2020-07-21T01:34:00+00:00, externally triggered: False> successful
[2020-07-23 15:51:01,750] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:35:00+00:00: scheduled__2020-07-21T01:35:00+00:00, externally triggered: False>
[2020-07-23 15:51:01,771] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:51:01,775] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:35:00+00:00 [scheduled]> in ORM
[2020-07-23 15:51:01,928] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.107 seconds
[2020-07-23 15:51:53,194] {scheduler_job.py:153} INFO - Started process (PID=300360) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:51:53,201] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:51:53,202] {logging_mixin.py:112} INFO - [2020-07-23 15:51:53,202] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:51:53,222] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:51:53,358] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:51:54,223] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:36:00+00:00: scheduled__2020-07-21T01:36:00+00:00, externally triggered: False>
[2020-07-23 15:51:54,229] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:35:00+00:00: scheduled__2020-07-21T01:35:00+00:00, externally triggered: False>
[2020-07-23 15:51:54,236] {logging_mixin.py:112} INFO - [2020-07-23 15:51:54,236] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:35:00+00:00: scheduled__2020-07-21T01:35:00+00:00, externally triggered: False> successful
[2020-07-23 15:51:54,600] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:36:00+00:00: scheduled__2020-07-21T01:36:00+00:00, externally triggered: False>
[2020-07-23 15:51:54,623] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:51:54,628] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:36:00+00:00 [scheduled]> in ORM
[2020-07-23 15:51:55,395] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.202 seconds
[2020-07-23 15:52:35,735] {scheduler_job.py:153} INFO - Started process (PID=301314) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:52:35,755] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:52:35,755] {logging_mixin.py:112} INFO - [2020-07-23 15:52:35,755] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:52:35,810] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:52:36,025] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:52:36,430] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:37:00+00:00: scheduled__2020-07-21T01:37:00+00:00, externally triggered: False>
[2020-07-23 15:52:36,433] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:36:00+00:00: scheduled__2020-07-21T01:36:00+00:00, externally triggered: False>
[2020-07-23 15:52:36,440] {logging_mixin.py:112} INFO - [2020-07-23 15:52:36,440] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:36:00+00:00: scheduled__2020-07-21T01:36:00+00:00, externally triggered: False> successful
[2020-07-23 15:52:36,573] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:37:00+00:00: scheduled__2020-07-21T01:37:00+00:00, externally triggered: False>
[2020-07-23 15:52:36,587] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:52:36,592] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:37:00+00:00 [scheduled]> in ORM
[2020-07-23 15:52:36,761] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.026 seconds
[2020-07-23 15:53:15,201] {scheduler_job.py:153} INFO - Started process (PID=302213) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:53:15,215] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:53:15,216] {logging_mixin.py:112} INFO - [2020-07-23 15:53:15,216] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:53:15,234] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:53:15,557] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:53:16,166] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:38:00+00:00: scheduled__2020-07-21T01:38:00+00:00, externally triggered: False>
[2020-07-23 15:53:16,170] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:37:00+00:00: scheduled__2020-07-21T01:37:00+00:00, externally triggered: False>
[2020-07-23 15:53:16,183] {logging_mixin.py:112} INFO - [2020-07-23 15:53:16,182] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:37:00+00:00: scheduled__2020-07-21T01:37:00+00:00, externally triggered: False> successful
[2020-07-23 15:53:16,407] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:38:00+00:00: scheduled__2020-07-21T01:38:00+00:00, externally triggered: False>
[2020-07-23 15:53:16,425] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:53:16,428] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:38:00+00:00 [scheduled]> in ORM
[2020-07-23 15:53:16,597] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.396 seconds
[2020-07-23 15:54:01,657] {scheduler_job.py:153} INFO - Started process (PID=303253) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:54:01,661] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:54:01,662] {logging_mixin.py:112} INFO - [2020-07-23 15:54:01,662] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:54:01,673] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:54:01,818] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:54:02,186] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:39:00+00:00: scheduled__2020-07-21T01:39:00+00:00, externally triggered: False>
[2020-07-23 15:54:02,189] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:38:00+00:00: scheduled__2020-07-21T01:38:00+00:00, externally triggered: False>
[2020-07-23 15:54:02,197] {logging_mixin.py:112} INFO - [2020-07-23 15:54:02,196] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:38:00+00:00: scheduled__2020-07-21T01:38:00+00:00, externally triggered: False> successful
[2020-07-23 15:54:02,408] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:39:00+00:00: scheduled__2020-07-21T01:39:00+00:00, externally triggered: False>
[2020-07-23 15:54:02,427] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:54:02,431] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:39:00+00:00 [scheduled]> in ORM
[2020-07-23 15:54:02,695] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.037 seconds
[2020-07-23 15:54:41,296] {scheduler_job.py:153} INFO - Started process (PID=304130) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:54:41,301] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:54:41,302] {logging_mixin.py:112} INFO - [2020-07-23 15:54:41,301] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:54:41,319] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:54:41,482] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:54:41,831] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:40:00+00:00: scheduled__2020-07-21T01:40:00+00:00, externally triggered: False>
[2020-07-23 15:54:41,834] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:39:00+00:00: scheduled__2020-07-21T01:39:00+00:00, externally triggered: False>
[2020-07-23 15:54:41,842] {logging_mixin.py:112} INFO - [2020-07-23 15:54:41,842] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:39:00+00:00: scheduled__2020-07-21T01:39:00+00:00, externally triggered: False> successful
[2020-07-23 15:54:41,952] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:40:00+00:00: scheduled__2020-07-21T01:40:00+00:00, externally triggered: False>
[2020-07-23 15:54:41,965] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:54:41,969] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:40:00+00:00 [scheduled]> in ORM
[2020-07-23 15:54:42,142] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.846 seconds
[2020-07-23 15:55:16,855] {scheduler_job.py:153} INFO - Started process (PID=305004) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:55:16,861] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:55:16,862] {logging_mixin.py:112} INFO - [2020-07-23 15:55:16,861] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:55:16,872] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:55:17,040] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:55:17,459] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:41:00+00:00: scheduled__2020-07-21T01:41:00+00:00, externally triggered: False>
[2020-07-23 15:55:17,463] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:40:00+00:00: scheduled__2020-07-21T01:40:00+00:00, externally triggered: False>
[2020-07-23 15:55:17,471] {logging_mixin.py:112} INFO - [2020-07-23 15:55:17,470] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:40:00+00:00: scheduled__2020-07-21T01:40:00+00:00, externally triggered: False> successful
[2020-07-23 15:55:17,586] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:41:00+00:00: scheduled__2020-07-21T01:41:00+00:00, externally triggered: False>
[2020-07-23 15:55:17,610] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:55:17,620] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:41:00+00:00 [scheduled]> in ORM
[2020-07-23 15:55:17,821] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.966 seconds
[2020-07-23 15:55:52,060] {scheduler_job.py:153} INFO - Started process (PID=305813) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:55:52,082] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:55:52,083] {logging_mixin.py:112} INFO - [2020-07-23 15:55:52,082] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:55:52,114] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:55:52,403] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:55:52,852] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:42:00+00:00: scheduled__2020-07-21T01:42:00+00:00, externally triggered: False>
[2020-07-23 15:55:52,860] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:41:00+00:00: scheduled__2020-07-21T01:41:00+00:00, externally triggered: False>
[2020-07-23 15:55:52,897] {logging_mixin.py:112} INFO - [2020-07-23 15:55:52,897] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:41:00+00:00: scheduled__2020-07-21T01:41:00+00:00, externally triggered: False> successful
[2020-07-23 15:55:53,021] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:42:00+00:00: scheduled__2020-07-21T01:42:00+00:00, externally triggered: False>
[2020-07-23 15:55:53,046] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:55:53,230] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:42:00+00:00 [scheduled]> in ORM
[2020-07-23 15:55:53,385] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.325 seconds
[2020-07-23 15:56:30,410] {scheduler_job.py:153} INFO - Started process (PID=306901) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:56:30,417] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:56:30,418] {logging_mixin.py:112} INFO - [2020-07-23 15:56:30,418] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:56:30,466] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:56:30,681] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:56:31,114] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:43:00+00:00: scheduled__2020-07-21T01:43:00+00:00, externally triggered: False>
[2020-07-23 15:56:31,119] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:42:00+00:00: scheduled__2020-07-21T01:42:00+00:00, externally triggered: False>
[2020-07-23 15:56:31,133] {logging_mixin.py:112} INFO - [2020-07-23 15:56:31,133] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:42:00+00:00: scheduled__2020-07-21T01:42:00+00:00, externally triggered: False> successful
[2020-07-23 15:56:31,243] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:43:00+00:00: scheduled__2020-07-21T01:43:00+00:00, externally triggered: False>
[2020-07-23 15:56:31,270] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:56:31,277] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:43:00+00:00 [scheduled]> in ORM
[2020-07-23 15:56:31,497] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.088 seconds
[2020-07-23 15:57:28,263] {scheduler_job.py:153} INFO - Started process (PID=308160) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:57:28,268] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:57:28,268] {logging_mixin.py:112} INFO - [2020-07-23 15:57:28,268] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:57:28,282] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:57:28,539] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:57:29,018] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:44:00+00:00: scheduled__2020-07-21T01:44:00+00:00, externally triggered: False>
[2020-07-23 15:57:29,023] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:43:00+00:00: scheduled__2020-07-21T01:43:00+00:00, externally triggered: False>
[2020-07-23 15:57:29,030] {logging_mixin.py:112} INFO - [2020-07-23 15:57:29,030] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:43:00+00:00: scheduled__2020-07-21T01:43:00+00:00, externally triggered: False> successful
[2020-07-23 15:57:29,144] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:44:00+00:00: scheduled__2020-07-21T01:44:00+00:00, externally triggered: False>
[2020-07-23 15:57:29,164] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:57:29,168] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:44:00+00:00 [scheduled]> in ORM
[2020-07-23 15:57:29,700] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.437 seconds
[2020-07-23 15:57:40,449] {scheduler_job.py:153} INFO - Started process (PID=308472) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:57:40,455] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:57:40,456] {logging_mixin.py:112} INFO - [2020-07-23 15:57:40,456] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:57:40,492] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:57:40,712] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:57:41,106] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:45:00+00:00: scheduled__2020-07-21T01:45:00+00:00, externally triggered: False>
[2020-07-23 15:57:41,110] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:44:00+00:00: scheduled__2020-07-21T01:44:00+00:00, externally triggered: False>
[2020-07-23 15:57:41,120] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:45:00+00:00: scheduled__2020-07-21T01:45:00+00:00, externally triggered: False>
[2020-07-23 15:57:41,150] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:57:41,156] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:45:00+00:00 [scheduled]> in ORM
[2020-07-23 15:57:41,331] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.882 seconds
[2020-07-23 15:58:40,127] {scheduler_job.py:153} INFO - Started process (PID=309706) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:58:40,130] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:58:40,131] {logging_mixin.py:112} INFO - [2020-07-23 15:58:40,131] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:58:40,143] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:58:40,493] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:58:41,014] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:46:00+00:00: scheduled__2020-07-21T01:46:00+00:00, externally triggered: False>
[2020-07-23 15:58:41,018] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:44:00+00:00: scheduled__2020-07-21T01:44:00+00:00, externally triggered: False>
[2020-07-23 15:58:41,028] {logging_mixin.py:112} INFO - [2020-07-23 15:58:41,028] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:44:00+00:00: scheduled__2020-07-21T01:44:00+00:00, externally triggered: False> successful
[2020-07-23 15:58:41,134] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:45:00+00:00: scheduled__2020-07-21T01:45:00+00:00, externally triggered: False>
[2020-07-23 15:58:41,143] {logging_mixin.py:112} INFO - [2020-07-23 15:58:41,143] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:45:00+00:00: scheduled__2020-07-21T01:45:00+00:00, externally triggered: False> successful
[2020-07-23 15:58:41,279] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:46:00+00:00: scheduled__2020-07-21T01:46:00+00:00, externally triggered: False>
[2020-07-23 15:58:41,299] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:58:41,302] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:46:00+00:00 [scheduled]> in ORM
[2020-07-23 15:58:41,572] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.446 seconds
[2020-07-23 15:59:25,343] {scheduler_job.py:153} INFO - Started process (PID=310667) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:59:25,348] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:59:25,348] {logging_mixin.py:112} INFO - [2020-07-23 15:59:25,348] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:59:25,429] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:59:25,668] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 15:59:26,175] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:47:00+00:00: scheduled__2020-07-21T01:47:00+00:00, externally triggered: False>
[2020-07-23 15:59:26,186] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:46:00+00:00: scheduled__2020-07-21T01:46:00+00:00, externally triggered: False>
[2020-07-23 15:59:26,204] {logging_mixin.py:112} INFO - [2020-07-23 15:59:26,204] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:46:00+00:00: scheduled__2020-07-21T01:46:00+00:00, externally triggered: False> successful
[2020-07-23 15:59:26,346] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:47:00+00:00: scheduled__2020-07-21T01:47:00+00:00, externally triggered: False>
[2020-07-23 15:59:26,364] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 15:59:26,370] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:47:00+00:00 [scheduled]> in ORM
[2020-07-23 15:59:26,567] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.225 seconds
[2020-07-23 15:59:59,556] {scheduler_job.py:153} INFO - Started process (PID=311485) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:59:59,574] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 15:59:59,576] {logging_mixin.py:112} INFO - [2020-07-23 15:59:59,576] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:59:59,613] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 15:59:59,800] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:00:00,141] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:48:00+00:00: scheduled__2020-07-21T01:48:00+00:00, externally triggered: False>
[2020-07-23 16:00:00,146] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:47:00+00:00: scheduled__2020-07-21T01:47:00+00:00, externally triggered: False>
[2020-07-23 16:00:00,154] {logging_mixin.py:112} INFO - [2020-07-23 16:00:00,154] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:47:00+00:00: scheduled__2020-07-21T01:47:00+00:00, externally triggered: False> successful
[2020-07-23 16:00:00,259] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:48:00+00:00: scheduled__2020-07-21T01:48:00+00:00, externally triggered: False>
[2020-07-23 16:00:00,278] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:00:00,282] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:48:00+00:00 [scheduled]> in ORM
[2020-07-23 16:00:00,437] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.881 seconds
[2020-07-23 16:00:44,650] {scheduler_job.py:153} INFO - Started process (PID=312444) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:00:44,655] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:00:44,655] {logging_mixin.py:112} INFO - [2020-07-23 16:00:44,655] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:00:44,670] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:00:44,799] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:00:45,222] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:49:00+00:00: scheduled__2020-07-21T01:49:00+00:00, externally triggered: False>
[2020-07-23 16:00:45,225] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:48:00+00:00: scheduled__2020-07-21T01:48:00+00:00, externally triggered: False>
[2020-07-23 16:00:45,232] {logging_mixin.py:112} INFO - [2020-07-23 16:00:45,232] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:48:00+00:00: scheduled__2020-07-21T01:48:00+00:00, externally triggered: False> successful
[2020-07-23 16:00:45,348] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:49:00+00:00: scheduled__2020-07-21T01:49:00+00:00, externally triggered: False>
[2020-07-23 16:00:45,363] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:00:45,370] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:49:00+00:00 [scheduled]> in ORM
[2020-07-23 16:00:45,553] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.903 seconds
[2020-07-23 16:01:27,463] {scheduler_job.py:153} INFO - Started process (PID=313392) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:01:27,470] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:01:27,471] {logging_mixin.py:112} INFO - [2020-07-23 16:01:27,471] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:01:27,485] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:01:27,716] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:01:28,077] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:50:00+00:00: scheduled__2020-07-21T01:50:00+00:00, externally triggered: False>
[2020-07-23 16:01:28,094] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:49:00+00:00: scheduled__2020-07-21T01:49:00+00:00, externally triggered: False>
[2020-07-23 16:01:28,131] {logging_mixin.py:112} INFO - [2020-07-23 16:01:28,131] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:49:00+00:00: scheduled__2020-07-21T01:49:00+00:00, externally triggered: False> successful
[2020-07-23 16:01:28,295] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:50:00+00:00: scheduled__2020-07-21T01:50:00+00:00, externally triggered: False>
[2020-07-23 16:01:28,333] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:01:28,342] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:50:00+00:00 [scheduled]> in ORM
[2020-07-23 16:01:28,503] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.040 seconds
[2020-07-23 16:02:11,057] {scheduler_job.py:153} INFO - Started process (PID=314341) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:02:11,061] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:02:11,062] {logging_mixin.py:112} INFO - [2020-07-23 16:02:11,062] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:02:11,080] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:02:11,264] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:02:11,603] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:51:00+00:00: scheduled__2020-07-21T01:51:00+00:00, externally triggered: False>
[2020-07-23 16:02:11,607] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:50:00+00:00: scheduled__2020-07-21T01:50:00+00:00, externally triggered: False>
[2020-07-23 16:02:11,615] {logging_mixin.py:112} INFO - [2020-07-23 16:02:11,615] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:50:00+00:00: scheduled__2020-07-21T01:50:00+00:00, externally triggered: False> successful
[2020-07-23 16:02:11,739] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:51:00+00:00: scheduled__2020-07-21T01:51:00+00:00, externally triggered: False>
[2020-07-23 16:02:11,756] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:02:11,762] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:51:00+00:00 [scheduled]> in ORM
[2020-07-23 16:02:11,962] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.906 seconds
[2020-07-23 16:02:49,122] {scheduler_job.py:153} INFO - Started process (PID=315173) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:02:49,127] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:02:49,128] {logging_mixin.py:112} INFO - [2020-07-23 16:02:49,128] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:02:49,144] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:02:49,299] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:02:49,698] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:52:00+00:00: scheduled__2020-07-21T01:52:00+00:00, externally triggered: False>
[2020-07-23 16:02:49,701] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:51:00+00:00: scheduled__2020-07-21T01:51:00+00:00, externally triggered: False>
[2020-07-23 16:02:49,708] {logging_mixin.py:112} INFO - [2020-07-23 16:02:49,708] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:51:00+00:00: scheduled__2020-07-21T01:51:00+00:00, externally triggered: False> successful
[2020-07-23 16:02:49,863] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:52:00+00:00: scheduled__2020-07-21T01:52:00+00:00, externally triggered: False>
[2020-07-23 16:02:49,881] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:02:49,885] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:52:00+00:00 [scheduled]> in ORM
[2020-07-23 16:02:50,053] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.931 seconds
[2020-07-23 16:03:32,984] {scheduler_job.py:153} INFO - Started process (PID=316204) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:03:32,990] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:03:32,992] {logging_mixin.py:112} INFO - [2020-07-23 16:03:32,991] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:03:33,009] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:03:33,171] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:03:33,659] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:53:00+00:00: scheduled__2020-07-21T01:53:00+00:00, externally triggered: False>
[2020-07-23 16:03:33,663] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:52:00+00:00: scheduled__2020-07-21T01:52:00+00:00, externally triggered: False>
[2020-07-23 16:03:33,671] {logging_mixin.py:112} INFO - [2020-07-23 16:03:33,671] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:52:00+00:00: scheduled__2020-07-21T01:52:00+00:00, externally triggered: False> successful
[2020-07-23 16:03:33,798] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:53:00+00:00: scheduled__2020-07-21T01:53:00+00:00, externally triggered: False>
[2020-07-23 16:03:33,816] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:03:33,821] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:53:00+00:00 [scheduled]> in ORM
[2020-07-23 16:03:34,011] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.027 seconds
[2020-07-23 16:04:05,066] {scheduler_job.py:153} INFO - Started process (PID=316971) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:04:05,071] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:04:05,071] {logging_mixin.py:112} INFO - [2020-07-23 16:04:05,071] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:04:05,086] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:04:05,443] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:04:06,337] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:54:00+00:00: scheduled__2020-07-21T01:54:00+00:00, externally triggered: False>
[2020-07-23 16:04:06,348] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:53:00+00:00: scheduled__2020-07-21T01:53:00+00:00, externally triggered: False>
[2020-07-23 16:04:06,372] {logging_mixin.py:112} INFO - [2020-07-23 16:04:06,372] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:53:00+00:00: scheduled__2020-07-21T01:53:00+00:00, externally triggered: False> successful
[2020-07-23 16:04:06,776] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:54:00+00:00: scheduled__2020-07-21T01:54:00+00:00, externally triggered: False>
[2020-07-23 16:04:06,814] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:04:06,820] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:54:00+00:00 [scheduled]> in ORM
[2020-07-23 16:04:07,121] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.054 seconds
[2020-07-23 16:05:06,834] {scheduler_job.py:153} INFO - Started process (PID=318215) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:05:06,839] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:05:06,840] {logging_mixin.py:112} INFO - [2020-07-23 16:05:06,840] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:05:06,856] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:05:07,017] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:05:07,620] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:55:00+00:00: scheduled__2020-07-21T01:55:00+00:00, externally triggered: False>
[2020-07-23 16:05:07,624] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:54:00+00:00: scheduled__2020-07-21T01:54:00+00:00, externally triggered: False>
[2020-07-23 16:05:07,632] {logging_mixin.py:112} INFO - [2020-07-23 16:05:07,632] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:54:00+00:00: scheduled__2020-07-21T01:54:00+00:00, externally triggered: False> successful
[2020-07-23 16:05:07,745] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:55:00+00:00: scheduled__2020-07-21T01:55:00+00:00, externally triggered: False>
[2020-07-23 16:05:07,763] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:05:07,766] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:55:00+00:00 [scheduled]> in ORM
[2020-07-23 16:05:07,934] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.100 seconds
[2020-07-23 16:05:19,559] {scheduler_job.py:153} INFO - Started process (PID=318569) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:05:19,564] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:05:19,565] {logging_mixin.py:112} INFO - [2020-07-23 16:05:19,565] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:05:19,584] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:05:19,766] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:05:20,096] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:56:00+00:00: scheduled__2020-07-21T01:56:00+00:00, externally triggered: False>
[2020-07-23 16:05:20,102] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:55:00+00:00: scheduled__2020-07-21T01:55:00+00:00, externally triggered: False>
[2020-07-23 16:05:20,115] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:56:00+00:00: scheduled__2020-07-21T01:56:00+00:00, externally triggered: False>
[2020-07-23 16:05:20,143] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:05:20,156] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:56:00+00:00 [scheduled]> in ORM
[2020-07-23 16:05:20,334] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.775 seconds
[2020-07-23 16:07:43,704] {scheduler_job.py:153} INFO - Started process (PID=321057) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:07:43,724] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:07:43,725] {logging_mixin.py:112} INFO - [2020-07-23 16:07:43,725] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:07:43,760] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:07:44,014] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:07:44,745] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:57:00+00:00: scheduled__2020-07-21T01:57:00+00:00, externally triggered: False>
[2020-07-23 16:07:44,753] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:55:00+00:00: scheduled__2020-07-21T01:55:00+00:00, externally triggered: False>
[2020-07-23 16:07:44,770] {logging_mixin.py:112} INFO - [2020-07-23 16:07:44,770] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:55:00+00:00: scheduled__2020-07-21T01:55:00+00:00, externally triggered: False> successful
[2020-07-23 16:07:45,217] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:56:00+00:00: scheduled__2020-07-21T01:56:00+00:00, externally triggered: False>
[2020-07-23 16:07:45,312] {logging_mixin.py:112} INFO - [2020-07-23 16:07:45,311] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:56:00+00:00: scheduled__2020-07-21T01:56:00+00:00, externally triggered: False> successful
[2020-07-23 16:07:45,520] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:57:00+00:00: scheduled__2020-07-21T01:57:00+00:00, externally triggered: False>
[2020-07-23 16:07:45,890] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:07:45,928] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:57:00+00:00 [scheduled]> in ORM
[2020-07-23 16:07:46,109] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.406 seconds
[2020-07-23 16:08:16,884] {scheduler_job.py:153} INFO - Started process (PID=321826) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:08:16,903] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:08:16,904] {logging_mixin.py:112} INFO - [2020-07-23 16:08:16,904] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:08:16,956] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:08:17,436] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:08:18,283] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:58:00+00:00: scheduled__2020-07-21T01:58:00+00:00, externally triggered: False>
[2020-07-23 16:08:18,314] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:57:00+00:00: scheduled__2020-07-21T01:57:00+00:00, externally triggered: False>
[2020-07-23 16:08:18,339] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:58:00+00:00: scheduled__2020-07-21T01:58:00+00:00, externally triggered: False>
[2020-07-23 16:08:18,399] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:08:18,410] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:58:00+00:00 [scheduled]> in ORM
[2020-07-23 16:08:18,831] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.947 seconds
[2020-07-23 16:10:28,572] {scheduler_job.py:153} INFO - Started process (PID=324330) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:10:28,581] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:10:28,582] {logging_mixin.py:112} INFO - [2020-07-23 16:10:28,581] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:10:28,609] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:10:28,770] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:10:29,220] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T01:59:00+00:00: scheduled__2020-07-21T01:59:00+00:00, externally triggered: False>
[2020-07-23 16:10:29,228] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:57:00+00:00: scheduled__2020-07-21T01:57:00+00:00, externally triggered: False>
[2020-07-23 16:10:29,238] {logging_mixin.py:112} INFO - [2020-07-23 16:10:29,238] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:57:00+00:00: scheduled__2020-07-21T01:57:00+00:00, externally triggered: False> successful
[2020-07-23 16:10:29,377] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:58:00+00:00: scheduled__2020-07-21T01:58:00+00:00, externally triggered: False>
[2020-07-23 16:10:29,406] {logging_mixin.py:112} INFO - [2020-07-23 16:10:29,401] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:58:00+00:00: scheduled__2020-07-21T01:58:00+00:00, externally triggered: False> successful
[2020-07-23 16:10:29,689] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:59:00+00:00: scheduled__2020-07-21T01:59:00+00:00, externally triggered: False>
[2020-07-23 16:10:29,726] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:10:29,734] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 01:59:00+00:00 [scheduled]> in ORM
[2020-07-23 16:10:29,922] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.351 seconds
[2020-07-23 16:12:08,245] {scheduler_job.py:153} INFO - Started process (PID=326256) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:12:08,251] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:12:08,252] {logging_mixin.py:112} INFO - [2020-07-23 16:12:08,252] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:12:08,267] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:12:08,419] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:12:08,830] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:00:00+00:00: scheduled__2020-07-21T02:00:00+00:00, externally triggered: False>
[2020-07-23 16:12:08,847] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 01:59:00+00:00: scheduled__2020-07-21T01:59:00+00:00, externally triggered: False>
[2020-07-23 16:12:08,862] {logging_mixin.py:112} INFO - [2020-07-23 16:12:08,861] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 01:59:00+00:00: scheduled__2020-07-21T01:59:00+00:00, externally triggered: False> successful
[2020-07-23 16:12:09,025] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:00:00+00:00: scheduled__2020-07-21T02:00:00+00:00, externally triggered: False>
[2020-07-23 16:12:09,043] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:12:09,050] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:00:00+00:00 [scheduled]> in ORM
[2020-07-23 16:12:09,215] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.970 seconds
[2020-07-23 16:13:14,592] {scheduler_job.py:153} INFO - Started process (PID=327662) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:13:14,595] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:13:14,596] {logging_mixin.py:112} INFO - [2020-07-23 16:13:14,596] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:13:14,604] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:13:14,782] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:13:15,204] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:01:00+00:00: scheduled__2020-07-21T02:01:00+00:00, externally triggered: False>
[2020-07-23 16:13:15,208] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:00:00+00:00: scheduled__2020-07-21T02:00:00+00:00, externally triggered: False>
[2020-07-23 16:13:15,217] {logging_mixin.py:112} INFO - [2020-07-23 16:13:15,217] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:00:00+00:00: scheduled__2020-07-21T02:00:00+00:00, externally triggered: False> successful
[2020-07-23 16:13:15,384] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:01:00+00:00: scheduled__2020-07-21T02:01:00+00:00, externally triggered: False>
[2020-07-23 16:13:15,403] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:13:15,408] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:01:00+00:00 [scheduled]> in ORM
[2020-07-23 16:13:15,573] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.981 seconds
[2020-07-23 16:14:12,152] {scheduler_job.py:153} INFO - Started process (PID=328776) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:14:12,158] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:14:12,159] {logging_mixin.py:112} INFO - [2020-07-23 16:14:12,159] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:14:12,171] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:14:12,333] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:14:12,693] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:02:00+00:00: scheduled__2020-07-21T02:02:00+00:00, externally triggered: False>
[2020-07-23 16:14:12,698] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:01:00+00:00: scheduled__2020-07-21T02:01:00+00:00, externally triggered: False>
[2020-07-23 16:14:12,708] {logging_mixin.py:112} INFO - [2020-07-23 16:14:12,708] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:01:00+00:00: scheduled__2020-07-21T02:01:00+00:00, externally triggered: False> successful
[2020-07-23 16:14:12,819] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:02:00+00:00: scheduled__2020-07-21T02:02:00+00:00, externally triggered: False>
[2020-07-23 16:14:12,839] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:14:12,843] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:02:00+00:00 [scheduled]> in ORM
[2020-07-23 16:14:12,986] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.834 seconds
[2020-07-23 16:15:04,617] {scheduler_job.py:153} INFO - Started process (PID=329833) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:15:04,637] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:15:04,642] {logging_mixin.py:112} INFO - [2020-07-23 16:15:04,642] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:15:04,740] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:15:05,006] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:15:05,505] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:03:00+00:00: scheduled__2020-07-21T02:03:00+00:00, externally triggered: False>
[2020-07-23 16:15:05,509] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:02:00+00:00: scheduled__2020-07-21T02:02:00+00:00, externally triggered: False>
[2020-07-23 16:15:05,519] {logging_mixin.py:112} INFO - [2020-07-23 16:15:05,519] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:02:00+00:00: scheduled__2020-07-21T02:02:00+00:00, externally triggered: False> successful
[2020-07-23 16:15:05,654] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:03:00+00:00: scheduled__2020-07-21T02:03:00+00:00, externally triggered: False>
[2020-07-23 16:15:05,672] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:15:05,676] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:03:00+00:00 [scheduled]> in ORM
[2020-07-23 16:15:05,845] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.228 seconds
[2020-07-23 16:15:55,818] {scheduler_job.py:153} INFO - Started process (PID=330891) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:15:55,822] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:15:55,823] {logging_mixin.py:112} INFO - [2020-07-23 16:15:55,822] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:15:55,833] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:15:56,063] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:15:56,763] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:04:00+00:00: scheduled__2020-07-21T02:04:00+00:00, externally triggered: False>
[2020-07-23 16:15:56,768] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:03:00+00:00: scheduled__2020-07-21T02:03:00+00:00, externally triggered: False>
[2020-07-23 16:15:56,778] {logging_mixin.py:112} INFO - [2020-07-23 16:15:56,778] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:03:00+00:00: scheduled__2020-07-21T02:03:00+00:00, externally triggered: False> successful
[2020-07-23 16:15:57,011] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:04:00+00:00: scheduled__2020-07-21T02:04:00+00:00, externally triggered: False>
[2020-07-23 16:15:57,036] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:15:57,045] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:04:00+00:00 [scheduled]> in ORM
[2020-07-23 16:15:57,376] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.558 seconds
[2020-07-23 16:17:02,494] {scheduler_job.py:153} INFO - Started process (PID=332162) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:17:02,504] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:17:02,504] {logging_mixin.py:112} INFO - [2020-07-23 16:17:02,504] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:17:02,538] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:17:02,755] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:17:03,251] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:05:00+00:00: scheduled__2020-07-21T02:05:00+00:00, externally triggered: False>
[2020-07-23 16:17:03,256] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:04:00+00:00: scheduled__2020-07-21T02:04:00+00:00, externally triggered: False>
[2020-07-23 16:17:03,273] {logging_mixin.py:112} INFO - [2020-07-23 16:17:03,273] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:04:00+00:00: scheduled__2020-07-21T02:04:00+00:00, externally triggered: False> successful
[2020-07-23 16:17:03,592] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:05:00+00:00: scheduled__2020-07-21T02:05:00+00:00, externally triggered: False>
[2020-07-23 16:17:03,621] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:17:03,629] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:05:00+00:00 [scheduled]> in ORM
[2020-07-23 16:17:03,789] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.295 seconds
[2020-07-23 16:17:55,885] {scheduler_job.py:153} INFO - Started process (PID=333245) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:17:55,888] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:17:55,889] {logging_mixin.py:112} INFO - [2020-07-23 16:17:55,889] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:17:55,900] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:17:56,013] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:17:56,649] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:06:00+00:00: scheduled__2020-07-21T02:06:00+00:00, externally triggered: False>
[2020-07-23 16:17:56,654] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:05:00+00:00: scheduled__2020-07-21T02:05:00+00:00, externally triggered: False>
[2020-07-23 16:17:56,666] {logging_mixin.py:112} INFO - [2020-07-23 16:17:56,665] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:05:00+00:00: scheduled__2020-07-21T02:05:00+00:00, externally triggered: False> successful
[2020-07-23 16:17:56,835] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:06:00+00:00: scheduled__2020-07-21T02:06:00+00:00, externally triggered: False>
[2020-07-23 16:17:56,863] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:17:56,868] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:06:00+00:00 [scheduled]> in ORM
[2020-07-23 16:17:57,017] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.132 seconds
[2020-07-23 16:18:53,603] {scheduler_job.py:153} INFO - Started process (PID=334349) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:18:53,608] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:18:53,609] {logging_mixin.py:112} INFO - [2020-07-23 16:18:53,609] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:18:53,622] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:18:53,810] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:18:54,133] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:07:00+00:00: scheduled__2020-07-21T02:07:00+00:00, externally triggered: False>
[2020-07-23 16:18:54,140] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:06:00+00:00: scheduled__2020-07-21T02:06:00+00:00, externally triggered: False>
[2020-07-23 16:18:54,153] {logging_mixin.py:112} INFO - [2020-07-23 16:18:54,153] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:06:00+00:00: scheduled__2020-07-21T02:06:00+00:00, externally triggered: False> successful
[2020-07-23 16:18:54,284] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:07:00+00:00: scheduled__2020-07-21T02:07:00+00:00, externally triggered: False>
[2020-07-23 16:18:54,312] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-23 10:48:06.127901+00:00: manual__2020-07-23T10:48:06.127901+00:00, externally triggered: True>
[2020-07-23 16:18:54,361] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:18:54,374] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:07:00+00:00 [scheduled]> in ORM
[2020-07-23 16:18:54,387] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-23 10:48:06.127901+00:00 [scheduled]> in ORM
[2020-07-23 16:18:54,588] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.986 seconds
[2020-07-23 16:20:33,609] {scheduler_job.py:153} INFO - Started process (PID=336278) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:20:33,616] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:20:33,617] {logging_mixin.py:112} INFO - [2020-07-23 16:20:33,617] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:20:33,645] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:20:33,786] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:20:34,321] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:08:00+00:00: scheduled__2020-07-21T02:08:00+00:00, externally triggered: False>
[2020-07-23 16:20:34,327] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:07:00+00:00: scheduled__2020-07-21T02:07:00+00:00, externally triggered: False>
[2020-07-23 16:20:34,339] {logging_mixin.py:112} INFO - [2020-07-23 16:20:34,339] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:07:00+00:00: scheduled__2020-07-21T02:07:00+00:00, externally triggered: False> successful
[2020-07-23 16:20:34,499] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:08:00+00:00: scheduled__2020-07-21T02:08:00+00:00, externally triggered: False>
[2020-07-23 16:20:34,511] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-23 10:48:06.127901+00:00: manual__2020-07-23T10:48:06.127901+00:00, externally triggered: True>
[2020-07-23 16:20:34,525] {logging_mixin.py:112} INFO - [2020-07-23 16:20:34,524] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-23 10:48:06.127901+00:00: manual__2020-07-23T10:48:06.127901+00:00, externally triggered: True> successful
[2020-07-23 16:20:34,631] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:20:34,648] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:08:00+00:00 [scheduled]> in ORM
[2020-07-23 16:20:34,832] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.223 seconds
[2020-07-23 16:21:23,361] {scheduler_job.py:153} INFO - Started process (PID=337283) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:21:23,368] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:21:23,369] {logging_mixin.py:112} INFO - [2020-07-23 16:21:23,369] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:21:23,400] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:21:23,555] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:21:23,910] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:09:00+00:00: scheduled__2020-07-21T02:09:00+00:00, externally triggered: False>
[2020-07-23 16:21:23,917] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:08:00+00:00: scheduled__2020-07-21T02:08:00+00:00, externally triggered: False>
[2020-07-23 16:21:23,931] {logging_mixin.py:112} INFO - [2020-07-23 16:21:23,931] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:08:00+00:00: scheduled__2020-07-21T02:08:00+00:00, externally triggered: False> successful
[2020-07-23 16:21:24,045] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:09:00+00:00: scheduled__2020-07-21T02:09:00+00:00, externally triggered: False>
[2020-07-23 16:21:24,062] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:21:24,068] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:09:00+00:00 [scheduled]> in ORM
[2020-07-23 16:21:24,246] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.885 seconds
[2020-07-23 16:22:12,528] {scheduler_job.py:153} INFO - Started process (PID=338293) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:22:12,532] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:22:12,533] {logging_mixin.py:112} INFO - [2020-07-23 16:22:12,533] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:22:12,547] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:22:12,833] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:22:14,581] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:10:00+00:00: scheduled__2020-07-21T02:10:00+00:00, externally triggered: False>
[2020-07-23 16:22:14,588] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:09:00+00:00: scheduled__2020-07-21T02:09:00+00:00, externally triggered: False>
[2020-07-23 16:22:14,602] {logging_mixin.py:112} INFO - [2020-07-23 16:22:14,601] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:09:00+00:00: scheduled__2020-07-21T02:09:00+00:00, externally triggered: False> successful
[2020-07-23 16:22:15,113] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:10:00+00:00: scheduled__2020-07-21T02:10:00+00:00, externally triggered: False>
[2020-07-23 16:22:15,127] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:22:15,131] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:10:00+00:00 [scheduled]> in ORM
[2020-07-23 16:22:15,404] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.876 seconds
[2020-07-23 16:22:50,946] {scheduler_job.py:153} INFO - Started process (PID=339216) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:22:50,950] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:22:50,951] {logging_mixin.py:112} INFO - [2020-07-23 16:22:50,951] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:22:50,966] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:22:51,140] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:22:51,552] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:11:00+00:00: scheduled__2020-07-21T02:11:00+00:00, externally triggered: False>
[2020-07-23 16:22:51,555] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:10:00+00:00: scheduled__2020-07-21T02:10:00+00:00, externally triggered: False>
[2020-07-23 16:22:51,562] {logging_mixin.py:112} INFO - [2020-07-23 16:22:51,562] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:10:00+00:00: scheduled__2020-07-21T02:10:00+00:00, externally triggered: False> successful
[2020-07-23 16:22:51,648] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:11:00+00:00: scheduled__2020-07-21T02:11:00+00:00, externally triggered: False>
[2020-07-23 16:22:51,666] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:22:51,672] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:11:00+00:00 [scheduled]> in ORM
[2020-07-23 16:22:51,860] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.914 seconds
[2020-07-23 16:23:26,978] {scheduler_job.py:153} INFO - Started process (PID=340047) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:23:26,983] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:23:26,984] {logging_mixin.py:112} INFO - [2020-07-23 16:23:26,984] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:23:26,999] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:23:27,207] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:23:27,621] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:12:00+00:00: scheduled__2020-07-21T02:12:00+00:00, externally triggered: False>
[2020-07-23 16:23:27,627] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:11:00+00:00: scheduled__2020-07-21T02:11:00+00:00, externally triggered: False>
[2020-07-23 16:23:27,641] {logging_mixin.py:112} INFO - [2020-07-23 16:23:27,641] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:11:00+00:00: scheduled__2020-07-21T02:11:00+00:00, externally triggered: False> successful
[2020-07-23 16:23:27,750] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:12:00+00:00: scheduled__2020-07-21T02:12:00+00:00, externally triggered: False>
[2020-07-23 16:23:27,771] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:23:27,777] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:12:00+00:00 [scheduled]> in ORM
[2020-07-23 16:23:27,961] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.983 seconds
[2020-07-23 16:24:04,003] {scheduler_job.py:153} INFO - Started process (PID=340871) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:24:04,008] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:24:04,008] {logging_mixin.py:112} INFO - [2020-07-23 16:24:04,008] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:24:04,025] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:24:04,183] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:24:04,536] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:13:00+00:00: scheduled__2020-07-21T02:13:00+00:00, externally triggered: False>
[2020-07-23 16:24:04,540] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:12:00+00:00: scheduled__2020-07-21T02:12:00+00:00, externally triggered: False>
[2020-07-23 16:24:04,547] {logging_mixin.py:112} INFO - [2020-07-23 16:24:04,547] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:12:00+00:00: scheduled__2020-07-21T02:12:00+00:00, externally triggered: False> successful
[2020-07-23 16:24:04,673] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:13:00+00:00: scheduled__2020-07-21T02:13:00+00:00, externally triggered: False>
[2020-07-23 16:24:04,692] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:24:04,696] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:13:00+00:00 [scheduled]> in ORM
[2020-07-23 16:24:04,896] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.893 seconds
[2020-07-23 16:24:30,791] {scheduler_job.py:153} INFO - Started process (PID=341507) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:24:30,794] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:24:30,794] {logging_mixin.py:112} INFO - [2020-07-23 16:24:30,794] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:24:30,803] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:24:30,959] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:24:31,403] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:14:00+00:00: scheduled__2020-07-21T02:14:00+00:00, externally triggered: False>
[2020-07-23 16:24:31,409] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:13:00+00:00: scheduled__2020-07-21T02:13:00+00:00, externally triggered: False>
[2020-07-23 16:24:31,421] {logging_mixin.py:112} INFO - [2020-07-23 16:24:31,421] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:13:00+00:00: scheduled__2020-07-21T02:13:00+00:00, externally triggered: False> successful
[2020-07-23 16:24:31,541] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:14:00+00:00: scheduled__2020-07-21T02:14:00+00:00, externally triggered: False>
[2020-07-23 16:24:31,559] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:24:31,563] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:14:00+00:00 [scheduled]> in ORM
[2020-07-23 16:24:31,729] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.937 seconds
[2020-07-23 16:25:09,819] {scheduler_job.py:153} INFO - Started process (PID=342350) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:25:09,823] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:25:09,824] {logging_mixin.py:112} INFO - [2020-07-23 16:25:09,824] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:25:09,840] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:25:09,978] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:25:10,294] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:15:00+00:00: scheduled__2020-07-21T02:15:00+00:00, externally triggered: False>
[2020-07-23 16:25:10,299] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:14:00+00:00: scheduled__2020-07-21T02:14:00+00:00, externally triggered: False>
[2020-07-23 16:25:10,306] {logging_mixin.py:112} INFO - [2020-07-23 16:25:10,306] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:14:00+00:00: scheduled__2020-07-21T02:14:00+00:00, externally triggered: False> successful
[2020-07-23 16:25:10,398] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:15:00+00:00: scheduled__2020-07-21T02:15:00+00:00, externally triggered: False>
[2020-07-23 16:25:10,418] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:25:10,422] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:15:00+00:00 [scheduled]> in ORM
[2020-07-23 16:25:10,576] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.757 seconds
[2020-07-23 16:25:47,965] {scheduler_job.py:153} INFO - Started process (PID=343213) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:25:47,970] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:25:47,971] {logging_mixin.py:112} INFO - [2020-07-23 16:25:47,971] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:25:47,985] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:25:48,129] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:25:48,529] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:16:00+00:00: scheduled__2020-07-21T02:16:00+00:00, externally triggered: False>
[2020-07-23 16:25:48,532] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:15:00+00:00: scheduled__2020-07-21T02:15:00+00:00, externally triggered: False>
[2020-07-23 16:25:48,539] {logging_mixin.py:112} INFO - [2020-07-23 16:25:48,539] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:15:00+00:00: scheduled__2020-07-21T02:15:00+00:00, externally triggered: False> successful
[2020-07-23 16:25:48,644] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:16:00+00:00: scheduled__2020-07-21T02:16:00+00:00, externally triggered: False>
[2020-07-23 16:25:48,663] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:25:48,667] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:16:00+00:00 [scheduled]> in ORM
[2020-07-23 16:25:48,822] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.857 seconds
[2020-07-23 16:26:27,171] {scheduler_job.py:153} INFO - Started process (PID=344165) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:26:27,178] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:26:27,178] {logging_mixin.py:112} INFO - [2020-07-23 16:26:27,178] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:26:27,195] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:26:27,363] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:26:27,819] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:17:00+00:00: scheduled__2020-07-21T02:17:00+00:00, externally triggered: False>
[2020-07-23 16:26:27,824] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:16:00+00:00: scheduled__2020-07-21T02:16:00+00:00, externally triggered: False>
[2020-07-23 16:26:27,833] {logging_mixin.py:112} INFO - [2020-07-23 16:26:27,833] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:16:00+00:00: scheduled__2020-07-21T02:16:00+00:00, externally triggered: False> successful
[2020-07-23 16:26:27,978] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:17:00+00:00: scheduled__2020-07-21T02:17:00+00:00, externally triggered: False>
[2020-07-23 16:26:27,999] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:26:28,007] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:17:00+00:00 [scheduled]> in ORM
[2020-07-23 16:26:28,154] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.983 seconds
[2020-07-23 16:27:06,085] {scheduler_job.py:153} INFO - Started process (PID=344993) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:27:06,091] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:27:06,092] {logging_mixin.py:112} INFO - [2020-07-23 16:27:06,091] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:27:06,106] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:27:06,252] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:27:06,625] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:18:00+00:00: scheduled__2020-07-21T02:18:00+00:00, externally triggered: False>
[2020-07-23 16:27:06,628] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:17:00+00:00: scheduled__2020-07-21T02:17:00+00:00, externally triggered: False>
[2020-07-23 16:27:06,636] {logging_mixin.py:112} INFO - [2020-07-23 16:27:06,636] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:17:00+00:00: scheduled__2020-07-21T02:17:00+00:00, externally triggered: False> successful
[2020-07-23 16:27:06,761] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:18:00+00:00: scheduled__2020-07-21T02:18:00+00:00, externally triggered: False>
[2020-07-23 16:27:06,777] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:27:06,781] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:18:00+00:00 [scheduled]> in ORM
[2020-07-23 16:27:06,955] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.870 seconds
[2020-07-23 16:27:45,453] {scheduler_job.py:153} INFO - Started process (PID=345904) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:27:45,471] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:27:45,471] {logging_mixin.py:112} INFO - [2020-07-23 16:27:45,471] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:27:45,494] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:27:45,646] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:27:45,943] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:19:00+00:00: scheduled__2020-07-21T02:19:00+00:00, externally triggered: False>
[2020-07-23 16:27:45,950] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:18:00+00:00: scheduled__2020-07-21T02:18:00+00:00, externally triggered: False>
[2020-07-23 16:27:45,957] {logging_mixin.py:112} INFO - [2020-07-23 16:27:45,957] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:18:00+00:00: scheduled__2020-07-21T02:18:00+00:00, externally triggered: False> successful
[2020-07-23 16:27:46,064] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:19:00+00:00: scheduled__2020-07-21T02:19:00+00:00, externally triggered: False>
[2020-07-23 16:27:46,090] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:27:46,096] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:19:00+00:00 [scheduled]> in ORM
[2020-07-23 16:27:46,292] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.840 seconds
[2020-07-23 16:28:26,267] {scheduler_job.py:153} INFO - Started process (PID=346831) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:28:26,271] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:28:26,272] {logging_mixin.py:112} INFO - [2020-07-23 16:28:26,272] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:28:26,289] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:28:26,436] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:28:26,767] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:20:00+00:00: scheduled__2020-07-21T02:20:00+00:00, externally triggered: False>
[2020-07-23 16:28:26,771] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:19:00+00:00: scheduled__2020-07-21T02:19:00+00:00, externally triggered: False>
[2020-07-23 16:28:26,780] {logging_mixin.py:112} INFO - [2020-07-23 16:28:26,780] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:19:00+00:00: scheduled__2020-07-21T02:19:00+00:00, externally triggered: False> successful
[2020-07-23 16:28:26,913] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:20:00+00:00: scheduled__2020-07-21T02:20:00+00:00, externally triggered: False>
[2020-07-23 16:28:26,925] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:28:26,929] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:20:00+00:00 [scheduled]> in ORM
[2020-07-23 16:28:27,074] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.808 seconds
[2020-07-23 16:29:07,381] {scheduler_job.py:153} INFO - Started process (PID=347748) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:29:07,387] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:29:07,389] {logging_mixin.py:112} INFO - [2020-07-23 16:29:07,388] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:29:07,434] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:29:07,662] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:29:08,095] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:21:00+00:00: scheduled__2020-07-21T02:21:00+00:00, externally triggered: False>
[2020-07-23 16:29:08,100] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:20:00+00:00: scheduled__2020-07-21T02:20:00+00:00, externally triggered: False>
[2020-07-23 16:29:08,107] {logging_mixin.py:112} INFO - [2020-07-23 16:29:08,107] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:20:00+00:00: scheduled__2020-07-21T02:20:00+00:00, externally triggered: False> successful
[2020-07-23 16:29:08,417] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:21:00+00:00: scheduled__2020-07-21T02:21:00+00:00, externally triggered: False>
[2020-07-23 16:29:08,435] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:29:08,439] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:21:00+00:00 [scheduled]> in ORM
[2020-07-23 16:29:08,759] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.378 seconds
[2020-07-23 16:29:47,611] {scheduler_job.py:153} INFO - Started process (PID=348659) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:29:47,614] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:29:47,615] {logging_mixin.py:112} INFO - [2020-07-23 16:29:47,614] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:29:47,626] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:29:47,750] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:29:48,165] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:22:00+00:00: scheduled__2020-07-21T02:22:00+00:00, externally triggered: False>
[2020-07-23 16:29:48,170] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:21:00+00:00: scheduled__2020-07-21T02:21:00+00:00, externally triggered: False>
[2020-07-23 16:29:48,183] {logging_mixin.py:112} INFO - [2020-07-23 16:29:48,183] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:21:00+00:00: scheduled__2020-07-21T02:21:00+00:00, externally triggered: False> successful
[2020-07-23 16:29:48,299] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:22:00+00:00: scheduled__2020-07-21T02:22:00+00:00, externally triggered: False>
[2020-07-23 16:29:48,312] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:29:48,316] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:22:00+00:00 [scheduled]> in ORM
[2020-07-23 16:29:48,472] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.861 seconds
[2020-07-23 16:30:25,934] {scheduler_job.py:153} INFO - Started process (PID=349469) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:30:25,938] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:30:25,939] {logging_mixin.py:112} INFO - [2020-07-23 16:30:25,938] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:30:25,963] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:30:26,126] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:30:26,523] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:23:00+00:00: scheduled__2020-07-21T02:23:00+00:00, externally triggered: False>
[2020-07-23 16:30:26,529] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:22:00+00:00: scheduled__2020-07-21T02:22:00+00:00, externally triggered: False>
[2020-07-23 16:30:26,542] {logging_mixin.py:112} INFO - [2020-07-23 16:30:26,542] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:22:00+00:00: scheduled__2020-07-21T02:22:00+00:00, externally triggered: False> successful
[2020-07-23 16:30:26,659] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:23:00+00:00: scheduled__2020-07-21T02:23:00+00:00, externally triggered: False>
[2020-07-23 16:30:26,677] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:30:26,684] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:23:00+00:00 [scheduled]> in ORM
[2020-07-23 16:30:26,850] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.917 seconds
[2020-07-23 16:30:42,588] {scheduler_job.py:153} INFO - Started process (PID=349918) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:30:42,636] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:30:42,638] {logging_mixin.py:112} INFO - [2020-07-23 16:30:42,637] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:30:42,703] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:30:43,172] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:30:43,729] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:24:00+00:00: scheduled__2020-07-21T02:24:00+00:00, externally triggered: False>
[2020-07-23 16:30:43,737] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:23:00+00:00: scheduled__2020-07-21T02:23:00+00:00, externally triggered: False>
[2020-07-23 16:30:43,755] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:24:00+00:00: scheduled__2020-07-21T02:24:00+00:00, externally triggered: False>
[2020-07-23 16:30:43,785] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:30:43,791] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:24:00+00:00 [scheduled]> in ORM
[2020-07-23 16:30:43,976] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.388 seconds
[2020-07-23 16:31:43,664] {scheduler_job.py:153} INFO - Started process (PID=351397) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:31:43,678] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:31:43,678] {logging_mixin.py:112} INFO - [2020-07-23 16:31:43,678] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:31:43,706] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:31:43,882] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:31:44,333] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:25:00+00:00: scheduled__2020-07-21T02:25:00+00:00, externally triggered: False>
[2020-07-23 16:31:44,341] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:23:00+00:00: scheduled__2020-07-21T02:23:00+00:00, externally triggered: False>
[2020-07-23 16:31:44,375] {logging_mixin.py:112} INFO - [2020-07-23 16:31:44,375] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:23:00+00:00: scheduled__2020-07-21T02:23:00+00:00, externally triggered: False> successful
[2020-07-23 16:31:44,666] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:24:00+00:00: scheduled__2020-07-21T02:24:00+00:00, externally triggered: False>
[2020-07-23 16:31:44,680] {logging_mixin.py:112} INFO - [2020-07-23 16:31:44,680] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:24:00+00:00: scheduled__2020-07-21T02:24:00+00:00, externally triggered: False> successful
[2020-07-23 16:31:44,821] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:25:00+00:00: scheduled__2020-07-21T02:25:00+00:00, externally triggered: False>
[2020-07-23 16:31:44,866] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:31:44,872] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:25:00+00:00 [scheduled]> in ORM
[2020-07-23 16:31:45,026] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.362 seconds
[2020-07-23 16:32:26,022] {scheduler_job.py:153} INFO - Started process (PID=352351) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:32:26,027] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:32:26,028] {logging_mixin.py:112} INFO - [2020-07-23 16:32:26,028] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:32:26,045] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:32:26,182] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:32:26,671] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:26:00+00:00: scheduled__2020-07-21T02:26:00+00:00, externally triggered: False>
[2020-07-23 16:32:26,677] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:25:00+00:00: scheduled__2020-07-21T02:25:00+00:00, externally triggered: False>
[2020-07-23 16:32:26,690] {logging_mixin.py:112} INFO - [2020-07-23 16:32:26,689] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:25:00+00:00: scheduled__2020-07-21T02:25:00+00:00, externally triggered: False> successful
[2020-07-23 16:32:26,825] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:26:00+00:00: scheduled__2020-07-21T02:26:00+00:00, externally triggered: False>
[2020-07-23 16:32:26,856] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:32:26,864] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:26:00+00:00 [scheduled]> in ORM
[2020-07-23 16:32:27,050] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.029 seconds
[2020-07-23 16:33:08,495] {scheduler_job.py:153} INFO - Started process (PID=353536) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:33:08,499] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:33:08,500] {logging_mixin.py:112} INFO - [2020-07-23 16:33:08,500] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:33:08,515] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:33:08,698] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:33:09,208] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:27:00+00:00: scheduled__2020-07-21T02:27:00+00:00, externally triggered: False>
[2020-07-23 16:33:09,214] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:26:00+00:00: scheduled__2020-07-21T02:26:00+00:00, externally triggered: False>
[2020-07-23 16:33:09,226] {logging_mixin.py:112} INFO - [2020-07-23 16:33:09,226] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:26:00+00:00: scheduled__2020-07-21T02:26:00+00:00, externally triggered: False> successful
[2020-07-23 16:33:09,351] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:27:00+00:00: scheduled__2020-07-21T02:27:00+00:00, externally triggered: False>
[2020-07-23 16:33:09,370] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:33:09,377] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:27:00+00:00 [scheduled]> in ORM
[2020-07-23 16:33:09,535] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.040 seconds
[2020-07-23 16:34:05,638] {scheduler_job.py:153} INFO - Started process (PID=355051) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:34:05,642] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:34:05,643] {logging_mixin.py:112} INFO - [2020-07-23 16:34:05,643] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:34:05,691] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:34:06,086] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:34:06,943] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:28:00+00:00: scheduled__2020-07-21T02:28:00+00:00, externally triggered: False>
[2020-07-23 16:34:06,947] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:27:00+00:00: scheduled__2020-07-21T02:27:00+00:00, externally triggered: False>
[2020-07-23 16:34:06,954] {logging_mixin.py:112} INFO - [2020-07-23 16:34:06,954] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-21 02:27:00+00:00: scheduled__2020-07-21T02:27:00+00:00, externally triggered: False> successful
[2020-07-23 16:34:07,289] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:28:00+00:00: scheduled__2020-07-21T02:28:00+00:00, externally triggered: False>
[2020-07-23 16:34:07,308] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:34:07,313] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:28:00+00:00 [scheduled]> in ORM
[2020-07-23 16:34:07,642] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.004 seconds
[2020-07-23 16:34:26,352] {scheduler_job.py:153} INFO - Started process (PID=355764) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:34:26,390] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-23 16:34:26,391] {logging_mixin.py:112} INFO - [2020-07-23 16:34:26,391] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:34:26,473] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-23 16:34:26,877] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-23 16:34:28,185] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-21T02:29:00+00:00: scheduled__2020-07-21T02:29:00+00:00, externally triggered: False>
[2020-07-23 16:34:28,190] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:28:00+00:00: scheduled__2020-07-21T02:28:00+00:00, externally triggered: False>
[2020-07-23 16:34:28,219] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-21 02:29:00+00:00: scheduled__2020-07-21T02:29:00+00:00, externally triggered: False>
[2020-07-23 16:34:28,297] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-23 16:34:28,304] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-21 02:29:00+00:00 [scheduled]> in ORM
[2020-07-23 16:34:28,606] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.254 seconds
