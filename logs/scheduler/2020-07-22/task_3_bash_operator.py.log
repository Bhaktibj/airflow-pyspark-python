[2020-07-22 09:54:41,374] {scheduler_job.py:153} INFO - Started process (PID=21477) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:54:41,449] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:54:41,452] {logging_mixin.py:112} INFO - [2020-07-22 09:54:41,452] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:54:42,270] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:54:43,172] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:54:44,922] {scheduler_job.py:1294} INFO - Created <DagRun MYSQLDAG @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-22 09:54:44,956] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-22 09:54:45,269] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:54:45,305] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.first_db_to_csv 2020-07-21 00:00:00+00:00 [scheduled]> in ORM
[2020-07-22 09:54:45,548] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 4.174 seconds
[2020-07-22 09:55:03,098] {scheduler_job.py:153} INFO - Started process (PID=22029) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:55:03,103] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:55:03,104] {logging_mixin.py:112} INFO - [2020-07-22 09:55:03,104] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:55:03,329] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:55:03,606] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:55:03,631] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-22 09:55:03,658] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:55:03,662] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.564 seconds
[2020-07-22 09:55:16,116] {scheduler_job.py:153} INFO - Started process (PID=22339) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:55:16,120] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:55:16,120] {logging_mixin.py:112} INFO - [2020-07-22 09:55:16,120] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:55:16,186] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:55:16,456] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:55:16,660] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-22 09:55:16,673] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:25:12.548905+00:00: manual__2020-07-22T04:25:12.548905+00:00, externally triggered: True>
[2020-07-22 09:55:16,712] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:55:16,719] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.first_db_to_csv 2020-07-22 04:25:12.548905+00:00 [scheduled]> in ORM
[2020-07-22 09:55:16,923] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.807 seconds
[2020-07-22 09:56:17,952] {scheduler_job.py:153} INFO - Started process (PID=23642) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:56:17,955] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:56:17,956] {logging_mixin.py:112} INFO - [2020-07-22 09:56:17,956] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:56:18,301] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:56:18,443] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:56:18,476] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-22 09:56:18,502] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:25:12.548905+00:00: manual__2020-07-22T04:25:12.548905+00:00, externally triggered: True>
[2020-07-22 09:56:18,558] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:56:18,562] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.csv_to_second_db 2020-07-21 00:00:00+00:00 [scheduled]> in ORM
[2020-07-22 09:56:18,569] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.csv_to_second_db 2020-07-22 04:25:12.548905+00:00 [scheduled]> in ORM
[2020-07-22 09:56:18,782] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.830 seconds
[2020-07-22 09:57:08,405] {scheduler_job.py:153} INFO - Started process (PID=24696) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:57:08,407] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:57:08,408] {logging_mixin.py:112} INFO - [2020-07-22 09:57:08,408] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:57:08,478] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:57:08,702] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:57:08,717] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-22 09:57:08,730] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:25:12.548905+00:00: manual__2020-07-22T04:25:12.548905+00:00, externally triggered: True>
[2020-07-22 09:57:08,756] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:57:08,760] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.dbdump_in_minio 2020-07-21 00:00:00+00:00 [scheduled]> in ORM
[2020-07-22 09:57:08,764] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.dbdump_in_minio 2020-07-22 04:25:12.548905+00:00 [scheduled]> in ORM
[2020-07-22 09:57:08,923] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.518 seconds
[2020-07-22 09:57:43,248] {scheduler_job.py:153} INFO - Started process (PID=25523) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:57:43,251] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:57:43,251] {logging_mixin.py:112} INFO - [2020-07-22 09:57:43,251] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:57:43,320] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:57:43,453] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:57:43,469] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-22 09:57:43,482] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:25:12.548905+00:00: manual__2020-07-22T04:25:12.548905+00:00, externally triggered: True>
[2020-07-22 09:57:43,517] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:57:43,525] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.dbdump_in_minio 2020-07-21 00:00:00+00:00 [scheduled]> in ORM
[2020-07-22 09:57:43,530] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.dbdump_in_minio 2020-07-22 04:25:12.548905+00:00 [scheduled]> in ORM
[2020-07-22 09:57:43,674] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.427 seconds
[2020-07-22 09:58:38,077] {scheduler_job.py:153} INFO - Started process (PID=26735) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:58:38,080] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:58:38,080] {logging_mixin.py:112} INFO - [2020-07-22 09:58:38,080] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:58:38,150] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:58:38,258] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:58:38,285] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False>
[2020-07-22 09:58:38,305] {logging_mixin.py:112} INFO - [2020-07-22 09:58:38,305] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-21 00:00:00+00:00: scheduled__2020-07-21T00:00:00+00:00, externally triggered: False> failed
[2020-07-22 09:58:38,490] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:25:12.548905+00:00: manual__2020-07-22T04:25:12.548905+00:00, externally triggered: True>
[2020-07-22 09:58:38,505] {logging_mixin.py:112} INFO - [2020-07-22 09:58:38,505] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 04:25:12.548905+00:00: manual__2020-07-22T04:25:12.548905+00:00, externally triggered: True> failed
[2020-07-22 09:58:38,613] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:58:38,620] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.544 seconds
[2020-07-22 09:58:47,680] {scheduler_job.py:153} INFO - Started process (PID=26958) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:58:47,684] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:58:47,685] {logging_mixin.py:112} INFO - [2020-07-22 09:58:47,685] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:58:47,769] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:58:48,360] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:58:48,398] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:58:48,404] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.724 seconds
[2020-07-22 09:59:02,218] {scheduler_job.py:153} INFO - Started process (PID=27355) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:02,222] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:59:02,223] {logging_mixin.py:112} INFO - [2020-07-22 09:59:02,223] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:02,300] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:02,419] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:59:02,435] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:59:02,437] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.219 seconds
[2020-07-22 09:59:10,383] {scheduler_job.py:153} INFO - Started process (PID=27564) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:10,387] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:59:10,388] {logging_mixin.py:112} INFO - [2020-07-22 09:59:10,388] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:10,478] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:10,700] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:59:10,729] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:59:10,734] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.351 seconds
[2020-07-22 09:59:18,067] {scheduler_job.py:153} INFO - Started process (PID=27764) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:18,069] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:59:18,070] {logging_mixin.py:112} INFO - [2020-07-22 09:59:18,070] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:18,147] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:18,384] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:59:18,401] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:59:18,403] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.337 seconds
[2020-07-22 09:59:35,544] {scheduler_job.py:153} INFO - Started process (PID=28139) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:35,547] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:59:35,548] {logging_mixin.py:112} INFO - [2020-07-22 09:59:35,548] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:35,628] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:35,788] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:59:35,816] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:59:35,820] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.276 seconds
[2020-07-22 09:59:51,161] {scheduler_job.py:153} INFO - Started process (PID=28507) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:51,176] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:59:51,177] {logging_mixin.py:112} INFO - [2020-07-22 09:59:51,177] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:51,358] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:51,544] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:59:51,568] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:59:51,572] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.411 seconds
[2020-07-22 09:59:59,634] {scheduler_job.py:153} INFO - Started process (PID=28751) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:59,637] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 09:59:59,637] {logging_mixin.py:112} INFO - [2020-07-22 09:59:59,637] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:59,706] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 09:59:59,818] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 09:59:59,833] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 09:59:59,836] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.202 seconds
[2020-07-22 10:00:07,300] {scheduler_job.py:153} INFO - Started process (PID=28940) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:07,303] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:00:07,304] {logging_mixin.py:112} INFO - [2020-07-22 10:00:07,303] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:07,373] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:07,691] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:00:07,706] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:00:07,709] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.408 seconds
[2020-07-22 10:00:16,629] {scheduler_job.py:153} INFO - Started process (PID=29197) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:16,633] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:00:16,634] {logging_mixin.py:112} INFO - [2020-07-22 10:00:16,634] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:16,833] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:17,146] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:00:17,208] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:00:17,225] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.596 seconds
[2020-07-22 10:00:30,278] {scheduler_job.py:153} INFO - Started process (PID=29538) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:30,282] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:00:30,283] {logging_mixin.py:112} INFO - [2020-07-22 10:00:30,283] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:30,353] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:30,454] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:00:30,476] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:00:30,478] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-22 10:00:40,702] {scheduler_job.py:153} INFO - Started process (PID=29770) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:40,704] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:00:40,705] {logging_mixin.py:112} INFO - [2020-07-22 10:00:40,705] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:40,802] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:41,182] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:00:41,202] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:00:41,204] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.503 seconds
[2020-07-22 10:00:51,928] {scheduler_job.py:153} INFO - Started process (PID=30015) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:51,932] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:00:51,933] {logging_mixin.py:112} INFO - [2020-07-22 10:00:51,933] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:52,069] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:00:52,401] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:00:52,426] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:00:52,431] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.503 seconds
[2020-07-22 10:01:06,796] {scheduler_job.py:153} INFO - Started process (PID=30332) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:01:06,801] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:01:06,801] {logging_mixin.py:112} INFO - [2020-07-22 10:01:06,801] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:01:07,213] {logging_mixin.py:112} INFO - [2020-07-22 10:01:07,211] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 27, in <module>
    t1 >> t2 >> t3
NameError: name 't1' is not defined
[2020-07-22 10:01:07,213] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:01:08,043] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.247 seconds
[2020-07-22 10:01:28,932] {scheduler_job.py:153} INFO - Started process (PID=30772) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:01:28,941] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:01:28,942] {logging_mixin.py:112} INFO - [2020-07-22 10:01:28,941] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:01:29,097] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:01:29,231] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:01:29,264] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:01:29,406] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.475 seconds
[2020-07-22 10:01:40,241] {scheduler_job.py:153} INFO - Started process (PID=31019) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:01:40,245] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:01:40,246] {logging_mixin.py:112} INFO - [2020-07-22 10:01:40,246] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:01:40,332] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:01:40,525] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:01:40,541] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:01:40,543] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.302 seconds
[2020-07-22 10:01:51,063] {scheduler_job.py:153} INFO - Started process (PID=31253) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:01:51,066] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:01:51,067] {logging_mixin.py:112} INFO - [2020-07-22 10:01:51,067] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:01:51,204] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:01:51,373] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:01:51,400] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:01:51,406] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.342 seconds
[2020-07-22 10:02:04,968] {scheduler_job.py:153} INFO - Started process (PID=31571) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:04,973] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:02:04,973] {logging_mixin.py:112} INFO - [2020-07-22 10:02:04,973] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:05,137] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:05,379] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:02:05,403] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:02:05,407] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.440 seconds
[2020-07-22 10:02:17,791] {scheduler_job.py:153} INFO - Started process (PID=31898) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:17,794] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:02:17,794] {logging_mixin.py:112} INFO - [2020-07-22 10:02:17,794] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:17,866] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:18,153] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:02:18,174] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:32:13.289020+00:00: manual__2020-07-22T04:32:13.289020+00:00, externally triggered: True>
[2020-07-22 10:02:18,187] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:02:18,191] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.dbdump_in_minio 2020-07-22 04:32:13.289020+00:00 [scheduled]> in ORM
[2020-07-22 10:02:18,336] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.545 seconds
[2020-07-22 10:02:27,057] {scheduler_job.py:153} INFO - Started process (PID=32155) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:27,061] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:02:27,062] {logging_mixin.py:112} INFO - [2020-07-22 10:02:27,062] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:27,147] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:27,310] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:02:27,327] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:32:13.289020+00:00: manual__2020-07-22T04:32:13.289020+00:00, externally triggered: True>
[2020-07-22 10:02:27,342] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:02:27,345] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.288 seconds
[2020-07-22 10:02:37,059] {scheduler_job.py:153} INFO - Started process (PID=32449) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:37,063] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:02:37,063] {logging_mixin.py:112} INFO - [2020-07-22 10:02:37,063] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:37,153] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:37,276] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:02:37,297] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:32:13.289020+00:00: manual__2020-07-22T04:32:13.289020+00:00, externally triggered: True>
[2020-07-22 10:02:37,312] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:02:37,314] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.255 seconds
[2020-07-22 10:02:48,230] {scheduler_job.py:153} INFO - Started process (PID=32724) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:48,234] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:02:48,235] {logging_mixin.py:112} INFO - [2020-07-22 10:02:48,235] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:48,377] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:02:48,525] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:02:48,567] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:32:13.289020+00:00: manual__2020-07-22T04:32:13.289020+00:00, externally triggered: True>
[2020-07-22 10:02:48,614] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:02:48,624] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.dbdump_in_minio 2020-07-22 04:32:13.289020+00:00 [scheduled]> in ORM
[2020-07-22 10:02:48,774] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.544 seconds
[2020-07-22 10:03:02,365] {scheduler_job.py:153} INFO - Started process (PID=33136) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:02,368] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:03:02,369] {logging_mixin.py:112} INFO - [2020-07-22 10:03:02,368] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:02,437] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:02,712] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:03:02,732] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:32:13.289020+00:00: manual__2020-07-22T04:32:13.289020+00:00, externally triggered: True>
[2020-07-22 10:03:02,745] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:03:02,748] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.383 seconds
[2020-07-22 10:03:11,951] {scheduler_job.py:153} INFO - Started process (PID=33369) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:11,954] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:03:11,955] {logging_mixin.py:112} INFO - [2020-07-22 10:03:11,955] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:12,023] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:12,135] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:03:12,155] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:32:13.289020+00:00: manual__2020-07-22T04:32:13.289020+00:00, externally triggered: True>
[2020-07-22 10:03:12,166] {logging_mixin.py:112} INFO - [2020-07-22 10:03:12,165] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 04:32:13.289020+00:00: manual__2020-07-22T04:32:13.289020+00:00, externally triggered: True> failed
[2020-07-22 10:03:12,317] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:03:12,321] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.370 seconds
[2020-07-22 10:03:20,516] {scheduler_job.py:153} INFO - Started process (PID=33579) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:20,518] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:03:20,519] {logging_mixin.py:112} INFO - [2020-07-22 10:03:20,519] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:20,596] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:20,736] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:03:20,769] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:03:20,773] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.257 seconds
[2020-07-22 10:03:29,099] {scheduler_job.py:153} INFO - Started process (PID=33782) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:29,102] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:03:29,102] {logging_mixin.py:112} INFO - [2020-07-22 10:03:29,102] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:29,180] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:29,332] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:03:29,370] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:03:29,374] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.275 seconds
[2020-07-22 10:03:44,370] {scheduler_job.py:153} INFO - Started process (PID=34185) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:44,372] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:03:44,373] {logging_mixin.py:112} INFO - [2020-07-22 10:03:44,373] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:44,444] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:44,599] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:03:44,616] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:03:44,619] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.250 seconds
[2020-07-22 10:03:53,061] {scheduler_job.py:153} INFO - Started process (PID=34423) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:53,065] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:03:53,065] {logging_mixin.py:112} INFO - [2020-07-22 10:03:53,065] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:53,161] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:03:53,271] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:03:53,314] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:03:53,322] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.262 seconds
[2020-07-22 10:04:02,839] {scheduler_job.py:153} INFO - Started process (PID=34679) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:04:02,843] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:04:02,844] {logging_mixin.py:112} INFO - [2020-07-22 10:04:02,843] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:04:03,107] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:04:03,379] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:04:03,418] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:04:03,430] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.591 seconds
[2020-07-22 10:04:12,741] {scheduler_job.py:153} INFO - Started process (PID=34904) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:04:12,745] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:04:12,746] {logging_mixin.py:112} INFO - [2020-07-22 10:04:12,745] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:04:12,839] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:04:13,344] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:04:13,392] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:04:13,401] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.657 seconds
[2020-07-22 10:04:24,896] {scheduler_job.py:153} INFO - Started process (PID=35200) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:04:24,910] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:04:24,910] {logging_mixin.py:112} INFO - [2020-07-22 10:04:24,910] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:04:25,005] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:04:25,120] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:04:25,145] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:34:15.766120+00:00: manual__2020-07-22T04:34:15.766120+00:00, externally triggered: True>
[2020-07-22 10:04:25,166] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:04:25,172] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.dbdump_in_minio 2020-07-22 04:34:15.766120+00:00 [scheduled]> in ORM
[2020-07-22 10:04:25,348] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.451 seconds
[2020-07-22 10:04:35,742] {scheduler_job.py:153} INFO - Started process (PID=35588) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:04:35,747] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:04:35,747] {logging_mixin.py:112} INFO - [2020-07-22 10:04:35,747] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:04:35,861] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:04:35,976] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:04:35,994] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:34:15.766120+00:00: manual__2020-07-22T04:34:15.766120+00:00, externally triggered: True>
[2020-07-22 10:04:36,013] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:04:36,017] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.275 seconds
[2020-07-22 10:05:01,124] {scheduler_job.py:153} INFO - Started process (PID=36115) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:01,127] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:05:01,128] {logging_mixin.py:112} INFO - [2020-07-22 10:05:01,127] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:01,236] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:01,351] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:05:01,375] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 04:34:15.766120+00:00: manual__2020-07-22T04:34:15.766120+00:00, externally triggered: True>
[2020-07-22 10:05:01,385] {logging_mixin.py:112} INFO - [2020-07-22 10:05:01,385] {dagrun.py:318} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 04:34:15.766120+00:00: manual__2020-07-22T04:34:15.766120+00:00, externally triggered: True> successful
[2020-07-22 10:05:01,496] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:05:01,501] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.377 seconds
[2020-07-22 10:05:14,233] {scheduler_job.py:153} INFO - Started process (PID=36598) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:14,236] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:05:14,237] {logging_mixin.py:112} INFO - [2020-07-22 10:05:14,237] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:14,302] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:14,417] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:05:14,432] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:05:14,435] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.202 seconds
[2020-07-22 10:05:24,347] {scheduler_job.py:153} INFO - Started process (PID=36823) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:24,351] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:05:24,351] {logging_mixin.py:112} INFO - [2020-07-22 10:05:24,351] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:24,434] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:24,550] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:05:24,566] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:05:24,568] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.222 seconds
[2020-07-22 10:05:32,517] {scheduler_job.py:153} INFO - Started process (PID=37027) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:32,521] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:05:32,521] {logging_mixin.py:112} INFO - [2020-07-22 10:05:32,521] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:32,594] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:32,725] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:05:32,741] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:05:32,743] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.226 seconds
[2020-07-22 10:05:42,924] {scheduler_job.py:153} INFO - Started process (PID=37313) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:42,929] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:05:42,929] {logging_mixin.py:112} INFO - [2020-07-22 10:05:42,929] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:43,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:43,167] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:05:43,193] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:05:43,198] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.274 seconds
[2020-07-22 10:05:59,391] {scheduler_job.py:153} INFO - Started process (PID=37693) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:59,394] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:05:59,395] {logging_mixin.py:112} INFO - [2020-07-22 10:05:59,395] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:59,469] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:05:59,587] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:05:59,604] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:05:59,606] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.216 seconds
[2020-07-22 10:06:07,862] {scheduler_job.py:153} INFO - Started process (PID=37924) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:07,866] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:06:07,866] {logging_mixin.py:112} INFO - [2020-07-22 10:06:07,866] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:07,949] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:08,061] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:06:08,076] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:06:08,079] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-22 10:06:15,959] {scheduler_job.py:153} INFO - Started process (PID=38125) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:15,967] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:06:15,968] {logging_mixin.py:112} INFO - [2020-07-22 10:06:15,967] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:16,089] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:16,262] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:06:16,283] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:06:16,287] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.328 seconds
[2020-07-22 10:06:25,614] {scheduler_job.py:153} INFO - Started process (PID=38381) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:25,618] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:06:25,618] {logging_mixin.py:112} INFO - [2020-07-22 10:06:25,618] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:25,790] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:25,990] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:06:26,029] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:06:26,035] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.420 seconds
[2020-07-22 10:06:37,850] {scheduler_job.py:153} INFO - Started process (PID=38734) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:37,858] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:06:37,859] {logging_mixin.py:112} INFO - [2020-07-22 10:06:37,859] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:37,949] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:38,075] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:06:38,091] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:06:38,094] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.244 seconds
[2020-07-22 10:06:51,852] {scheduler_job.py:153} INFO - Started process (PID=39017) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:51,856] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:06:51,856] {logging_mixin.py:112} INFO - [2020-07-22 10:06:51,856] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:52,034] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:06:52,221] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:06:52,242] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:06:52,245] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.393 seconds
[2020-07-22 10:07:02,556] {scheduler_job.py:153} INFO - Started process (PID=39258) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:02,559] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:07:02,560] {logging_mixin.py:112} INFO - [2020-07-22 10:07:02,560] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:02,679] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:02,797] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:07:02,813] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:07:02,816] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.260 seconds
[2020-07-22 10:07:24,463] {scheduler_job.py:153} INFO - Started process (PID=39753) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:24,477] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:07:24,477] {logging_mixin.py:112} INFO - [2020-07-22 10:07:24,477] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:24,626] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:24,765] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:07:24,792] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:07:24,797] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.333 seconds
[2020-07-22 10:07:32,427] {scheduler_job.py:153} INFO - Started process (PID=39963) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:32,432] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:07:32,432] {logging_mixin.py:112} INFO - [2020-07-22 10:07:32,432] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:32,505] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:32,707] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:07:32,724] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:07:32,727] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.300 seconds
[2020-07-22 10:07:43,484] {scheduler_job.py:153} INFO - Started process (PID=40233) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:43,489] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:07:43,489] {logging_mixin.py:112} INFO - [2020-07-22 10:07:43,489] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:43,562] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:43,679] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:07:43,709] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:07:43,715] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.231 seconds
[2020-07-22 10:07:52,360] {scheduler_job.py:153} INFO - Started process (PID=40478) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:52,363] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:07:52,363] {logging_mixin.py:112} INFO - [2020-07-22 10:07:52,363] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:52,460] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:07:52,739] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:07:52,755] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:07:52,758] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.398 seconds
[2020-07-22 10:08:03,087] {scheduler_job.py:153} INFO - Started process (PID=40771) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:03,093] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:08:03,094] {logging_mixin.py:112} INFO - [2020-07-22 10:08:03,093] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:03,277] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:03,445] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:08:03,476] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:08:03,482] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.396 seconds
[2020-07-22 10:08:15,472] {scheduler_job.py:153} INFO - Started process (PID=41113) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:15,475] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:08:15,475] {logging_mixin.py:112} INFO - [2020-07-22 10:08:15,475] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:15,683] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:15,810] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:08:15,825] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:08:15,828] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.355 seconds
[2020-07-22 10:08:23,637] {scheduler_job.py:153} INFO - Started process (PID=41317) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:23,640] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:08:23,641] {logging_mixin.py:112} INFO - [2020-07-22 10:08:23,641] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:23,722] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:23,995] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:08:24,012] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:08:24,014] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.377 seconds
[2020-07-22 10:08:31,809] {scheduler_job.py:153} INFO - Started process (PID=41518) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:31,811] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:08:31,812] {logging_mixin.py:112} INFO - [2020-07-22 10:08:31,812] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:31,897] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:32,020] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:08:32,034] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:08:32,037] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.228 seconds
[2020-07-22 10:08:41,498] {scheduler_job.py:153} INFO - Started process (PID=41769) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:41,505] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:08:41,506] {logging_mixin.py:112} INFO - [2020-07-22 10:08:41,506] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:41,619] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:41,743] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:08:41,765] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:08:41,768] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.271 seconds
[2020-07-22 10:08:55,801] {scheduler_job.py:153} INFO - Started process (PID=42136) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:55,809] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:08:55,810] {logging_mixin.py:112} INFO - [2020-07-22 10:08:55,810] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:56,060] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:08:56,240] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:08:56,260] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:08:56,263] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.463 seconds
[2020-07-22 10:09:04,143] {scheduler_job.py:153} INFO - Started process (PID=42377) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:04,147] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:09:04,148] {logging_mixin.py:112} INFO - [2020-07-22 10:09:04,147] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:04,254] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:04,415] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:09:04,430] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:09:04,432] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.289 seconds
[2020-07-22 10:09:12,115] {scheduler_job.py:153} INFO - Started process (PID=42604) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:12,118] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:09:12,119] {logging_mixin.py:112} INFO - [2020-07-22 10:09:12,119] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:12,191] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:12,323] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:09:12,340] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:09:12,344] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.229 seconds
[2020-07-22 10:09:20,280] {scheduler_job.py:153} INFO - Started process (PID=42811) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:20,284] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:09:20,285] {logging_mixin.py:112} INFO - [2020-07-22 10:09:20,284] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:20,362] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:20,520] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:09:20,535] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:09:20,538] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.257 seconds
[2020-07-22 10:09:27,756] {scheduler_job.py:153} INFO - Started process (PID=43006) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:27,759] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:09:27,760] {logging_mixin.py:112} INFO - [2020-07-22 10:09:27,759] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:27,833] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:27,974] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:09:27,994] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:09:27,997] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.241 seconds
[2020-07-22 10:09:40,176] {scheduler_job.py:153} INFO - Started process (PID=43337) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:40,180] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:09:40,181] {logging_mixin.py:112} INFO - [2020-07-22 10:09:40,181] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:40,343] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:40,573] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:09:40,601] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:09:40,606] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.430 seconds
[2020-07-22 10:09:49,477] {scheduler_job.py:153} INFO - Started process (PID=43616) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:49,481] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:09:49,482] {logging_mixin.py:112} INFO - [2020-07-22 10:09:49,481] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:49,548] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:49,671] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:09:49,686] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:09:49,688] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.211 seconds
[2020-07-22 10:09:59,510] {scheduler_job.py:153} INFO - Started process (PID=43862) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:59,520] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:09:59,521] {logging_mixin.py:112} INFO - [2020-07-22 10:09:59,521] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:59,699] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:09:59,854] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:09:59,890] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:09:59,896] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.386 seconds
[2020-07-22 10:10:09,540] {scheduler_job.py:153} INFO - Started process (PID=44109) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:09,552] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:10:09,553] {logging_mixin.py:112} INFO - [2020-07-22 10:10:09,553] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:09,864] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:10,018] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:10:10,050] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:10:10,056] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.516 seconds
[2020-07-22 10:10:24,381] {scheduler_job.py:153} INFO - Started process (PID=44517) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:24,384] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:10:24,385] {logging_mixin.py:112} INFO - [2020-07-22 10:10:24,385] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:24,488] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:24,661] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:10:24,691] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:10:24,696] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.315 seconds
[2020-07-22 10:10:33,378] {scheduler_job.py:153} INFO - Started process (PID=44765) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:33,380] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:10:33,381] {logging_mixin.py:112} INFO - [2020-07-22 10:10:33,381] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:33,448] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:33,691] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:10:34,040] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:10:34,047] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.670 seconds
[2020-07-22 10:10:41,746] {scheduler_job.py:153} INFO - Started process (PID=44972) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:41,750] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:10:41,751] {logging_mixin.py:112} INFO - [2020-07-22 10:10:41,751] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:41,821] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:41,926] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:10:41,945] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:10:41,947] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.201 seconds
[2020-07-22 10:10:49,023] {scheduler_job.py:153} INFO - Started process (PID=45185) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:49,026] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:10:49,027] {logging_mixin.py:112} INFO - [2020-07-22 10:10:49,027] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:49,099] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:49,220] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:10:49,238] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:10:49,242] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.219 seconds
[2020-07-22 10:10:57,095] {scheduler_job.py:153} INFO - Started process (PID=45393) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:57,098] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:10:57,099] {logging_mixin.py:112} INFO - [2020-07-22 10:10:57,099] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:57,173] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:10:57,294] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:10:57,320] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:10:57,325] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.230 seconds
[2020-07-22 10:11:07,523] {scheduler_job.py:153} INFO - Started process (PID=45699) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:07,536] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:11:07,537] {logging_mixin.py:112} INFO - [2020-07-22 10:11:07,537] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:07,711] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:07,835] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:11:07,879] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:11:07,884] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.361 seconds
[2020-07-22 10:11:16,024] {scheduler_job.py:153} INFO - Started process (PID=45960) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:16,028] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:11:16,028] {logging_mixin.py:112} INFO - [2020-07-22 10:11:16,028] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:16,108] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:16,267] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:11:16,282] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:11:16,285] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.261 seconds
[2020-07-22 10:11:23,587] {scheduler_job.py:153} INFO - Started process (PID=46155) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:23,590] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:11:23,591] {logging_mixin.py:112} INFO - [2020-07-22 10:11:23,590] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:23,701] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:23,840] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:11:23,856] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:11:23,859] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.273 seconds
[2020-07-22 10:11:31,753] {scheduler_job.py:153} INFO - Started process (PID=46367) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:31,757] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:11:31,758] {logging_mixin.py:112} INFO - [2020-07-22 10:11:31,757] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:31,857] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:31,961] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:11:31,977] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:11:31,980] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.227 seconds
[2020-07-22 10:11:39,119] {scheduler_job.py:153} INFO - Started process (PID=46567) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:39,124] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:11:39,125] {logging_mixin.py:112} INFO - [2020-07-22 10:11:39,125] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:39,192] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:39,288] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:11:39,303] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:11:39,306] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.187 seconds
[2020-07-22 10:11:49,420] {scheduler_job.py:153} INFO - Started process (PID=46892) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:49,425] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:11:49,425] {logging_mixin.py:112} INFO - [2020-07-22 10:11:49,425] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:49,526] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:49,688] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:11:49,736] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:11:49,740] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.320 seconds
[2020-07-22 10:11:58,081] {scheduler_job.py:153} INFO - Started process (PID=47132) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:58,087] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:11:58,087] {logging_mixin.py:112} INFO - [2020-07-22 10:11:58,087] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:58,211] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:11:58,334] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:11:58,360] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:11:58,364] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.283 seconds
[2020-07-22 10:12:05,955] {scheduler_job.py:153} INFO - Started process (PID=47336) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:05,959] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:12:05,960] {logging_mixin.py:112} INFO - [2020-07-22 10:12:05,960] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:06,025] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:06,133] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:12:06,150] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:12:06,153] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.198 seconds
[2020-07-22 10:12:13,307] {scheduler_job.py:153} INFO - Started process (PID=47533) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:13,312] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:12:13,312] {logging_mixin.py:112} INFO - [2020-07-22 10:12:13,312] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:13,388] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:13,509] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:12:13,524] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:12:13,527] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.220 seconds
[2020-07-22 10:12:22,412] {scheduler_job.py:153} INFO - Started process (PID=47770) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:22,417] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:12:22,418] {logging_mixin.py:112} INFO - [2020-07-22 10:12:22,418] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:22,541] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:22,656] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:12:22,682] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:12:22,686] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.274 seconds
[2020-07-22 10:12:35,942] {scheduler_job.py:153} INFO - Started process (PID=48147) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:35,944] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:12:35,944] {logging_mixin.py:112} INFO - [2020-07-22 10:12:35,944] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:36,009] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:36,115] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:12:36,131] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:12:36,134] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.192 seconds
[2020-07-22 10:12:43,092] {scheduler_job.py:153} INFO - Started process (PID=48338) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:43,094] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:12:43,095] {logging_mixin.py:112} INFO - [2020-07-22 10:12:43,094] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:43,170] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:43,543] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:12:43,558] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:12:43,560] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.469 seconds
[2020-07-22 10:12:52,695] {scheduler_job.py:153} INFO - Started process (PID=48578) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:52,698] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:12:52,698] {logging_mixin.py:112} INFO - [2020-07-22 10:12:52,698] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:52,787] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:12:52,939] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:12:52,955] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:12:52,958] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.263 seconds
[2020-07-22 10:13:02,338] {scheduler_job.py:153} INFO - Started process (PID=48803) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:02,341] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:13:02,342] {logging_mixin.py:112} INFO - [2020-07-22 10:13:02,342] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:02,407] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:02,532] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:13:02,547] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:13:02,549] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.212 seconds
[2020-07-22 10:13:15,881] {scheduler_job.py:153} INFO - Started process (PID=49175) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:15,884] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:13:15,885] {logging_mixin.py:112} INFO - [2020-07-22 10:13:15,885] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:16,044] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:16,250] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:13:16,265] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:13:16,268] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.387 seconds
[2020-07-22 10:13:23,747] {scheduler_job.py:153} INFO - Started process (PID=49400) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:23,753] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:13:23,754] {logging_mixin.py:112} INFO - [2020-07-22 10:13:23,754] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:23,830] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:23,964] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:13:23,979] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:13:23,981] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.234 seconds
[2020-07-22 10:13:32,457] {scheduler_job.py:153} INFO - Started process (PID=49617) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:32,462] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:13:32,463] {logging_mixin.py:112} INFO - [2020-07-22 10:13:32,462] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:32,536] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:32,643] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:13:32,658] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:13:32,660] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 10:13:43,206] {scheduler_job.py:153} INFO - Started process (PID=49850) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:43,211] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:13:43,212] {logging_mixin.py:112} INFO - [2020-07-22 10:13:43,211] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:43,283] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:43,412] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:13:43,441] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:13:43,446] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.240 seconds
[2020-07-22 10:13:55,611] {scheduler_job.py:153} INFO - Started process (PID=50218) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:55,615] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:13:55,616] {logging_mixin.py:112} INFO - [2020-07-22 10:13:55,616] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:55,703] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:13:55,821] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:13:55,846] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:13:55,850] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.239 seconds
[2020-07-22 10:14:02,864] {scheduler_job.py:153} INFO - Started process (PID=50436) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:02,867] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:14:02,868] {logging_mixin.py:112} INFO - [2020-07-22 10:14:02,867] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:02,934] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:03,110] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:14:03,125] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:14:03,127] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.264 seconds
[2020-07-22 10:14:12,514] {scheduler_job.py:153} INFO - Started process (PID=50655) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:12,517] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:14:12,517] {logging_mixin.py:112} INFO - [2020-07-22 10:14:12,517] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:12,583] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:12,711] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:14:12,729] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:14:12,733] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.219 seconds
[2020-07-22 10:14:22,753] {scheduler_job.py:153} INFO - Started process (PID=50907) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:22,756] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:14:22,756] {logging_mixin.py:112} INFO - [2020-07-22 10:14:22,756] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:22,837] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:23,054] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:14:23,069] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:14:23,072] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.319 seconds
[2020-07-22 10:14:35,282] {scheduler_job.py:153} INFO - Started process (PID=51243) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:35,293] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:14:35,298] {logging_mixin.py:112} INFO - [2020-07-22 10:14:35,294] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:35,416] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:35,604] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:14:35,628] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:14:35,632] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.351 seconds
[2020-07-22 10:14:43,853] {scheduler_job.py:153} INFO - Started process (PID=51478) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:43,856] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:14:43,856] {logging_mixin.py:112} INFO - [2020-07-22 10:14:43,856] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:43,923] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:44,031] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:14:44,046] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:14:44,048] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.196 seconds
[2020-07-22 10:14:53,076] {scheduler_job.py:153} INFO - Started process (PID=51723) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:53,080] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:14:53,080] {logging_mixin.py:112} INFO - [2020-07-22 10:14:53,080] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:53,147] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:14:53,281] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:14:53,298] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:14:53,300] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.224 seconds
[2020-07-22 10:15:02,469] {scheduler_job.py:153} INFO - Started process (PID=51946) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:02,472] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:15:02,473] {logging_mixin.py:112} INFO - [2020-07-22 10:15:02,472] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:02,548] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:02,658] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:15:02,674] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:15:02,676] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 10:15:14,701] {scheduler_job.py:153} INFO - Started process (PID=52239) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:14,704] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:15:14,705] {logging_mixin.py:112} INFO - [2020-07-22 10:15:14,705] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:14,829] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:14,959] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:15:14,989] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:15:14,994] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.293 seconds
[2020-07-22 10:15:24,892] {scheduler_job.py:153} INFO - Started process (PID=52555) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:24,896] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:15:24,896] {logging_mixin.py:112} INFO - [2020-07-22 10:15:24,896] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:24,976] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:25,142] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:15:25,157] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:15:25,160] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.268 seconds
[2020-07-22 10:15:32,292] {scheduler_job.py:153} INFO - Started process (PID=52746) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:32,296] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:15:32,296] {logging_mixin.py:112} INFO - [2020-07-22 10:15:32,296] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:32,368] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:32,565] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:15:32,580] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:15:32,583] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.290 seconds
[2020-07-22 10:15:43,748] {scheduler_job.py:153} INFO - Started process (PID=52988) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:43,750] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:15:43,751] {logging_mixin.py:112} INFO - [2020-07-22 10:15:43,751] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:43,829] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:44,032] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:15:44,047] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:15:44,050] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.302 seconds
[2020-07-22 10:15:54,791] {scheduler_job.py:153} INFO - Started process (PID=53296) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:54,795] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:15:54,796] {logging_mixin.py:112} INFO - [2020-07-22 10:15:54,795] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:54,883] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:15:55,003] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:15:55,055] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:15:55,063] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.272 seconds
[2020-07-22 10:16:05,176] {scheduler_job.py:153} INFO - Started process (PID=53602) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:05,179] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:16:05,180] {logging_mixin.py:112} INFO - [2020-07-22 10:16:05,180] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:05,278] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:05,371] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:16:05,387] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:16:05,390] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.213 seconds
[2020-07-22 10:16:12,657] {scheduler_job.py:153} INFO - Started process (PID=53796) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:12,659] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:16:12,660] {logging_mixin.py:112} INFO - [2020-07-22 10:16:12,660] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:12,725] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:12,840] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:16:12,855] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:16:12,858] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.201 seconds
[2020-07-22 10:16:22,798] {scheduler_job.py:153} INFO - Started process (PID=54025) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:22,804] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:16:22,805] {logging_mixin.py:112} INFO - [2020-07-22 10:16:22,805] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:22,870] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:22,977] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:16:22,991] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:16:22,994] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.196 seconds
[2020-07-22 10:16:33,291] {scheduler_job.py:153} INFO - Started process (PID=54282) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:33,293] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:16:33,294] {logging_mixin.py:112} INFO - [2020-07-22 10:16:33,294] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:33,363] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:33,476] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:16:33,501] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:16:33,506] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.215 seconds
[2020-07-22 10:16:45,747] {scheduler_job.py:153} INFO - Started process (PID=54643) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:45,750] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:16:45,751] {logging_mixin.py:112} INFO - [2020-07-22 10:16:45,751] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:45,843] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:45,943] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:16:46,065] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:16:46,070] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.323 seconds
[2020-07-22 10:16:53,308] {scheduler_job.py:153} INFO - Started process (PID=54837) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:53,312] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:16:53,312] {logging_mixin.py:112} INFO - [2020-07-22 10:16:53,312] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:53,377] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:16:53,495] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:16:53,510] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:16:53,512] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 10:17:03,416] {scheduler_job.py:153} INFO - Started process (PID=55098) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:03,419] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:17:03,419] {logging_mixin.py:112} INFO - [2020-07-22 10:17:03,419] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:03,486] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:03,596] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:17:03,611] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:17:03,614] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.198 seconds
[2020-07-22 10:17:12,726] {scheduler_job.py:153} INFO - Started process (PID=55311) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:12,730] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:17:12,730] {logging_mixin.py:112} INFO - [2020-07-22 10:17:12,730] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:12,796] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:12,898] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:17:12,914] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:17:12,916] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.190 seconds
[2020-07-22 10:17:29,227] {scheduler_job.py:153} INFO - Started process (PID=55753) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:29,230] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:17:29,230] {logging_mixin.py:112} INFO - [2020-07-22 10:17:29,230] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:29,299] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:29,419] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:17:29,434] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:17:29,436] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.209 seconds
[2020-07-22 10:17:37,099] {scheduler_job.py:153} INFO - Started process (PID=55952) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:37,103] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:17:37,103] {logging_mixin.py:112} INFO - [2020-07-22 10:17:37,103] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:37,170] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:37,273] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:17:37,291] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:17:37,293] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.195 seconds
[2020-07-22 10:17:44,268] {scheduler_job.py:153} INFO - Started process (PID=56141) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:44,271] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:17:44,272] {logging_mixin.py:112} INFO - [2020-07-22 10:17:44,271] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:44,383] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:44,525] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:17:44,552] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:17:44,556] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.288 seconds
[2020-07-22 10:17:52,448] {scheduler_job.py:153} INFO - Started process (PID=56352) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:52,452] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:17:52,452] {logging_mixin.py:112} INFO - [2020-07-22 10:17:52,452] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:52,558] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:17:52,674] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:17:52,690] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:17:52,693] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.246 seconds
[2020-07-22 10:18:09,434] {scheduler_job.py:153} INFO - Started process (PID=56790) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:09,438] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:18:09,439] {logging_mixin.py:112} INFO - [2020-07-22 10:18:09,439] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:09,504] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:09,619] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:18:09,648] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:18:09,652] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.218 seconds
[2020-07-22 10:18:16,789] {scheduler_job.py:153} INFO - Started process (PID=56989) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:16,794] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:18:16,795] {logging_mixin.py:112} INFO - [2020-07-22 10:18:16,795] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:16,918] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:17,094] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:18:17,121] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:18:17,126] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.337 seconds
[2020-07-22 10:18:23,948] {scheduler_job.py:153} INFO - Started process (PID=57184) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:23,951] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:18:23,951] {logging_mixin.py:112} INFO - [2020-07-22 10:18:23,951] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:24,015] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:24,127] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:18:24,141] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:18:24,144] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.196 seconds
[2020-07-22 10:18:33,101] {scheduler_job.py:153} INFO - Started process (PID=57423) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:33,105] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:18:33,105] {logging_mixin.py:112} INFO - [2020-07-22 10:18:33,105] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:33,180] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:33,345] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:18:33,372] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:18:33,375] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.274 seconds
[2020-07-22 10:18:45,247] {scheduler_job.py:153} INFO - Started process (PID=57780) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:45,250] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:18:45,251] {logging_mixin.py:112} INFO - [2020-07-22 10:18:45,251] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:45,335] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:45,472] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:18:45,487] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:18:45,489] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.243 seconds
[2020-07-22 10:18:52,729] {scheduler_job.py:153} INFO - Started process (PID=57974) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:52,732] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:18:52,733] {logging_mixin.py:112} INFO - [2020-07-22 10:18:52,733] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:52,797] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:18:52,908] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:18:52,922] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:18:52,925] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.196 seconds
[2020-07-22 10:19:02,761] {scheduler_job.py:153} INFO - Started process (PID=58225) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:02,765] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:19:02,765] {logging_mixin.py:112} INFO - [2020-07-22 10:19:02,765] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:02,837] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:02,953] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:19:02,968] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:19:02,970] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.209 seconds
[2020-07-22 10:19:13,185] {scheduler_job.py:153} INFO - Started process (PID=58456) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:13,189] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:19:13,189] {logging_mixin.py:112} INFO - [2020-07-22 10:19:13,189] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:13,256] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:13,371] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:19:13,398] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:19:13,403] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.218 seconds
[2020-07-22 10:19:25,599] {scheduler_job.py:153} INFO - Started process (PID=58820) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:25,602] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:19:25,603] {logging_mixin.py:112} INFO - [2020-07-22 10:19:25,603] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:25,682] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:25,809] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:19:25,827] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:19:25,830] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.231 seconds
[2020-07-22 10:19:33,157] {scheduler_job.py:153} INFO - Started process (PID=59043) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:33,160] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:19:33,160] {logging_mixin.py:112} INFO - [2020-07-22 10:19:33,160] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:33,226] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:33,345] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:19:33,360] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:19:33,363] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.206 seconds
[2020-07-22 10:19:42,605] {scheduler_job.py:153} INFO - Started process (PID=59259) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:42,609] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:19:42,609] {logging_mixin.py:112} INFO - [2020-07-22 10:19:42,609] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:42,688] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:42,899] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:19:42,920] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:19:42,923] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.318 seconds
[2020-07-22 10:19:52,808] {scheduler_job.py:153} INFO - Started process (PID=59491) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:52,811] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:19:52,811] {logging_mixin.py:112} INFO - [2020-07-22 10:19:52,811] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:52,876] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:19:53,057] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:19:53,072] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:19:53,075] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.267 seconds
[2020-07-22 10:20:06,100] {scheduler_job.py:153} INFO - Started process (PID=59889) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:06,104] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:20:06,104] {logging_mixin.py:112} INFO - [2020-07-22 10:20:06,104] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:06,188] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:06,318] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:20:06,334] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:20:06,338] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.238 seconds
[2020-07-22 10:20:13,257] {scheduler_job.py:153} INFO - Started process (PID=60084) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:13,259] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:20:13,260] {logging_mixin.py:112} INFO - [2020-07-22 10:20:13,259] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:13,325] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:13,436] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:20:13,451] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:20:13,454] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.197 seconds
[2020-07-22 10:20:23,135] {scheduler_job.py:153} INFO - Started process (PID=60305) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:23,139] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:20:23,140] {logging_mixin.py:112} INFO - [2020-07-22 10:20:23,140] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:23,206] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:23,324] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:20:23,340] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:20:23,344] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 10:20:33,074] {scheduler_job.py:153} INFO - Started process (PID=60553) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:33,077] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:20:33,078] {logging_mixin.py:112} INFO - [2020-07-22 10:20:33,077] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:33,144] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:33,269] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:20:33,284] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:20:33,286] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.212 seconds
[2020-07-22 10:20:45,413] {scheduler_job.py:153} INFO - Started process (PID=60882) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:45,417] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:20:45,418] {logging_mixin.py:112} INFO - [2020-07-22 10:20:45,418] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:45,565] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:45,782] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:20:45,813] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:20:45,817] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.404 seconds
[2020-07-22 10:20:59,083] {scheduler_job.py:153} INFO - Started process (PID=61187) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:59,085] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:20:59,086] {logging_mixin.py:112} INFO - [2020-07-22 10:20:59,086] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:59,162] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:20:59,283] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:20:59,298] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:20:59,300] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.218 seconds
[2020-07-22 10:21:06,353] {scheduler_job.py:153} INFO - Started process (PID=61405) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:06,357] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:21:06,357] {logging_mixin.py:112} INFO - [2020-07-22 10:21:06,357] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:06,423] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:06,538] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:21:06,553] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:21:06,555] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.202 seconds
[2020-07-22 10:21:13,735] {scheduler_job.py:153} INFO - Started process (PID=61595) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:13,738] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:21:13,739] {logging_mixin.py:112} INFO - [2020-07-22 10:21:13,739] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:13,809] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:13,928] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:21:13,952] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:21:13,954] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.220 seconds
[2020-07-22 10:21:25,794] {scheduler_job.py:153} INFO - Started process (PID=61923) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:25,798] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:21:25,799] {logging_mixin.py:112} INFO - [2020-07-22 10:21:25,799] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:25,937] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:26,128] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:21:26,156] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:21:26,159] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.365 seconds
[2020-07-22 10:21:35,478] {scheduler_job.py:153} INFO - Started process (PID=62237) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:35,480] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:21:35,481] {logging_mixin.py:112} INFO - [2020-07-22 10:21:35,481] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:35,546] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:35,708] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:21:35,722] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:21:35,725] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.247 seconds
[2020-07-22 10:21:42,626] {scheduler_job.py:153} INFO - Started process (PID=62433) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:42,629] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:21:42,630] {logging_mixin.py:112} INFO - [2020-07-22 10:21:42,630] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:42,695] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:42,784] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:21:42,804] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:21:42,807] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.182 seconds
[2020-07-22 10:21:52,929] {scheduler_job.py:153} INFO - Started process (PID=62657) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:52,932] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:21:52,933] {logging_mixin.py:112} INFO - [2020-07-22 10:21:52,933] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:53,000] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:21:53,106] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:21:53,122] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:21:53,124] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.196 seconds
[2020-07-22 10:22:11,039] {scheduler_job.py:153} INFO - Started process (PID=63093) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:11,042] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:22:11,043] {logging_mixin.py:112} INFO - [2020-07-22 10:22:11,043] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:11,124] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:11,220] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:22:11,235] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:22:11,237] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.199 seconds
[2020-07-22 10:22:18,290] {scheduler_job.py:153} INFO - Started process (PID=63305) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:18,294] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:22:18,295] {logging_mixin.py:112} INFO - [2020-07-22 10:22:18,295] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:18,367] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:18,476] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:22:18,491] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:22:18,494] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 10:22:25,566] {scheduler_job.py:153} INFO - Started process (PID=63498) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:25,569] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:22:25,570] {logging_mixin.py:112} INFO - [2020-07-22 10:22:25,570] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:25,636] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:25,755] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:22:25,770] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:22:25,772] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.206 seconds
[2020-07-22 10:22:33,317] {scheduler_job.py:153} INFO - Started process (PID=63705) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:33,321] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:22:33,321] {logging_mixin.py:112} INFO - [2020-07-22 10:22:33,321] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:33,387] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:33,497] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:22:33,512] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:22:33,514] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.197 seconds
[2020-07-22 10:22:42,898] {scheduler_job.py:153} INFO - Started process (PID=63949) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:42,903] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:22:42,903] {logging_mixin.py:112} INFO - [2020-07-22 10:22:42,903] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:42,993] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:43,194] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:22:43,210] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:22:43,213] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.315 seconds
[2020-07-22 10:22:54,768] {scheduler_job.py:153} INFO - Started process (PID=64298) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:54,770] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:22:54,771] {logging_mixin.py:112} INFO - [2020-07-22 10:22:54,771] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:54,856] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:22:55,053] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:22:55,068] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:22:55,071] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.303 seconds
[2020-07-22 10:23:03,517] {scheduler_job.py:153} INFO - Started process (PID=64521) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:03,521] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:23:03,521] {logging_mixin.py:112} INFO - [2020-07-22 10:23:03,521] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:03,589] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:03,705] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:23:03,727] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:23:03,731] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.214 seconds
[2020-07-22 10:23:13,255] {scheduler_job.py:153} INFO - Started process (PID=64763) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:13,258] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:23:13,258] {logging_mixin.py:112} INFO - [2020-07-22 10:23:13,258] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:13,325] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:13,422] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:23:13,441] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:23:13,445] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.190 seconds
[2020-07-22 10:23:23,456] {scheduler_job.py:153} INFO - Started process (PID=65023) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:23,460] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:23:23,460] {logging_mixin.py:112} INFO - [2020-07-22 10:23:23,460] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:23,584] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:23,723] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:23:23,772] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:23:23,777] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.321 seconds
[2020-07-22 10:23:35,709] {scheduler_job.py:153} INFO - Started process (PID=65356) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:35,713] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:23:35,713] {logging_mixin.py:112} INFO - [2020-07-22 10:23:35,713] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:35,790] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:35,912] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:23:35,927] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:23:35,930] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.220 seconds
[2020-07-22 10:23:42,860] {scheduler_job.py:153} INFO - Started process (PID=65571) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:42,864] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:23:42,865] {logging_mixin.py:112} INFO - [2020-07-22 10:23:42,865] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:42,980] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:43,100] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:23:43,117] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:23:43,120] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.260 seconds
[2020-07-22 10:23:53,140] {scheduler_job.py:153} INFO - Started process (PID=65797) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:53,143] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:23:53,144] {logging_mixin.py:112} INFO - [2020-07-22 10:23:53,143] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:53,215] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:23:53,319] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:23:53,337] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:23:53,340] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-22 10:24:03,218] {scheduler_job.py:153} INFO - Started process (PID=66026) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:03,222] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:24:03,223] {logging_mixin.py:112} INFO - [2020-07-22 10:24:03,222] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:03,296] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:03,425] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:24:03,452] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:24:03,456] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.238 seconds
[2020-07-22 10:24:15,617] {scheduler_job.py:153} INFO - Started process (PID=66410) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:15,621] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:24:15,622] {logging_mixin.py:112} INFO - [2020-07-22 10:24:15,622] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:15,689] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:15,809] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:24:15,824] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:24:15,827] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.210 seconds
[2020-07-22 10:24:23,191] {scheduler_job.py:153} INFO - Started process (PID=66603) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:23,194] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:24:23,194] {logging_mixin.py:112} INFO - [2020-07-22 10:24:23,194] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:23,290] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:23,461] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:24:23,487] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:24:23,491] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.300 seconds
[2020-07-22 10:24:32,910] {scheduler_job.py:153} INFO - Started process (PID=66831) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:32,913] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:24:32,913] {logging_mixin.py:112} INFO - [2020-07-22 10:24:32,913] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:32,980] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:33,227] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:24:33,243] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:24:33,245] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.335 seconds
[2020-07-22 10:24:43,614] {scheduler_job.py:153} INFO - Started process (PID=67094) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:43,617] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:24:43,618] {logging_mixin.py:112} INFO - [2020-07-22 10:24:43,618] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:43,734] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:43,870] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:24:43,895] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:24:43,900] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.286 seconds
[2020-07-22 10:24:55,472] {scheduler_job.py:153} INFO - Started process (PID=67455) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:55,476] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:24:55,477] {logging_mixin.py:112} INFO - [2020-07-22 10:24:55,476] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:55,542] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:24:55,650] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:24:55,668] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:24:55,672] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-22 10:25:02,822] {scheduler_job.py:153} INFO - Started process (PID=67663) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:02,826] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:25:02,826] {logging_mixin.py:112} INFO - [2020-07-22 10:25:02,826] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:02,891] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:02,993] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:25:03,009] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:25:03,012] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.191 seconds
[2020-07-22 10:25:13,761] {scheduler_job.py:153} INFO - Started process (PID=67921) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:13,764] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:25:13,765] {logging_mixin.py:112} INFO - [2020-07-22 10:25:13,765] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:13,839] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:14,105] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:25:14,131] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:25:14,135] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.374 seconds
[2020-07-22 10:25:23,183] {scheduler_job.py:153} INFO - Started process (PID=68147) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:23,187] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:25:23,187] {logging_mixin.py:112} INFO - [2020-07-22 10:25:23,187] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:23,253] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:23,372] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:25:23,387] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:25:23,389] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.206 seconds
[2020-07-22 10:25:35,686] {scheduler_job.py:153} INFO - Started process (PID=68502) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:35,689] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:25:35,689] {logging_mixin.py:112} INFO - [2020-07-22 10:25:35,689] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:35,753] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:35,872] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:25:35,887] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:25:35,889] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 10:25:43,568] {scheduler_job.py:153} INFO - Started process (PID=68735) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:43,572] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:25:43,572] {logging_mixin.py:112} INFO - [2020-07-22 10:25:43,572] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:43,639] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:43,755] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:25:43,771] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:25:43,773] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.205 seconds
[2020-07-22 10:25:53,311] {scheduler_job.py:153} INFO - Started process (PID=68984) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:53,316] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:25:53,317] {logging_mixin.py:112} INFO - [2020-07-22 10:25:53,317] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:53,425] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:25:53,571] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:25:53,587] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:25:53,590] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.279 seconds
[2020-07-22 10:26:03,898] {scheduler_job.py:153} INFO - Started process (PID=69227) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:26:03,901] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:26:03,901] {logging_mixin.py:112} INFO - [2020-07-22 10:26:03,901] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:26:03,966] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:26:04,086] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:26:04,105] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:26:04,108] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.210 seconds
[2020-07-22 10:26:28,043] {scheduler_job.py:153} INFO - Started process (PID=69797) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:26:28,049] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:26:28,050] {logging_mixin.py:112} INFO - [2020-07-22 10:26:28,050] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:26:28,197] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:26:28,343] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:26:28,367] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:26:28,371] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.328 seconds
[2020-07-22 10:26:40,763] {scheduler_job.py:153} INFO - Started process (PID=70056) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:26:40,766] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:26:40,766] {logging_mixin.py:112} INFO - [2020-07-22 10:26:40,766] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:26:40,883] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:26:41,083] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:26:41,319] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:26:41,328] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.565 seconds
[2020-07-22 10:26:51,705] {scheduler_job.py:153} INFO - Started process (PID=70320) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:26:51,710] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:26:51,710] {logging_mixin.py:112} INFO - [2020-07-22 10:26:51,710] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:26:51,838] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:26:52,024] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:26:52,041] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:26:52,044] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.339 seconds
[2020-07-22 10:27:00,654] {scheduler_job.py:153} INFO - Started process (PID=70571) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:00,656] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:27:00,657] {logging_mixin.py:112} INFO - [2020-07-22 10:27:00,657] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:00,751] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:00,916] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:27:00,950] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:27:00,954] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.301 seconds
[2020-07-22 10:27:10,752] {scheduler_job.py:153} INFO - Started process (PID=70868) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:10,754] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:27:10,755] {logging_mixin.py:112} INFO - [2020-07-22 10:27:10,755] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:10,820] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:10,927] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:27:10,944] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:27:10,948] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.196 seconds
[2020-07-22 10:27:18,025] {scheduler_job.py:153} INFO - Started process (PID=71079) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:18,028] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:27:18,028] {logging_mixin.py:112} INFO - [2020-07-22 10:27:18,028] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:18,107] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:18,221] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:27:18,236] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:27:18,239] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.214 seconds
[2020-07-22 10:27:25,825] {scheduler_job.py:153} INFO - Started process (PID=71287) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:25,829] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:27:25,830] {logging_mixin.py:112} INFO - [2020-07-22 10:27:25,830] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:25,958] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:26,159] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:27:26,176] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:27:26,180] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.355 seconds
[2020-07-22 10:27:33,584] {scheduler_job.py:153} INFO - Started process (PID=71481) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:33,588] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:27:33,589] {logging_mixin.py:112} INFO - [2020-07-22 10:27:33,589] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:33,655] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:33,757] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:27:33,787] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:27:33,792] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 10:27:41,494] {scheduler_job.py:153} INFO - Started process (PID=71718) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:41,498] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:27:41,498] {logging_mixin.py:112} INFO - [2020-07-22 10:27:41,498] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:41,572] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:41,686] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:27:41,713] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:27:41,717] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.224 seconds
[2020-07-22 10:27:52,185] {scheduler_job.py:153} INFO - Started process (PID=72047) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:52,188] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:27:52,188] {logging_mixin.py:112} INFO - [2020-07-22 10:27:52,188] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:52,261] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:27:52,393] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:27:52,410] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:27:52,413] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.229 seconds
[2020-07-22 10:28:00,063] {scheduler_job.py:153} INFO - Started process (PID=72244) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:00,068] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:28:00,068] {logging_mixin.py:112} INFO - [2020-07-22 10:28:00,068] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:00,195] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:00,346] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:28:00,372] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:28:00,376] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.313 seconds
[2020-07-22 10:28:07,325] {scheduler_job.py:153} INFO - Started process (PID=72448) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:07,328] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:28:07,329] {logging_mixin.py:112} INFO - [2020-07-22 10:28:07,329] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:07,394] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:07,543] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:28:07,558] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:28:07,561] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.235 seconds
[2020-07-22 10:28:14,484] {scheduler_job.py:153} INFO - Started process (PID=72643) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:14,491] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:28:14,492] {logging_mixin.py:112} INFO - [2020-07-22 10:28:14,492] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:14,603] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:15,189] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:28:15,205] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:28:15,208] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.724 seconds
[2020-07-22 10:28:24,188] {scheduler_job.py:153} INFO - Started process (PID=72910) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:24,191] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:28:24,192] {logging_mixin.py:112} INFO - [2020-07-22 10:28:24,192] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:24,270] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:24,424] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:28:24,452] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:28:24,456] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.269 seconds
[2020-07-22 10:28:36,013] {scheduler_job.py:153} INFO - Started process (PID=73237) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:36,018] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:28:36,019] {logging_mixin.py:112} INFO - [2020-07-22 10:28:36,019] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:36,091] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:36,211] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:28:36,226] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:28:36,228] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.215 seconds
[2020-07-22 10:28:43,909] {scheduler_job.py:153} INFO - Started process (PID=73443) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:43,914] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:28:43,915] {logging_mixin.py:112} INFO - [2020-07-22 10:28:43,915] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:43,984] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:44,109] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:28:44,124] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:28:44,126] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-22 10:28:53,642] {scheduler_job.py:153} INFO - Started process (PID=73681) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:53,645] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:28:53,645] {logging_mixin.py:112} INFO - [2020-07-22 10:28:53,645] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:53,712] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:28:53,954] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:28:53,970] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:28:53,972] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.330 seconds
[2020-07-22 10:29:03,882] {scheduler_job.py:153} INFO - Started process (PID=73920) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:03,886] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:29:03,886] {logging_mixin.py:112} INFO - [2020-07-22 10:29:03,886] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:04,036] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:04,214] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:29:04,244] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:29:04,248] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.370 seconds
[2020-07-22 10:29:16,561] {scheduler_job.py:153} INFO - Started process (PID=74305) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:16,563] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:29:16,564] {logging_mixin.py:112} INFO - [2020-07-22 10:29:16,564] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:16,642] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:16,812] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:29:16,827] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:29:16,829] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.269 seconds
[2020-07-22 10:29:25,133] {scheduler_job.py:153} INFO - Started process (PID=74512) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:25,136] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:29:25,136] {logging_mixin.py:112} INFO - [2020-07-22 10:29:25,136] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:25,219] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:25,361] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:29:25,377] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:29:25,381] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.249 seconds
[2020-07-22 10:29:33,784] {scheduler_job.py:153} INFO - Started process (PID=74721) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:33,787] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:29:33,787] {logging_mixin.py:112} INFO - [2020-07-22 10:29:33,787] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:33,867] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:34,010] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:29:34,026] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:29:34,028] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.244 seconds
[2020-07-22 10:29:43,883] {scheduler_job.py:153} INFO - Started process (PID=74952) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:43,886] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:29:43,887] {logging_mixin.py:112} INFO - [2020-07-22 10:29:43,887] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:43,963] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:44,147] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:29:44,167] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:29:44,170] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.287 seconds
[2020-07-22 10:29:57,267] {scheduler_job.py:153} INFO - Started process (PID=75346) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:57,270] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:29:57,271] {logging_mixin.py:112} INFO - [2020-07-22 10:29:57,271] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:57,337] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:29:57,457] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:29:57,472] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:29:57,475] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.207 seconds
[2020-07-22 10:30:04,644] {scheduler_job.py:153} INFO - Started process (PID=75547) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:04,648] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:30:04,649] {logging_mixin.py:112} INFO - [2020-07-22 10:30:04,648] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:04,735] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:04,845] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:30:04,861] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:30:04,863] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.220 seconds
[2020-07-22 10:30:14,433] {scheduler_job.py:153} INFO - Started process (PID=75772) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:14,436] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:30:14,437] {logging_mixin.py:112} INFO - [2020-07-22 10:30:14,437] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:14,504] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:14,624] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:30:14,639] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:30:14,641] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.209 seconds
[2020-07-22 10:30:23,931] {scheduler_job.py:153} INFO - Started process (PID=76021) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:23,934] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:30:23,935] {logging_mixin.py:112} INFO - [2020-07-22 10:30:23,935] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:24,031] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:24,140] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:30:24,156] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:30:24,158] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.227 seconds
[2020-07-22 10:30:37,302] {scheduler_job.py:153} INFO - Started process (PID=76369) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:37,304] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:30:37,305] {logging_mixin.py:112} INFO - [2020-07-22 10:30:37,305] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:37,372] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:37,543] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:30:37,559] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:30:37,562] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.260 seconds
[2020-07-22 10:30:45,177] {scheduler_job.py:153} INFO - Started process (PID=76595) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:45,181] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:30:45,182] {logging_mixin.py:112} INFO - [2020-07-22 10:30:45,181] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:45,278] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:45,392] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:30:45,409] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:30:45,412] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.235 seconds
[2020-07-22 10:30:53,955] {scheduler_job.py:153} INFO - Started process (PID=76827) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:53,958] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:30:53,958] {logging_mixin.py:112} INFO - [2020-07-22 10:30:53,958] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:54,024] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:30:54,135] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:30:54,150] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:30:54,153] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.197 seconds
[2020-07-22 10:31:03,665] {scheduler_job.py:153} INFO - Started process (PID=77053) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:03,670] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:31:03,670] {logging_mixin.py:112} INFO - [2020-07-22 10:31:03,670] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:03,736] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:03,844] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:31:03,858] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:31:03,861] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.196 seconds
[2020-07-22 10:31:17,507] {scheduler_job.py:153} INFO - Started process (PID=77378) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:17,510] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:31:17,511] {logging_mixin.py:112} INFO - [2020-07-22 10:31:17,511] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:17,701] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:17,827] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:31:17,856] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:31:17,861] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.354 seconds
[2020-07-22 10:31:26,365] {scheduler_job.py:153} INFO - Started process (PID=77660) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:26,369] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:31:26,370] {logging_mixin.py:112} INFO - [2020-07-22 10:31:26,370] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:26,437] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:26,548] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:31:26,562] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:31:26,565] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-22 10:31:33,827] {scheduler_job.py:153} INFO - Started process (PID=77860) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:33,831] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:31:33,831] {logging_mixin.py:112} INFO - [2020-07-22 10:31:33,831] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:33,908] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:34,027] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:31:34,041] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:31:34,044] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-22 10:31:43,811] {scheduler_job.py:153} INFO - Started process (PID=78080) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:43,816] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:31:43,816] {logging_mixin.py:112} INFO - [2020-07-22 10:31:43,816] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:43,894] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:44,136] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:31:44,151] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:31:44,154] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.342 seconds
[2020-07-22 10:31:55,917] {scheduler_job.py:153} INFO - Started process (PID=78395) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:55,921] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:31:55,922] {logging_mixin.py:112} INFO - [2020-07-22 10:31:55,922] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:56,043] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:31:56,240] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:31:56,258] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:31:56,262] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.344 seconds
[2020-07-22 10:32:07,074] {scheduler_job.py:153} INFO - Started process (PID=78708) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:07,077] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:32:07,078] {logging_mixin.py:112} INFO - [2020-07-22 10:32:07,077] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:07,143] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:07,264] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:32:07,292] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:32:07,297] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.223 seconds
[2020-07-22 10:32:14,254] {scheduler_job.py:153} INFO - Started process (PID=78900) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:14,257] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:32:14,258] {logging_mixin.py:112} INFO - [2020-07-22 10:32:14,258] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:14,341] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:14,592] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:32:14,607] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:32:14,610] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.356 seconds
[2020-07-22 10:32:24,982] {scheduler_job.py:153} INFO - Started process (PID=79166) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:24,986] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:32:24,986] {logging_mixin.py:112} INFO - [2020-07-22 10:32:24,986] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:25,052] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:25,160] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:32:25,175] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:32:25,178] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.195 seconds
[2020-07-22 10:32:33,861] {scheduler_job.py:153} INFO - Started process (PID=79378) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:33,864] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:32:33,865] {logging_mixin.py:112} INFO - [2020-07-22 10:32:33,865] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:33,935] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:34,169] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:32:34,184] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:32:34,187] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.326 seconds
[2020-07-22 10:32:46,861] {scheduler_job.py:153} INFO - Started process (PID=79748) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:46,864] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:32:46,865] {logging_mixin.py:112} INFO - [2020-07-22 10:32:46,865] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:46,931] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:47,091] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:32:47,107] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:32:47,109] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.248 seconds
[2020-07-22 10:32:54,517] {scheduler_job.py:153} INFO - Started process (PID=79964) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:54,521] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:32:54,521] {logging_mixin.py:112} INFO - [2020-07-22 10:32:54,521] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:54,609] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:32:54,765] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:32:54,782] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:32:54,785] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.268 seconds
[2020-07-22 10:33:03,795] {scheduler_job.py:153} INFO - Started process (PID=80181) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:03,799] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:33:03,799] {logging_mixin.py:112} INFO - [2020-07-22 10:33:03,799] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:03,871] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:03,976] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:33:04,003] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:33:04,008] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.213 seconds
[2020-07-22 10:33:13,908] {scheduler_job.py:153} INFO - Started process (PID=80407) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:13,912] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:33:13,913] {logging_mixin.py:112} INFO - [2020-07-22 10:33:13,912] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:13,977] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:14,119] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:33:14,148] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:33:14,153] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.244 seconds
[2020-07-22 10:33:27,986] {scheduler_job.py:153} INFO - Started process (PID=80803) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:27,989] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:33:27,990] {logging_mixin.py:112} INFO - [2020-07-22 10:33:27,990] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:28,092] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:28,233] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:33:28,248] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:33:28,250] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.265 seconds
[2020-07-22 10:33:35,635] {scheduler_job.py:153} INFO - Started process (PID=81031) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:35,638] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:33:35,638] {logging_mixin.py:112} INFO - [2020-07-22 10:33:35,638] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:35,820] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:35,942] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:33:35,957] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:33:35,959] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.324 seconds
[2020-07-22 10:33:43,734] {scheduler_job.py:153} INFO - Started process (PID=81235) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:43,737] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:33:43,737] {logging_mixin.py:112} INFO - [2020-07-22 10:33:43,737] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:43,812] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:43,976] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:33:43,990] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:33:43,993] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.259 seconds
[2020-07-22 10:33:54,884] {scheduler_job.py:153} INFO - Started process (PID=81496) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:54,886] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:33:54,887] {logging_mixin.py:112} INFO - [2020-07-22 10:33:54,887] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:54,956] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:33:55,116] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:33:55,132] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:33:55,135] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.251 seconds
[2020-07-22 10:34:06,749] {scheduler_job.py:153} INFO - Started process (PID=81786) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:06,754] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:34:06,755] {logging_mixin.py:112} INFO - [2020-07-22 10:34:06,755] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:06,893] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:07,077] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:34:07,110] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:34:07,115] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.366 seconds
[2020-07-22 10:34:15,624] {scheduler_job.py:153} INFO - Started process (PID=82061) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:15,627] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:34:15,628] {logging_mixin.py:112} INFO - [2020-07-22 10:34:15,628] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:15,706] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:15,821] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:34:15,836] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:34:15,838] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.214 seconds
[2020-07-22 10:34:23,585] {scheduler_job.py:153} INFO - Started process (PID=82260) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:23,589] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:34:23,589] {logging_mixin.py:112} INFO - [2020-07-22 10:34:23,589] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:23,738] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:23,828] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:34:23,843] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:34:23,845] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.261 seconds
[2020-07-22 10:34:34,298] {scheduler_job.py:153} INFO - Started process (PID=82529) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:34,301] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:34:34,301] {logging_mixin.py:112} INFO - [2020-07-22 10:34:34,301] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:34,373] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:34,488] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:34:34,505] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:34:34,508] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.210 seconds
[2020-07-22 10:34:44,521] {scheduler_job.py:153} INFO - Started process (PID=82790) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:44,525] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:34:44,526] {logging_mixin.py:112} INFO - [2020-07-22 10:34:44,525] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:44,616] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:44,731] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:34:44,749] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:34:44,753] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.233 seconds
[2020-07-22 10:34:55,724] {scheduler_job.py:153} INFO - Started process (PID=83117) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:55,728] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:34:55,728] {logging_mixin.py:112} INFO - [2020-07-22 10:34:55,728] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:55,802] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:34:55,981] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:34:55,995] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:34:55,997] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.274 seconds
[2020-07-22 10:35:03,947] {scheduler_job.py:153} INFO - Started process (PID=83328) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:03,950] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:35:03,951] {logging_mixin.py:112} INFO - [2020-07-22 10:35:03,950] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:04,031] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:04,195] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:35:04,209] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:35:04,212] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.265 seconds
[2020-07-22 10:35:13,940] {scheduler_job.py:153} INFO - Started process (PID=83559) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:13,943] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:35:13,944] {logging_mixin.py:112} INFO - [2020-07-22 10:35:13,944] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:14,014] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:14,272] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:35:14,287] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:35:14,289] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.350 seconds
[2020-07-22 10:35:24,996] {scheduler_job.py:153} INFO - Started process (PID=83839) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:24,998] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:35:24,999] {logging_mixin.py:112} INFO - [2020-07-22 10:35:24,999] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:25,069] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:25,180] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:35:25,196] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:35:25,199] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 10:35:36,090] {scheduler_job.py:153} INFO - Started process (PID=84167) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:36,092] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:35:36,093] {logging_mixin.py:112} INFO - [2020-07-22 10:35:36,093] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:36,162] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:36,283] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:35:36,300] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:35:36,304] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.215 seconds
[2020-07-22 10:35:44,659] {scheduler_job.py:153} INFO - Started process (PID=84376) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:44,663] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:35:44,664] {logging_mixin.py:112} INFO - [2020-07-22 10:35:44,663] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:44,730] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:44,836] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:35:44,852] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:35:44,854] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.195 seconds
[2020-07-22 10:35:54,193] {scheduler_job.py:153} INFO - Started process (PID=84599) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:54,196] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:35:54,197] {logging_mixin.py:112} INFO - [2020-07-22 10:35:54,197] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:54,271] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:35:54,402] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:35:54,418] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:35:54,421] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.227 seconds
[2020-07-22 10:36:04,384] {scheduler_job.py:153} INFO - Started process (PID=84856) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:04,388] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:36:04,389] {logging_mixin.py:112} INFO - [2020-07-22 10:36:04,388] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:04,492] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:04,592] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:36:04,607] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:36:04,610] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.226 seconds
[2020-07-22 10:36:16,736] {scheduler_job.py:153} INFO - Started process (PID=85213) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:16,738] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:36:16,739] {logging_mixin.py:112} INFO - [2020-07-22 10:36:16,739] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:16,817] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:16,999] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:36:17,014] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:36:17,017] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.281 seconds
[2020-07-22 10:36:24,044] {scheduler_job.py:153} INFO - Started process (PID=85411) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:24,047] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:36:24,048] {logging_mixin.py:112} INFO - [2020-07-22 10:36:24,047] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:24,117] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:24,222] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:36:24,237] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:36:24,239] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.196 seconds
[2020-07-22 10:36:33,929] {scheduler_job.py:153} INFO - Started process (PID=85661) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:33,933] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:36:33,933] {logging_mixin.py:112} INFO - [2020-07-22 10:36:33,933] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:34,001] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:34,191] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:36:34,205] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:36:34,208] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.279 seconds
[2020-07-22 10:36:44,362] {scheduler_job.py:153} INFO - Started process (PID=85891) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:44,375] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:36:44,376] {logging_mixin.py:112} INFO - [2020-07-22 10:36:44,376] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:44,521] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:44,714] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:36:44,757] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:36:44,762] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.401 seconds
[2020-07-22 10:36:56,890] {scheduler_job.py:153} INFO - Started process (PID=86252) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:56,894] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:36:56,895] {logging_mixin.py:112} INFO - [2020-07-22 10:36:56,895] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:56,991] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:36:57,196] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:36:57,212] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:36:57,215] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.325 seconds
[2020-07-22 10:37:04,540] {scheduler_job.py:153} INFO - Started process (PID=86473) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:04,543] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:37:04,544] {logging_mixin.py:112} INFO - [2020-07-22 10:37:04,544] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:04,608] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:04,714] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:37:04,730] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:37:04,732] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.192 seconds
[2020-07-22 10:37:14,074] {scheduler_job.py:153} INFO - Started process (PID=86686) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:14,077] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:37:14,077] {logging_mixin.py:112} INFO - [2020-07-22 10:37:14,077] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:14,188] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:14,315] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:37:14,330] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:37:14,333] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.258 seconds
[2020-07-22 10:37:24,281] {scheduler_job.py:153} INFO - Started process (PID=86929) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:24,284] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:37:24,284] {logging_mixin.py:112} INFO - [2020-07-22 10:37:24,284] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:24,352] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:24,457] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:37:24,472] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:37:24,475] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.194 seconds
[2020-07-22 10:37:37,340] {scheduler_job.py:153} INFO - Started process (PID=87310) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:37,342] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:37:37,343] {logging_mixin.py:112} INFO - [2020-07-22 10:37:37,343] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:37,443] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:37,589] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:37:37,605] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:37:37,608] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.268 seconds
[2020-07-22 10:37:44,497] {scheduler_job.py:153} INFO - Started process (PID=87507) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:44,500] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:37:44,501] {logging_mixin.py:112} INFO - [2020-07-22 10:37:44,501] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:44,573] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:44,695] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:37:44,710] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:37:44,712] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.216 seconds
[2020-07-22 10:37:55,057] {scheduler_job.py:153} INFO - Started process (PID=87743) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:55,060] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:37:55,060] {logging_mixin.py:112} INFO - [2020-07-22 10:37:55,060] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:55,125] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:37:55,251] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:37:55,266] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:37:55,269] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.212 seconds
[2020-07-22 10:38:04,258] {scheduler_job.py:153} INFO - Started process (PID=87985) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:04,260] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:38:04,261] {logging_mixin.py:112} INFO - [2020-07-22 10:38:04,261] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:04,343] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:04,450] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:38:04,465] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:38:04,468] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.210 seconds
[2020-07-22 10:38:17,429] {scheduler_job.py:153} INFO - Started process (PID=88353) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:17,433] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:38:17,434] {logging_mixin.py:112} INFO - [2020-07-22 10:38:17,433] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:17,500] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:17,664] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:38:17,680] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:38:17,683] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.254 seconds
[2020-07-22 10:38:25,231] {scheduler_job.py:153} INFO - Started process (PID=88560) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:25,235] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:38:25,235] {logging_mixin.py:112} INFO - [2020-07-22 10:38:25,235] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:25,300] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:25,418] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:38:25,434] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:38:25,437] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.205 seconds
[2020-07-22 10:38:34,465] {scheduler_job.py:153} INFO - Started process (PID=88798) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:34,469] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:38:34,469] {logging_mixin.py:112} INFO - [2020-07-22 10:38:34,469] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:34,543] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:34,664] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:38:34,679] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:38:34,682] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.216 seconds
[2020-07-22 10:38:44,077] {scheduler_job.py:153} INFO - Started process (PID=89019) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:44,081] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:38:44,081] {logging_mixin.py:112} INFO - [2020-07-22 10:38:44,081] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:44,146] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:44,288] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:38:44,315] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:38:44,319] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.242 seconds
[2020-07-22 10:38:58,346] {scheduler_job.py:153} INFO - Started process (PID=89380) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:58,351] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:38:58,352] {logging_mixin.py:112} INFO - [2020-07-22 10:38:58,352] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:58,471] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:38:58,639] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:38:58,655] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:38:58,658] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.312 seconds
[2020-07-22 10:39:06,112] {scheduler_job.py:153} INFO - Started process (PID=89629) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:06,116] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:39:06,116] {logging_mixin.py:112} INFO - [2020-07-22 10:39:06,116] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:06,181] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:06,288] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:39:06,303] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:39:06,305] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.194 seconds
[2020-07-22 10:39:14,108] {scheduler_job.py:153} INFO - Started process (PID=89834) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:14,111] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:39:14,111] {logging_mixin.py:112} INFO - [2020-07-22 10:39:14,111] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:14,180] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:14,346] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:39:14,361] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:39:14,364] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.256 seconds
[2020-07-22 10:39:24,346] {scheduler_job.py:153} INFO - Started process (PID=90059) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:24,349] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:39:24,350] {logging_mixin.py:112} INFO - [2020-07-22 10:39:24,350] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:24,415] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:24,545] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:39:24,560] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:39:24,563] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-22 10:39:37,097] {scheduler_job.py:153} INFO - Started process (PID=90387) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:37,102] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:39:37,103] {logging_mixin.py:112} INFO - [2020-07-22 10:39:37,102] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:37,221] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:37,348] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:39:37,382] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:39:37,387] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.289 seconds
[2020-07-22 10:39:45,699] {scheduler_job.py:153} INFO - Started process (PID=90657) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:45,703] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:39:45,703] {logging_mixin.py:112} INFO - [2020-07-22 10:39:45,703] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:45,771] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:45,870] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:39:45,889] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:39:45,892] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.192 seconds
[2020-07-22 10:39:54,256] {scheduler_job.py:153} INFO - Started process (PID=90872) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:54,260] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:39:54,260] {logging_mixin.py:112} INFO - [2020-07-22 10:39:54,260] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:54,325] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:39:54,447] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:39:54,462] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:39:54,465] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.209 seconds
[2020-07-22 10:40:05,185] {scheduler_job.py:153} INFO - Started process (PID=91136) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:05,187] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:40:05,188] {logging_mixin.py:112} INFO - [2020-07-22 10:40:05,188] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:05,280] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:05,421] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:40:05,437] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:40:05,439] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.255 seconds
[2020-07-22 10:40:14,768] {scheduler_job.py:153} INFO - Started process (PID=91396) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:14,771] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:40:14,771] {logging_mixin.py:112} INFO - [2020-07-22 10:40:14,771] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:14,875] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:14,993] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:40:15,016] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:40:15,019] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.252 seconds
[2020-07-22 10:40:25,816] {scheduler_job.py:153} INFO - Started process (PID=91702) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:25,819] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:40:25,820] {logging_mixin.py:112} INFO - [2020-07-22 10:40:25,820] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:25,897] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:26,049] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:40:26,064] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:40:26,067] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.252 seconds
[2020-07-22 10:40:34,298] {scheduler_job.py:153} INFO - Started process (PID=91922) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:34,303] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:40:34,304] {logging_mixin.py:112} INFO - [2020-07-22 10:40:34,303] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:34,410] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:34,895] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:40:34,920] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:40:34,924] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.625 seconds
[2020-07-22 10:40:44,202] {scheduler_job.py:153} INFO - Started process (PID=92155) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:44,206] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:40:44,207] {logging_mixin.py:112} INFO - [2020-07-22 10:40:44,207] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:44,291] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:44,418] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:40:44,433] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:40:44,435] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.233 seconds
[2020-07-22 10:40:55,030] {scheduler_job.py:153} INFO - Started process (PID=92430) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:55,032] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:40:55,033] {logging_mixin.py:112} INFO - [2020-07-22 10:40:55,033] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:55,102] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:40:55,200] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:40:55,217] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:40:55,220] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.191 seconds
[2020-07-22 10:41:06,900] {scheduler_job.py:153} INFO - Started process (PID=92768) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:06,903] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:41:06,903] {logging_mixin.py:112} INFO - [2020-07-22 10:41:06,903] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:06,995] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:07,179] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:41:07,195] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:41:07,198] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.298 seconds
[2020-07-22 10:41:14,343] {scheduler_job.py:153} INFO - Started process (PID=92970) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:14,346] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:41:14,346] {logging_mixin.py:112} INFO - [2020-07-22 10:41:14,346] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:14,416] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:14,575] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:41:14,590] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:41:14,592] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.249 seconds
[2020-07-22 10:41:24,792] {scheduler_job.py:153} INFO - Started process (PID=93201) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:24,795] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:41:24,795] {logging_mixin.py:112} INFO - [2020-07-22 10:41:24,795] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:24,868] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:24,974] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:41:24,989] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:41:24,992] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-22 10:41:35,213] {scheduler_job.py:153} INFO - Started process (PID=93464) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:35,216] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:41:35,217] {logging_mixin.py:112} INFO - [2020-07-22 10:41:35,217] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:35,325] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:35,540] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:41:35,560] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:41:35,563] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.349 seconds
[2020-07-22 10:41:47,539] {scheduler_job.py:153} INFO - Started process (PID=93845) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:47,543] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:41:47,544] {logging_mixin.py:112} INFO - [2020-07-22 10:41:47,544] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:47,619] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:47,735] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:41:47,752] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:41:47,755] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.216 seconds
[2020-07-22 10:41:55,909] {scheduler_job.py:153} INFO - Started process (PID=94058) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:55,913] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:41:55,914] {logging_mixin.py:112} INFO - [2020-07-22 10:41:55,914] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:55,996] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:41:56,123] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:41:56,153] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:41:56,160] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.251 seconds
[2020-07-22 10:42:11,306] {scheduler_job.py:153} INFO - Started process (PID=94395) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:11,318] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:42:11,319] {logging_mixin.py:112} INFO - [2020-07-22 10:42:11,319] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:11,517] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:11,684] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:42:11,704] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:42:11,707] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.401 seconds
[2020-07-22 10:42:23,137] {scheduler_job.py:153} INFO - Started process (PID=94727) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:23,141] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:42:23,143] {logging_mixin.py:112} INFO - [2020-07-22 10:42:23,142] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:23,335] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:23,568] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:42:23,601] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:42:23,604] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.468 seconds
[2020-07-22 10:42:31,688] {scheduler_job.py:153} INFO - Started process (PID=94981) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:31,691] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:42:31,691] {logging_mixin.py:112} INFO - [2020-07-22 10:42:31,691] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:31,760] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:31,933] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:42:31,950] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:42:31,952] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.264 seconds
[2020-07-22 10:42:38,777] {scheduler_job.py:153} INFO - Started process (PID=95182) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:38,781] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:42:38,782] {logging_mixin.py:112} INFO - [2020-07-22 10:42:38,782] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:38,858] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:39,921] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:42:39,936] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:42:39,939] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.161 seconds
[2020-07-22 10:42:47,251] {scheduler_job.py:153} INFO - Started process (PID=95411) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:47,255] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:42:47,256] {logging_mixin.py:112} INFO - [2020-07-22 10:42:47,256] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:47,369] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:47,502] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:42:47,527] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:42:47,530] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.279 seconds
[2020-07-22 10:42:54,930] {scheduler_job.py:153} INFO - Started process (PID=95606) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:54,933] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:42:54,933] {logging_mixin.py:112} INFO - [2020-07-22 10:42:54,933] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:55,001] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:42:55,112] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:42:55,127] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:42:55,129] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.199 seconds
[2020-07-22 10:43:07,456] {scheduler_job.py:153} INFO - Started process (PID=95939) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:07,459] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:43:07,460] {logging_mixin.py:112} INFO - [2020-07-22 10:43:07,460] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:07,600] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:07,755] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:43:07,790] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:43:07,798] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.342 seconds
[2020-07-22 10:43:14,812] {scheduler_job.py:153} INFO - Started process (PID=96188) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:14,816] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:43:14,816] {logging_mixin.py:112} INFO - [2020-07-22 10:43:14,816] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:14,883] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:14,976] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:43:14,991] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:43:14,994] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.182 seconds
[2020-07-22 10:43:25,260] {scheduler_job.py:153} INFO - Started process (PID=96422) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:25,262] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:43:25,263] {logging_mixin.py:112} INFO - [2020-07-22 10:43:25,263] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:25,327] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:25,426] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:43:25,441] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:43:25,444] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.184 seconds
[2020-07-22 10:43:34,455] {scheduler_job.py:153} INFO - Started process (PID=96635) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:34,459] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:43:34,459] {logging_mixin.py:112} INFO - [2020-07-22 10:43:34,459] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:34,525] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:34,648] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:43:34,662] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:43:34,665] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.210 seconds
[2020-07-22 10:43:47,634] {scheduler_job.py:153} INFO - Started process (PID=97002) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:47,648] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:43:47,649] {logging_mixin.py:112} INFO - [2020-07-22 10:43:47,648] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:47,784] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:47,910] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:43:47,927] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:43:47,930] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.297 seconds
[2020-07-22 10:43:55,787] {scheduler_job.py:153} INFO - Started process (PID=97233) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:55,790] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:43:55,790] {logging_mixin.py:112} INFO - [2020-07-22 10:43:55,790] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:55,860] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:43:55,971] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:43:55,986] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:43:55,988] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.201 seconds
[2020-07-22 10:44:04,656] {scheduler_job.py:153} INFO - Started process (PID=97448) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:04,658] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:44:04,659] {logging_mixin.py:112} INFO - [2020-07-22 10:44:04,658] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:04,730] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:04,850] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:44:04,865] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:44:04,867] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.212 seconds
[2020-07-22 10:44:15,191] {scheduler_job.py:153} INFO - Started process (PID=97702) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:15,194] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:44:15,195] {logging_mixin.py:112} INFO - [2020-07-22 10:44:15,194] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:15,263] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:15,361] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:44:15,387] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:44:15,390] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.198 seconds
[2020-07-22 10:44:28,125] {scheduler_job.py:153} INFO - Started process (PID=98028) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:28,129] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:44:28,129] {logging_mixin.py:112} INFO - [2020-07-22 10:44:28,129] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:28,239] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:28,373] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:44:28,398] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:44:28,402] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.277 seconds
[2020-07-22 10:44:36,085] {scheduler_job.py:153} INFO - Started process (PID=98268) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:36,089] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:44:36,090] {logging_mixin.py:112} INFO - [2020-07-22 10:44:36,090] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:36,165] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:36,416] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:44:36,430] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:44:36,433] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.348 seconds
[2020-07-22 10:44:54,776] {scheduler_job.py:153} INFO - Started process (PID=98618) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:54,779] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:44:54,780] {logging_mixin.py:112} INFO - [2020-07-22 10:44:54,780] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:54,876] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:44:55,035] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:44:55,050] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:44:55,054] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.278 seconds
[2020-07-22 10:45:02,449] {scheduler_job.py:153} INFO - Started process (PID=98832) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:02,452] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:45:02,452] {logging_mixin.py:112} INFO - [2020-07-22 10:45:02,452] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:02,529] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:02,678] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:45:02,700] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:45:02,705] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.256 seconds
[2020-07-22 10:45:13,199] {scheduler_job.py:153} INFO - Started process (PID=99183) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:13,204] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:45:13,205] {logging_mixin.py:112} INFO - [2020-07-22 10:45:13,205] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:13,348] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:13,952] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:45:13,967] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:45:13,969] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.770 seconds
[2020-07-22 10:45:20,935] {scheduler_job.py:153} INFO - Started process (PID=99393) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:20,940] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:45:20,940] {logging_mixin.py:112} INFO - [2020-07-22 10:45:20,940] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:21,004] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:21,120] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:45:21,140] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:45:21,143] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 10:45:28,211] {scheduler_job.py:153} INFO - Started process (PID=99589) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:28,217] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:45:28,217] {logging_mixin.py:112} INFO - [2020-07-22 10:45:28,217] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:28,310] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:28,425] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:45:28,440] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:45:28,442] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.231 seconds
[2020-07-22 10:45:35,866] {scheduler_job.py:153} INFO - Started process (PID=99791) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:35,870] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:45:35,871] {logging_mixin.py:112} INFO - [2020-07-22 10:45:35,871] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:35,943] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:36,064] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:45:36,079] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:45:36,082] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.216 seconds
[2020-07-22 10:45:45,792] {scheduler_job.py:153} INFO - Started process (PID=100079) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:45,797] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:45:45,797] {logging_mixin.py:112} INFO - [2020-07-22 10:45:45,797] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:45,907] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:46,091] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:45:46,107] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:45:46,110] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.318 seconds
[2020-07-22 10:45:57,007] {scheduler_job.py:153} INFO - Started process (PID=100389) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:57,012] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:45:57,012] {logging_mixin.py:112} INFO - [2020-07-22 10:45:57,012] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:57,077] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:45:57,189] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:45:57,204] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:45:57,206] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-22 10:46:05,178] {scheduler_job.py:153} INFO - Started process (PID=100598) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:05,181] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:46:05,182] {logging_mixin.py:112} INFO - [2020-07-22 10:46:05,182] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:05,261] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:05,480] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:46:05,495] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:46:05,498] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.320 seconds
[2020-07-22 10:46:14,696] {scheduler_job.py:153} INFO - Started process (PID=100814) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:14,700] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:46:14,700] {logging_mixin.py:112} INFO - [2020-07-22 10:46:14,700] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:14,778] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:14,965] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:46:14,981] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:46:14,983] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.287 seconds
[2020-07-22 10:46:24,720] {scheduler_job.py:153} INFO - Started process (PID=101063) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:24,723] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:46:24,723] {logging_mixin.py:112} INFO - [2020-07-22 10:46:24,723] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:24,797] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:24,941] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:46:24,981] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:46:24,986] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.266 seconds
[2020-07-22 10:46:37,254] {scheduler_job.py:153} INFO - Started process (PID=101436) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:37,258] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:46:37,258] {logging_mixin.py:112} INFO - [2020-07-22 10:46:37,258] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:37,335] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:37,440] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:46:37,457] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:46:37,460] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.206 seconds
[2020-07-22 10:46:44,828] {scheduler_job.py:153} INFO - Started process (PID=101625) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:44,831] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:46:44,832] {logging_mixin.py:112} INFO - [2020-07-22 10:46:44,832] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:44,898] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:45,011] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:46:45,026] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:46:45,029] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.201 seconds
[2020-07-22 10:46:55,240] {scheduler_job.py:153} INFO - Started process (PID=101877) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:55,243] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:46:55,243] {logging_mixin.py:112} INFO - [2020-07-22 10:46:55,243] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:55,342] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:46:55,468] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:46:55,482] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:46:55,485] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.244 seconds
[2020-07-22 10:47:05,783] {scheduler_job.py:153} INFO - Started process (PID=102121) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:05,785] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:47:05,786] {logging_mixin.py:112} INFO - [2020-07-22 10:47:05,786] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:05,859] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:06,017] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:47:06,042] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:47:06,046] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.263 seconds
[2020-07-22 10:47:18,700] {scheduler_job.py:153} INFO - Started process (PID=102509) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:18,704] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:47:18,704] {logging_mixin.py:112} INFO - [2020-07-22 10:47:18,704] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:18,783] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:18,901] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:47:18,925] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:47:18,929] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.229 seconds
[2020-07-22 10:47:26,166] {scheduler_job.py:153} INFO - Started process (PID=102706) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:26,169] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:47:26,169] {logging_mixin.py:112} INFO - [2020-07-22 10:47:26,169] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:26,234] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:26,363] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:47:26,378] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:47:26,381] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.214 seconds
[2020-07-22 10:47:34,601] {scheduler_job.py:153} INFO - Started process (PID=102910) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:34,604] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:47:34,605] {logging_mixin.py:112} INFO - [2020-07-22 10:47:34,605] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:34,671] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:34,799] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:47:34,829] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:47:34,833] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.232 seconds
[2020-07-22 10:47:45,423] {scheduler_job.py:153} INFO - Started process (PID=103151) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:45,427] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:47:45,428] {logging_mixin.py:112} INFO - [2020-07-22 10:47:45,428] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:45,518] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:45,636] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:47:45,651] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:47:45,653] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.230 seconds
[2020-07-22 10:47:57,866] {scheduler_job.py:153} INFO - Started process (PID=103531) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:57,869] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:47:57,870] {logging_mixin.py:112} INFO - [2020-07-22 10:47:57,870] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:57,936] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:47:58,095] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:47:58,114] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:47:58,119] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.253 seconds
[2020-07-22 10:48:05,020] {scheduler_job.py:153} INFO - Started process (PID=103722) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:05,022] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:48:05,023] {logging_mixin.py:112} INFO - [2020-07-22 10:48:05,023] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:05,089] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:05,211] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:48:05,232] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:48:05,235] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.215 seconds
[2020-07-22 10:48:14,854] {scheduler_job.py:153} INFO - Started process (PID=103970) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:14,857] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:48:14,857] {logging_mixin.py:112} INFO - [2020-07-22 10:48:14,857] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:14,928] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:15,030] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:48:15,046] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:48:15,049] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.195 seconds
[2020-07-22 10:48:24,963] {scheduler_job.py:153} INFO - Started process (PID=104231) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:24,966] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:48:24,966] {logging_mixin.py:112} INFO - [2020-07-22 10:48:24,966] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:25,032] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:25,195] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:48:25,209] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:48:25,212] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.249 seconds
[2020-07-22 10:48:37,996] {scheduler_job.py:153} INFO - Started process (PID=104594) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:37,998] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:48:37,999] {logging_mixin.py:112} INFO - [2020-07-22 10:48:37,998] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:38,067] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:38,164] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:48:38,180] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:48:38,183] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.188 seconds
[2020-07-22 10:48:45,053] {scheduler_job.py:153} INFO - Started process (PID=104787) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:45,058] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:48:45,058] {logging_mixin.py:112} INFO - [2020-07-22 10:48:45,058] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:45,123] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:45,239] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:48:45,253] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:48:45,256] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.203 seconds
[2020-07-22 10:48:55,286] {scheduler_job.py:153} INFO - Started process (PID=105041) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:55,289] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:48:55,289] {logging_mixin.py:112} INFO - [2020-07-22 10:48:55,289] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:55,354] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:48:55,483] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:48:55,498] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:48:55,500] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.215 seconds
[2020-07-22 10:49:05,203] {scheduler_job.py:153} INFO - Started process (PID=105269) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:05,206] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:49:05,207] {logging_mixin.py:112} INFO - [2020-07-22 10:49:05,207] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:05,273] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:05,549] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:49:05,564] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:49:05,567] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.364 seconds
[2020-07-22 10:49:17,444] {scheduler_job.py:153} INFO - Started process (PID=105599) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:17,448] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:49:17,449] {logging_mixin.py:112} INFO - [2020-07-22 10:49:17,449] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:17,563] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:17,738] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:49:17,753] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:49:17,756] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.311 seconds
[2020-07-22 10:49:25,739] {scheduler_job.py:153} INFO - Started process (PID=105853) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:25,741] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:49:25,742] {logging_mixin.py:112} INFO - [2020-07-22 10:49:25,742] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:25,807] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:25,896] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:49:25,910] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:49:25,913] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.174 seconds
[2020-07-22 10:49:34,930] {scheduler_job.py:153} INFO - Started process (PID=106069) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:34,934] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:49:34,934] {logging_mixin.py:112} INFO - [2020-07-22 10:49:34,934] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:35,001] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:35,119] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:49:35,133] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:49:35,136] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.205 seconds
[2020-07-22 10:49:44,666] {scheduler_job.py:153} INFO - Started process (PID=106291) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:44,669] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:49:44,670] {logging_mixin.py:112} INFO - [2020-07-22 10:49:44,670] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:44,760] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:44,924] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:49:44,941] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:49:44,946] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.280 seconds
[2020-07-22 10:49:57,718] {scheduler_job.py:153} INFO - Started process (PID=106630) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:57,723] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:49:57,724] {logging_mixin.py:112} INFO - [2020-07-22 10:49:57,723] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:57,831] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:49:58,013] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:49:58,036] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:49:58,039] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.321 seconds
[2020-07-22 10:50:06,281] {scheduler_job.py:153} INFO - Started process (PID=106882) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:06,284] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:50:06,284] {logging_mixin.py:112} INFO - [2020-07-22 10:50:06,284] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:06,349] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:06,463] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:50:06,478] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:50:06,480] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-22 10:50:14,884] {scheduler_job.py:153} INFO - Started process (PID=107095) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:14,889] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:50:14,890] {logging_mixin.py:112} INFO - [2020-07-22 10:50:14,889] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:14,980] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:15,091] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:50:15,107] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:50:15,110] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.226 seconds
[2020-07-22 10:50:25,201] {scheduler_job.py:153} INFO - Started process (PID=107346) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:25,204] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:50:25,205] {logging_mixin.py:112} INFO - [2020-07-22 10:50:25,204] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:25,275] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:25,396] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:50:25,414] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:50:25,416] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.215 seconds
[2020-07-22 10:50:36,838] {scheduler_job.py:153} INFO - Started process (PID=107629) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:36,843] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:50:36,844] {logging_mixin.py:112} INFO - [2020-07-22 10:50:36,844] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:37,158] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:37,367] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:50:37,391] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:50:37,394] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.555 seconds
[2020-07-22 10:50:47,025] {scheduler_job.py:153} INFO - Started process (PID=107950) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:47,029] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:50:47,030] {logging_mixin.py:112} INFO - [2020-07-22 10:50:47,030] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:47,102] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:47,220] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:50:47,252] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:50:47,258] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.233 seconds
[2020-07-22 10:50:57,670] {scheduler_job.py:153} INFO - Started process (PID=108219) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:57,672] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:50:57,673] {logging_mixin.py:112} INFO - [2020-07-22 10:50:57,673] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:57,745] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:50:57,860] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:50:57,889] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:50:57,895] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.225 seconds
[2020-07-22 10:51:07,178] {scheduler_job.py:153} INFO - Started process (PID=108445) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:07,183] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:51:07,185] {logging_mixin.py:112} INFO - [2020-07-22 10:51:07,184] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:07,267] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:07,387] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:51:07,403] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:51:07,406] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.228 seconds
[2020-07-22 10:51:17,181] {scheduler_job.py:153} INFO - Started process (PID=108730) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:17,186] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:51:17,186] {logging_mixin.py:112} INFO - [2020-07-22 10:51:17,186] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:17,251] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:17,399] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:51:17,414] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:51:17,417] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.236 seconds
[2020-07-22 10:51:28,114] {scheduler_job.py:153} INFO - Started process (PID=109057) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:28,117] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:51:28,117] {logging_mixin.py:112} INFO - [2020-07-22 10:51:28,117] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:28,193] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:28,356] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:51:28,372] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:51:28,374] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.260 seconds
[2020-07-22 10:51:36,391] {scheduler_job.py:153} INFO - Started process (PID=109271) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:36,394] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:51:36,394] {logging_mixin.py:112} INFO - [2020-07-22 10:51:36,394] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:36,460] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:36,580] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:51:36,595] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:51:36,598] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.207 seconds
[2020-07-22 10:51:45,803] {scheduler_job.py:153} INFO - Started process (PID=109488) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:45,810] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:51:45,812] {logging_mixin.py:112} INFO - [2020-07-22 10:51:45,812] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:45,899] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:46,073] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:51:46,107] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:51:46,113] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.309 seconds
[2020-07-22 10:51:56,141] {scheduler_job.py:153} INFO - Started process (PID=109726) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:56,147] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:51:56,149] {logging_mixin.py:112} INFO - [2020-07-22 10:51:56,148] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:56,378] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:51:56,526] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:51:56,619] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:51:56,641] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.500 seconds
[2020-07-22 10:52:13,724] {scheduler_job.py:153} INFO - Started process (PID=110182) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:13,730] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:52:13,731] {logging_mixin.py:112} INFO - [2020-07-22 10:52:13,731] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:13,829] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:13,968] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:52:13,984] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:52:13,986] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.262 seconds
[2020-07-22 10:52:22,289] {scheduler_job.py:153} INFO - Started process (PID=110388) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:22,293] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:52:22,293] {logging_mixin.py:112} INFO - [2020-07-22 10:52:22,293] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:22,358] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:22,469] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:52:22,484] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:52:22,487] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.198 seconds
[2020-07-22 10:52:30,270] {scheduler_job.py:153} INFO - Started process (PID=110616) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:30,273] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:52:30,274] {logging_mixin.py:112} INFO - [2020-07-22 10:52:30,274] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:30,349] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:30,469] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:52:30,484] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:52:30,486] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.216 seconds
[2020-07-22 10:52:42,357] {scheduler_job.py:153} INFO - Started process (PID=110897) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:42,361] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:52:42,361] {logging_mixin.py:112} INFO - [2020-07-22 10:52:42,361] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:42,428] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:42,560] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:52:42,574] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:52:42,577] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.220 seconds
[2020-07-22 10:52:53,638] {scheduler_job.py:153} INFO - Started process (PID=111216) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:53,657] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:52:53,658] {logging_mixin.py:112} INFO - [2020-07-22 10:52:53,657] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:53,779] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:52:53,927] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:52:53,958] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:52:53,963] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.325 seconds
[2020-07-22 10:53:01,508] {scheduler_job.py:153} INFO - Started process (PID=111464) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:01,512] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:53:01,513] {logging_mixin.py:112} INFO - [2020-07-22 10:53:01,513] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:01,598] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:01,725] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:53:01,740] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:53:01,742] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.235 seconds
[2020-07-22 10:53:08,989] {scheduler_job.py:153} INFO - Started process (PID=111653) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:08,993] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:53:08,994] {logging_mixin.py:112} INFO - [2020-07-22 10:53:08,993] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:09,059] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:09,254] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:53:09,286] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:53:09,291] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.302 seconds
[2020-07-22 10:53:17,888] {scheduler_job.py:153} INFO - Started process (PID=111873) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:17,893] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:53:17,893] {logging_mixin.py:112} INFO - [2020-07-22 10:53:17,893] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:17,962] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:18,149] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:53:18,163] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:53:18,166] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.278 seconds
[2020-07-22 10:53:25,933] {scheduler_job.py:153} INFO - Started process (PID=112078) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:25,952] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:53:25,953] {logging_mixin.py:112} INFO - [2020-07-22 10:53:25,952] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:26,035] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:26,197] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:53:26,217] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:53:26,220] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.287 seconds
[2020-07-22 10:53:41,602] {scheduler_job.py:153} INFO - Started process (PID=112474) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:41,608] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:53:41,609] {logging_mixin.py:112} INFO - [2020-07-22 10:53:41,609] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:41,756] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:41,898] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:53:41,914] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:53:41,917] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.315 seconds
[2020-07-22 10:53:55,796] {scheduler_job.py:153} INFO - Started process (PID=112797) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:55,801] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:53:55,801] {logging_mixin.py:112} INFO - [2020-07-22 10:53:55,801] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:55,910] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:53:56,039] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:53:56,066] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:53:56,070] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.275 seconds
[2020-07-22 10:54:04,966] {scheduler_job.py:153} INFO - Started process (PID=113042) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:04,969] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:54:04,970] {logging_mixin.py:112} INFO - [2020-07-22 10:54:04,970] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:05,048] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:05,161] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:54:05,179] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:54:05,181] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.215 seconds
[2020-07-22 10:54:13,651] {scheduler_job.py:153} INFO - Started process (PID=113252) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:13,655] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:54:13,655] {logging_mixin.py:112} INFO - [2020-07-22 10:54:13,655] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:13,727] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:13,855] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:54:13,871] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:54:13,874] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.223 seconds
[2020-07-22 10:54:32,072] {scheduler_job.py:153} INFO - Started process (PID=113696) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:32,076] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:54:32,076] {logging_mixin.py:112} INFO - [2020-07-22 10:54:32,076] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:32,193] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:32,433] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:54:32,462] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:54:32,467] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.395 seconds
[2020-07-22 10:54:40,885] {scheduler_job.py:153} INFO - Started process (PID=113915) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:40,888] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:54:40,889] {logging_mixin.py:112} INFO - [2020-07-22 10:54:40,888] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:40,955] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:41,084] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:54:41,104] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:54:41,107] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.221 seconds
[2020-07-22 10:54:49,850] {scheduler_job.py:153} INFO - Started process (PID=114135) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:49,852] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:54:49,853] {logging_mixin.py:112} INFO - [2020-07-22 10:54:49,853] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:49,921] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:50,039] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:54:50,055] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:54:50,057] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 10:54:58,320] {scheduler_job.py:153} INFO - Started process (PID=114345) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:58,322] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:54:58,323] {logging_mixin.py:112} INFO - [2020-07-22 10:54:58,323] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:58,392] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:54:58,509] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:54:58,525] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:54:58,528] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 10:55:09,391] {scheduler_job.py:153} INFO - Started process (PID=114648) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:09,395] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:55:09,396] {logging_mixin.py:112} INFO - [2020-07-22 10:55:09,396] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:09,624] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:09,779] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:55:09,828] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:55:09,833] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.442 seconds
[2020-07-22 10:55:20,293] {scheduler_job.py:153} INFO - Started process (PID=114958) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:20,295] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:55:20,296] {logging_mixin.py:112} INFO - [2020-07-22 10:55:20,296] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:20,363] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:20,573] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:55:20,588] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:55:20,591] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.298 seconds
[2020-07-22 10:55:30,505] {scheduler_job.py:153} INFO - Started process (PID=115192) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:30,510] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:55:30,511] {logging_mixin.py:112} INFO - [2020-07-22 10:55:30,511] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:30,591] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:30,707] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:55:30,723] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:55:30,725] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.220 seconds
[2020-07-22 10:55:39,167] {scheduler_job.py:153} INFO - Started process (PID=115427) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:39,171] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:55:39,171] {logging_mixin.py:112} INFO - [2020-07-22 10:55:39,171] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:39,246] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:39,368] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:55:39,385] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:55:39,389] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.222 seconds
[2020-07-22 10:55:46,903] {scheduler_job.py:153} INFO - Started process (PID=115626) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:46,907] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:55:46,908] {logging_mixin.py:112} INFO - [2020-07-22 10:55:46,908] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:46,995] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:55:47,465] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:55:47,522] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:55:47,526] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.624 seconds
[2020-07-22 10:56:06,861] {scheduler_job.py:153} INFO - Started process (PID=116074) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:06,878] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:56:06,879] {logging_mixin.py:112} INFO - [2020-07-22 10:56:06,879] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:07,197] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:07,353] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:56:07,368] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:56:07,371] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.510 seconds
[2020-07-22 10:56:14,518] {scheduler_job.py:153} INFO - Started process (PID=116289) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:14,521] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:56:14,522] {logging_mixin.py:112} INFO - [2020-07-22 10:56:14,522] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:14,610] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:14,778] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:56:14,794] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:56:14,797] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.279 seconds
[2020-07-22 10:56:23,602] {scheduler_job.py:153} INFO - Started process (PID=116508) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:23,606] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:56:23,607] {logging_mixin.py:112} INFO - [2020-07-22 10:56:23,607] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:23,673] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:23,842] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:56:23,867] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 05:26:17.816273+00:00: manual__2020-07-22T05:26:17.816273+00:00, externally triggered: True>
[2020-07-22 10:56:23,889] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:56:23,896] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.dbdump_in_minio 2020-07-22 05:26:17.816273+00:00 [scheduled]> in ORM
[2020-07-22 10:56:24,051] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.449 seconds
[2020-07-22 10:56:32,772] {scheduler_job.py:153} INFO - Started process (PID=116729) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:32,780] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:56:32,782] {logging_mixin.py:112} INFO - [2020-07-22 10:56:32,781] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:33,698] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:33,948] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:56:34,008] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 05:26:17.816273+00:00: manual__2020-07-22T05:26:17.816273+00:00, externally triggered: True>
[2020-07-22 10:56:34,042] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:56:34,069] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.298 seconds
[2020-07-22 10:56:49,335] {scheduler_job.py:153} INFO - Started process (PID=117192) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:49,338] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:56:49,339] {logging_mixin.py:112} INFO - [2020-07-22 10:56:49,339] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:49,457] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:56:50,406] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:56:50,437] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 05:26:17.816273+00:00: manual__2020-07-22T05:26:17.816273+00:00, externally triggered: True>
[2020-07-22 10:56:50,463] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:56:50,468] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.133 seconds
[2020-07-22 10:57:09,671] {scheduler_job.py:153} INFO - Started process (PID=117681) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:09,675] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:57:09,676] {logging_mixin.py:112} INFO - [2020-07-22 10:57:09,676] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:09,860] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:09,965] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:57:09,983] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 05:26:17.816273+00:00: manual__2020-07-22T05:26:17.816273+00:00, externally triggered: True>
[2020-07-22 10:57:09,992] {logging_mixin.py:112} INFO - [2020-07-22 10:57:09,992] {dagrun.py:318} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 05:26:17.816273+00:00: manual__2020-07-22T05:26:17.816273+00:00, externally triggered: True> successful
[2020-07-22 10:57:10,108] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:57:10,115] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.444 seconds
[2020-07-22 10:57:19,374] {scheduler_job.py:153} INFO - Started process (PID=117905) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:19,378] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:57:19,379] {logging_mixin.py:112} INFO - [2020-07-22 10:57:19,379] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:19,474] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:19,684] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:57:19,701] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:57:19,704] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.330 seconds
[2020-07-22 10:57:32,077] {scheduler_job.py:153} INFO - Started process (PID=118226) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:32,080] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:57:32,081] {logging_mixin.py:112} INFO - [2020-07-22 10:57:32,081] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:32,223] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:32,411] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:57:32,436] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:57:32,440] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.363 seconds
[2020-07-22 10:57:44,399] {scheduler_job.py:153} INFO - Started process (PID=118548) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:44,403] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:57:44,403] {logging_mixin.py:112} INFO - [2020-07-22 10:57:44,403] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:44,468] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:44,590] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:57:44,605] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:57:44,608] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 10:57:53,911] {scheduler_job.py:153} INFO - Started process (PID=118810) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:53,914] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:57:53,915] {logging_mixin.py:112} INFO - [2020-07-22 10:57:53,915] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:53,986] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:57:54,174] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:57:54,189] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:57:54,192] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.281 seconds
[2020-07-22 10:58:01,568] {scheduler_job.py:153} INFO - Started process (PID=119009) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:01,571] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:58:01,572] {logging_mixin.py:112} INFO - [2020-07-22 10:58:01,572] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:01,639] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:01,811] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:58:01,844] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:58:01,846] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.278 seconds
[2020-07-22 10:58:12,506] {scheduler_job.py:153} INFO - Started process (PID=119305) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:12,509] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:58:12,509] {logging_mixin.py:112} INFO - [2020-07-22 10:58:12,509] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:12,607] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:12,796] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:58:12,863] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:58:12,870] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.364 seconds
[2020-07-22 10:58:27,001] {scheduler_job.py:153} INFO - Started process (PID=119643) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:27,005] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:58:27,005] {logging_mixin.py:112} INFO - [2020-07-22 10:58:27,005] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:27,128] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:27,238] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:58:27,262] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:58:27,268] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.266 seconds
[2020-07-22 10:58:36,903] {scheduler_job.py:153} INFO - Started process (PID=119871) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:36,908] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:58:36,908] {logging_mixin.py:112} INFO - [2020-07-22 10:58:36,908] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:36,983] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:37,147] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:58:37,162] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:58:37,164] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.262 seconds
[2020-07-22 10:58:48,157] {scheduler_job.py:153} INFO - Started process (PID=120131) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:48,164] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:58:48,166] {logging_mixin.py:112} INFO - [2020-07-22 10:58:48,165] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:48,332] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:48,451] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:58:48,468] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:58:48,471] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.314 seconds
[2020-07-22 10:58:59,001] {scheduler_job.py:153} INFO - Started process (PID=120397) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:59,006] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:58:59,007] {logging_mixin.py:112} INFO - [2020-07-22 10:58:59,007] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:59,098] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:58:59,224] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:58:59,240] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:58:59,242] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.241 seconds
[2020-07-22 10:59:14,645] {scheduler_job.py:153} INFO - Started process (PID=120789) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:14,652] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:59:14,652] {logging_mixin.py:112} INFO - [2020-07-22 10:59:14,652] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:14,720] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:14,837] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:59:14,853] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:59:14,856] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.211 seconds
[2020-07-22 10:59:23,966] {scheduler_job.py:153} INFO - Started process (PID=121012) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:23,971] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:59:23,972] {logging_mixin.py:112} INFO - [2020-07-22 10:59:23,971] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:24,040] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:24,142] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:59:24,157] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:59:24,160] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.195 seconds
[2020-07-22 10:59:32,332] {scheduler_job.py:153} INFO - Started process (PID=121214) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:32,337] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:59:32,337] {logging_mixin.py:112} INFO - [2020-07-22 10:59:32,337] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:32,432] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:32,615] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:59:32,640] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:59:32,645] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.313 seconds
[2020-07-22 10:59:40,015] {scheduler_job.py:153} INFO - Started process (PID=121418) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:40,020] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:59:40,020] {logging_mixin.py:112} INFO - [2020-07-22 10:59:40,020] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:40,233] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:40,359] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:59:40,374] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:59:40,377] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.363 seconds
[2020-07-22 10:59:52,808] {scheduler_job.py:153} INFO - Started process (PID=121776) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:52,826] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 10:59:52,841] {logging_mixin.py:112} INFO - [2020-07-22 10:59:52,840] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:53,068] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 10:59:53,259] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 10:59:53,346] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 10:59:53,361] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.553 seconds
[2020-07-22 11:00:01,675] {scheduler_job.py:153} INFO - Started process (PID=122014) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:01,677] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:00:01,678] {logging_mixin.py:112} INFO - [2020-07-22 11:00:01,678] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:01,748] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:01,934] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:00:01,954] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:00:01,957] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.282 seconds
[2020-07-22 11:00:10,439] {scheduler_job.py:153} INFO - Started process (PID=122234) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:10,444] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:00:10,444] {logging_mixin.py:112} INFO - [2020-07-22 11:00:10,444] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:10,593] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:10,740] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:00:10,757] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:00:10,760] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.322 seconds
[2020-07-22 11:00:19,103] {scheduler_job.py:153} INFO - Started process (PID=122462) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:19,107] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:00:19,108] {logging_mixin.py:112} INFO - [2020-07-22 11:00:19,108] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:19,193] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:19,315] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:00:19,330] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:00:19,333] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.230 seconds
[2020-07-22 11:00:29,828] {scheduler_job.py:153} INFO - Started process (PID=122730) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:29,831] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:00:29,831] {logging_mixin.py:112} INFO - [2020-07-22 11:00:29,831] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:29,950] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:30,078] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:00:30,095] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:00:30,099] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.271 seconds
[2020-07-22 11:00:42,902] {scheduler_job.py:153} INFO - Started process (PID=123067) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:42,906] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:00:42,906] {logging_mixin.py:112} INFO - [2020-07-22 11:00:42,906] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:43,021] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:43,137] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:00:43,154] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:00:43,157] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.254 seconds
[2020-07-22 11:00:52,171] {scheduler_job.py:153} INFO - Started process (PID=123307) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:52,175] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:00:52,176] {logging_mixin.py:112} INFO - [2020-07-22 11:00:52,176] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:52,435] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:00:52,622] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:00:52,640] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:00:52,643] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.472 seconds
[2020-07-22 11:01:01,159] {scheduler_job.py:153} INFO - Started process (PID=123528) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:01,164] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:01:01,165] {logging_mixin.py:112} INFO - [2020-07-22 11:01:01,165] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:01,289] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:01,430] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:01:01,458] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:01:01,463] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.303 seconds
[2020-07-22 11:01:09,251] {scheduler_job.py:153} INFO - Started process (PID=123733) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:09,255] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:01:09,256] {logging_mixin.py:112} INFO - [2020-07-22 11:01:09,256] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:09,324] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:09,581] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:01:09,599] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:01:09,601] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.351 seconds
[2020-07-22 11:01:24,958] {scheduler_job.py:153} INFO - Started process (PID=124121) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:24,970] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:01:24,971] {logging_mixin.py:112} INFO - [2020-07-22 11:01:24,971] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:25,125] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:25,257] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:01:25,300] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:01:25,304] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.346 seconds
[2020-07-22 11:01:32,933] {scheduler_job.py:153} INFO - Started process (PID=124348) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:32,936] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:01:32,937] {logging_mixin.py:112} INFO - [2020-07-22 11:01:32,936] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:33,037] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:33,222] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:01:33,240] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:01:33,244] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.311 seconds
[2020-07-22 11:01:42,212] {scheduler_job.py:153} INFO - Started process (PID=124577) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:42,216] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:01:42,216] {logging_mixin.py:112} INFO - [2020-07-22 11:01:42,216] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:42,299] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:42,400] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:01:42,415] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 05:31:36.590587+00:00: manual__2020-07-22T05:31:36.590587+00:00, externally triggered: True>
[2020-07-22 11:01:42,428] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:01:42,432] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.dbdump_in_minio 2020-07-22 05:31:36.590587+00:00 [scheduled]> in ORM
[2020-07-22 11:01:42,560] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.347 seconds
[2020-07-22 11:01:50,787] {scheduler_job.py:153} INFO - Started process (PID=124847) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:50,790] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:01:50,791] {logging_mixin.py:112} INFO - [2020-07-22 11:01:50,791] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:50,863] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:01:51,080] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:01:51,095] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 05:31:36.590587+00:00: manual__2020-07-22T05:31:36.590587+00:00, externally triggered: True>
[2020-07-22 11:01:51,107] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:01:51,110] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.323 seconds
[2020-07-22 11:02:12,342] {scheduler_job.py:153} INFO - Started process (PID=125416) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:12,345] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:02:12,346] {logging_mixin.py:112} INFO - [2020-07-22 11:02:12,345] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:12,447] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:12,583] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:02:12,616] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 05:31:36.590587+00:00: manual__2020-07-22T05:31:36.590587+00:00, externally triggered: True>
[2020-07-22 11:02:12,632] {logging_mixin.py:112} INFO - [2020-07-22 11:02:12,632] {dagrun.py:318} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 05:31:36.590587+00:00: manual__2020-07-22T05:31:36.590587+00:00, externally triggered: True> successful
[2020-07-22 11:02:12,772] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:02:12,775] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.433 seconds
[2020-07-22 11:02:23,361] {scheduler_job.py:153} INFO - Started process (PID=125676) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:23,365] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:02:23,365] {logging_mixin.py:112} INFO - [2020-07-22 11:02:23,365] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:23,433] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:23,563] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:02:23,580] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:02:23,582] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.221 seconds
[2020-07-22 11:02:33,268] {scheduler_job.py:153} INFO - Started process (PID=125902) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:33,271] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:02:33,272] {logging_mixin.py:112} INFO - [2020-07-22 11:02:33,272] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:33,347] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:33,463] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:02:33,480] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:02:33,482] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.214 seconds
[2020-07-22 11:02:44,753] {scheduler_job.py:153} INFO - Started process (PID=126182) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:44,760] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:02:44,763] {logging_mixin.py:112} INFO - [2020-07-22 11:02:44,761] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:44,895] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:45,032] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:02:45,078] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:02:45,087] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.334 seconds
[2020-07-22 11:02:59,512] {scheduler_job.py:153} INFO - Started process (PID=126614) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:59,519] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:02:59,519] {logging_mixin.py:112} INFO - [2020-07-22 11:02:59,519] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:59,654] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:02:59,899] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:02:59,937] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:02:59,943] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.431 seconds
[2020-07-22 11:03:09,154] {scheduler_job.py:153} INFO - Started process (PID=126837) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:09,158] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:03:09,158] {logging_mixin.py:112} INFO - [2020-07-22 11:03:09,158] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:09,230] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:09,339] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:03:09,367] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:03:09,371] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-22 11:03:19,883] {scheduler_job.py:153} INFO - Started process (PID=127097) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:19,890] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:03:19,890] {logging_mixin.py:112} INFO - [2020-07-22 11:03:19,890] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:20,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:20,204] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:03:20,225] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:03:20,231] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.348 seconds
[2020-07-22 11:03:29,702] {scheduler_job.py:153} INFO - Started process (PID=127355) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:29,707] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:03:29,708] {logging_mixin.py:112} INFO - [2020-07-22 11:03:29,707] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:29,867] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:29,992] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:03:30,027] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:03:30,031] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.329 seconds
[2020-07-22 11:03:40,338] {scheduler_job.py:153} INFO - Started process (PID=127653) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:40,341] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:03:40,341] {logging_mixin.py:112} INFO - [2020-07-22 11:03:40,341] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:40,410] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:40,571] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:03:40,586] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:03:40,589] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.251 seconds
[2020-07-22 11:03:48,247] {scheduler_job.py:153} INFO - Started process (PID=127861) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:48,253] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:03:48,254] {logging_mixin.py:112} INFO - [2020-07-22 11:03:48,254] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:48,616] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:48,899] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:03:48,969] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:03:48,979] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.736 seconds
[2020-07-22 11:03:57,326] {scheduler_job.py:153} INFO - Started process (PID=128112) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:57,329] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:03:57,330] {logging_mixin.py:112} INFO - [2020-07-22 11:03:57,330] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:57,403] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:03:57,520] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:03:57,537] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:03:57,540] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.213 seconds
[2020-07-22 11:04:05,394] {scheduler_job.py:153} INFO - Started process (PID=128317) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:05,397] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:04:05,397] {logging_mixin.py:112} INFO - [2020-07-22 11:04:05,397] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:05,474] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:05,656] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:04:05,672] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:04:05,675] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.281 seconds
[2020-07-22 11:04:14,513] {scheduler_job.py:153} INFO - Started process (PID=128563) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:14,516] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:04:14,517] {logging_mixin.py:112} INFO - [2020-07-22 11:04:14,517] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:14,740] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:14,913] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:04:14,934] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:04:14,937] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.425 seconds
[2020-07-22 11:04:28,048] {scheduler_job.py:153} INFO - Started process (PID=128922) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:28,052] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:04:28,052] {logging_mixin.py:112} INFO - [2020-07-22 11:04:28,052] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:28,117] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:28,235] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:04:28,249] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:04:28,252] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 11:04:36,201] {scheduler_job.py:153} INFO - Started process (PID=129123) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:36,204] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:04:36,205] {logging_mixin.py:112} INFO - [2020-07-22 11:04:36,205] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:36,283] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:36,399] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:04:36,415] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:04:36,418] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-22 11:04:46,638] {scheduler_job.py:153} INFO - Started process (PID=129359) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:46,643] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:04:46,644] {logging_mixin.py:112} INFO - [2020-07-22 11:04:46,644] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:46,762] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:46,908] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:04:46,926] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:04:46,929] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.291 seconds
[2020-07-22 11:04:58,689] {scheduler_job.py:153} INFO - Started process (PID=129666) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:58,694] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:04:58,696] {logging_mixin.py:112} INFO - [2020-07-22 11:04:58,695] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:58,815] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:04:58,986] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:04:59,013] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 05:34:53.416890+00:00: manual__2020-07-22T05:34:53.416890+00:00, externally triggered: True>
[2020-07-22 11:04:59,041] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:04:59,048] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.dbdump_in_minio 2020-07-22 05:34:53.416890+00:00 [scheduled]> in ORM
[2020-07-22 11:04:59,187] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.499 seconds
[2020-07-22 11:05:21,189] {scheduler_job.py:153} INFO - Started process (PID=130266) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:05:21,193] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:05:21,194] {logging_mixin.py:112} INFO - [2020-07-22 11:05:21,194] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:05:21,279] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:05:21,479] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:05:21,503] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 05:34:53.416890+00:00: manual__2020-07-22T05:34:53.416890+00:00, externally triggered: True>
[2020-07-22 11:05:21,519] {logging_mixin.py:112} INFO - [2020-07-22 11:05:21,518] {dagrun.py:318} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 05:34:53.416890+00:00: manual__2020-07-22T05:34:53.416890+00:00, externally triggered: True> successful
[2020-07-22 11:05:21,621] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:05:21,625] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.436 seconds
[2020-07-22 11:05:32,636] {scheduler_job.py:153} INFO - Started process (PID=130538) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:05:32,640] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:05:32,640] {logging_mixin.py:112} INFO - [2020-07-22 11:05:32,640] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:05:32,704] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:05:32,827] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:05:32,842] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:05:32,845] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.209 seconds
[2020-07-22 11:05:41,857] {scheduler_job.py:153} INFO - Started process (PID=130755) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:05:41,861] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:05:41,861] {logging_mixin.py:112} INFO - [2020-07-22 11:05:41,861] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:05:41,981] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:05:42,180] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:05:42,195] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:05:42,198] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.341 seconds
[2020-07-22 11:05:54,397] {scheduler_job.py:153} INFO - Started process (PID=131134) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:05:54,402] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:05:54,402] {logging_mixin.py:112} INFO - [2020-07-22 11:05:54,402] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:05:54,466] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:05:54,593] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:05:54,608] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:05:54,611] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.214 seconds
[2020-07-22 11:06:02,096] {scheduler_job.py:153} INFO - Started process (PID=131342) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:02,101] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:06:02,102] {logging_mixin.py:112} INFO - [2020-07-22 11:06:02,101] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:02,222] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:02,408] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:06:02,424] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:06:02,427] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.331 seconds
[2020-07-22 11:06:11,792] {scheduler_job.py:153} INFO - Started process (PID=131566) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:11,797] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:06:11,798] {logging_mixin.py:112} INFO - [2020-07-22 11:06:11,798] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:11,904] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:12,009] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:06:12,025] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:06:12,028] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.236 seconds
[2020-07-22 11:06:22,629] {scheduler_job.py:153} INFO - Started process (PID=131799) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:22,634] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:06:22,635] {logging_mixin.py:112} INFO - [2020-07-22 11:06:22,635] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:22,758] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:22,872] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:06:22,899] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:06:22,905] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.276 seconds
[2020-07-22 11:06:37,672] {scheduler_job.py:153} INFO - Started process (PID=132219) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:37,676] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:06:37,676] {logging_mixin.py:112} INFO - [2020-07-22 11:06:37,676] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:37,748] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:37,907] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:06:37,926] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:06:37,929] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.257 seconds
[2020-07-22 11:06:46,141] {scheduler_job.py:153} INFO - Started process (PID=132426) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:46,145] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:06:46,145] {logging_mixin.py:112} INFO - [2020-07-22 11:06:46,145] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:46,226] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:46,387] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:06:46,405] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:06:46,408] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.267 seconds
[2020-07-22 11:06:54,928] {scheduler_job.py:153} INFO - Started process (PID=132638) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:54,931] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:06:54,932] {logging_mixin.py:112} INFO - [2020-07-22 11:06:54,931] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:54,999] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:06:55,111] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:06:55,132] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:06:55,137] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.209 seconds
[2020-07-22 11:07:03,311] {scheduler_job.py:153} INFO - Started process (PID=132863) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:03,314] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:07:03,315] {logging_mixin.py:112} INFO - [2020-07-22 11:07:03,315] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:03,383] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:03,491] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:07:03,507] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:07:03,510] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.199 seconds
[2020-07-22 11:07:18,425] {scheduler_job.py:153} INFO - Started process (PID=133245) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:18,431] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:07:18,432] {logging_mixin.py:112} INFO - [2020-07-22 11:07:18,431] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:18,596] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:18,758] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:07:18,786] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:07:18,791] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.366 seconds
[2020-07-22 11:07:27,403] {scheduler_job.py:153} INFO - Started process (PID=133515) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:27,407] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:07:27,408] {logging_mixin.py:112} INFO - [2020-07-22 11:07:27,408] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:27,480] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:27,593] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:07:27,608] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:07:27,611] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 11:07:36,078] {scheduler_job.py:153} INFO - Started process (PID=133731) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:36,081] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:07:36,082] {logging_mixin.py:112} INFO - [2020-07-22 11:07:36,082] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:36,149] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:36,252] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:07:36,270] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:07:36,273] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.195 seconds
[2020-07-22 11:07:45,795] {scheduler_job.py:153} INFO - Started process (PID=133951) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:45,799] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:07:45,799] {logging_mixin.py:112} INFO - [2020-07-22 11:07:45,799] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:45,872] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:45,993] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:07:46,009] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:07:46,012] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.218 seconds
[2020-07-22 11:07:54,867] {scheduler_job.py:153} INFO - Started process (PID=134198) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:54,870] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:07:54,870] {logging_mixin.py:112} INFO - [2020-07-22 11:07:54,870] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:54,961] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:07:55,130] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:07:55,155] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:07:55,159] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.293 seconds
[2020-07-22 11:08:06,818] {scheduler_job.py:153} INFO - Started process (PID=134546) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:06,823] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:08:06,823] {logging_mixin.py:112} INFO - [2020-07-22 11:08:06,823] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:06,901] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:07,016] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:08:07,033] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:08:07,035] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.218 seconds
[2020-07-22 11:08:14,882] {scheduler_job.py:153} INFO - Started process (PID=134752) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:14,889] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:08:14,890] {logging_mixin.py:112} INFO - [2020-07-22 11:08:14,889] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:15,017] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:15,178] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:08:15,194] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:08:15,197] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.315 seconds
[2020-07-22 11:08:22,759] {scheduler_job.py:153} INFO - Started process (PID=134957) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:22,763] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:08:22,764] {logging_mixin.py:112} INFO - [2020-07-22 11:08:22,764] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:22,833] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:22,951] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:08:22,968] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:08:22,970] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.211 seconds
[2020-07-22 11:08:34,307] {scheduler_job.py:153} INFO - Started process (PID=135222) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:34,312] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:08:34,312] {logging_mixin.py:112} INFO - [2020-07-22 11:08:34,312] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:34,402] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:34,542] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:08:34,601] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:08:34,615] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.309 seconds
[2020-07-22 11:08:49,433] {scheduler_job.py:153} INFO - Started process (PID=135593) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:49,437] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:08:49,438] {logging_mixin.py:112} INFO - [2020-07-22 11:08:49,437] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:49,692] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:49,842] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:08:49,860] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:08:49,863] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.430 seconds
[2020-07-22 11:08:57,978] {scheduler_job.py:153} INFO - Started process (PID=135817) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:57,981] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:08:57,981] {logging_mixin.py:112} INFO - [2020-07-22 11:08:57,981] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:58,066] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:08:58,227] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:08:58,255] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:08:58,260] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.282 seconds
[2020-07-22 11:09:05,840] {scheduler_job.py:153} INFO - Started process (PID=136047) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:05,842] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:09:05,843] {logging_mixin.py:112} INFO - [2020-07-22 11:09:05,843] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:05,911] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:06,015] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:09:06,034] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:09:06,037] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.198 seconds
[2020-07-22 11:09:14,948] {scheduler_job.py:153} INFO - Started process (PID=136264) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:14,952] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:09:14,953] {logging_mixin.py:112} INFO - [2020-07-22 11:09:14,952] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:15,062] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:15,168] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:09:15,187] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:09:15,190] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.242 seconds
[2020-07-22 11:09:26,858] {scheduler_job.py:153} INFO - Started process (PID=136559) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:26,863] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:09:26,863] {logging_mixin.py:112} INFO - [2020-07-22 11:09:26,863] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:27,010] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:27,231] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:09:27,263] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:09:27,268] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.410 seconds
[2020-07-22 11:09:40,806] {scheduler_job.py:153} INFO - Started process (PID=136935) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:40,811] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:09:40,811] {logging_mixin.py:112} INFO - [2020-07-22 11:09:40,811] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:40,925] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:41,038] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:09:41,055] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:09:41,058] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.252 seconds
[2020-07-22 11:09:50,424] {scheduler_job.py:153} INFO - Started process (PID=137156) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:50,427] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:09:50,427] {logging_mixin.py:112} INFO - [2020-07-22 11:09:50,427] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:50,501] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:09:50,611] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:09:50,626] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:09:50,629] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.205 seconds
[2020-07-22 11:10:02,776] {scheduler_job.py:153} INFO - Started process (PID=137422) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:02,783] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:10:02,784] {logging_mixin.py:112} INFO - [2020-07-22 11:10:02,784] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:02,919] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:03,107] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:10:03,168] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 05:40:01.280445+00:00: manual__2020-07-22T05:40:01.280445+00:00, externally triggered: True>
[2020-07-22 11:10:03,202] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:10:03,210] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.dbdump_in_minio 2020-07-22 05:40:01.280445+00:00 [scheduled]> in ORM
[2020-07-22 11:10:03,356] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.580 seconds
[2020-07-22 11:10:16,031] {scheduler_job.py:153} INFO - Started process (PID=137799) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:16,035] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:10:16,035] {logging_mixin.py:112} INFO - [2020-07-22 11:10:16,035] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:16,359] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:16,596] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:10:16,636] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 05:40:01.280445+00:00: manual__2020-07-22T05:40:01.280445+00:00, externally triggered: True>
[2020-07-22 11:10:16,663] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:10:16,668] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.637 seconds
[2020-07-22 11:10:37,508] {scheduler_job.py:153} INFO - Started process (PID=138319) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:37,512] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:10:37,513] {logging_mixin.py:112} INFO - [2020-07-22 11:10:37,513] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:37,641] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:37,775] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:10:37,793] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 05:40:01.280445+00:00: manual__2020-07-22T05:40:01.280445+00:00, externally triggered: True>
[2020-07-22 11:10:37,805] {logging_mixin.py:112} INFO - [2020-07-22 11:10:37,805] {dagrun.py:318} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 05:40:01.280445+00:00: manual__2020-07-22T05:40:01.280445+00:00, externally triggered: True> successful
[2020-07-22 11:10:37,909] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:10:37,912] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.405 seconds
[2020-07-22 11:10:45,758] {scheduler_job.py:153} INFO - Started process (PID=138526) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:45,760] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:10:45,761] {logging_mixin.py:112} INFO - [2020-07-22 11:10:45,761] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:45,838] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:45,941] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:10:45,958] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:10:45,960] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.203 seconds
[2020-07-22 11:10:58,668] {scheduler_job.py:153} INFO - Started process (PID=138788) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:58,677] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:10:58,680] {logging_mixin.py:112} INFO - [2020-07-22 11:10:58,680] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:58,926] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:10:59,065] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:10:59,105] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:10:59,110] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.441 seconds
[2020-07-22 11:11:15,609] {scheduler_job.py:153} INFO - Started process (PID=139224) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:15,613] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:11:15,614] {logging_mixin.py:112} INFO - [2020-07-22 11:11:15,613] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:15,689] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:15,811] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:11:15,827] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:11:15,829] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.220 seconds
[2020-07-22 11:11:24,389] {scheduler_job.py:153} INFO - Started process (PID=139435) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:24,394] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:11:24,395] {logging_mixin.py:112} INFO - [2020-07-22 11:11:24,394] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:24,471] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:24,579] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:11:24,596] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:11:24,599] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.211 seconds
[2020-07-22 11:11:31,760] {scheduler_job.py:153} INFO - Started process (PID=139629) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:31,764] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:11:31,764] {logging_mixin.py:112} INFO - [2020-07-22 11:11:31,764] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:31,841] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:31,979] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:11:31,994] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:11:31,997] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.237 seconds
[2020-07-22 11:11:44,633] {scheduler_job.py:153} INFO - Started process (PID=139919) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:44,637] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:11:44,638] {logging_mixin.py:112} INFO - [2020-07-22 11:11:44,638] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:44,826] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:44,935] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:11:44,964] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:11:44,968] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.335 seconds
[2020-07-22 11:11:58,505] {scheduler_job.py:153} INFO - Started process (PID=140266) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:58,509] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:11:58,510] {logging_mixin.py:112} INFO - [2020-07-22 11:11:58,509] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:58,624] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:11:58,768] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:11:58,793] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:11:58,797] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.292 seconds
[2020-07-22 11:12:07,192] {scheduler_job.py:153} INFO - Started process (PID=140538) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:07,196] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:12:07,196] {logging_mixin.py:112} INFO - [2020-07-22 11:12:07,196] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:07,265] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:07,430] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:12:07,446] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:12:07,448] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.257 seconds
[2020-07-22 11:12:15,995] {scheduler_job.py:153} INFO - Started process (PID=140795) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:16,000] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:12:16,001] {logging_mixin.py:112} INFO - [2020-07-22 11:12:16,001] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:16,075] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:16,200] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:12:16,215] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:12:16,217] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.222 seconds
[2020-07-22 11:12:25,083] {scheduler_job.py:153} INFO - Started process (PID=141009) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:25,087] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:12:25,088] {logging_mixin.py:112} INFO - [2020-07-22 11:12:25,088] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:25,241] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:25,513] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:12:25,551] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:12:25,555] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.472 seconds
[2020-07-22 11:12:46,308] {scheduler_job.py:153} INFO - Started process (PID=141504) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:46,313] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:12:46,313] {logging_mixin.py:112} INFO - [2020-07-22 11:12:46,313] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:46,549] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:46,796] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:12:46,830] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:12:46,835] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.527 seconds
[2020-07-22 11:12:58,930] {scheduler_job.py:153} INFO - Started process (PID=141827) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:58,937] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:12:58,937] {logging_mixin.py:112} INFO - [2020-07-22 11:12:58,937] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:59,024] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:12:59,221] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:12:59,240] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:12:59,243] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.313 seconds
[2020-07-22 11:13:09,443] {scheduler_job.py:153} INFO - Started process (PID=142092) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:09,448] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:13:09,448] {logging_mixin.py:112} INFO - [2020-07-22 11:13:09,448] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:09,513] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:09,621] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:13:09,635] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:13:09,638] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.195 seconds
[2020-07-22 11:13:16,696] {scheduler_job.py:153} INFO - Started process (PID=142281) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:16,700] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:13:16,700] {logging_mixin.py:112} INFO - [2020-07-22 11:13:16,700] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:16,769] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:16,972] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:13:16,990] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:13:16,992] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.296 seconds
[2020-07-22 11:13:34,042] {scheduler_job.py:153} INFO - Started process (PID=142677) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:34,048] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:13:34,049] {logging_mixin.py:112} INFO - [2020-07-22 11:13:34,049] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:34,183] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:34,343] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:13:34,375] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:13:34,380] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.338 seconds
[2020-07-22 11:13:41,895] {scheduler_job.py:153} INFO - Started process (PID=142925) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:41,898] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:13:41,898] {logging_mixin.py:112} INFO - [2020-07-22 11:13:41,898] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:41,963] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:42,081] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:13:42,096] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:13:42,099] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 11:13:49,278] {scheduler_job.py:153} INFO - Started process (PID=143124) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:49,282] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:13:49,283] {logging_mixin.py:112} INFO - [2020-07-22 11:13:49,283] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:49,357] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:49,467] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:13:49,482] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:13:49,485] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.207 seconds
[2020-07-22 11:13:59,499] {scheduler_job.py:153} INFO - Started process (PID=143353) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:59,503] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:13:59,504] {logging_mixin.py:112} INFO - [2020-07-22 11:13:59,504] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:59,586] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:13:59,706] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:13:59,724] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:13:59,727] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.228 seconds
[2020-07-22 11:14:10,920] {scheduler_job.py:153} INFO - Started process (PID=143680) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:10,923] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:14:10,924] {logging_mixin.py:112} INFO - [2020-07-22 11:14:10,924] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:11,037] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:11,241] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:14:11,269] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:14:11,273] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.353 seconds
[2020-07-22 11:14:31,494] {scheduler_job.py:153} INFO - Started process (PID=144091) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:31,498] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:14:31,498] {logging_mixin.py:112} INFO - [2020-07-22 11:14:31,498] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:31,576] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:31,822] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:14:31,841] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:14:31,844] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.350 seconds
[2020-07-22 11:14:41,591] {scheduler_job.py:153} INFO - Started process (PID=144353) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:41,594] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:14:41,594] {logging_mixin.py:112} INFO - [2020-07-22 11:14:41,594] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:41,661] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:41,949] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:14:41,970] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:14:41,972] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.381 seconds
[2020-07-22 11:14:49,761] {scheduler_job.py:153} INFO - Started process (PID=144559) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:49,765] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:14:49,765] {logging_mixin.py:112} INFO - [2020-07-22 11:14:49,765] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:49,834] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:49,950] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:14:49,966] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:14:49,969] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 11:14:58,656] {scheduler_job.py:153} INFO - Started process (PID=144812) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:58,660] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:14:58,660] {logging_mixin.py:112} INFO - [2020-07-22 11:14:58,660] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:58,770] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:14:58,888] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:14:58,918] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:14:58,923] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.267 seconds
[2020-07-22 11:15:11,019] {scheduler_job.py:153} INFO - Started process (PID=145137) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:11,023] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:15:11,023] {logging_mixin.py:112} INFO - [2020-07-22 11:15:11,023] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:11,090] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:11,206] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:15:11,221] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:15:11,223] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 11:15:19,113] {scheduler_job.py:153} INFO - Started process (PID=145361) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:19,117] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:15:19,117] {logging_mixin.py:112} INFO - [2020-07-22 11:15:19,117] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:19,192] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:19,291] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:15:19,310] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:15:19,313] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-22 11:15:26,874] {scheduler_job.py:153} INFO - Started process (PID=145565) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:26,876] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:15:26,877] {logging_mixin.py:112} INFO - [2020-07-22 11:15:26,877] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:27,128] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:27,297] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:15:27,312] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:15:27,314] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.441 seconds
[2020-07-22 11:15:35,537] {scheduler_job.py:153} INFO - Started process (PID=145773) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:35,540] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:15:35,540] {logging_mixin.py:112} INFO - [2020-07-22 11:15:35,540] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:35,607] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:35,992] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:15:36,020] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:15:36,024] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.488 seconds
[2020-07-22 11:15:44,950] {scheduler_job.py:153} INFO - Started process (PID=146053) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:44,964] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:15:44,965] {logging_mixin.py:112} INFO - [2020-07-22 11:15:44,965] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:45,145] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:45,267] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:15:45,293] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:15:45,297] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.347 seconds
[2020-07-22 11:15:54,662] {scheduler_job.py:153} INFO - Started process (PID=146341) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:54,665] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:15:54,665] {logging_mixin.py:112} INFO - [2020-07-22 11:15:54,665] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:54,732] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:15:54,831] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:15:54,846] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:15:54,848] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.186 seconds
[2020-07-22 11:16:02,307] {scheduler_job.py:153} INFO - Started process (PID=146555) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:02,309] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:16:02,310] {logging_mixin.py:112} INFO - [2020-07-22 11:16:02,310] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:02,391] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:02,502] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:16:02,524] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:16:02,529] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.223 seconds
[2020-07-22 11:16:10,781] {scheduler_job.py:153} INFO - Started process (PID=146785) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:10,784] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:16:10,784] {logging_mixin.py:112} INFO - [2020-07-22 11:16:10,784] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:10,853] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:10,994] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:16:11,012] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:16:11,014] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.233 seconds
[2020-07-22 11:16:19,452] {scheduler_job.py:153} INFO - Started process (PID=147028) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:19,456] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:16:19,457] {logging_mixin.py:112} INFO - [2020-07-22 11:16:19,457] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:19,538] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:19,652] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:16:19,668] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:16:19,670] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.218 seconds
[2020-07-22 11:16:35,112] {scheduler_job.py:153} INFO - Started process (PID=147376) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:35,116] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:16:35,117] {logging_mixin.py:112} INFO - [2020-07-22 11:16:35,117] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:35,270] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:35,444] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:16:35,490] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:16:35,497] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.386 seconds
[2020-07-22 11:16:55,390] {scheduler_job.py:153} INFO - Started process (PID=147799) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:55,395] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:16:55,395] {logging_mixin.py:112} INFO - [2020-07-22 11:16:55,395] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:55,528] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:16:55,652] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:16:55,681] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:16:55,686] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.296 seconds
[2020-07-22 11:17:06,293] {scheduler_job.py:153} INFO - Started process (PID=148061) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:06,298] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:17:06,299] {logging_mixin.py:112} INFO - [2020-07-22 11:17:06,299] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:06,378] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:06,502] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:17:06,517] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:17:06,520] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.227 seconds
[2020-07-22 11:17:17,013] {scheduler_job.py:153} INFO - Started process (PID=148316) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:17,018] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:17:17,019] {logging_mixin.py:112} INFO - [2020-07-22 11:17:17,019] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:17,107] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:17,221] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:17:17,239] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:17:17,242] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.229 seconds
[2020-07-22 11:17:28,554] {scheduler_job.py:153} INFO - Started process (PID=148655) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:28,565] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:17:28,565] {logging_mixin.py:112} INFO - [2020-07-22 11:17:28,565] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:28,689] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:28,829] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:17:28,844] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:17:28,847] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.293 seconds
[2020-07-22 11:17:38,134] {scheduler_job.py:153} INFO - Started process (PID=148906) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:38,136] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:17:38,137] {logging_mixin.py:112} INFO - [2020-07-22 11:17:38,136] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:38,210] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:38,319] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:17:38,334] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:17:38,337] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.203 seconds
[2020-07-22 11:17:49,053] {scheduler_job.py:153} INFO - Started process (PID=149193) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:49,058] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:17:49,060] {logging_mixin.py:112} INFO - [2020-07-22 11:17:49,059] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:49,211] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:17:49,412] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:17:49,435] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:17:49,442] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.390 seconds
[2020-07-22 11:18:00,779] {scheduler_job.py:153} INFO - Started process (PID=149434) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:00,784] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:18:00,785] {logging_mixin.py:112} INFO - [2020-07-22 11:18:00,784] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:00,943] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:01,116] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:18:01,137] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:18:01,140] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.361 seconds
[2020-07-22 11:18:12,613] {scheduler_job.py:153} INFO - Started process (PID=149785) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:12,617] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:18:12,617] {logging_mixin.py:112} INFO - [2020-07-22 11:18:12,617] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:12,700] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:12,811] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:18:12,826] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:18:12,830] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-22 11:18:23,860] {scheduler_job.py:153} INFO - Started process (PID=150053) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:23,864] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:18:23,864] {logging_mixin.py:112} INFO - [2020-07-22 11:18:23,864] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:23,930] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:24,046] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:18:24,062] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:18:24,065] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.205 seconds
[2020-07-22 11:18:33,567] {scheduler_job.py:153} INFO - Started process (PID=150274) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:33,569] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:18:33,570] {logging_mixin.py:112} INFO - [2020-07-22 11:18:33,570] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:33,636] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:33,737] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:18:33,755] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:18:33,757] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.191 seconds
[2020-07-22 11:18:42,949] {scheduler_job.py:153} INFO - Started process (PID=150491) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:42,958] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:18:42,959] {logging_mixin.py:112} INFO - [2020-07-22 11:18:42,959] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:43,084] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:43,213] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:18:43,234] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:18:43,237] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.288 seconds
[2020-07-22 11:18:58,038] {scheduler_job.py:153} INFO - Started process (PID=150881) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:58,041] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:18:58,041] {logging_mixin.py:112} INFO - [2020-07-22 11:18:58,041] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:58,110] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:18:58,275] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:18:58,289] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:18:58,292] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.254 seconds
[2020-07-22 11:19:05,494] {scheduler_job.py:153} INFO - Started process (PID=151096) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:05,497] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:19:05,498] {logging_mixin.py:112} INFO - [2020-07-22 11:19:05,498] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:05,584] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:05,743] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:19:05,758] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:19:05,761] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.267 seconds
[2020-07-22 11:19:13,778] {scheduler_job.py:153} INFO - Started process (PID=151304) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:13,782] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:19:13,782] {logging_mixin.py:112} INFO - [2020-07-22 11:19:13,782] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:13,850] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:13,965] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:19:13,979] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:19:13,982] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 11:19:22,160] {scheduler_job.py:153} INFO - Started process (PID=151530) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:22,166] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:19:22,166] {logging_mixin.py:112} INFO - [2020-07-22 11:19:22,166] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:22,327] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:22,467] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:19:22,488] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:19:22,494] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.335 seconds
[2020-07-22 11:19:30,864] {scheduler_job.py:153} INFO - Started process (PID=151772) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:30,867] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:19:30,868] {logging_mixin.py:112} INFO - [2020-07-22 11:19:30,868] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:30,962] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:31,074] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:19:31,095] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:19:31,098] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.234 seconds
[2020-07-22 11:19:46,512] {scheduler_job.py:153} INFO - Started process (PID=152123) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:46,517] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:19:46,518] {logging_mixin.py:112} INFO - [2020-07-22 11:19:46,518] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:46,623] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:46,740] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:19:46,757] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:19:46,760] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.248 seconds
[2020-07-22 11:19:59,822] {scheduler_job.py:153} INFO - Started process (PID=152444) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:59,826] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:19:59,826] {logging_mixin.py:112} INFO - [2020-07-22 11:19:59,826] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:19:59,902] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:00,015] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:20:00,041] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:20:00,046] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.224 seconds
[2020-07-22 11:20:08,083] {scheduler_job.py:153} INFO - Started process (PID=152650) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:08,088] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:20:08,089] {logging_mixin.py:112} INFO - [2020-07-22 11:20:08,089] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:08,173] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:08,276] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:20:08,296] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:20:08,299] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.216 seconds
[2020-07-22 11:20:17,875] {scheduler_job.py:153} INFO - Started process (PID=152869) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:17,881] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:20:17,881] {logging_mixin.py:112} INFO - [2020-07-22 11:20:17,881] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:18,077] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:18,228] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:20:18,260] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:20:18,267] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.392 seconds
[2020-07-22 11:20:31,473] {scheduler_job.py:153} INFO - Started process (PID=153239) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:31,476] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:20:31,477] {logging_mixin.py:112} INFO - [2020-07-22 11:20:31,477] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:31,545] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:31,683] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:20:31,698] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:20:31,701] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.228 seconds
[2020-07-22 11:20:40,138] {scheduler_job.py:153} INFO - Started process (PID=153470) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:40,144] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:20:40,144] {logging_mixin.py:112} INFO - [2020-07-22 11:20:40,144] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:40,219] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:40,357] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:20:40,386] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:20:40,391] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.254 seconds
[2020-07-22 11:20:52,428] {scheduler_job.py:153} INFO - Started process (PID=153728) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:52,433] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:20:52,434] {logging_mixin.py:112} INFO - [2020-07-22 11:20:52,434] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:52,525] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:52,673] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:20:52,690] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:20:52,694] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.267 seconds
[2020-07-22 11:20:59,580] {scheduler_job.py:153} INFO - Started process (PID=153947) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:59,584] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:20:59,584] {logging_mixin.py:112} INFO - [2020-07-22 11:20:59,584] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:59,648] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:20:59,764] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:20:59,779] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:20:59,781] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.201 seconds
[2020-07-22 11:21:08,921] {scheduler_job.py:153} INFO - Started process (PID=154202) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:08,925] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:21:08,925] {logging_mixin.py:112} INFO - [2020-07-22 11:21:08,925] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:09,058] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:09,199] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:21:09,231] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:21:09,236] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.315 seconds
[2020-07-22 11:21:18,518] {scheduler_job.py:153} INFO - Started process (PID=154488) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:18,521] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:21:18,522] {logging_mixin.py:112} INFO - [2020-07-22 11:21:18,521] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:18,588] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:18,701] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:21:18,730] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:21:18,736] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.218 seconds
[2020-07-22 11:21:26,287] {scheduler_job.py:153} INFO - Started process (PID=154716) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:26,290] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:21:26,290] {logging_mixin.py:112} INFO - [2020-07-22 11:21:26,290] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:26,355] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:26,467] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:21:26,482] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:21:26,485] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.198 seconds
[2020-07-22 11:21:33,458] {scheduler_job.py:153} INFO - Started process (PID=154907) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:33,461] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:21:33,461] {logging_mixin.py:112} INFO - [2020-07-22 11:21:33,461] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:33,611] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:33,724] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:21:33,739] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:21:33,741] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.283 seconds
[2020-07-22 11:21:41,029] {scheduler_job.py:153} INFO - Started process (PID=155109) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:41,039] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:21:41,039] {logging_mixin.py:112} INFO - [2020-07-22 11:21:41,039] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:41,152] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:41,274] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:21:41,289] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:21:41,292] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.263 seconds
[2020-07-22 11:21:48,609] {scheduler_job.py:153} INFO - Started process (PID=155337) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:48,612] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:21:48,613] {logging_mixin.py:112} INFO - [2020-07-22 11:21:48,613] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:48,686] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:48,837] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:21:48,860] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:21:48,865] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.255 seconds
[2020-07-22 11:21:59,024] {scheduler_job.py:153} INFO - Started process (PID=155654) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:59,027] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:21:59,027] {logging_mixin.py:112} INFO - [2020-07-22 11:21:59,027] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:59,099] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:21:59,224] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:21:59,257] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:21:59,262] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.238 seconds
[2020-07-22 11:22:06,285] {scheduler_job.py:153} INFO - Started process (PID=155847) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:06,290] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:22:06,291] {logging_mixin.py:112} INFO - [2020-07-22 11:22:06,290] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:06,394] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:06,505] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:22:06,520] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:22:06,522] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.237 seconds
[2020-07-22 11:22:14,463] {scheduler_job.py:153} INFO - Started process (PID=156068) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:14,468] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:22:14,469] {logging_mixin.py:112} INFO - [2020-07-22 11:22:14,468] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:14,536] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:14,716] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:22:14,731] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:22:14,733] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.270 seconds
[2020-07-22 11:22:22,117] {scheduler_job.py:153} INFO - Started process (PID=156261) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:22,121] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:22:22,121] {logging_mixin.py:112} INFO - [2020-07-22 11:22:22,121] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:22,188] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:22,306] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:22:22,321] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:22:22,324] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.207 seconds
[2020-07-22 11:22:30,108] {scheduler_job.py:153} INFO - Started process (PID=156516) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:30,112] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:22:30,113] {logging_mixin.py:112} INFO - [2020-07-22 11:22:30,112] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:30,224] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:30,358] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:22:30,382] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:22:30,386] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.278 seconds
[2020-07-22 11:22:40,322] {scheduler_job.py:153} INFO - Started process (PID=156815) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:40,325] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:22:40,325] {logging_mixin.py:112} INFO - [2020-07-22 11:22:40,325] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:40,391] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:40,519] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:22:40,534] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:22:40,537] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.214 seconds
[2020-07-22 11:22:48,692] {scheduler_job.py:153} INFO - Started process (PID=157021) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:48,695] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:22:48,696] {logging_mixin.py:112} INFO - [2020-07-22 11:22:48,696] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:48,762] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:48,987] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:22:49,002] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:22:49,005] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.313 seconds
[2020-07-22 11:22:56,063] {scheduler_job.py:153} INFO - Started process (PID=157236) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:56,067] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:22:56,068] {logging_mixin.py:112} INFO - [2020-07-22 11:22:56,068] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:56,182] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:22:56,349] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:22:56,369] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:22:56,372] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.309 seconds
[2020-07-22 11:23:03,827] {scheduler_job.py:153} INFO - Started process (PID=157436) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:03,830] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:23:03,831] {logging_mixin.py:112} INFO - [2020-07-22 11:23:03,831] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:03,896] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:04,023] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:23:04,047] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:23:04,050] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.223 seconds
[2020-07-22 11:23:11,902] {scheduler_job.py:153} INFO - Started process (PID=157673) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:11,906] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:23:11,907] {logging_mixin.py:112} INFO - [2020-07-22 11:23:11,906] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:12,001] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:12,130] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:23:12,165] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:23:12,171] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.268 seconds
[2020-07-22 11:23:22,949] {scheduler_job.py:153} INFO - Started process (PID=157987) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:22,952] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:23:22,953] {logging_mixin.py:112} INFO - [2020-07-22 11:23:22,953] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:23,018] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:23,135] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:23:23,150] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:23:23,153] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.203 seconds
[2020-07-22 11:23:30,400] {scheduler_job.py:153} INFO - Started process (PID=158206) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:30,404] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:23:30,405] {logging_mixin.py:112} INFO - [2020-07-22 11:23:30,405] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:30,492] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:30,597] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:23:30,614] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:23:30,616] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.216 seconds
[2020-07-22 11:23:37,375] {scheduler_job.py:153} INFO - Started process (PID=158388) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:37,377] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:23:37,378] {logging_mixin.py:112} INFO - [2020-07-22 11:23:37,377] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:37,477] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:37,624] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:23:37,640] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:23:37,642] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.268 seconds
[2020-07-22 11:23:45,025] {scheduler_job.py:153} INFO - Started process (PID=158590) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:45,028] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:23:45,029] {logging_mixin.py:112} INFO - [2020-07-22 11:23:45,029] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:45,103] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:45,221] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:23:45,236] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:23:45,239] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.214 seconds
[2020-07-22 11:23:59,219] {scheduler_job.py:153} INFO - Started process (PID=158945) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:59,223] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:23:59,223] {logging_mixin.py:112} INFO - [2020-07-22 11:23:59,223] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:59,331] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:23:59,516] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:23:59,541] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:23:59,546] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.327 seconds
[2020-07-22 11:24:07,576] {scheduler_job.py:153} INFO - Started process (PID=159201) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:07,579] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:24:07,580] {logging_mixin.py:112} INFO - [2020-07-22 11:24:07,580] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:07,645] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:07,767] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:24:07,794] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:24:07,798] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.222 seconds
[2020-07-22 11:24:14,942] {scheduler_job.py:153} INFO - Started process (PID=159401) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:14,947] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:24:14,947] {logging_mixin.py:112} INFO - [2020-07-22 11:24:14,947] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:15,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:15,166] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:24:15,182] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:24:15,184] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.242 seconds
[2020-07-22 11:24:22,505] {scheduler_job.py:153} INFO - Started process (PID=159596) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:22,508] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:24:22,509] {logging_mixin.py:112} INFO - [2020-07-22 11:24:22,509] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:22,577] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:22,687] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:24:22,704] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:24:22,706] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.202 seconds
[2020-07-22 11:24:30,376] {scheduler_job.py:153} INFO - Started process (PID=159828) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:30,379] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:24:30,380] {logging_mixin.py:112} INFO - [2020-07-22 11:24:30,380] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:30,446] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:30,568] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:24:30,585] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:24:30,587] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.211 seconds
[2020-07-22 11:24:39,671] {scheduler_job.py:153} INFO - Started process (PID=160079) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:39,686] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:24:39,687] {logging_mixin.py:112} INFO - [2020-07-22 11:24:39,686] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:39,862] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:39,982] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:24:39,998] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:24:40,001] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.330 seconds
[2020-07-22 11:24:48,529] {scheduler_job.py:153} INFO - Started process (PID=160360) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:48,531] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:24:48,532] {logging_mixin.py:112} INFO - [2020-07-22 11:24:48,532] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:48,598] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:48,710] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:24:48,725] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:24:48,728] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-22 11:24:55,902] {scheduler_job.py:153} INFO - Started process (PID=160552) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:55,906] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:24:55,907] {logging_mixin.py:112} INFO - [2020-07-22 11:24:55,907] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:56,031] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:24:56,193] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:24:56,209] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:24:56,211] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.309 seconds
[2020-07-22 11:25:04,177] {scheduler_job.py:153} INFO - Started process (PID=160784) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:04,181] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:25:04,181] {logging_mixin.py:112} INFO - [2020-07-22 11:25:04,181] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:04,246] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:04,355] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:25:04,370] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:25:04,373] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.196 seconds
[2020-07-22 11:25:12,153] {scheduler_job.py:153} INFO - Started process (PID=160986) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:12,156] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:25:12,157] {logging_mixin.py:112} INFO - [2020-07-22 11:25:12,157] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:12,222] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:12,344] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:25:12,359] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:25:12,362] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 11:25:22,194] {scheduler_job.py:153} INFO - Started process (PID=161275) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:22,214] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:25:22,215] {logging_mixin.py:112} INFO - [2020-07-22 11:25:22,214] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:22,354] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:22,458] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:25:22,475] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:25:22,478] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.284 seconds
[2020-07-22 11:25:31,085] {scheduler_job.py:153} INFO - Started process (PID=161551) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:31,088] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:25:31,089] {logging_mixin.py:112} INFO - [2020-07-22 11:25:31,089] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:31,153] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:31,275] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:25:31,292] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:25:31,295] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.210 seconds
[2020-07-22 11:25:38,465] {scheduler_job.py:153} INFO - Started process (PID=161743) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:38,468] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:25:38,469] {logging_mixin.py:112} INFO - [2020-07-22 11:25:38,469] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:38,533] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:38,659] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:25:38,675] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:25:38,677] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.212 seconds
[2020-07-22 11:25:46,390] {scheduler_job.py:153} INFO - Started process (PID=161950) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:46,393] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:25:46,394] {logging_mixin.py:112} INFO - [2020-07-22 11:25:46,394] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:46,470] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:46,580] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:25:46,595] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:25:46,598] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 11:25:56,500] {scheduler_job.py:153} INFO - Started process (PID=162178) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:56,503] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:25:56,503] {logging_mixin.py:112} INFO - [2020-07-22 11:25:56,503] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:56,585] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:25:56,727] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:25:56,751] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:25:56,754] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.254 seconds
[2020-07-22 11:26:09,048] {scheduler_job.py:153} INFO - Started process (PID=162563) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:09,052] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:26:09,052] {logging_mixin.py:112} INFO - [2020-07-22 11:26:09,052] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:09,125] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:09,213] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:26:09,237] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:26:09,242] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.194 seconds
[2020-07-22 11:26:16,310] {scheduler_job.py:153} INFO - Started process (PID=162761) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:16,314] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:26:16,314] {logging_mixin.py:112} INFO - [2020-07-22 11:26:16,314] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:16,400] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:16,534] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:26:16,551] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:26:16,554] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.244 seconds
[2020-07-22 11:26:26,145] {scheduler_job.py:153} INFO - Started process (PID=162980) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:26,148] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:26:26,149] {logging_mixin.py:112} INFO - [2020-07-22 11:26:26,149] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:26,216] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:26,329] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:26:26,343] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:26:26,346] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.201 seconds
[2020-07-22 11:26:36,566] {scheduler_job.py:153} INFO - Started process (PID=163246) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:36,570] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:26:36,571] {logging_mixin.py:112} INFO - [2020-07-22 11:26:36,571] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:36,733] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:36,891] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:26:36,920] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:26:36,925] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.359 seconds
[2020-07-22 11:26:49,113] {scheduler_job.py:153} INFO - Started process (PID=163618) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:49,118] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:26:49,119] {logging_mixin.py:112} INFO - [2020-07-22 11:26:49,119] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:49,187] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:49,309] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:26:49,324] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:26:49,327] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.213 seconds
[2020-07-22 11:26:56,355] {scheduler_job.py:153} INFO - Started process (PID=163808) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:56,359] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:26:56,359] {logging_mixin.py:112} INFO - [2020-07-22 11:26:56,359] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:56,427] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:26:56,544] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:26:56,559] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:26:56,561] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.206 seconds
[2020-07-22 11:27:06,589] {scheduler_job.py:153} INFO - Started process (PID=164061) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:06,592] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:27:06,592] {logging_mixin.py:112} INFO - [2020-07-22 11:27:06,592] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:06,658] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:06,765] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:27:06,780] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:27:06,783] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.194 seconds
[2020-07-22 11:27:17,202] {scheduler_job.py:153} INFO - Started process (PID=164307) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:17,205] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:27:17,205] {logging_mixin.py:112} INFO - [2020-07-22 11:27:17,205] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:17,320] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:17,504] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:27:17,527] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:27:17,530] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.328 seconds
[2020-07-22 11:27:28,953] {scheduler_job.py:153} INFO - Started process (PID=164652) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:28,957] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:27:28,958] {logging_mixin.py:112} INFO - [2020-07-22 11:27:28,958] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:29,024] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:29,135] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:27:29,150] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:27:29,153] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-22 11:27:36,815] {scheduler_job.py:153} INFO - Started process (PID=164878) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:36,817] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:27:36,818] {logging_mixin.py:112} INFO - [2020-07-22 11:27:36,818] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:36,882] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:37,001] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:27:37,016] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:27:37,019] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 11:27:47,352] {scheduler_job.py:153} INFO - Started process (PID=165111) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:47,355] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:27:47,356] {logging_mixin.py:112} INFO - [2020-07-22 11:27:47,356] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:47,421] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:47,596] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:27:47,619] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:27:47,621] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.270 seconds
[2020-07-22 11:27:56,226] {scheduler_job.py:153} INFO - Started process (PID=165324) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:56,230] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:27:56,231] {logging_mixin.py:112} INFO - [2020-07-22 11:27:56,231] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:56,298] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:27:56,404] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:27:56,419] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:27:56,421] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.195 seconds
[2020-07-22 11:28:09,182] {scheduler_job.py:153} INFO - Started process (PID=165709) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:09,187] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:28:09,188] {logging_mixin.py:112} INFO - [2020-07-22 11:28:09,187] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:09,253] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:09,360] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:28:09,375] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:28:09,378] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.196 seconds
[2020-07-22 11:28:17,070] {scheduler_job.py:153} INFO - Started process (PID=165915) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:17,075] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:28:17,075] {logging_mixin.py:112} INFO - [2020-07-22 11:28:17,075] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:17,139] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:17,240] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:28:17,255] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:28:17,257] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.187 seconds
[2020-07-22 11:28:26,254] {scheduler_job.py:153} INFO - Started process (PID=166129) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:26,257] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:28:26,258] {logging_mixin.py:112} INFO - [2020-07-22 11:28:26,258] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:26,327] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:26,528] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:28:26,544] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:28:26,546] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.292 seconds
[2020-07-22 11:28:36,265] {scheduler_job.py:153} INFO - Started process (PID=166381) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:36,269] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:28:36,269] {logging_mixin.py:112} INFO - [2020-07-22 11:28:36,269] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:36,337] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:36,495] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:28:36,516] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:28:36,519] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.254 seconds
[2020-07-22 11:28:50,360] {scheduler_job.py:153} INFO - Started process (PID=166738) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:50,364] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:28:50,365] {logging_mixin.py:112} INFO - [2020-07-22 11:28:50,365] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:50,518] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:50,647] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:28:50,663] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:28:50,665] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.306 seconds
[2020-07-22 11:28:58,426] {scheduler_job.py:153} INFO - Started process (PID=166965) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:58,430] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:28:58,431] {logging_mixin.py:112} INFO - [2020-07-22 11:28:58,431] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:58,520] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:28:58,987] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:28:59,001] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:28:59,004] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.578 seconds
[2020-07-22 11:29:06,825] {scheduler_job.py:153} INFO - Started process (PID=167193) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:06,828] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:29:06,829] {logging_mixin.py:112} INFO - [2020-07-22 11:29:06,828] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:06,907] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:07,067] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:29:07,082] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:29:07,084] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.259 seconds
[2020-07-22 11:29:16,705] {scheduler_job.py:153} INFO - Started process (PID=167418) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:16,708] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:29:16,709] {logging_mixin.py:112} INFO - [2020-07-22 11:29:16,709] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:16,790] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:16,893] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:29:16,908] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:29:16,911] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.206 seconds
[2020-07-22 11:29:29,087] {scheduler_job.py:153} INFO - Started process (PID=167746) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:29,092] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:29:29,092] {logging_mixin.py:112} INFO - [2020-07-22 11:29:29,092] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:29,213] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:29,364] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:29:29,387] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:29:29,391] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.304 seconds
[2020-07-22 11:29:37,730] {scheduler_job.py:153} INFO - Started process (PID=168011) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:37,733] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:29:37,734] {logging_mixin.py:112} INFO - [2020-07-22 11:29:37,734] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:37,801] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:38,059] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:29:38,078] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:29:38,081] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.352 seconds
[2020-07-22 11:29:46,357] {scheduler_job.py:153} INFO - Started process (PID=168227) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:46,361] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:29:46,361] {logging_mixin.py:112} INFO - [2020-07-22 11:29:46,361] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:46,426] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:46,535] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:29:46,550] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:29:46,553] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.195 seconds
[2020-07-22 11:29:56,974] {scheduler_job.py:153} INFO - Started process (PID=168458) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:56,977] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:29:56,977] {logging_mixin.py:112} INFO - [2020-07-22 11:29:56,977] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:57,048] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:29:57,210] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:29:57,226] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:29:57,229] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.255 seconds
[2020-07-22 11:30:08,682] {scheduler_job.py:153} INFO - Started process (PID=168773) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:08,686] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:30:08,687] {logging_mixin.py:112} INFO - [2020-07-22 11:30:08,686] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:08,771] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:08,877] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:30:08,894] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:30:08,897] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.215 seconds
[2020-07-22 11:30:18,203] {scheduler_job.py:153} INFO - Started process (PID=169051) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:18,206] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:30:18,206] {logging_mixin.py:112} INFO - [2020-07-22 11:30:18,206] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:18,274] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:18,394] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:30:18,409] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:30:18,413] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.210 seconds
[2020-07-22 11:30:27,493] {scheduler_job.py:153} INFO - Started process (PID=169279) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:27,498] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:30:27,499] {logging_mixin.py:112} INFO - [2020-07-22 11:30:27,498] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:27,621] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:27,721] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:30:27,738] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:30:27,741] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.247 seconds
[2020-07-22 11:30:36,906] {scheduler_job.py:153} INFO - Started process (PID=169498) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:36,910] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:30:36,911] {logging_mixin.py:112} INFO - [2020-07-22 11:30:36,910] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:36,976] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:37,095] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:30:37,111] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:30:37,113] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.207 seconds
[2020-07-22 11:30:47,030] {scheduler_job.py:153} INFO - Started process (PID=169782) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:47,033] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:30:47,034] {logging_mixin.py:112} INFO - [2020-07-22 11:30:47,034] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:47,115] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:47,228] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:30:47,252] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:30:47,256] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.226 seconds
[2020-07-22 11:30:57,958] {scheduler_job.py:153} INFO - Started process (PID=170083) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:57,963] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:30:57,964] {logging_mixin.py:112} INFO - [2020-07-22 11:30:57,964] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:58,179] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:30:58,294] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:30:58,314] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:30:58,318] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.360 seconds
[2020-07-22 11:31:06,470] {scheduler_job.py:153} INFO - Started process (PID=170295) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:06,473] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:31:06,473] {logging_mixin.py:112} INFO - [2020-07-22 11:31:06,473] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:06,546] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:06,698] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:31:06,713] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:31:06,716] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.246 seconds
[2020-07-22 11:31:16,754] {scheduler_job.py:153} INFO - Started process (PID=170550) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:16,756] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:31:16,757] {logging_mixin.py:112} INFO - [2020-07-22 11:31:16,757] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:16,823] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:16,933] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:31:16,947] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:31:16,950] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.196 seconds
[2020-07-22 11:31:27,590] {scheduler_job.py:153} INFO - Started process (PID=170823) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:27,594] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:31:27,595] {logging_mixin.py:112} INFO - [2020-07-22 11:31:27,594] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:27,668] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:27,783] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:31:27,804] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:31:27,807] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-22 11:31:38,940] {scheduler_job.py:153} INFO - Started process (PID=171138) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:38,944] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:31:38,944] {logging_mixin.py:112} INFO - [2020-07-22 11:31:38,944] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:39,010] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:39,123] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:31:39,138] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:31:39,141] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.201 seconds
[2020-07-22 11:31:46,784] {scheduler_job.py:153} INFO - Started process (PID=171365) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:46,786] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:31:46,787] {logging_mixin.py:112} INFO - [2020-07-22 11:31:46,787] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:46,859] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:47,011] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:31:47,026] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:31:47,029] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.245 seconds
[2020-07-22 11:31:56,523] {scheduler_job.py:153} INFO - Started process (PID=171580) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:56,528] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:31:56,528] {logging_mixin.py:112} INFO - [2020-07-22 11:31:56,528] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:56,645] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:31:56,839] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:31:56,855] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:31:56,858] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.335 seconds
[2020-07-22 11:32:07,850] {scheduler_job.py:153} INFO - Started process (PID=171879) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:07,861] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:32:07,861] {logging_mixin.py:112} INFO - [2020-07-22 11:32:07,861] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:08,034] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:08,292] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:32:08,324] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:32:08,329] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.479 seconds
[2020-07-22 11:32:23,191] {scheduler_job.py:153} INFO - Started process (PID=172286) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:23,194] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:32:23,194] {logging_mixin.py:112} INFO - [2020-07-22 11:32:23,194] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:23,264] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:23,370] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:32:23,387] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:32:23,390] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.199 seconds
[2020-07-22 11:32:31,464] {scheduler_job.py:153} INFO - Started process (PID=172492) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:31,470] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:32:31,471] {logging_mixin.py:112} INFO - [2020-07-22 11:32:31,470] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:31,549] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:31,713] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:32:31,729] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:32:31,731] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.267 seconds
[2020-07-22 11:32:39,135] {scheduler_job.py:153} INFO - Started process (PID=172703) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:39,139] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:32:39,139] {logging_mixin.py:112} INFO - [2020-07-22 11:32:39,139] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:39,269] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:39,428] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:32:39,456] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:32:39,461] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.326 seconds
[2020-07-22 11:32:49,266] {scheduler_job.py:153} INFO - Started process (PID=172986) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:49,270] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:32:49,271] {logging_mixin.py:112} INFO - [2020-07-22 11:32:49,270] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:49,363] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:32:49,517] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:32:49,544] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:32:49,548] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.282 seconds
[2020-07-22 11:33:03,576] {scheduler_job.py:153} INFO - Started process (PID=173308) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:03,580] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:33:03,581] {logging_mixin.py:112} INFO - [2020-07-22 11:33:03,581] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:03,759] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:04,049] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:33:04,067] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:33:04,070] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.494 seconds
[2020-07-22 11:33:14,804] {scheduler_job.py:153} INFO - Started process (PID=173648) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:14,809] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:33:14,810] {logging_mixin.py:112} INFO - [2020-07-22 11:33:14,809] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:14,875] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:14,995] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:33:15,010] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:33:15,012] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 11:33:23,581] {scheduler_job.py:153} INFO - Started process (PID=173852) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:23,587] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:33:23,588] {logging_mixin.py:112} INFO - [2020-07-22 11:33:23,588] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:23,668] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:23,782] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:33:23,807] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:33:23,812] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.231 seconds
[2020-07-22 11:33:31,741] {scheduler_job.py:153} INFO - Started process (PID=174055) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:31,745] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:33:31,745] {logging_mixin.py:112} INFO - [2020-07-22 11:33:31,745] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:31,821] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:31,946] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:33:31,967] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:33:31,972] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.231 seconds
[2020-07-22 11:33:39,439] {scheduler_job.py:153} INFO - Started process (PID=174262) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:39,442] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:33:39,442] {logging_mixin.py:112} INFO - [2020-07-22 11:33:39,442] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:39,522] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:39,629] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:33:39,647] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:33:39,650] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.211 seconds
[2020-07-22 11:33:52,067] {scheduler_job.py:153} INFO - Started process (PID=174637) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:52,071] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:33:52,071] {logging_mixin.py:112} INFO - [2020-07-22 11:33:52,071] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:52,139] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:52,271] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:33:52,294] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:33:52,299] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.232 seconds
[2020-07-22 11:33:59,415] {scheduler_job.py:153} INFO - Started process (PID=174838) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:59,420] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:33:59,421] {logging_mixin.py:112} INFO - [2020-07-22 11:33:59,421] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:59,495] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:33:59,612] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:33:59,627] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:33:59,630] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.215 seconds
[2020-07-22 11:34:06,991] {scheduler_job.py:153} INFO - Started process (PID=175033) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:06,993] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:34:06,994] {logging_mixin.py:112} INFO - [2020-07-22 11:34:06,994] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:07,068] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:07,257] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:34:07,273] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:34:07,276] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.285 seconds
[2020-07-22 11:34:18,847] {scheduler_job.py:153} INFO - Started process (PID=175324) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:18,852] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:34:18,852] {logging_mixin.py:112} INFO - [2020-07-22 11:34:18,852] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:18,982] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:19,106] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:34:19,134] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:34:19,139] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.292 seconds
[2020-07-22 11:34:30,266] {scheduler_job.py:153} INFO - Started process (PID=175613) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:30,270] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:34:30,270] {logging_mixin.py:112} INFO - [2020-07-22 11:34:30,270] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:30,387] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:30,504] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:34:30,532] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:34:30,536] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.270 seconds
[2020-07-22 11:34:42,492] {scheduler_job.py:153} INFO - Started process (PID=175935) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:42,496] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:34:42,497] {logging_mixin.py:112} INFO - [2020-07-22 11:34:42,497] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:42,568] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:42,668] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:34:42,683] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:34:42,686] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.194 seconds
[2020-07-22 11:34:50,858] {scheduler_job.py:153} INFO - Started process (PID=176160) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:50,862] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:34:50,862] {logging_mixin.py:112} INFO - [2020-07-22 11:34:50,862] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:50,956] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:34:51,127] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:34:51,162] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:34:51,167] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.308 seconds
[2020-07-22 11:35:00,968] {scheduler_job.py:153} INFO - Started process (PID=176393) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:00,971] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:35:00,972] {logging_mixin.py:112} INFO - [2020-07-22 11:35:00,972] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:01,051] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:01,315] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:35:01,345] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:35:01,355] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.388 seconds
[2020-07-22 11:35:12,850] {scheduler_job.py:153} INFO - Started process (PID=176685) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:12,855] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:35:12,856] {logging_mixin.py:112} INFO - [2020-07-22 11:35:12,856] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:13,059] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:13,205] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:35:13,276] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:35:13,288] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.439 seconds
[2020-07-22 11:35:25,122] {scheduler_job.py:153} INFO - Started process (PID=177032) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:25,125] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:35:25,125] {logging_mixin.py:112} INFO - [2020-07-22 11:35:25,125] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:25,219] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:25,333] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:35:25,349] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:35:25,352] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.230 seconds
[2020-07-22 11:35:33,497] {scheduler_job.py:153} INFO - Started process (PID=177244) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:33,501] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:35:33,501] {logging_mixin.py:112} INFO - [2020-07-22 11:35:33,501] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:33,506] {logging_mixin.py:112} INFO - [2020-07-22 11:35:33,505] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:35:33,506] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:33,665] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.168 seconds
[2020-07-22 11:35:44,450] {scheduler_job.py:153} INFO - Started process (PID=177497) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:44,471] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:35:44,478] {logging_mixin.py:112} INFO - [2020-07-22 11:35:44,475] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:44,495] {logging_mixin.py:112} INFO - [2020-07-22 11:35:44,489] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:35:44,496] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:44,693] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.243 seconds
[2020-07-22 11:35:56,153] {scheduler_job.py:153} INFO - Started process (PID=177813) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:56,158] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:35:56,159] {logging_mixin.py:112} INFO - [2020-07-22 11:35:56,159] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:56,167] {logging_mixin.py:112} INFO - [2020-07-22 11:35:56,166] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:35:56,167] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:35:56,269] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.116 seconds
[2020-07-22 11:36:13,082] {scheduler_job.py:153} INFO - Started process (PID=178175) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:36:13,087] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:36:13,088] {logging_mixin.py:112} INFO - [2020-07-22 11:36:13,088] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:36:13,108] {logging_mixin.py:112} INFO - [2020-07-22 11:36:13,105] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:36:13,108] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:36:13,282] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-22 11:36:21,865] {scheduler_job.py:153} INFO - Started process (PID=178433) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:36:21,868] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:36:21,868] {logging_mixin.py:112} INFO - [2020-07-22 11:36:21,868] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:36:21,873] {logging_mixin.py:112} INFO - [2020-07-22 11:36:21,872] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:36:21,873] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:36:22,025] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.160 seconds
[2020-07-22 11:36:36,881] {scheduler_job.py:153} INFO - Started process (PID=178723) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:36:36,884] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:36:36,885] {logging_mixin.py:112} INFO - [2020-07-22 11:36:36,885] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:36:36,891] {logging_mixin.py:112} INFO - [2020-07-22 11:36:36,890] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:36:36,891] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:36:37,026] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.146 seconds
[2020-07-22 11:36:50,886] {scheduler_job.py:153} INFO - Started process (PID=179031) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:36:50,889] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:36:50,890] {logging_mixin.py:112} INFO - [2020-07-22 11:36:50,890] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:36:50,894] {logging_mixin.py:112} INFO - [2020-07-22 11:36:50,893] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:36:50,894] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:36:51,048] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.162 seconds
[2020-07-22 11:37:03,578] {scheduler_job.py:153} INFO - Started process (PID=179355) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:03,597] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:37:03,597] {logging_mixin.py:112} INFO - [2020-07-22 11:37:03,597] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:03,610] {logging_mixin.py:112} INFO - [2020-07-22 11:37:03,608] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:37:03,611] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:03,794] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.216 seconds
[2020-07-22 11:37:13,054] {scheduler_job.py:153} INFO - Started process (PID=179630) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:13,058] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:37:13,058] {logging_mixin.py:112} INFO - [2020-07-22 11:37:13,058] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:13,063] {logging_mixin.py:112} INFO - [2020-07-22 11:37:13,062] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:37:13,063] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:13,150] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.096 seconds
[2020-07-22 11:37:20,737] {scheduler_job.py:153} INFO - Started process (PID=179828) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:20,740] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:37:20,741] {logging_mixin.py:112} INFO - [2020-07-22 11:37:20,741] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:20,745] {logging_mixin.py:112} INFO - [2020-07-22 11:37:20,744] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:37:20,745] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:20,885] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.147 seconds
[2020-07-22 11:37:31,340] {scheduler_job.py:153} INFO - Started process (PID=180122) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:31,343] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:37:31,343] {logging_mixin.py:112} INFO - [2020-07-22 11:37:31,343] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:31,347] {logging_mixin.py:112} INFO - [2020-07-22 11:37:31,346] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:37:31,347] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:31,451] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.111 seconds
[2020-07-22 11:37:49,311] {scheduler_job.py:153} INFO - Started process (PID=180517) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:49,314] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:37:49,315] {logging_mixin.py:112} INFO - [2020-07-22 11:37:49,315] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:49,322] {logging_mixin.py:112} INFO - [2020-07-22 11:37:49,320] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:37:49,323] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:37:49,431] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.120 seconds
[2020-07-22 11:38:05,456] {scheduler_job.py:153} INFO - Started process (PID=180883) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:05,459] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:38:05,460] {logging_mixin.py:112} INFO - [2020-07-22 11:38:05,460] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:05,465] {logging_mixin.py:112} INFO - [2020-07-22 11:38:05,463] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:38:05,465] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:05,566] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.109 seconds
[2020-07-22 11:38:15,691] {scheduler_job.py:153} INFO - Started process (PID=181138) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:15,695] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:38:15,696] {logging_mixin.py:112} INFO - [2020-07-22 11:38:15,695] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:15,701] {logging_mixin.py:112} INFO - [2020-07-22 11:38:15,700] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:38:15,702] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:15,868] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.177 seconds
[2020-07-22 11:38:28,903] {scheduler_job.py:153} INFO - Started process (PID=181510) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:28,908] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:38:28,909] {logging_mixin.py:112} INFO - [2020-07-22 11:38:28,908] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:28,915] {logging_mixin.py:112} INFO - [2020-07-22 11:38:28,914] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:38:28,916] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:29,122] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.219 seconds
[2020-07-22 11:38:48,951] {scheduler_job.py:153} INFO - Started process (PID=181931) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:48,954] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:38:48,955] {logging_mixin.py:112} INFO - [2020-07-22 11:38:48,955] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:48,961] {logging_mixin.py:112} INFO - [2020-07-22 11:38:48,959] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 7, in <module>
    from airflow.operators import SparkSubmitOperator
ImportError: cannot import name 'SparkSubmitOperator' from 'airflow.operators' (unknown location)
[2020-07-22 11:38:48,961] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:49,090] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.139 seconds
[2020-07-22 11:38:57,726] {scheduler_job.py:153} INFO - Started process (PID=182173) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:57,730] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:38:57,731] {logging_mixin.py:112} INFO - [2020-07-22 11:38:57,731] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:57,891] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:38:58,000] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:38:58,016] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:38:58,114] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.387 seconds
[2020-07-22 11:39:05,387] {scheduler_job.py:153} INFO - Started process (PID=182363) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:05,390] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:39:05,391] {logging_mixin.py:112} INFO - [2020-07-22 11:39:05,390] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:05,462] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:05,577] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:39:05,625] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:39:05,630] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.243 seconds
[2020-07-22 11:39:18,073] {scheduler_job.py:153} INFO - Started process (PID=182705) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:18,076] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:39:18,077] {logging_mixin.py:112} INFO - [2020-07-22 11:39:18,077] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:18,329] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:18,504] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:39:18,569] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:39:18,573] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.501 seconds
[2020-07-22 11:39:28,898] {scheduler_job.py:153} INFO - Started process (PID=182987) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:28,903] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:39:28,904] {logging_mixin.py:112} INFO - [2020-07-22 11:39:28,904] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:28,999] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:29,194] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:39:29,210] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:39:29,212] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.314 seconds
[2020-07-22 11:39:38,269] {scheduler_job.py:153} INFO - Started process (PID=183213) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:38,273] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:39:38,275] {logging_mixin.py:112} INFO - [2020-07-22 11:39:38,275] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:38,373] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:38,488] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:39:38,504] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:39:38,506] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.238 seconds
[2020-07-22 11:39:47,952] {scheduler_job.py:153} INFO - Started process (PID=183431) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:47,954] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:39:47,955] {logging_mixin.py:112} INFO - [2020-07-22 11:39:47,955] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:48,022] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:39:48,147] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:39:48,173] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:39:48,177] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.226 seconds
[2020-07-22 11:40:00,469] {scheduler_job.py:153} INFO - Started process (PID=183767) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:00,481] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:40:00,483] {logging_mixin.py:112} INFO - [2020-07-22 11:40:00,483] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:00,687] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:00,918] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:40:00,943] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:40:00,947] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.478 seconds
[2020-07-22 11:40:10,979] {scheduler_job.py:153} INFO - Started process (PID=184045) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:10,983] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:40:10,984] {logging_mixin.py:112} INFO - [2020-07-22 11:40:10,984] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:11,058] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:11,181] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:40:11,196] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:40:11,199] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.219 seconds
[2020-07-22 11:40:18,359] {scheduler_job.py:153} INFO - Started process (PID=184236) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:18,362] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:40:18,363] {logging_mixin.py:112} INFO - [2020-07-22 11:40:18,363] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:18,438] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:18,549] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:40:18,567] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:40:18,571] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.212 seconds
[2020-07-22 11:40:27,153] {scheduler_job.py:153} INFO - Started process (PID=184454) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:27,157] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:40:27,157] {logging_mixin.py:112} INFO - [2020-07-22 11:40:27,157] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:27,227] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:27,419] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:40:27,436] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:40:27,439] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.285 seconds
[2020-07-22 11:40:34,807] {scheduler_job.py:153} INFO - Started process (PID=184674) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:34,812] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:40:34,812] {logging_mixin.py:112} INFO - [2020-07-22 11:40:34,812] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:35,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:35,128] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:40:35,149] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:40:35,152] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.346 seconds
[2020-07-22 11:40:47,480] {scheduler_job.py:153} INFO - Started process (PID=185009) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:47,483] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:40:47,483] {logging_mixin.py:112} INFO - [2020-07-22 11:40:47,483] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:47,562] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:47,683] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:40:47,698] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:40:47,700] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.221 seconds
[2020-07-22 11:40:54,942] {scheduler_job.py:153} INFO - Started process (PID=185221) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:54,946] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:40:54,946] {logging_mixin.py:112} INFO - [2020-07-22 11:40:54,946] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:55,038] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:40:55,226] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:40:55,241] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:40:55,244] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.302 seconds
[2020-07-22 11:41:02,912] {scheduler_job.py:153} INFO - Started process (PID=185457) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:02,917] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:41:02,918] {logging_mixin.py:112} INFO - [2020-07-22 11:41:02,918] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:02,986] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:03,135] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:41:03,153] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:41:03,156] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.244 seconds
[2020-07-22 11:41:10,266] {scheduler_job.py:153} INFO - Started process (PID=185654) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:10,269] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:41:10,269] {logging_mixin.py:112} INFO - [2020-07-22 11:41:10,269] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:10,366] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:10,464] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:41:10,490] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:41:10,495] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.229 seconds
[2020-07-22 11:41:18,035] {scheduler_job.py:153} INFO - Started process (PID=185854) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:18,038] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:41:18,039] {logging_mixin.py:112} INFO - [2020-07-22 11:41:18,039] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:18,110] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:18,232] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:41:18,251] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:41:18,254] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.220 seconds
[2020-07-22 11:41:29,889] {scheduler_job.py:153} INFO - Started process (PID=186214) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:29,893] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:41:29,894] {logging_mixin.py:112} INFO - [2020-07-22 11:41:29,894] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:30,059] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:30,295] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:41:30,354] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:41:30,374] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.485 seconds
[2020-07-22 11:41:39,878] {scheduler_job.py:153} INFO - Started process (PID=186486) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:39,882] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:41:39,883] {logging_mixin.py:112} INFO - [2020-07-22 11:41:39,883] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:39,954] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:40,054] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:41:40,073] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:41:40,075] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.197 seconds
[2020-07-22 11:41:48,754] {scheduler_job.py:153} INFO - Started process (PID=186693) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:48,760] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:41:48,760] {logging_mixin.py:112} INFO - [2020-07-22 11:41:48,760] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:48,891] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:49,048] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:41:49,064] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:41:49,068] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.314 seconds
[2020-07-22 11:41:56,333] {scheduler_job.py:153} INFO - Started process (PID=186888) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:56,337] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:41:56,338] {logging_mixin.py:112} INFO - [2020-07-22 11:41:56,338] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:56,341] {logging_mixin.py:112} INFO - [2020-07-22 11:41:56,340] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:41:56,341] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:41:56,503] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.170 seconds
[2020-07-22 11:42:05,250] {scheduler_job.py:153} INFO - Started process (PID=187161) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:05,256] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:42:05,256] {logging_mixin.py:112} INFO - [2020-07-22 11:42:05,256] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:05,261] {logging_mixin.py:112} INFO - [2020-07-22 11:42:05,259] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:42:05,261] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:05,415] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.165 seconds
[2020-07-22 11:42:20,135] {scheduler_job.py:153} INFO - Started process (PID=187483) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:20,139] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:42:20,140] {logging_mixin.py:112} INFO - [2020-07-22 11:42:20,140] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:20,143] {logging_mixin.py:112} INFO - [2020-07-22 11:42:20,142] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:42:20,143] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:20,294] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.159 seconds
[2020-07-22 11:42:29,411] {scheduler_job.py:153} INFO - Started process (PID=187708) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:29,416] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:42:29,416] {logging_mixin.py:112} INFO - [2020-07-22 11:42:29,416] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:29,419] {logging_mixin.py:112} INFO - [2020-07-22 11:42:29,418] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:42:29,419] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:29,528] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.117 seconds
[2020-07-22 11:42:37,885] {scheduler_job.py:153} INFO - Started process (PID=187941) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:37,889] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:42:37,890] {logging_mixin.py:112} INFO - [2020-07-22 11:42:37,889] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:37,892] {logging_mixin.py:112} INFO - [2020-07-22 11:42:37,891] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:42:37,892] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:38,006] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.120 seconds
[2020-07-22 11:42:46,492] {scheduler_job.py:153} INFO - Started process (PID=188148) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:46,497] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:42:46,498] {logging_mixin.py:112} INFO - [2020-07-22 11:42:46,497] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:46,500] {logging_mixin.py:112} INFO - [2020-07-22 11:42:46,500] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:42:46,501] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:42:46,617] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.125 seconds
[2020-07-22 11:43:00,091] {scheduler_job.py:153} INFO - Started process (PID=188487) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:00,095] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:43:00,096] {logging_mixin.py:112} INFO - [2020-07-22 11:43:00,096] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:00,102] {logging_mixin.py:112} INFO - [2020-07-22 11:43:00,101] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:43:00,103] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:00,195] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.104 seconds
[2020-07-22 11:43:09,783] {scheduler_job.py:153} INFO - Started process (PID=188767) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:09,786] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:43:09,786] {logging_mixin.py:112} INFO - [2020-07-22 11:43:09,786] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:09,789] {logging_mixin.py:112} INFO - [2020-07-22 11:43:09,788] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:43:09,789] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:09,883] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.100 seconds
[2020-07-22 11:43:18,146] {scheduler_job.py:153} INFO - Started process (PID=188988) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:18,150] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:43:18,151] {logging_mixin.py:112} INFO - [2020-07-22 11:43:18,150] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:18,155] {logging_mixin.py:112} INFO - [2020-07-22 11:43:18,153] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:43:18,156] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:18,260] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.114 seconds
[2020-07-22 11:43:27,428] {scheduler_job.py:153} INFO - Started process (PID=189198) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:27,431] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:43:27,432] {logging_mixin.py:112} INFO - [2020-07-22 11:43:27,431] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:27,434] {logging_mixin.py:112} INFO - [2020-07-22 11:43:27,433] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:43:27,435] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:27,536] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.108 seconds
[2020-07-22 11:43:36,003] {scheduler_job.py:153} INFO - Started process (PID=189459) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:36,008] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:43:36,008] {logging_mixin.py:112} INFO - [2020-07-22 11:43:36,008] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:36,012] {logging_mixin.py:112} INFO - [2020-07-22 11:43:36,011] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:43:36,013] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:36,147] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.144 seconds
[2020-07-22 11:43:49,014] {scheduler_job.py:153} INFO - Started process (PID=189800) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:49,019] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:43:49,019] {logging_mixin.py:112} INFO - [2020-07-22 11:43:49,019] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:49,022] {logging_mixin.py:112} INFO - [2020-07-22 11:43:49,021] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:43:49,022] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:49,179] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.166 seconds
[2020-07-22 11:43:57,382] {scheduler_job.py:153} INFO - Started process (PID=190003) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:57,388] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:43:57,389] {logging_mixin.py:112} INFO - [2020-07-22 11:43:57,388] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:57,393] {logging_mixin.py:112} INFO - [2020-07-22 11:43:57,391] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:43:57,393] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:43:57,566] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.184 seconds
[2020-07-22 11:44:07,211] {scheduler_job.py:153} INFO - Started process (PID=190273) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:07,214] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:44:07,214] {logging_mixin.py:112} INFO - [2020-07-22 11:44:07,214] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:07,217] {logging_mixin.py:112} INFO - [2020-07-22 11:44:07,216] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:44:07,217] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:07,344] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.133 seconds
[2020-07-22 11:44:14,384] {scheduler_job.py:153} INFO - Started process (PID=190482) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:14,388] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:44:14,388] {logging_mixin.py:112} INFO - [2020-07-22 11:44:14,388] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:14,391] {logging_mixin.py:112} INFO - [2020-07-22 11:44:14,390] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:44:14,391] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:14,476] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.092 seconds
[2020-07-22 11:44:25,832] {scheduler_job.py:153} INFO - Started process (PID=190766) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:25,839] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:44:25,840] {logging_mixin.py:112} INFO - [2020-07-22 11:44:25,840] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:25,845] {logging_mixin.py:112} INFO - [2020-07-22 11:44:25,844] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:44:25,846] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:25,986] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.155 seconds
[2020-07-22 11:44:36,555] {scheduler_job.py:153} INFO - Started process (PID=191090) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:36,562] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:44:36,562] {logging_mixin.py:112} INFO - [2020-07-22 11:44:36,562] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:36,594] {logging_mixin.py:112} INFO - [2020-07-22 11:44:36,571] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:44:36,594] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:36,731] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.176 seconds
[2020-07-22 11:44:45,535] {scheduler_job.py:153} INFO - Started process (PID=191309) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:45,539] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:44:45,541] {logging_mixin.py:112} INFO - [2020-07-22 11:44:45,540] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:45,545] {logging_mixin.py:112} INFO - [2020-07-22 11:44:45,544] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:44:45,545] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:45,642] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.107 seconds
[2020-07-22 11:44:54,409] {scheduler_job.py:153} INFO - Started process (PID=191522) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:54,414] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:44:54,414] {logging_mixin.py:112} INFO - [2020-07-22 11:44:54,414] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:54,418] {logging_mixin.py:112} INFO - [2020-07-22 11:44:54,417] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:44:54,419] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:44:54,561] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.152 seconds
[2020-07-22 11:45:03,659] {scheduler_job.py:153} INFO - Started process (PID=191785) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:03,663] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:45:03,664] {logging_mixin.py:112} INFO - [2020-07-22 11:45:03,664] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:03,667] {logging_mixin.py:112} INFO - [2020-07-22 11:45:03,666] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:45:03,668] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:03,827] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.168 seconds
[2020-07-22 11:45:19,520] {scheduler_job.py:153} INFO - Started process (PID=192161) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:19,530] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:45:19,532] {logging_mixin.py:112} INFO - [2020-07-22 11:45:19,531] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:19,537] {logging_mixin.py:112} INFO - [2020-07-22 11:45:19,535] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:45:19,538] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:19,682] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.163 seconds
[2020-07-22 11:45:28,984] {scheduler_job.py:153} INFO - Started process (PID=192394) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:28,988] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:45:28,989] {logging_mixin.py:112} INFO - [2020-07-22 11:45:28,989] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:28,993] {logging_mixin.py:112} INFO - [2020-07-22 11:45:28,991] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:45:28,993] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:29,103] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.119 seconds
[2020-07-22 11:45:42,597] {scheduler_job.py:153} INFO - Started process (PID=192692) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:42,602] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:45:42,603] {logging_mixin.py:112} INFO - [2020-07-22 11:45:42,603] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:42,606] {logging_mixin.py:112} INFO - [2020-07-22 11:45:42,605] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:45:42,607] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:42,691] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.094 seconds
[2020-07-22 11:45:55,644] {scheduler_job.py:153} INFO - Started process (PID=193033) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:55,648] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:45:55,649] {logging_mixin.py:112} INFO - [2020-07-22 11:45:55,648] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:55,652] {logging_mixin.py:112} INFO - [2020-07-22 11:45:55,651] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 28
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:45:55,653] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:45:55,779] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.135 seconds
[2020-07-22 11:46:03,820] {scheduler_job.py:153} INFO - Started process (PID=193265) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:03,822] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:46:03,823] {logging_mixin.py:112} INFO - [2020-07-22 11:46:03,822] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:03,825] {logging_mixin.py:112} INFO - [2020-07-22 11:46:03,824] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 30
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:46:03,825] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:03,945] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.126 seconds
[2020-07-22 11:46:11,109] {scheduler_job.py:153} INFO - Started process (PID=193482) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:11,112] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:46:11,113] {logging_mixin.py:112} INFO - [2020-07-22 11:46:11,112] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:11,115] {logging_mixin.py:112} INFO - [2020-07-22 11:46:11,114] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 30
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:46:11,116] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:11,222] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.113 seconds
[2020-07-22 11:46:24,102] {scheduler_job.py:153} INFO - Started process (PID=193740) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:24,106] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:46:24,106] {logging_mixin.py:112} INFO - [2020-07-22 11:46:24,106] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:24,109] {logging_mixin.py:112} INFO - [2020-07-22 11:46:24,108] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 30
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:46:24,109] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:24,266] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.163 seconds
[2020-07-22 11:46:35,056] {scheduler_job.py:153} INFO - Started process (PID=194022) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:35,059] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:46:35,060] {logging_mixin.py:112} INFO - [2020-07-22 11:46:35,060] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:35,063] {logging_mixin.py:112} INFO - [2020-07-22 11:46:35,062] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 30
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:46:35,063] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:35,176] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.120 seconds
[2020-07-22 11:46:53,309] {scheduler_job.py:153} INFO - Started process (PID=194418) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:53,313] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:46:53,314] {logging_mixin.py:112} INFO - [2020-07-22 11:46:53,313] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:53,316] {logging_mixin.py:112} INFO - [2020-07-22 11:46:53,315] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 30
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:46:53,317] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:46:53,486] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.177 seconds
[2020-07-22 11:47:01,783] {scheduler_job.py:153} INFO - Started process (PID=194643) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:01,786] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:47:01,786] {logging_mixin.py:112} INFO - [2020-07-22 11:47:01,786] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:01,789] {logging_mixin.py:112} INFO - [2020-07-22 11:47:01,788] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 30
    t4 = SparkSubmitOperator(task_id="submit-in-python", application=)
                                                                     ^
SyntaxError: invalid syntax
[2020-07-22 11:47:01,789] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:01,864] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.081 seconds
[2020-07-22 11:47:12,517] {scheduler_job.py:153} INFO - Started process (PID=194911) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:12,520] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:47:12,520] {logging_mixin.py:112} INFO - [2020-07-22 11:47:12,520] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:12,602] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:47:12,606] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:12,778] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:47:12,793] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:47:12,885] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.368 seconds
[2020-07-22 11:47:23,352] {scheduler_job.py:153} INFO - Started process (PID=195143) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:23,355] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:47:23,355] {logging_mixin.py:112} INFO - [2020-07-22 11:47:23,355] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:23,592] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:47:23,602] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:23,806] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:47:23,825] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:47:23,828] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.477 seconds
[2020-07-22 11:47:38,629] {scheduler_job.py:153} INFO - Started process (PID=195509) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:38,632] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:47:38,632] {logging_mixin.py:112} INFO - [2020-07-22 11:47:38,632] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:38,744] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:47:38,763] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:38,908] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:47:38,926] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:47:38,929] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.300 seconds
[2020-07-22 11:47:46,781] {scheduler_job.py:153} INFO - Started process (PID=195762) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:46,784] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:47:46,784] {logging_mixin.py:112} INFO - [2020-07-22 11:47:46,784] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:46,877] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:47:46,882] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:47,000] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:47:47,023] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:47:47,026] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.246 seconds
[2020-07-22 11:47:56,116] {scheduler_job.py:153} INFO - Started process (PID=195985) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:56,119] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:47:56,120] {logging_mixin.py:112} INFO - [2020-07-22 11:47:56,119] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:56,187] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:47:56,191] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:47:56,301] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:47:56,316] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:47:56,319] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.203 seconds
[2020-07-22 11:48:05,025] {scheduler_job.py:153} INFO - Started process (PID=196189) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:05,030] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:48:05,030] {logging_mixin.py:112} INFO - [2020-07-22 11:48:05,030] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:05,118] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:48:05,122] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:05,324] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:48:05,361] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:48:05,369] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.344 seconds
[2020-07-22 11:48:19,009] {scheduler_job.py:153} INFO - Started process (PID=196524) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:19,012] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:48:19,012] {logging_mixin.py:112} INFO - [2020-07-22 11:48:19,012] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:19,119] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:48:19,125] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:19,341] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:48:19,388] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:48:19,401] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.392 seconds
[2020-07-22 11:48:30,989] {scheduler_job.py:153} INFO - Started process (PID=196843) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:30,992] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:48:30,993] {logging_mixin.py:112} INFO - [2020-07-22 11:48:30,993] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:31,061] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:48:31,064] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:31,188] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:48:31,202] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:48:31,205] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.216 seconds
[2020-07-22 11:48:39,383] {scheduler_job.py:153} INFO - Started process (PID=197048) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:39,386] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:48:39,386] {logging_mixin.py:112} INFO - [2020-07-22 11:48:39,386] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:39,450] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:48:39,454] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:39,547] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:48:39,576] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:48:39,581] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.199 seconds
[2020-07-22 11:48:49,602] {scheduler_job.py:153} INFO - Started process (PID=197308) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:49,605] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:48:49,606] {logging_mixin.py:112} INFO - [2020-07-22 11:48:49,605] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:49,670] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:48:49,673] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:49,833] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:48:49,862] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:48:49,867] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.266 seconds
[2020-07-22 11:48:57,498] {scheduler_job.py:153} INFO - Started process (PID=197520) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:57,501] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:48:57,502] {logging_mixin.py:112} INFO - [2020-07-22 11:48:57,502] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:57,662] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:48:57,683] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:48:57,836] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:48:57,879] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:48:57,883] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.386 seconds
[2020-07-22 11:49:12,354] {scheduler_job.py:153} INFO - Started process (PID=197898) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:12,361] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:49:12,362] {logging_mixin.py:112} INFO - [2020-07-22 11:49:12,361] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:12,473] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:49:12,479] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:12,602] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:49:12,632] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:49:12,636] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.282 seconds
[2020-07-22 11:49:21,666] {scheduler_job.py:153} INFO - Started process (PID=198150) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:21,670] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:49:21,671] {logging_mixin.py:112} INFO - [2020-07-22 11:49:21,671] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:21,752] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:49:21,755] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:21,862] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:49:21,877] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:49:21,879] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.213 seconds
[2020-07-22 11:49:30,249] {scheduler_job.py:153} INFO - Started process (PID=198358) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:30,255] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:49:30,255] {logging_mixin.py:112} INFO - [2020-07-22 11:49:30,255] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:30,377] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:49:30,381] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:30,522] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:49:30,549] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:49:30,553] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.304 seconds
[2020-07-22 11:49:39,842] {scheduler_job.py:153} INFO - Started process (PID=198580) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:39,846] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:49:39,846] {logging_mixin.py:112} INFO - [2020-07-22 11:49:39,846] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:39,927] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:49:39,930] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:40,046] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:49:40,064] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:49:40,067] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.225 seconds
[2020-07-22 11:49:55,790] {scheduler_job.py:153} INFO - Started process (PID=198957) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:55,810] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:49:55,811] {logging_mixin.py:112} INFO - [2020-07-22 11:49:55,811] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:55,998] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:49:56,003] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:49:56,158] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:49:56,184] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:49:56,188] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.398 seconds
[2020-07-22 11:50:06,908] {scheduler_job.py:153} INFO - Started process (PID=199242) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:06,913] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:50:06,914] {logging_mixin.py:112} INFO - [2020-07-22 11:50:06,914] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:06,994] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:50:06,997] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:07,092] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:50:07,113] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:20:04.310110+00:00: manual__2020-07-22T06:20:04.310110+00:00, externally triggered: True>
[2020-07-22 11:50:07,127] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:50:07,131] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:20:04.310110+00:00 [scheduled]> in ORM
[2020-07-22 11:50:07,294] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.386 seconds
[2020-07-22 11:50:17,291] {scheduler_job.py:153} INFO - Started process (PID=199496) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:17,294] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:50:17,294] {logging_mixin.py:112} INFO - [2020-07-22 11:50:17,294] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:17,418] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:50:17,425] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:17,544] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:50:17,561] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:20:04.310110+00:00: manual__2020-07-22T06:20:04.310110+00:00, externally triggered: True>
[2020-07-22 11:50:17,575] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:50:17,578] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.287 seconds
[2020-07-22 11:50:27,348] {scheduler_job.py:153} INFO - Started process (PID=199759) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:27,351] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:50:27,352] {logging_mixin.py:112} INFO - [2020-07-22 11:50:27,351] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:27,421] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:50:27,424] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:27,511] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:50:27,528] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:20:04.310110+00:00: manual__2020-07-22T06:20:04.310110+00:00, externally triggered: True>
[2020-07-22 11:50:27,553] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:50:27,557] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:20:04.310110+00:00 [scheduled]> in ORM
[2020-07-22 11:50:27,738] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.390 seconds
[2020-07-22 11:50:41,525] {scheduler_job.py:153} INFO - Started process (PID=200111) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:41,530] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:50:41,531] {logging_mixin.py:112} INFO - [2020-07-22 11:50:41,531] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:41,669] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:50:41,675] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:41,797] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:50:41,821] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:20:04.310110+00:00: manual__2020-07-22T06:20:04.310110+00:00, externally triggered: True>
[2020-07-22 11:50:41,842] {logging_mixin.py:112} INFO - [2020-07-22 11:50:41,841] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 06:20:04.310110+00:00: manual__2020-07-22T06:20:04.310110+00:00, externally triggered: True> failed
[2020-07-22 11:50:41,947] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:50:41,950] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.426 seconds
[2020-07-22 11:50:53,729] {scheduler_job.py:153} INFO - Started process (PID=200447) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:53,732] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:50:53,733] {logging_mixin.py:112} INFO - [2020-07-22 11:50:53,733] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:53,818] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:50:53,821] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:50:53,921] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:50:53,938] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:50:53,941] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.213 seconds
[2020-07-22 11:51:01,596] {scheduler_job.py:153} INFO - Started process (PID=200647) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:01,599] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:51:01,600] {logging_mixin.py:112} INFO - [2020-07-22 11:51:01,599] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:01,688] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:51:01,691] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:01,812] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:51:01,828] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:51:01,831] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.235 seconds
[2020-07-22 11:51:09,873] {scheduler_job.py:153} INFO - Started process (PID=200857) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:09,877] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:51:09,878] {logging_mixin.py:112} INFO - [2020-07-22 11:51:09,878] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:09,956] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:51:09,959] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:10,077] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:51:10,096] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:51:10,101] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.228 seconds
[2020-07-22 11:51:17,740] {scheduler_job.py:153} INFO - Started process (PID=201067) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:17,744] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:51:17,745] {logging_mixin.py:112} INFO - [2020-07-22 11:51:17,745] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:17,856] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:51:17,861] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:18,536] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:51:18,555] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:51:18,560] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.819 seconds
[2020-07-22 11:51:34,796] {scheduler_job.py:153} INFO - Started process (PID=201515) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:34,815] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:51:34,819] {logging_mixin.py:112} INFO - [2020-07-22 11:51:34,819] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:35,221] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:51:35,232] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:35,458] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:51:35,498] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:51:35,502] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.706 seconds
[2020-07-22 11:51:43,429] {scheduler_job.py:153} INFO - Started process (PID=201759) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:43,432] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:51:43,433] {logging_mixin.py:112} INFO - [2020-07-22 11:51:43,433] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:43,501] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:51:43,505] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:43,607] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:51:43,638] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:51:43,644] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.216 seconds
[2020-07-22 11:51:52,488] {scheduler_job.py:153} INFO - Started process (PID=201993) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:52,492] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:51:52,493] {logging_mixin.py:112} INFO - [2020-07-22 11:51:52,493] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:52,563] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:51:52,566] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:51:52,664] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:51:52,680] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:51:52,683] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.195 seconds
[2020-07-22 11:52:01,581] {scheduler_job.py:153} INFO - Started process (PID=202225) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:01,585] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:52:01,585] {logging_mixin.py:112} INFO - [2020-07-22 11:52:01,585] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:01,656] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:52:01,659] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:01,782] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:52:01,799] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:52:01,802] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.221 seconds
[2020-07-22 11:52:14,589] {scheduler_job.py:153} INFO - Started process (PID=202519) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:14,604] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:52:14,605] {logging_mixin.py:112} INFO - [2020-07-22 11:52:14,605] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:14,845] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:52:14,853] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:15,098] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:52:15,166] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:52:15,171] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.582 seconds
[2020-07-22 11:52:28,234] {scheduler_job.py:153} INFO - Started process (PID=202877) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:28,238] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:52:28,238] {logging_mixin.py:112} INFO - [2020-07-22 11:52:28,238] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:28,310] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:52:28,313] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:28,413] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:52:28,428] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:52:28,431] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.197 seconds
[2020-07-22 11:52:37,133] {scheduler_job.py:153} INFO - Started process (PID=203094) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:37,138] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:52:37,138] {logging_mixin.py:112} INFO - [2020-07-22 11:52:37,138] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:37,270] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:52:37,276] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:37,417] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:52:37,447] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:52:37,452] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.319 seconds
[2020-07-22 11:52:45,701] {scheduler_job.py:153} INFO - Started process (PID=203299) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:45,708] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:52:45,708] {logging_mixin.py:112} INFO - [2020-07-22 11:52:45,708] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:45,844] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:52:45,852] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:46,024] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:52:46,041] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:52:46,044] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.343 seconds
[2020-07-22 11:52:54,485] {scheduler_job.py:153} INFO - Started process (PID=203548) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:54,487] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:52:54,488] {logging_mixin.py:112} INFO - [2020-07-22 11:52:54,488] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:54,567] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:52:54,570] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:52:54,679] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:52:54,699] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:22:47.875443+00:00: manual__2020-07-22T06:22:47.875443+00:00, externally triggered: True>
[2020-07-22 11:52:54,713] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:52:54,717] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:22:47.875443+00:00 [scheduled]> in ORM
[2020-07-22 11:52:54,878] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.394 seconds
[2020-07-22 11:53:12,888] {scheduler_job.py:153} INFO - Started process (PID=203983) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:12,892] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:53:12,893] {logging_mixin.py:112} INFO - [2020-07-22 11:53:12,893] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:12,970] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:53:12,973] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:13,078] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:53:13,096] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:22:47.875443+00:00: manual__2020-07-22T06:22:47.875443+00:00, externally triggered: True>
[2020-07-22 11:53:13,112] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:53:13,115] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.227 seconds
[2020-07-22 11:53:20,849] {scheduler_job.py:153} INFO - Started process (PID=204212) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:20,852] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:53:20,853] {logging_mixin.py:112} INFO - [2020-07-22 11:53:20,852] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:20,917] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:53:20,920] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:21,024] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:53:21,039] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:22:47.875443+00:00: manual__2020-07-22T06:22:47.875443+00:00, externally triggered: True>
[2020-07-22 11:53:21,051] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:53:21,055] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:22:47.875443+00:00 [scheduled]> in ORM
[2020-07-22 11:53:21,191] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.342 seconds
[2020-07-22 11:53:33,138] {scheduler_job.py:153} INFO - Started process (PID=204528) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:33,141] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:53:33,141] {logging_mixin.py:112} INFO - [2020-07-22 11:53:33,141] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:33,654] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:53:33,660] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:33,849] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:53:33,911] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:22:47.875443+00:00: manual__2020-07-22T06:22:47.875443+00:00, externally triggered: True>
[2020-07-22 11:53:33,950] {logging_mixin.py:112} INFO - [2020-07-22 11:53:33,949] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 06:22:47.875443+00:00: manual__2020-07-22T06:22:47.875443+00:00, externally triggered: True> failed
[2020-07-22 11:53:34,113] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:53:34,120] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.982 seconds
[2020-07-22 11:53:43,501] {scheduler_job.py:153} INFO - Started process (PID=204760) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:43,508] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:53:43,509] {logging_mixin.py:112} INFO - [2020-07-22 11:53:43,509] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:43,680] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:53:43,686] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:43,921] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:53:44,170] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:53:44,184] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.684 seconds
[2020-07-22 11:53:55,959] {scheduler_job.py:153} INFO - Started process (PID=205113) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:55,963] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:53:55,963] {logging_mixin.py:112} INFO - [2020-07-22 11:53:55,963] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:56,153] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:53:56,158] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:53:56,309] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:53:56,330] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:53:56,332] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.373 seconds
[2020-07-22 11:54:03,720] {scheduler_job.py:153} INFO - Started process (PID=205339) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:03,723] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:54:03,724] {logging_mixin.py:112} INFO - [2020-07-22 11:54:03,724] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:03,798] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:54:03,802] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:03,925] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:54:03,942] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:54:03,944] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.224 seconds
[2020-07-22 11:54:12,020] {scheduler_job.py:153} INFO - Started process (PID=205544) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:12,024] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:54:12,025] {logging_mixin.py:112} INFO - [2020-07-22 11:54:12,025] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:12,112] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:54:12,115] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:12,225] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:54:12,241] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:54:12,243] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.224 seconds
[2020-07-22 11:54:21,605] {scheduler_job.py:153} INFO - Started process (PID=205775) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:21,608] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:54:21,608] {logging_mixin.py:112} INFO - [2020-07-22 11:54:21,608] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:21,674] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:54:21,676] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:21,819] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:54:21,849] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:54:21,852] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.247 seconds
[2020-07-22 11:54:31,407] {scheduler_job.py:153} INFO - Started process (PID=206043) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:31,410] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:54:31,410] {logging_mixin.py:112} INFO - [2020-07-22 11:54:31,410] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:31,506] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:54:31,509] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:31,696] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:54:31,734] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:54:31,742] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.335 seconds
[2020-07-22 11:54:45,735] {scheduler_job.py:153} INFO - Started process (PID=206400) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:45,739] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:54:45,739] {logging_mixin.py:112} INFO - [2020-07-22 11:54:45,739] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:45,841] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:54:45,847] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:46,045] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:54:46,065] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:54:46,069] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.334 seconds
[2020-07-22 11:54:58,085] {scheduler_job.py:153} INFO - Started process (PID=206712) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:58,089] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:54:58,089] {logging_mixin.py:112} INFO - [2020-07-22 11:54:58,089] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:58,211] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:54:58,217] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:54:58,345] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:54:58,361] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:24:55.036760+00:00: manual__2020-07-22T06:24:55.036760+00:00, externally triggered: True>
[2020-07-22 11:54:58,374] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:54:58,377] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:24:55.036760+00:00 [scheduled]> in ORM
[2020-07-22 11:54:58,523] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.438 seconds
[2020-07-22 11:55:09,498] {scheduler_job.py:153} INFO - Started process (PID=207019) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:09,501] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:55:09,502] {logging_mixin.py:112} INFO - [2020-07-22 11:55:09,502] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:09,744] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:55:09,749] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:09,881] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:55:09,920] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:24:55.036760+00:00: manual__2020-07-22T06:24:55.036760+00:00, externally triggered: True>
[2020-07-22 11:55:09,951] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:55:09,957] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.459 seconds
[2020-07-22 11:55:22,353] {scheduler_job.py:153} INFO - Started process (PID=207327) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:22,356] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:55:22,357] {logging_mixin.py:112} INFO - [2020-07-22 11:55:22,356] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:22,511] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:55:22,516] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:22,697] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:55:22,713] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:24:55.036760+00:00: manual__2020-07-22T06:24:55.036760+00:00, externally triggered: True>
[2020-07-22 11:55:22,737] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:55:22,747] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:24:55.036760+00:00 [scheduled]> in ORM
[2020-07-22 11:55:22,878] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.525 seconds
[2020-07-22 11:55:34,603] {scheduler_job.py:153} INFO - Started process (PID=207687) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:34,606] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:55:34,606] {logging_mixin.py:112} INFO - [2020-07-22 11:55:34,606] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:34,706] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:55:34,710] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:34,823] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:55:34,837] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:24:55.036760+00:00: manual__2020-07-22T06:24:55.036760+00:00, externally triggered: True>
[2020-07-22 11:55:34,846] {logging_mixin.py:112} INFO - [2020-07-22 11:55:34,846] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 06:24:55.036760+00:00: manual__2020-07-22T06:24:55.036760+00:00, externally triggered: True> failed
[2020-07-22 11:55:34,956] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:55:34,961] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.359 seconds
[2020-07-22 11:55:42,269] {scheduler_job.py:153} INFO - Started process (PID=207890) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:42,273] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:55:42,274] {logging_mixin.py:112} INFO - [2020-07-22 11:55:42,274] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:42,380] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:55:42,383] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:42,510] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:55:42,525] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:55:42,528] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.259 seconds
[2020-07-22 11:55:54,393] {scheduler_job.py:153} INFO - Started process (PID=208169) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:54,396] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:55:54,397] {logging_mixin.py:112} INFO - [2020-07-22 11:55:54,397] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:54,509] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:55:54,518] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:55:54,675] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:55:54,704] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:55:54,708] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.315 seconds
[2020-07-22 11:56:06,145] {scheduler_job.py:153} INFO - Started process (PID=208487) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:06,151] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:56:06,152] {logging_mixin.py:112} INFO - [2020-07-22 11:56:06,152] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:06,555] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:56:06,588] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:06,741] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:56:06,760] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:56:06,764] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.619 seconds
[2020-07-22 11:56:16,969] {scheduler_job.py:153} INFO - Started process (PID=208787) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:16,972] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:56:16,973] {logging_mixin.py:112} INFO - [2020-07-22 11:56:16,973] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:17,037] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:56:17,040] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:17,189] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:56:17,217] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:56:17,222] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.253 seconds
[2020-07-22 11:56:26,590] {scheduler_job.py:153} INFO - Started process (PID=209021) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:26,596] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:56:26,596] {logging_mixin.py:112} INFO - [2020-07-22 11:56:26,596] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:26,729] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:56:26,736] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:26,938] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:56:26,959] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:56:26,966] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.376 seconds
[2020-07-22 11:56:36,193] {scheduler_job.py:153} INFO - Started process (PID=209279) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:36,198] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:56:36,198] {logging_mixin.py:112} INFO - [2020-07-22 11:56:36,198] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:36,264] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:56:36,267] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:36,445] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:56:36,459] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:56:36,462] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.269 seconds
[2020-07-22 11:56:43,688] {scheduler_job.py:153} INFO - Started process (PID=209480) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:43,711] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:56:43,712] {logging_mixin.py:112} INFO - [2020-07-22 11:56:43,712] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:43,811] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:56:43,815] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:43,962] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:56:43,979] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:56:43,982] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.295 seconds
[2020-07-22 11:56:56,537] {scheduler_job.py:153} INFO - Started process (PID=209823) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:56,540] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:56:56,541] {logging_mixin.py:112} INFO - [2020-07-22 11:56:56,541] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:56,618] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:56:56,621] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:56:56,723] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:56:56,741] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:56:56,744] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.207 seconds
[2020-07-22 11:57:04,914] {scheduler_job.py:153} INFO - Started process (PID=210082) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:04,919] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:57:04,920] {logging_mixin.py:112} INFO - [2020-07-22 11:57:04,920] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:05,039] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:57:05,044] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:05,159] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:57:05,185] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:57:05,189] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.275 seconds
[2020-07-22 11:57:12,794] {scheduler_job.py:153} INFO - Started process (PID=210285) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:12,797] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:57:12,798] {logging_mixin.py:112} INFO - [2020-07-22 11:57:12,798] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:12,863] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:57:12,865] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:12,985] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:57:13,013] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:57:13,017] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.223 seconds
[2020-07-22 11:57:22,285] {scheduler_job.py:153} INFO - Started process (PID=210518) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:22,289] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:57:22,290] {logging_mixin.py:112} INFO - [2020-07-22 11:57:22,290] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:22,361] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:57:22,364] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:22,680] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:57:22,695] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:57:22,698] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.413 seconds
[2020-07-22 11:57:31,464] {scheduler_job.py:153} INFO - Started process (PID=210785) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:31,468] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:57:31,469] {logging_mixin.py:112} INFO - [2020-07-22 11:57:31,469] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:31,599] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:57:31,604] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:31,744] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:57:31,763] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:57:31,767] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.304 seconds
[2020-07-22 11:57:44,629] {scheduler_job.py:153} INFO - Started process (PID=211121) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:44,632] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:57:44,632] {logging_mixin.py:112} INFO - [2020-07-22 11:57:44,632] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:44,700] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:57:44,703] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:44,927] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:57:44,943] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:57:44,946] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.317 seconds
[2020-07-22 11:57:53,510] {scheduler_job.py:153} INFO - Started process (PID=211347) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:53,513] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:57:53,514] {logging_mixin.py:112} INFO - [2020-07-22 11:57:53,514] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:53,623] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:57:53,626] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:57:53,770] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:57:53,797] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:57:53,801] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.291 seconds
[2020-07-22 11:58:03,422] {scheduler_job.py:153} INFO - Started process (PID=211609) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:03,428] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:58:03,429] {logging_mixin.py:112} INFO - [2020-07-22 11:58:03,429] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:03,525] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:58:03,528] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:03,634] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:58:03,654] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:58:03,661] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.239 seconds
[2020-07-22 11:58:13,952] {scheduler_job.py:153} INFO - Started process (PID=211879) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:13,958] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:58:13,958] {logging_mixin.py:112} INFO - [2020-07-22 11:58:13,958] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:14,251] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:58:14,256] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:14,456] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:58:14,514] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:58:14,518] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.568 seconds
[2020-07-22 11:58:29,299] {scheduler_job.py:153} INFO - Started process (PID=212233) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:29,303] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:58:29,303] {logging_mixin.py:112} INFO - [2020-07-22 11:58:29,303] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:29,541] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:58:29,546] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:29,679] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:58:29,702] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:58:29,705] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.406 seconds
[2020-07-22 11:58:39,290] {scheduler_job.py:153} INFO - Started process (PID=212487) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:39,293] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:58:39,293] {logging_mixin.py:112} INFO - [2020-07-22 11:58:39,293] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:39,359] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:58:39,361] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:39,472] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:58:39,488] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:28:34.410103+00:00: manual__2020-07-22T06:28:34.410103+00:00, externally triggered: True>
[2020-07-22 11:58:39,502] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:58:39,506] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:28:34.410103+00:00 [scheduled]> in ORM
[2020-07-22 11:58:39,646] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.356 seconds
[2020-07-22 11:58:49,927] {scheduler_job.py:153} INFO - Started process (PID=212758) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:49,930] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:58:49,930] {logging_mixin.py:112} INFO - [2020-07-22 11:58:49,930] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:49,994] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:58:49,997] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:58:50,089] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:58:50,104] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:28:34.410103+00:00: manual__2020-07-22T06:28:34.410103+00:00, externally triggered: True>
[2020-07-22 11:58:50,117] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:58:50,120] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.193 seconds
[2020-07-22 11:59:08,378] {scheduler_job.py:153} INFO - Started process (PID=213173) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:59:08,382] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:59:08,383] {logging_mixin.py:112} INFO - [2020-07-22 11:59:08,383] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:59:08,491] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:59:08,496] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:59:08,649] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:59:08,695] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:28:34.410103+00:00: manual__2020-07-22T06:28:34.410103+00:00, externally triggered: True>
[2020-07-22 11:59:08,736] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:59:08,744] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:28:34.410103+00:00 [scheduled]> in ORM
[2020-07-22 11:59:08,912] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.534 seconds
[2020-07-22 11:59:26,251] {scheduler_job.py:153} INFO - Started process (PID=213594) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:59:26,255] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:59:26,256] {logging_mixin.py:112} INFO - [2020-07-22 11:59:26,256] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:59:26,323] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:59:26,325] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:59:26,445] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:59:26,467] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:28:34.410103+00:00: manual__2020-07-22T06:28:34.410103+00:00, externally triggered: True>
[2020-07-22 11:59:26,479] {logging_mixin.py:112} INFO - [2020-07-22 11:59:26,479] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 06:28:34.410103+00:00: manual__2020-07-22T06:28:34.410103+00:00, externally triggered: True> failed
[2020-07-22 11:59:26,614] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:59:26,619] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.368 seconds
[2020-07-22 11:59:38,126] {scheduler_job.py:153} INFO - Started process (PID=213872) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:59:38,129] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:59:38,129] {logging_mixin.py:112} INFO - [2020-07-22 11:59:38,129] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:59:38,200] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:59:38,203] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:59:38,294] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:59:38,309] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:59:38,312] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.185 seconds
[2020-07-22 11:59:58,346] {scheduler_job.py:153} INFO - Started process (PID=214298) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:59:58,357] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 11:59:58,358] {logging_mixin.py:112} INFO - [2020-07-22 11:59:58,358] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:59:58,631] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 11:59:58,632] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 11:59:58,636] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 11:59:58,730] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 11:59:58,762] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 11:59:58,765] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.420 seconds
[2020-07-22 12:00:06,699] {scheduler_job.py:153} INFO - Started process (PID=214556) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:06,702] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:00:06,703] {logging_mixin.py:112} INFO - [2020-07-22 12:00:06,703] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:06,775] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:00:06,777] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:00:06,779] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:06,882] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:00:06,897] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:00:06,899] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-22 12:00:16,705] {scheduler_job.py:153} INFO - Started process (PID=214784) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:16,708] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:00:16,709] {logging_mixin.py:112} INFO - [2020-07-22 12:00:16,708] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:16,790] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:00:16,791] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:00:16,794] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:16,915] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:00:16,932] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:00:16,934] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.229 seconds
[2020-07-22 12:00:25,929] {scheduler_job.py:153} INFO - Started process (PID=214992) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:25,941] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:00:25,941] {logging_mixin.py:112} INFO - [2020-07-22 12:00:25,941] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:26,123] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:00:26,125] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:00:26,132] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:26,287] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:00:26,307] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:00:26,311] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.382 seconds
[2020-07-22 12:00:37,420] {scheduler_job.py:153} INFO - Started process (PID=215304) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:37,425] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:00:37,425] {logging_mixin.py:112} INFO - [2020-07-22 12:00:37,425] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:37,550] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:00:37,552] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:00:37,557] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:37,686] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:00:37,718] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:30:31.274737+00:00: manual__2020-07-22T06:30:31.274737+00:00, externally triggered: True>
[2020-07-22 12:00:37,743] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:00:37,750] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:30:31.274737+00:00 [scheduled]> in ORM
[2020-07-22 12:00:37,912] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.492 seconds
[2020-07-22 12:00:50,960] {scheduler_job.py:153} INFO - Started process (PID=215639) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:50,963] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:00:50,963] {logging_mixin.py:112} INFO - [2020-07-22 12:00:50,963] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:51,066] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:00:51,067] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:00:51,074] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:00:51,225] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:00:51,240] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:30:31.274737+00:00: manual__2020-07-22T06:30:31.274737+00:00, externally triggered: True>
[2020-07-22 12:00:51,252] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:00:51,256] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:30:31.274737+00:00 [scheduled]> in ORM
[2020-07-22 12:00:51,401] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.441 seconds
[2020-07-22 12:01:13,869] {scheduler_job.py:153} INFO - Started process (PID=216063) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:01:13,872] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:01:13,872] {logging_mixin.py:112} INFO - [2020-07-22 12:01:13,872] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:01:14,076] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:01:14,077] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:01:14,081] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:01:14,205] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:01:14,221] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:30:31.274737+00:00: manual__2020-07-22T06:30:31.274737+00:00, externally triggered: True>
[2020-07-22 12:01:14,230] {logging_mixin.py:112} INFO - [2020-07-22 12:01:14,230] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 06:30:31.274737+00:00: manual__2020-07-22T06:30:31.274737+00:00, externally triggered: True> failed
[2020-07-22 12:01:14,337] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:01:14,341] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.472 seconds
[2020-07-22 12:01:32,047] {scheduler_job.py:153} INFO - Started process (PID=216487) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:01:32,061] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:01:32,062] {logging_mixin.py:112} INFO - [2020-07-22 12:01:32,061] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:01:32,325] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:01:32,327] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:01:32,336] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:01:32,483] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:01:32,506] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:01:32,509] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.462 seconds
[2020-07-22 12:01:42,364] {scheduler_job.py:153} INFO - Started process (PID=216775) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:01:42,368] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:01:42,368] {logging_mixin.py:112} INFO - [2020-07-22 12:01:42,368] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:01:42,434] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:01:42,436] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:01:42,438] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:01:42,560] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:01:42,575] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:01:42,579] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.214 seconds
[2020-07-22 12:01:51,856] {scheduler_job.py:153} INFO - Started process (PID=217002) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:01:51,860] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:01:51,860] {logging_mixin.py:112} INFO - [2020-07-22 12:01:51,860] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:01:51,930] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:01:51,931] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:01:51,934] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:01:52,184] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:01:52,199] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:01:52,202] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.345 seconds
[2020-07-22 12:02:01,455] {scheduler_job.py:153} INFO - Started process (PID=217228) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:02:01,459] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:02:01,460] {logging_mixin.py:112} INFO - [2020-07-22 12:02:01,459] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:02:01,589] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:02:01,590] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:02:01,592] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:02:01,754] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:02:01,813] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:02:01,820] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.365 seconds
[2020-07-22 12:02:16,174] {scheduler_job.py:153} INFO - Started process (PID=217587) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:02:16,177] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:02:16,177] {logging_mixin.py:112} INFO - [2020-07-22 12:02:16,177] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:02:16,293] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:02:16,295] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:02:16,299] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:02:16,468] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:02:16,493] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:32:07.675948+00:00: manual__2020-07-22T06:32:07.675948+00:00, externally triggered: True>
[2020-07-22 12:02:16,511] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:02:16,518] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:32:07.675948+00:00 [scheduled]> in ORM
[2020-07-22 12:02:16,654] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.480 seconds
[2020-07-22 12:02:30,013] {scheduler_job.py:153} INFO - Started process (PID=217933) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:02:30,017] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:02:30,018] {logging_mixin.py:112} INFO - [2020-07-22 12:02:30,017] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:02:30,449] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:02:30,450] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:02:30,452] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:02:30,577] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:02:30,603] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:32:07.675948+00:00: manual__2020-07-22T06:32:07.675948+00:00, externally triggered: True>
[2020-07-22 12:02:30,636] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:02:30,640] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.626 seconds
[2020-07-22 12:02:40,603] {scheduler_job.py:153} INFO - Started process (PID=218190) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:02:40,608] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:02:40,609] {logging_mixin.py:112} INFO - [2020-07-22 12:02:40,609] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:02:40,713] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:02:40,714] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:02:40,718] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:02:40,983] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:02:40,998] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:32:07.675948+00:00: manual__2020-07-22T06:32:07.675948+00:00, externally triggered: True>
[2020-07-22 12:02:41,011] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:02:41,015] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:32:07.675948+00:00 [scheduled]> in ORM
[2020-07-22 12:02:41,160] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.557 seconds
[2020-07-22 12:03:06,615] {scheduler_job.py:153} INFO - Started process (PID=218768) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:06,620] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:03:06,620] {logging_mixin.py:112} INFO - [2020-07-22 12:03:06,620] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:06,689] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:03:06,690] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:03:06,693] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:06,865] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:03:06,881] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:32:07.675948+00:00: manual__2020-07-22T06:32:07.675948+00:00, externally triggered: True>
[2020-07-22 12:03:06,891] {logging_mixin.py:112} INFO - [2020-07-22 12:03:06,890] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 06:32:07.675948+00:00: manual__2020-07-22T06:32:07.675948+00:00, externally triggered: True> failed
[2020-07-22 12:03:07,006] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:03:07,015] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.400 seconds
[2020-07-22 12:03:15,523] {scheduler_job.py:153} INFO - Started process (PID=219013) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:15,528] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:03:15,528] {logging_mixin.py:112} INFO - [2020-07-22 12:03:15,528] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:15,603] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:03:15,605] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:03:15,607] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:15,735] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:03:15,752] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:03:15,756] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.233 seconds
[2020-07-22 12:03:24,231] {scheduler_job.py:153} INFO - Started process (PID=219214) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:24,238] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:03:24,239] {logging_mixin.py:112} INFO - [2020-07-22 12:03:24,239] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:24,319] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:03:24,320] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:03:24,323] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:24,465] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:03:24,494] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:03:24,499] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.268 seconds
[2020-07-22 12:03:38,101] {scheduler_job.py:153} INFO - Started process (PID=219528) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:38,117] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:03:38,117] {logging_mixin.py:112} INFO - [2020-07-22 12:03:38,117] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:38,720] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:03:38,723] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:03:38,727] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:39,042] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:03:39,094] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:03:39,102] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.001 seconds
[2020-07-22 12:03:52,449] {scheduler_job.py:153} INFO - Started process (PID=219896) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:52,452] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:03:52,453] {logging_mixin.py:112} INFO - [2020-07-22 12:03:52,453] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:52,959] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:03:52,961] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:03:52,966] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:03:53,202] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:03:53,235] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:33:42.814891+00:00: manual__2020-07-22T06:33:42.814891+00:00, externally triggered: True>
[2020-07-22 12:03:53,269] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:03:53,279] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:33:42.814891+00:00 [scheduled]> in ORM
[2020-07-22 12:03:53,449] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.001 seconds
[2020-07-22 12:04:04,783] {scheduler_job.py:153} INFO - Started process (PID=220186) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:04:04,787] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:04:04,788] {logging_mixin.py:112} INFO - [2020-07-22 12:04:04,787] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:04:04,910] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:04:04,912] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:04:04,917] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:04:05,059] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:04:05,075] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:33:42.814891+00:00: manual__2020-07-22T06:33:42.814891+00:00, externally triggered: True>
[2020-07-22 12:04:05,090] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:04:05,093] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.310 seconds
[2020-07-22 12:04:18,870] {scheduler_job.py:153} INFO - Started process (PID=220487) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:04:18,874] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:04:18,874] {logging_mixin.py:112} INFO - [2020-07-22 12:04:18,874] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:04:18,942] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:04:18,943] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:04:18,946] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:04:19,055] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:04:19,081] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:33:42.814891+00:00: manual__2020-07-22T06:33:42.814891+00:00, externally triggered: True>
[2020-07-22 12:04:19,102] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:04:19,109] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:33:42.814891+00:00 [scheduled]> in ORM
[2020-07-22 12:04:19,260] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.390 seconds
[2020-07-22 12:04:43,376] {scheduler_job.py:153} INFO - Started process (PID=221069) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:04:43,379] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:04:43,380] {logging_mixin.py:112} INFO - [2020-07-22 12:04:43,380] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:04:44,386] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:04:44,387] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:04:44,390] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:04:44,548] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:04:44,564] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:33:42.814891+00:00: manual__2020-07-22T06:33:42.814891+00:00, externally triggered: True>
[2020-07-22 12:04:44,573] {logging_mixin.py:112} INFO - [2020-07-22 12:04:44,573] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 06:33:42.814891+00:00: manual__2020-07-22T06:33:42.814891+00:00, externally triggered: True> failed
[2020-07-22 12:04:44,675] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:04:44,681] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.304 seconds
[2020-07-22 12:04:54,330] {scheduler_job.py:153} INFO - Started process (PID=221320) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:04:54,333] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:04:54,333] {logging_mixin.py:112} INFO - [2020-07-22 12:04:54,333] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:04:54,398] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:04:54,400] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:04:54,402] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:04:54,510] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:04:54,534] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:04:54,539] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.209 seconds
[2020-07-22 12:05:04,568] {scheduler_job.py:153} INFO - Started process (PID=221553) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:04,571] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:05:04,572] {logging_mixin.py:112} INFO - [2020-07-22 12:05:04,572] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:04,658] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:05:04,660] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:05:04,666] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:04,851] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:05:04,875] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:05:04,880] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.312 seconds
[2020-07-22 12:05:20,495] {scheduler_job.py:153} INFO - Started process (PID=221920) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:20,497] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:05:20,498] {logging_mixin.py:112} INFO - [2020-07-22 12:05:20,498] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:20,578] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:05:20,579] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:05:20,583] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:20,762] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:05:20,796] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:05:20,800] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.306 seconds
[2020-07-22 12:05:32,822] {scheduler_job.py:153} INFO - Started process (PID=222239) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:32,825] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:05:32,826] {logging_mixin.py:112} INFO - [2020-07-22 12:05:32,825] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:32,896] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:05:32,897] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:05:32,901] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:33,078] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:05:33,102] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:05:33,106] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.284 seconds
[2020-07-22 12:05:42,633] {scheduler_job.py:153} INFO - Started process (PID=222466) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:42,638] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:05:42,639] {logging_mixin.py:112} INFO - [2020-07-22 12:05:42,638] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:42,762] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:05:42,764] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:05:42,770] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:42,953] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:05:42,979] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:35:34.074652+00:00: manual__2020-07-22T06:35:34.074652+00:00, externally triggered: True>
[2020-07-22 12:05:43,000] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:05:43,009] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:35:34.074652+00:00 [scheduled]> in ORM
[2020-07-22 12:05:43,168] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.534 seconds
[2020-07-22 12:05:53,444] {scheduler_job.py:153} INFO - Started process (PID=222767) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:53,446] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:05:53,447] {logging_mixin.py:112} INFO - [2020-07-22 12:05:53,447] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:53,514] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:05:53,516] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:05:53,519] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:05:53,633] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:05:53,648] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:35:34.074652+00:00: manual__2020-07-22T06:35:34.074652+00:00, externally triggered: True>
[2020-07-22 12:05:53,661] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:05:53,663] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.219 seconds
[2020-07-22 12:06:14,495] {scheduler_job.py:153} INFO - Started process (PID=223246) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:06:14,497] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:06:14,498] {logging_mixin.py:112} INFO - [2020-07-22 12:06:14,498] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:06:14,562] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:06:14,563] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:06:14,566] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:06:14,681] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:06:14,707] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:35:34.074652+00:00: manual__2020-07-22T06:35:34.074652+00:00, externally triggered: True>
[2020-07-22 12:06:14,729] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:06:14,736] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:35:34.074652+00:00 [scheduled]> in ORM
[2020-07-22 12:06:14,931] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.436 seconds
[2020-07-22 12:06:29,827] {scheduler_job.py:153} INFO - Started process (PID=223619) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:06:29,830] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:06:29,830] {logging_mixin.py:112} INFO - [2020-07-22 12:06:29,830] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:06:29,917] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:06:29,918] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:06:29,920] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:06:30,190] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:06:30,213] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:35:34.074652+00:00: manual__2020-07-22T06:35:34.074652+00:00, externally triggered: True>
[2020-07-22 12:06:30,224] {logging_mixin.py:112} INFO - [2020-07-22 12:06:30,223] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 06:35:34.074652+00:00: manual__2020-07-22T06:35:34.074652+00:00, externally triggered: True> failed
[2020-07-22 12:06:30,377] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:06:30,380] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.553 seconds
[2020-07-22 12:06:42,113] {scheduler_job.py:153} INFO - Started process (PID=223883) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:06:42,117] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:06:42,118] {logging_mixin.py:112} INFO - [2020-07-22 12:06:42,118] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:06:42,266] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:06:42,267] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:06:42,273] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:06:42,439] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:06:42,473] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:06:42,480] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.368 seconds
[2020-07-22 12:06:57,103] {scheduler_job.py:153} INFO - Started process (PID=224297) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:06:57,107] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:06:57,108] {logging_mixin.py:112} INFO - [2020-07-22 12:06:57,108] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:06:57,208] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:06:57,209] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:06:57,213] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:06:57,322] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:06:57,345] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:06:57,349] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.246 seconds
[2020-07-22 12:07:07,097] {scheduler_job.py:153} INFO - Started process (PID=224563) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:07,099] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:07:07,100] {logging_mixin.py:112} INFO - [2020-07-22 12:07:07,100] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:07,184] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:07:07,185] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:07:07,188] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:07,314] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:07:07,337] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:07:07,341] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.245 seconds
[2020-07-22 12:07:17,900] {scheduler_job.py:153} INFO - Started process (PID=224825) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:17,904] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:07:17,905] {logging_mixin.py:112} INFO - [2020-07-22 12:07:17,905] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:17,975] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:07:17,976] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:07:17,979] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:18,098] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:07:18,146] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:07:18,154] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.254 seconds
[2020-07-22 12:07:27,197] {scheduler_job.py:153} INFO - Started process (PID=225066) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:27,200] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:07:27,201] {logging_mixin.py:112} INFO - [2020-07-22 12:07:27,201] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:27,269] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:07:27,270] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:07:27,274] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:27,703] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:07:27,718] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:07:27,720] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.523 seconds
[2020-07-22 12:07:39,256] {scheduler_job.py:153} INFO - Started process (PID=225384) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:39,260] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:07:39,263] {logging_mixin.py:112} INFO - [2020-07-22 12:07:39,263] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:39,373] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:07:39,375] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:07:39,379] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:39,713] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:07:39,739] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:07:39,743] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.487 seconds
[2020-07-22 12:07:52,804] {scheduler_job.py:153} INFO - Started process (PID=225714) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:52,807] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:07:52,808] {logging_mixin.py:112} INFO - [2020-07-22 12:07:52,808] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:52,873] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:07:52,875] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:07:52,877] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:07:53,147] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:07:53,162] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:07:53,164] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.360 seconds
[2020-07-22 12:08:00,572] {scheduler_job.py:153} INFO - Started process (PID=225911) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:00,575] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:08:00,575] {logging_mixin.py:112} INFO - [2020-07-22 12:08:00,575] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:00,644] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:08:00,645] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:08:00,648] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:00,826] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:08:00,865] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:08:00,872] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.300 seconds
[2020-07-22 12:08:08,459] {scheduler_job.py:153} INFO - Started process (PID=226113) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:08,463] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:08:08,464] {logging_mixin.py:112} INFO - [2020-07-22 12:08:08,464] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:08,549] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:08:08,550] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:08:08,552] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:08,659] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:08:08,685] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:08:08,689] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.230 seconds
[2020-07-22 12:08:20,497] {scheduler_job.py:153} INFO - Started process (PID=226405) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:20,503] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:08:20,504] {logging_mixin.py:112} INFO - [2020-07-22 12:08:20,504] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:20,772] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:08:20,774] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:08:20,781] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:20,977] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:08:21,019] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:08:21,023] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.527 seconds
[2020-07-22 12:08:33,673] {scheduler_job.py:153} INFO - Started process (PID=226739) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:33,676] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:08:33,676] {logging_mixin.py:112} INFO - [2020-07-22 12:08:33,676] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:33,744] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:08:33,745] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:08:33,748] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:33,996] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:08:34,196] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:08:34,198] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.525 seconds
[2020-07-22 12:08:53,116] {scheduler_job.py:153} INFO - Started process (PID=227115) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:53,120] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:08:53,121] {logging_mixin.py:112} INFO - [2020-07-22 12:08:53,121] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:53,245] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:08:53,246] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:08:53,251] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:08:53,354] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:08:53,372] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:08:53,375] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.259 seconds
[2020-07-22 12:09:03,208] {scheduler_job.py:153} INFO - Started process (PID=227371) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:03,213] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:09:03,213] {logging_mixin.py:112} INFO - [2020-07-22 12:09:03,213] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:03,353] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:09:03,355] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:09:03,360] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:03,542] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:09:03,570] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:09:03,574] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.366 seconds
[2020-07-22 12:09:15,421] {scheduler_job.py:153} INFO - Started process (PID=227693) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:15,428] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:09:15,429] {logging_mixin.py:112} INFO - [2020-07-22 12:09:15,428] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:15,575] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:09:15,576] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:09:15,581] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:15,710] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:09:15,727] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:09:15,730] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.309 seconds
[2020-07-22 12:09:24,082] {scheduler_job.py:153} INFO - Started process (PID=227931) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:24,087] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:09:24,087] {logging_mixin.py:112} INFO - [2020-07-22 12:09:24,087] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:24,204] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:09:24,205] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:09:24,210] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:24,332] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:09:24,348] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:09:24,350] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.268 seconds
[2020-07-22 12:09:33,060] {scheduler_job.py:153} INFO - Started process (PID=228148) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:33,063] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:09:33,064] {logging_mixin.py:112} INFO - [2020-07-22 12:09:33,063] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:33,133] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:09:33,134] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:09:33,138] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:33,247] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:09:33,264] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:09:33,266] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.207 seconds
[2020-07-22 12:09:40,931] {scheduler_job.py:153} INFO - Started process (PID=228351) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:40,934] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:09:40,935] {logging_mixin.py:112} INFO - [2020-07-22 12:09:40,935] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:41,008] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:09:41,009] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:09:41,012] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:41,125] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:09:41,142] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:09:41,144] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.213 seconds
[2020-07-22 12:09:52,268] {scheduler_job.py:153} INFO - Started process (PID=228645) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:52,272] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:09:52,274] {logging_mixin.py:112} INFO - [2020-07-22 12:09:52,274] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:52,404] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:09:52,407] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:09:52,411] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:09:52,558] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:09:52,594] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:09:52,598] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.331 seconds
[2020-07-22 12:10:03,084] {scheduler_job.py:153} INFO - Started process (PID=228931) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:03,090] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:10:03,090] {logging_mixin.py:112} INFO - [2020-07-22 12:10:03,090] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:03,220] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:10:03,223] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:10:03,228] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:03,400] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:10:03,417] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:10:03,419] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.335 seconds
[2020-07-22 12:10:12,368] {scheduler_job.py:153} INFO - Started process (PID=229151) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:12,372] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:10:12,373] {logging_mixin.py:112} INFO - [2020-07-22 12:10:12,373] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:12,453] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:10:12,454] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:10:12,457] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:12,588] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:10:12,620] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:10:12,624] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.257 seconds
[2020-07-22 12:10:20,950] {scheduler_job.py:153} INFO - Started process (PID=229352) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:20,955] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:10:20,956] {logging_mixin.py:112} INFO - [2020-07-22 12:10:20,955] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:21,027] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:10:21,028] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:10:21,031] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:21,150] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:10:21,167] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:10:21,171] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.221 seconds
[2020-07-22 12:10:30,748] {scheduler_job.py:153} INFO - Started process (PID=229607) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:30,752] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:10:30,752] {logging_mixin.py:112} INFO - [2020-07-22 12:10:30,752] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:30,825] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:10:30,826] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:10:30,829] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:31,020] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:10:31,049] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:10:31,054] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.305 seconds
[2020-07-22 12:10:39,904] {scheduler_job.py:153} INFO - Started process (PID=229828) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:39,908] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:10:39,909] {logging_mixin.py:112} INFO - [2020-07-22 12:10:39,908] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:39,984] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:10:39,986] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:10:39,988] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:40,159] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:10:40,510] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:10:40,513] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.608 seconds
[2020-07-22 12:10:49,598] {scheduler_job.py:153} INFO - Started process (PID=230082) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:49,603] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:10:49,603] {logging_mixin.py:112} INFO - [2020-07-22 12:10:49,603] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:49,714] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:10:49,716] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:10:49,721] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:50,113] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:10:50,133] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:10:50,136] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.538 seconds
[2020-07-22 12:10:59,313] {scheduler_job.py:153} INFO - Started process (PID=230355) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:59,321] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:10:59,323] {logging_mixin.py:112} INFO - [2020-07-22 12:10:59,323] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:59,454] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:10:59,456] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:10:59,460] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:10:59,573] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:10:59,591] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:10:59,594] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.280 seconds
[2020-07-22 12:11:11,264] {scheduler_job.py:153} INFO - Started process (PID=230605) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:11,267] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:11:11,268] {logging_mixin.py:112} INFO - [2020-07-22 12:11:11,268] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:11,348] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:11:11,349] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:11:11,352] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:11,466] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:11:11,490] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:11:11,495] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.231 seconds
[2020-07-22 12:11:19,715] {scheduler_job.py:153} INFO - Started process (PID=230830) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:19,719] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:11:19,720] {logging_mixin.py:112} INFO - [2020-07-22 12:11:19,719] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:19,789] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:11:19,790] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:11:19,792] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:19,908] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:11:19,924] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:41:12.923579+00:00: manual__2020-07-22T06:41:12.923579+00:00, externally triggered: True>
[2020-07-22 12:11:19,939] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:11:19,943] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:41:12.923579+00:00 [scheduled]> in ORM
[2020-07-22 12:11:20,086] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.370 seconds
[2020-07-22 12:11:36,177] {scheduler_job.py:153} INFO - Started process (PID=231261) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:36,192] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:11:36,193] {logging_mixin.py:112} INFO - [2020-07-22 12:11:36,193] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:36,393] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:11:36,395] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:11:36,411] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:36,656] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:11:36,720] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:41:12.923579+00:00: manual__2020-07-22T06:41:12.923579+00:00, externally triggered: True>
[2020-07-22 12:11:36,779] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:11:36,807] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.634 seconds
[2020-07-22 12:11:47,375] {scheduler_job.py:153} INFO - Started process (PID=231532) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:47,377] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:11:47,378] {logging_mixin.py:112} INFO - [2020-07-22 12:11:47,378] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:47,440] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:11:47,441] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:11:47,444] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:47,559] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:11:47,591] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:41:12.923579+00:00: manual__2020-07-22T06:41:12.923579+00:00, externally triggered: True>
[2020-07-22 12:11:47,619] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:11:47,625] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:41:12.923579+00:00 [scheduled]> in ORM
[2020-07-22 12:11:47,783] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.408 seconds
[2020-07-22 12:11:57,167] {scheduler_job.py:153} INFO - Started process (PID=231799) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:57,170] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:11:57,171] {logging_mixin.py:112} INFO - [2020-07-22 12:11:57,171] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:57,234] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:11:57,235] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:11:57,238] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:11:57,364] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:11:57,381] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:41:12.923579+00:00: manual__2020-07-22T06:41:12.923579+00:00, externally triggered: True>
[2020-07-22 12:11:57,392] {logging_mixin.py:112} INFO - [2020-07-22 12:11:57,392] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 06:41:12.923579+00:00: manual__2020-07-22T06:41:12.923579+00:00, externally triggered: True> failed
[2020-07-22 12:11:57,541] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:11:57,550] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.383 seconds
[2020-07-22 12:12:06,656] {scheduler_job.py:153} INFO - Started process (PID=232035) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:06,659] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:12:06,660] {logging_mixin.py:112} INFO - [2020-07-22 12:12:06,660] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:06,760] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:12:06,761] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:12:06,765] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:06,898] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:12:06,928] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:12:06,932] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.276 seconds
[2020-07-22 12:12:22,049] {scheduler_job.py:153} INFO - Started process (PID=232394) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:22,065] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:12:22,066] {logging_mixin.py:112} INFO - [2020-07-22 12:12:22,066] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:22,241] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:12:22,243] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:12:22,248] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:22,476] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:12:22,499] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:12:22,503] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.454 seconds
[2020-07-22 12:12:32,648] {scheduler_job.py:153} INFO - Started process (PID=232685) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:32,652] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:12:32,653] {logging_mixin.py:112} INFO - [2020-07-22 12:12:32,652] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:32,761] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:12:32,762] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:12:32,766] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:32,872] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:12:32,893] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:12:32,899] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.252 seconds
[2020-07-22 12:12:43,140] {scheduler_job.py:153} INFO - Started process (PID=232913) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:43,143] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:12:43,143] {logging_mixin.py:112} INFO - [2020-07-22 12:12:43,143] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:43,210] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:12:43,211] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:12:43,214] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:43,367] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:12:43,384] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:12:43,386] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.247 seconds
[2020-07-22 12:12:53,748] {scheduler_job.py:153} INFO - Started process (PID=233164) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:53,751] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:12:53,752] {logging_mixin.py:112} INFO - [2020-07-22 12:12:53,752] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:53,822] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:12:53,823] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:12:53,826] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:12:53,941] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:12:53,956] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:42:44.032981+00:00: manual__2020-07-22T06:42:44.032981+00:00, externally triggered: True>
[2020-07-22 12:12:53,970] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:12:53,974] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:42:44.032981+00:00 [scheduled]> in ORM
[2020-07-22 12:12:54,110] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.362 seconds
[2020-07-22 12:13:14,070] {scheduler_job.py:153} INFO - Started process (PID=233650) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:13:14,073] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:13:14,073] {logging_mixin.py:112} INFO - [2020-07-22 12:13:14,073] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:13:14,164] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:13:14,165] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:13:14,168] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:13:14,273] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:13:14,299] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:42:44.032981+00:00: manual__2020-07-22T06:42:44.032981+00:00, externally triggered: True>
[2020-07-22 12:13:14,319] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:13:14,324] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:42:44.032981+00:00 [scheduled]> in ORM
[2020-07-22 12:13:14,467] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.397 seconds
[2020-07-22 12:13:38,745] {scheduler_job.py:153} INFO - Started process (PID=234141) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:13:38,748] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:13:38,749] {logging_mixin.py:112} INFO - [2020-07-22 12:13:38,749] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:13:38,822] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:13:38,823] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:13:38,825] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:13:38,955] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:13:38,970] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:42:44.032981+00:00: manual__2020-07-22T06:42:44.032981+00:00, externally triggered: True>
[2020-07-22 12:13:38,980] {logging_mixin.py:112} INFO - [2020-07-22 12:13:38,980] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 06:42:44.032981+00:00: manual__2020-07-22T06:42:44.032981+00:00, externally triggered: True> failed
[2020-07-22 12:13:39,123] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:13:39,129] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.385 seconds
[2020-07-22 12:13:50,476] {scheduler_job.py:153} INFO - Started process (PID=234425) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:13:50,481] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:13:50,482] {logging_mixin.py:112} INFO - [2020-07-22 12:13:50,482] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:13:50,619] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:13:50,621] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:13:50,626] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:13:50,759] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:13:50,789] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:13:50,794] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.317 seconds
[2020-07-22 12:14:02,435] {scheduler_job.py:153} INFO - Started process (PID=234768) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:02,439] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:14:02,440] {logging_mixin.py:112} INFO - [2020-07-22 12:14:02,440] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:02,509] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:14:02,510] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:14:02,513] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:02,751] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:14:02,769] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:14:02,771] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.336 seconds
[2020-07-22 12:14:11,300] {scheduler_job.py:153} INFO - Started process (PID=234985) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:11,305] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:14:11,305] {logging_mixin.py:112} INFO - [2020-07-22 12:14:11,305] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:11,369] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:14:11,370] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:14:11,373] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:11,480] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:14:11,496] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:14:11,499] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.199 seconds
[2020-07-22 12:14:21,192] {scheduler_job.py:153} INFO - Started process (PID=235235) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:21,195] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:14:21,196] {logging_mixin.py:112} INFO - [2020-07-22 12:14:21,195] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:21,299] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:14:21,300] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:14:21,306] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:21,502] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:14:21,535] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:14:21,540] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.349 seconds
[2020-07-22 12:14:30,087] {scheduler_job.py:153} INFO - Started process (PID=235474) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:30,091] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:14:30,092] {logging_mixin.py:112} INFO - [2020-07-22 12:14:30,092] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:30,194] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:14:30,195] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:14:30,198] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:30,296] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:14:30,317] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:14:30,321] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.234 seconds
[2020-07-22 12:14:41,923] {scheduler_job.py:153} INFO - Started process (PID=235822) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:41,926] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:14:41,927] {logging_mixin.py:112} INFO - [2020-07-22 12:14:41,927] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:41,992] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:14:41,993] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:14:41,996] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:42,122] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:14:42,158] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:14:42,165] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.241 seconds
[2020-07-22 12:14:50,097] {scheduler_job.py:153} INFO - Started process (PID=236040) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:50,099] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:14:50,100] {logging_mixin.py:112} INFO - [2020-07-22 12:14:50,100] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:50,174] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:14:50,176] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:14:50,181] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:14:50,353] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:14:50,372] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:14:50,376] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.279 seconds
[2020-07-22 12:15:00,866] {scheduler_job.py:153} INFO - Started process (PID=236293) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:00,870] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:15:00,871] {logging_mixin.py:112} INFO - [2020-07-22 12:15:00,871] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:00,941] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:15:00,943] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:15:00,945] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:01,160] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:15:01,181] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:15:01,183] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.317 seconds
[2020-07-22 12:15:08,626] {scheduler_job.py:153} INFO - Started process (PID=236521) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:08,629] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:15:08,630] {logging_mixin.py:112} INFO - [2020-07-22 12:15:08,630] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:08,711] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:15:08,712] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:15:08,716] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:08,813] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:15:08,831] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:15:08,834] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 12:15:21,041] {scheduler_job.py:153} INFO - Started process (PID=236845) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:21,046] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:15:21,046] {logging_mixin.py:112} INFO - [2020-07-22 12:15:21,046] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:21,248] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:15:21,250] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:15:21,254] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:21,384] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:15:21,417] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:15:21,422] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.381 seconds
[2020-07-22 12:15:30,320] {scheduler_job.py:153} INFO - Started process (PID=237094) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:30,322] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:15:30,323] {logging_mixin.py:112} INFO - [2020-07-22 12:15:30,322] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:30,393] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:15:30,394] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:15:30,397] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:30,503] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:15:30,519] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:15:30,522] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.202 seconds
[2020-07-22 12:15:38,591] {scheduler_job.py:153} INFO - Started process (PID=237327) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:38,594] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:15:38,594] {logging_mixin.py:112} INFO - [2020-07-22 12:15:38,594] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:38,660] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:15:38,661] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:15:38,664] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:38,780] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:15:38,804] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:15:38,809] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.218 seconds
[2020-07-22 12:15:49,319] {scheduler_job.py:153} INFO - Started process (PID=237576) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:49,321] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:15:49,322] {logging_mixin.py:112} INFO - [2020-07-22 12:15:49,322] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:49,390] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:15:49,391] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:15:49,394] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:15:49,539] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:15:49,555] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:15:49,557] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.239 seconds
[2020-07-22 12:16:01,873] {scheduler_job.py:153} INFO - Started process (PID=237872) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:01,883] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:16:01,884] {logging_mixin.py:112} INFO - [2020-07-22 12:16:01,883] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:02,007] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:16:02,008] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:16:02,014] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:02,152] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:16:02,180] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:16:02,183] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.310 seconds
[2020-07-22 12:16:14,223] {scheduler_job.py:153} INFO - Started process (PID=238214) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:14,226] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:16:14,226] {logging_mixin.py:112} INFO - [2020-07-22 12:16:14,226] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:14,299] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:16:14,300] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:16:14,304] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:14,517] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:16:14,532] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:16:14,535] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.313 seconds
[2020-07-22 12:16:21,882] {scheduler_job.py:153} INFO - Started process (PID=238411) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:21,885] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:16:21,886] {logging_mixin.py:112} INFO - [2020-07-22 12:16:21,885] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:21,969] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:16:21,970] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:16:21,973] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:22,229] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:16:22,244] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:16:22,247] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.365 seconds
[2020-07-22 12:16:35,592] {scheduler_job.py:153} INFO - Started process (PID=238693) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:35,607] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:16:35,607] {logging_mixin.py:112} INFO - [2020-07-22 12:16:35,607] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:35,767] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:16:35,769] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:16:35,773] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:35,909] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:16:35,935] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:16:35,940] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.348 seconds
[2020-07-22 12:16:46,096] {scheduler_job.py:153} INFO - Started process (PID=238989) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:46,100] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:16:46,101] {logging_mixin.py:112} INFO - [2020-07-22 12:16:46,101] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:46,216] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:16:46,217] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:16:46,222] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:46,418] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:16:46,456] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:16:46,460] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.365 seconds
[2020-07-22 12:16:56,298] {scheduler_job.py:153} INFO - Started process (PID=239282) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:56,303] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:16:56,304] {logging_mixin.py:112} INFO - [2020-07-22 12:16:56,303] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:56,404] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:16:56,405] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:16:56,410] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:16:56,659] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:16:56,677] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:16:56,680] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.382 seconds
[2020-07-22 12:17:05,680] {scheduler_job.py:153} INFO - Started process (PID=239510) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:05,687] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:17:05,689] {logging_mixin.py:112} INFO - [2020-07-22 12:17:05,688] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:05,790] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:17:05,793] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:17:05,796] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:05,935] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:17:05,950] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:17:05,953] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.273 seconds
[2020-07-22 12:17:15,892] {scheduler_job.py:153} INFO - Started process (PID=239767) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:15,896] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:17:15,896] {logging_mixin.py:112} INFO - [2020-07-22 12:17:15,896] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:15,980] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:17:15,983] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:17:15,988] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:16,163] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:17:16,318] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:17:16,325] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.433 seconds
[2020-07-22 12:17:26,131] {scheduler_job.py:153} INFO - Started process (PID=240038) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:26,138] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:17:26,138] {logging_mixin.py:112} INFO - [2020-07-22 12:17:26,138] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:26,235] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:17:26,236] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:17:26,241] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:26,615] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:17:26,635] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:17:26,640] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.509 seconds
[2020-07-22 12:17:40,122] {scheduler_job.py:153} INFO - Started process (PID=240405) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:40,127] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:17:40,128] {logging_mixin.py:112} INFO - [2020-07-22 12:17:40,128] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:40,203] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:17:40,204] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:17:40,207] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:40,331] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:17:40,347] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:17:40,350] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.228 seconds
[2020-07-22 12:17:49,874] {scheduler_job.py:153} INFO - Started process (PID=240649) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:49,877] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:17:49,878] {logging_mixin.py:112} INFO - [2020-07-22 12:17:49,878] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:49,953] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:17:49,954] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:17:49,958] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:17:50,077] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:17:50,092] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:17:50,095] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.221 seconds
[2020-07-22 12:18:00,276] {scheduler_job.py:153} INFO - Started process (PID=240873) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:18:00,280] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:18:00,281] {logging_mixin.py:112} INFO - [2020-07-22 12:18:00,280] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:18:00,410] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:18:00,412] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:18:00,418] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:18:00,551] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:18:00,591] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:18:00,596] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.321 seconds
[2020-07-22 12:18:11,178] {scheduler_job.py:153} INFO - Started process (PID=241170) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:18:11,182] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:18:11,183] {logging_mixin.py:112} INFO - [2020-07-22 12:18:11,183] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:18:11,414] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:18:11,416] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:18:11,418] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:18:11,580] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:18:11,603] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:48:06.167652+00:00: manual__2020-07-22T06:48:06.167652+00:00, externally triggered: True>
[2020-07-22 12:18:11,624] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:18:11,630] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:48:06.167652+00:00 [scheduled]> in ORM
[2020-07-22 12:18:11,762] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.584 seconds
[2020-07-22 12:18:30,319] {scheduler_job.py:153} INFO - Started process (PID=241636) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:18:30,324] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:18:30,325] {logging_mixin.py:112} INFO - [2020-07-22 12:18:30,324] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:18:30,400] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:18:30,401] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:18:30,404] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:18:30,499] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:18:30,520] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:48:06.167652+00:00: manual__2020-07-22T06:48:06.167652+00:00, externally triggered: True>
[2020-07-22 12:18:30,533] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:18:30,536] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-22 12:18:39,699] {scheduler_job.py:153} INFO - Started process (PID=241855) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:18:39,702] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:18:39,703] {logging_mixin.py:112} INFO - [2020-07-22 12:18:39,703] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:18:39,784] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:18:39,785] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:18:39,788] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:18:40,001] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:18:40,019] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:48:06.167652+00:00: manual__2020-07-22T06:48:06.167652+00:00, externally triggered: True>
[2020-07-22 12:18:40,036] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:18:40,040] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:48:06.167652+00:00 [scheduled]> in ORM
[2020-07-22 12:18:40,263] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.564 seconds
[2020-07-22 12:19:00,577] {scheduler_job.py:153} INFO - Started process (PID=242318) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:00,591] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:19:00,591] {logging_mixin.py:112} INFO - [2020-07-22 12:19:00,591] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:00,904] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:19:00,906] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:19:00,912] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:01,126] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:19:01,156] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:48:06.167652+00:00: manual__2020-07-22T06:48:06.167652+00:00, externally triggered: True>
[2020-07-22 12:19:01,169] {logging_mixin.py:112} INFO - [2020-07-22 12:19:01,169] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 06:48:06.167652+00:00: manual__2020-07-22T06:48:06.167652+00:00, externally triggered: True> failed
[2020-07-22 12:19:01,266] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:19:01,270] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.694 seconds
[2020-07-22 12:19:13,945] {scheduler_job.py:153} INFO - Started process (PID=242686) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:13,950] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:19:13,951] {logging_mixin.py:112} INFO - [2020-07-22 12:19:13,950] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:14,044] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:19:14,046] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:19:14,051] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:14,176] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:19:14,200] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:19:14,206] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.261 seconds
[2020-07-22 12:19:22,331] {scheduler_job.py:153} INFO - Started process (PID=242891) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:22,334] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:19:22,334] {logging_mixin.py:112} INFO - [2020-07-22 12:19:22,334] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:22,406] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:19:22,407] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:19:22,410] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:22,521] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:19:22,558] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:19:22,563] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.232 seconds
[2020-07-22 12:19:32,375] {scheduler_job.py:153} INFO - Started process (PID=243123) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:32,380] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:19:32,380] {logging_mixin.py:112} INFO - [2020-07-22 12:19:32,380] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:32,467] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:19:32,468] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:19:32,470] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:32,578] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:19:32,596] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:19:32,600] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.225 seconds
[2020-07-22 12:19:44,412] {scheduler_job.py:153} INFO - Started process (PID=243433) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:44,425] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:19:44,427] {logging_mixin.py:112} INFO - [2020-07-22 12:19:44,427] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:44,684] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:19:44,686] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:19:44,690] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:44,892] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:19:45,107] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:19:45,152] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.740 seconds
[2020-07-22 12:19:56,541] {scheduler_job.py:153} INFO - Started process (PID=243747) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:56,550] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:19:56,551] {logging_mixin.py:112} INFO - [2020-07-22 12:19:56,551] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:56,820] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:19:56,823] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:19:56,830] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:19:57,003] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:19:57,030] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:49:52.005027+00:00: manual__2020-07-22T06:49:52.005027+00:00, externally triggered: True>
[2020-07-22 12:19:57,061] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:19:57,070] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:49:52.005027+00:00 [scheduled]> in ORM
[2020-07-22 12:19:57,238] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.697 seconds
[2020-07-22 12:20:14,344] {scheduler_job.py:153} INFO - Started process (PID=244134) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:20:14,346] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:20:14,347] {logging_mixin.py:112} INFO - [2020-07-22 12:20:14,347] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:20:14,409] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:20:14,410] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:20:14,413] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:20:14,563] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:20:14,579] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:49:52.005027+00:00: manual__2020-07-22T06:49:52.005027+00:00, externally triggered: True>
[2020-07-22 12:20:14,592] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:20:14,594] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.251 seconds
[2020-07-22 12:20:26,108] {scheduler_job.py:153} INFO - Started process (PID=244417) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:20:26,112] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:20:26,112] {logging_mixin.py:112} INFO - [2020-07-22 12:20:26,112] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:20:26,191] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:20:26,193] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:20:26,196] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:20:26,301] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:20:26,323] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:49:52.005027+00:00: manual__2020-07-22T06:49:52.005027+00:00, externally triggered: True>
[2020-07-22 12:20:26,338] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:20:26,342] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:49:52.005027+00:00 [scheduled]> in ORM
[2020-07-22 12:20:26,474] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.366 seconds
[2020-07-22 12:20:47,624] {scheduler_job.py:153} INFO - Started process (PID=244926) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:20:47,627] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:20:47,628] {logging_mixin.py:112} INFO - [2020-07-22 12:20:47,627] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:20:48,266] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:20:48,268] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:20:48,272] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:20:48,452] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:20:48,474] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:49:52.005027+00:00: manual__2020-07-22T06:49:52.005027+00:00, externally triggered: True>
[2020-07-22 12:20:48,486] {logging_mixin.py:112} INFO - [2020-07-22 12:20:48,486] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 06:49:52.005027+00:00: manual__2020-07-22T06:49:52.005027+00:00, externally triggered: True> failed
[2020-07-22 12:20:48,590] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:20:48,598] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.974 seconds
[2020-07-22 12:21:00,530] {scheduler_job.py:153} INFO - Started process (PID=245203) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:00,533] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:21:00,533] {logging_mixin.py:112} INFO - [2020-07-22 12:21:00,533] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:00,600] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:21:00,601] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:21:00,605] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:00,718] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:21:00,747] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:21:00,752] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.222 seconds
[2020-07-22 12:21:16,160] {scheduler_job.py:153} INFO - Started process (PID=245574) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:16,169] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:21:16,170] {logging_mixin.py:112} INFO - [2020-07-22 12:21:16,169] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:16,511] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:21:16,513] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:21:16,518] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:16,677] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:21:16,733] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:21:16,739] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.579 seconds
[2020-07-22 12:21:26,999] {scheduler_job.py:153} INFO - Started process (PID=245882) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:27,003] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:21:27,004] {logging_mixin.py:112} INFO - [2020-07-22 12:21:27,004] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:27,071] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:21:27,072] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:21:27,075] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:27,195] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:21:27,210] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:21:27,213] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.214 seconds
[2020-07-22 12:21:34,769] {scheduler_job.py:153} INFO - Started process (PID=246079) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:34,772] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:21:34,773] {logging_mixin.py:112} INFO - [2020-07-22 12:21:34,773] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:34,839] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:21:34,840] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:21:34,843] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:34,995] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:21:35,016] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:21:35,019] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.251 seconds
[2020-07-22 12:21:43,678] {scheduler_job.py:153} INFO - Started process (PID=246298) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:43,682] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:21:43,682] {logging_mixin.py:112} INFO - [2020-07-22 12:21:43,682] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:43,749] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:21:43,750] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:21:43,753] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:43,852] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:21:43,869] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:21:43,872] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.193 seconds
[2020-07-22 12:21:52,048] {scheduler_job.py:153} INFO - Started process (PID=246524) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:52,051] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:21:52,051] {logging_mixin.py:112} INFO - [2020-07-22 12:21:52,051] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:52,119] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:21:52,120] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:21:52,123] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:21:52,229] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:21:52,245] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:21:52,247] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.199 seconds
[2020-07-22 12:22:04,047] {scheduler_job.py:153} INFO - Started process (PID=246831) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:04,051] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:22:04,051] {logging_mixin.py:112} INFO - [2020-07-22 12:22:04,051] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:04,156] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:22:04,157] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:22:04,161] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:04,387] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:22:04,412] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:22:04,417] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.370 seconds
[2020-07-22 12:22:16,473] {scheduler_job.py:153} INFO - Started process (PID=247165) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:16,475] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:22:16,476] {logging_mixin.py:112} INFO - [2020-07-22 12:22:16,476] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:16,584] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:22:16,585] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:22:16,592] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:17,240] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:22:17,266] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:22:17,270] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.797 seconds
[2020-07-22 12:22:25,361] {scheduler_job.py:153} INFO - Started process (PID=247407) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:25,364] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:22:25,364] {logging_mixin.py:112} INFO - [2020-07-22 12:22:25,364] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:25,426] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:22:25,427] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:22:25,430] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:25,591] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:22:25,605] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:22:25,608] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.247 seconds
[2020-07-22 12:22:33,472] {scheduler_job.py:153} INFO - Started process (PID=247606) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:33,478] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:22:33,478] {logging_mixin.py:112} INFO - [2020-07-22 12:22:33,478] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:33,593] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:22:33,595] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:22:33,601] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:33,733] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:22:33,749] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:22:33,751] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.279 seconds
[2020-07-22 12:22:43,727] {scheduler_job.py:153} INFO - Started process (PID=247867) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:43,730] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:22:43,731] {logging_mixin.py:112} INFO - [2020-07-22 12:22:43,730] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:43,845] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:22:43,847] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:22:43,851] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:43,961] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:22:43,991] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:22:44,000] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.272 seconds
[2020-07-22 12:22:58,671] {scheduler_job.py:153} INFO - Started process (PID=248268) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:58,674] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:22:58,675] {logging_mixin.py:112} INFO - [2020-07-22 12:22:58,675] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:58,738] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:22:58,739] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:22:58,742] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:22:58,878] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:22:58,893] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:22:58,895] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.225 seconds
[2020-07-22 12:23:06,740] {scheduler_job.py:153} INFO - Started process (PID=248471) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:06,744] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:23:06,745] {logging_mixin.py:112} INFO - [2020-07-22 12:23:06,745] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:06,810] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:23:06,811] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:23:06,814] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:06,963] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:23:06,988] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:23:06,994] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.254 seconds
[2020-07-22 12:23:14,714] {scheduler_job.py:153} INFO - Started process (PID=248679) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:14,719] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:23:14,719] {logging_mixin.py:112} INFO - [2020-07-22 12:23:14,719] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:14,818] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:23:14,819] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:23:14,825] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:14,936] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:23:14,951] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:23:14,954] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.240 seconds
[2020-07-22 12:23:22,984] {scheduler_job.py:153} INFO - Started process (PID=248906) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:22,987] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:23:22,987] {logging_mixin.py:112} INFO - [2020-07-22 12:23:22,987] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:23,067] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:23:23,069] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:23:23,071] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:23,249] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:23:23,264] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:23:23,266] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.283 seconds
[2020-07-22 12:23:31,582] {scheduler_job.py:153} INFO - Started process (PID=249144) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:31,586] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:23:31,587] {logging_mixin.py:112} INFO - [2020-07-22 12:23:31,587] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:31,709] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:23:31,710] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:23:31,714] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:31,936] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:23:31,964] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:23:31,969] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.387 seconds
[2020-07-22 12:23:42,400] {scheduler_job.py:153} INFO - Started process (PID=249452) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:42,403] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:23:42,404] {logging_mixin.py:112} INFO - [2020-07-22 12:23:42,404] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:42,476] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:23:42,477] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:23:42,480] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:42,598] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:23:42,614] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:23:42,617] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-22 12:23:50,759] {scheduler_job.py:153} INFO - Started process (PID=249683) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:50,762] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:23:50,763] {logging_mixin.py:112} INFO - [2020-07-22 12:23:50,763] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:50,830] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:23:50,831] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:23:50,834] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:50,981] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:23:50,997] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:23:50,999] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.240 seconds
[2020-07-22 12:23:59,847] {scheduler_job.py:153} INFO - Started process (PID=249902) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:23:59,852] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:23:59,852] {logging_mixin.py:112} INFO - [2020-07-22 12:23:59,852] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:00,066] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:24:00,067] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:24:00,074] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:00,235] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:24:00,264] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:24:00,269] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.422 seconds
[2020-07-22 12:24:09,033] {scheduler_job.py:153} INFO - Started process (PID=250117) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:09,036] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:24:09,036] {logging_mixin.py:112} INFO - [2020-07-22 12:24:09,036] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:09,138] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:24:09,139] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:24:09,145] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:09,328] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:24:09,365] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:24:09,369] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.336 seconds
[2020-07-22 12:24:21,801] {scheduler_job.py:153} INFO - Started process (PID=250509) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:21,806] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:24:21,807] {logging_mixin.py:112} INFO - [2020-07-22 12:24:21,806] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:21,870] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:24:21,871] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:24:21,875] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:21,999] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:24:22,017] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:24:22,020] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.219 seconds
[2020-07-22 12:24:29,672] {scheduler_job.py:153} INFO - Started process (PID=250718) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:29,676] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:24:29,676] {logging_mixin.py:112} INFO - [2020-07-22 12:24:29,676] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:29,748] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:24:29,749] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:24:29,752] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:29,900] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:24:30,025] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:24:30,027] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.356 seconds
[2020-07-22 12:24:39,304] {scheduler_job.py:153} INFO - Started process (PID=250968) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:39,308] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:24:39,308] {logging_mixin.py:112} INFO - [2020-07-22 12:24:39,308] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:39,371] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:24:39,372] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:24:39,375] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:39,480] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:24:39,507] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:24:39,512] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.207 seconds
[2020-07-22 12:24:49,971] {scheduler_job.py:153} INFO - Started process (PID=251240) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:49,975] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:24:49,976] {logging_mixin.py:112} INFO - [2020-07-22 12:24:49,976] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:50,040] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:24:50,041] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:24:50,044] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:24:50,158] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:24:50,173] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:24:50,176] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.205 seconds
[2020-07-22 12:25:02,955] {scheduler_job.py:153} INFO - Started process (PID=251610) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:02,960] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:25:02,961] {logging_mixin.py:112} INFO - [2020-07-22 12:25:02,961] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:03,061] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:25:03,062] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:25:03,067] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:03,183] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:25:03,208] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:25:03,213] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.258 seconds
[2020-07-22 12:25:10,422] {scheduler_job.py:153} INFO - Started process (PID=251830) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:10,426] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:25:10,427] {logging_mixin.py:112} INFO - [2020-07-22 12:25:10,427] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:10,488] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:25:10,489] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:25:10,492] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:10,604] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:25:10,618] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:25:10,621] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.199 seconds
[2020-07-22 12:25:18,614] {scheduler_job.py:153} INFO - Started process (PID=252034) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:18,618] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:25:18,618] {logging_mixin.py:112} INFO - [2020-07-22 12:25:18,618] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:18,683] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:25:18,684] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:25:18,687] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:18,786] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:25:18,803] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:25:18,806] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.192 seconds
[2020-07-22 12:25:28,834] {scheduler_job.py:153} INFO - Started process (PID=252285) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:28,837] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:25:28,837] {logging_mixin.py:112} INFO - [2020-07-22 12:25:28,837] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:28,901] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:25:28,902] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:25:28,905] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:29,005] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:25:29,020] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:25:29,023] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.189 seconds
[2020-07-22 12:25:42,256] {scheduler_job.py:153} INFO - Started process (PID=252591) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:42,261] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:25:42,262] {logging_mixin.py:112} INFO - [2020-07-22 12:25:42,262] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:42,433] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:25:42,435] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:25:42,439] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:42,607] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:25:42,649] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:25:42,656] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.399 seconds
[2020-07-22 12:25:54,406] {scheduler_job.py:153} INFO - Started process (PID=252970) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:54,409] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:25:54,409] {logging_mixin.py:112} INFO - [2020-07-22 12:25:54,409] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:54,486] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:25:54,487] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:25:54,490] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:25:54,621] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:25:54,640] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:25:54,643] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.237 seconds
[2020-07-22 12:26:02,370] {scheduler_job.py:153} INFO - Started process (PID=253176) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:02,373] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:26:02,374] {logging_mixin.py:112} INFO - [2020-07-22 12:26:02,373] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:02,452] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:26:02,453] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:26:02,455] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:02,564] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:26:02,579] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:26:02,582] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.212 seconds
[2020-07-22 12:26:11,164] {scheduler_job.py:153} INFO - Started process (PID=253397) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:11,169] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:26:11,170] {logging_mixin.py:112} INFO - [2020-07-22 12:26:11,170] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:11,242] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:26:11,243] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:26:11,246] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:11,363] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:26:11,380] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:26:11,382] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.218 seconds
[2020-07-22 12:26:18,981] {scheduler_job.py:153} INFO - Started process (PID=253600) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:18,984] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:26:18,985] {logging_mixin.py:112} INFO - [2020-07-22 12:26:18,985] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:19,077] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:26:19,078] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:26:19,083] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:19,219] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:26:19,284] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:26:19,289] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.307 seconds
[2020-07-22 12:26:32,252] {scheduler_job.py:153} INFO - Started process (PID=253983) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:32,255] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:26:32,256] {logging_mixin.py:112} INFO - [2020-07-22 12:26:32,256] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:32,333] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:26:32,335] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:26:32,337] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:32,452] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:26:32,474] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:26:32,477] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.225 seconds
[2020-07-22 12:26:42,138] {scheduler_job.py:153} INFO - Started process (PID=254219) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:42,143] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:26:42,144] {logging_mixin.py:112} INFO - [2020-07-22 12:26:42,144] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:42,397] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:26:42,399] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:26:42,403] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:42,546] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:26:42,575] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:26:42,579] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.441 seconds
[2020-07-22 12:26:53,067] {scheduler_job.py:153} INFO - Started process (PID=254444) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:53,070] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:26:53,070] {logging_mixin.py:112} INFO - [2020-07-22 12:26:53,070] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:53,156] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:26:53,158] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:26:53,162] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:26:53,351] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:26:53,376] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:26:53,379] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.312 seconds
[2020-07-22 12:27:01,955] {scheduler_job.py:153} INFO - Started process (PID=254685) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:27:01,959] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:27:01,960] {logging_mixin.py:112} INFO - [2020-07-22 12:27:01,960] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:27:02,490] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:27:02,506] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:27:02,525] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:27:02,709] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:27:02,749] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:56:54.660524+00:00: manual__2020-07-22T06:56:54.660524+00:00, externally triggered: True>
[2020-07-22 12:27:02,773] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:27:02,780] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:56:54.660524+00:00 [scheduled]> in ORM
[2020-07-22 12:27:02,959] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.003 seconds
[2020-07-22 12:27:27,875] {scheduler_job.py:153} INFO - Started process (PID=255253) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:27:27,900] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:27:27,900] {logging_mixin.py:112} INFO - [2020-07-22 12:27:27,900] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:27:28,176] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:27:28,192] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:27:28,197] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:27:28,350] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:27:28,384] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:56:54.660524+00:00: manual__2020-07-22T06:56:54.660524+00:00, externally triggered: True>
[2020-07-22 12:27:28,401] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:27:28,408] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.spark-submit-python 2020-07-22 06:56:54.660524+00:00 [scheduled]> in ORM
[2020-07-22 12:27:28,691] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.816 seconds
[2020-07-22 12:27:59,625] {scheduler_job.py:153} INFO - Started process (PID=255889) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:27:59,629] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:27:59,630] {logging_mixin.py:112} INFO - [2020-07-22 12:27:59,630] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:27:59,811] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:27:59,813] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:27:59,818] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:00,045] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:28:00,083] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-22 06:56:54.660524+00:00: manual__2020-07-22T06:56:54.660524+00:00, externally triggered: True>
[2020-07-22 12:28:00,123] {logging_mixin.py:112} INFO - [2020-07-22 12:28:00,121] {dagrun.py:309} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-22 06:56:54.660524+00:00: manual__2020-07-22T06:56:54.660524+00:00, externally triggered: True> failed
[2020-07-22 12:28:00,230] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:28:00,238] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.613 seconds
[2020-07-22 12:28:11,376] {scheduler_job.py:153} INFO - Started process (PID=256217) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:11,383] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:28:11,384] {logging_mixin.py:112} INFO - [2020-07-22 12:28:11,383] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:11,491] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:28:11,493] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:28:11,496] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:11,626] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:28:11,651] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:28:11,658] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.282 seconds
[2020-07-22 12:28:20,652] {scheduler_job.py:153} INFO - Started process (PID=256450) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:20,657] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:28:20,657] {logging_mixin.py:112} INFO - [2020-07-22 12:28:20,657] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:20,749] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:28:20,751] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:28:20,753] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:20,967] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:28:20,983] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:28:20,985] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.334 seconds
[2020-07-22 12:28:29,239] {scheduler_job.py:153} INFO - Started process (PID=256690) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:29,243] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:28:29,244] {logging_mixin.py:112} INFO - [2020-07-22 12:28:29,243] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:29,357] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:28:29,358] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:28:29,361] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:29,521] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:28:29,537] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:28:29,539] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.300 seconds
[2020-07-22 12:28:38,781] {scheduler_job.py:153} INFO - Started process (PID=256909) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:38,787] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:28:38,788] {logging_mixin.py:112} INFO - [2020-07-22 12:28:38,788] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:38,874] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:28:38,875] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:28:38,881] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:39,051] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:28:39,068] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:28:39,070] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.289 seconds
[2020-07-22 12:28:53,901] {scheduler_job.py:153} INFO - Started process (PID=257306) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:53,904] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:28:53,905] {logging_mixin.py:112} INFO - [2020-07-22 12:28:53,905] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:54,054] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:28:54,055] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:28:54,061] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:28:54,249] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:28:54,298] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:28:54,304] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.404 seconds
[2020-07-22 12:29:03,735] {scheduler_job.py:153} INFO - Started process (PID=257588) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:03,738] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:29:03,739] {logging_mixin.py:112} INFO - [2020-07-22 12:29:03,738] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:03,805] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:29:03,806] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:29:03,808] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:03,922] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:29:03,937] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:29:03,939] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 12:29:12,907] {scheduler_job.py:153} INFO - Started process (PID=257807) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:12,912] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:29:12,912] {logging_mixin.py:112} INFO - [2020-07-22 12:29:12,912] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:13,026] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:29:13,028] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:29:13,033] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:13,259] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:29:13,284] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:29:13,287] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.380 seconds
[2020-07-22 12:29:21,674] {scheduler_job.py:153} INFO - Started process (PID=258029) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:21,678] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:29:21,679] {logging_mixin.py:112} INFO - [2020-07-22 12:29:21,679] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:21,748] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:29:21,749] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:29:21,752] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:21,869] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:29:21,885] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:29:21,889] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.215 seconds
[2020-07-22 12:29:32,389] {scheduler_job.py:153} INFO - Started process (PID=258324) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:32,392] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:29:32,393] {logging_mixin.py:112} INFO - [2020-07-22 12:29:32,392] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:32,497] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:29:32,498] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:29:32,502] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:32,672] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:29:32,699] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:29:32,704] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.314 seconds
[2020-07-22 12:29:44,165] {scheduler_job.py:153} INFO - Started process (PID=258644) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:44,169] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:29:44,169] {logging_mixin.py:112} INFO - [2020-07-22 12:29:44,169] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:44,245] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:29:44,246] {logging_mixin.py:112} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py:127: PendingDeprecationWarning: Invalid arguments were passed to SparkSubmitOperator (task_id: spark-submit-python). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'application_file': '~/spark-test/spark_test.py'}
  super(SparkSubmitOperator, self).__init__(*args, **kwargs)
[2020-07-22 12:29:44,249] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:44,365] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:29:44,383] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:29:44,386] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.221 seconds
[2020-07-22 12:29:53,684] {scheduler_job.py:153} INFO - Started process (PID=258862) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:53,687] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:29:53,688] {logging_mixin.py:112} INFO - [2020-07-22 12:29:53,687] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:53,754] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:29:53,756] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:29:53,860] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:29:53,875] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:29:53,877] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.193 seconds
[2020-07-22 12:30:02,765] {scheduler_job.py:153} INFO - Started process (PID=259107) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:02,769] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:30:02,770] {logging_mixin.py:112} INFO - [2020-07-22 12:30:02,770] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:02,859] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:30:02,862] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:02,965] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:30:02,980] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:30:02,983] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.218 seconds
[2020-07-22 12:30:10,454] {scheduler_job.py:153} INFO - Started process (PID=259314) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:10,457] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:30:10,457] {logging_mixin.py:112} INFO - [2020-07-22 12:30:10,457] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:10,527] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:30:10,530] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:10,701] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:30:10,908] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:30:10,911] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.457 seconds
[2020-07-22 12:30:21,282] {scheduler_job.py:153} INFO - Started process (PID=259639) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:21,285] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:30:21,285] {logging_mixin.py:112} INFO - [2020-07-22 12:30:21,285] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:21,361] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:30:21,364] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:21,499] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:30:21,517] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:30:21,521] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.239 seconds
[2020-07-22 12:30:28,545] {scheduler_job.py:153} INFO - Started process (PID=259849) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:28,549] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:30:28,549] {logging_mixin.py:112} INFO - [2020-07-22 12:30:28,549] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:28,627] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:30:28,630] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:28,886] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:30:29,083] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:30:29,086] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.541 seconds
[2020-07-22 12:30:36,642] {scheduler_job.py:153} INFO - Started process (PID=260078) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:36,646] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:30:36,646] {logging_mixin.py:112} INFO - [2020-07-22 12:30:36,646] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:36,762] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:30:36,766] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:36,882] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:30:36,901] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:30:36,904] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.262 seconds
[2020-07-22 12:30:45,313] {scheduler_job.py:153} INFO - Started process (PID=260290) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:45,316] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:30:45,317] {logging_mixin.py:112} INFO - [2020-07-22 12:30:45,317] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:45,391] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:30:45,394] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:45,507] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:30:45,523] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:30:45,525] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.212 seconds
[2020-07-22 12:30:56,569] {scheduler_job.py:153} INFO - Started process (PID=260561) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:56,573] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:30:56,574] {logging_mixin.py:112} INFO - [2020-07-22 12:30:56,573] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:56,692] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:30:56,696] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:30:56,902] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:30:56,965] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:30:56,970] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.401 seconds
[2020-07-22 12:31:06,674] {scheduler_job.py:153} INFO - Started process (PID=260880) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:06,677] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:31:06,677] {logging_mixin.py:112} INFO - [2020-07-22 12:31:06,677] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:06,747] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:31:06,751] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:06,941] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:31:06,983] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:31:06,988] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.314 seconds
[2020-07-22 12:31:15,261] {scheduler_job.py:153} INFO - Started process (PID=261102) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:15,265] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:31:15,265] {logging_mixin.py:112} INFO - [2020-07-22 12:31:15,265] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:15,330] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:31:15,333] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:15,467] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:31:15,482] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:31:15,485] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.224 seconds
[2020-07-22 12:31:25,486] {scheduler_job.py:153} INFO - Started process (PID=261328) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:25,490] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:31:25,490] {logging_mixin.py:112} INFO - [2020-07-22 12:31:25,490] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:25,553] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:31:25,556] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:25,664] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:31:25,679] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:31:25,681] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.195 seconds
[2020-07-22 12:31:36,497] {scheduler_job.py:153} INFO - Started process (PID=261622) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:36,515] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:31:36,515] {logging_mixin.py:112} INFO - [2020-07-22 12:31:36,515] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:36,613] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:31:36,617] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:36,827] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:31:36,855] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:31:36,859] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.362 seconds
[2020-07-22 12:31:48,020] {scheduler_job.py:153} INFO - Started process (PID=261939) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:48,025] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:31:48,026] {logging_mixin.py:112} INFO - [2020-07-22 12:31:48,026] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:48,088] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:31:48,091] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:48,244] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:31:48,259] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:31:48,261] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.241 seconds
[2020-07-22 12:31:55,186] {scheduler_job.py:153} INFO - Started process (PID=262128) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:55,191] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:31:55,191] {logging_mixin.py:112} INFO - [2020-07-22 12:31:55,191] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:55,255] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:31:55,258] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:31:55,377] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:31:55,392] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:31:55,395] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.209 seconds
[2020-07-22 12:32:08,528] {scheduler_job.py:153} INFO - Started process (PID=262523) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:08,532] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:32:08,532] {logging_mixin.py:112} INFO - [2020-07-22 12:32:08,532] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:08,602] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:32:08,605] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:08,723] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:32:08,740] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:32:08,745] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-22 12:32:16,532] {scheduler_job.py:153} INFO - Started process (PID=262736) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:16,535] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:32:16,536] {logging_mixin.py:112} INFO - [2020-07-22 12:32:16,536] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:16,630] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:32:16,634] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:16,735] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:32:16,752] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:32:16,754] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.223 seconds
[2020-07-22 12:32:28,089] {scheduler_job.py:153} INFO - Started process (PID=263083) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:28,094] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:32:28,095] {logging_mixin.py:112} INFO - [2020-07-22 12:32:28,094] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:28,164] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:32:28,167] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:28,279] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:32:28,294] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:32:28,297] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 12:32:35,645] {scheduler_job.py:153} INFO - Started process (PID=263275) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:35,649] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:32:35,650] {logging_mixin.py:112} INFO - [2020-07-22 12:32:35,649] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:35,740] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:32:35,743] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:35,859] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:32:35,874] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:32:35,876] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.231 seconds
[2020-07-22 12:32:45,466] {scheduler_job.py:153} INFO - Started process (PID=263530) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:45,469] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:32:45,470] {logging_mixin.py:112} INFO - [2020-07-22 12:32:45,469] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:45,535] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:32:45,538] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:45,647] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:32:45,672] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:32:45,675] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.209 seconds
[2020-07-22 12:32:55,270] {scheduler_job.py:153} INFO - Started process (PID=263750) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:55,272] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:32:55,273] {logging_mixin.py:112} INFO - [2020-07-22 12:32:55,273] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:55,341] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:32:55,345] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:32:55,498] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:32:55,515] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:32:55,518] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.249 seconds
[2020-07-22 12:33:08,950] {scheduler_job.py:153} INFO - Started process (PID=264157) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:08,953] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:33:08,953] {logging_mixin.py:112} INFO - [2020-07-22 12:33:08,953] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:09,017] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:33:09,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:09,117] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:33:09,131] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:33:09,134] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.184 seconds
[2020-07-22 12:33:15,903] {scheduler_job.py:153} INFO - Started process (PID=264343) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:15,905] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:33:15,906] {logging_mixin.py:112} INFO - [2020-07-22 12:33:15,906] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:15,985] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:33:15,988] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:16,135] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:33:16,151] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:33:16,154] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.251 seconds
[2020-07-22 12:33:25,819] {scheduler_job.py:153} INFO - Started process (PID=264575) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:25,824] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:33:25,825] {logging_mixin.py:112} INFO - [2020-07-22 12:33:25,825] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:25,939] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:33:25,944] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:26,061] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:33:26,087] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:33:26,091] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.271 seconds
[2020-07-22 12:33:35,437] {scheduler_job.py:153} INFO - Started process (PID=264793) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:35,440] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:33:35,440] {logging_mixin.py:112} INFO - [2020-07-22 12:33:35,440] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:35,504] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:33:35,507] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:35,628] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:33:35,643] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:33:35,646] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 12:33:48,726] {scheduler_job.py:153} INFO - Started process (PID=265161) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:48,730] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:33:48,731] {logging_mixin.py:112} INFO - [2020-07-22 12:33:48,731] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:48,845] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:33:48,848] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:48,976] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:33:49,009] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:33:49,014] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.288 seconds
[2020-07-22 12:33:56,688] {scheduler_job.py:153} INFO - Started process (PID=265394) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:56,691] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:33:56,691] {logging_mixin.py:112} INFO - [2020-07-22 12:33:56,691] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:56,761] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:33:56,764] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:33:56,875] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:33:56,890] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:33:56,892] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 12:34:05,473] {scheduler_job.py:153} INFO - Started process (PID=265607) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:05,478] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:34:05,478] {logging_mixin.py:112} INFO - [2020-07-22 12:34:05,478] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:05,544] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:34:05,546] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:05,720] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:34:05,735] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:34:05,737] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.264 seconds
[2020-07-22 12:34:15,367] {scheduler_job.py:153} INFO - Started process (PID=265861) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:15,370] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:34:15,371] {logging_mixin.py:112} INFO - [2020-07-22 12:34:15,371] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:15,446] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:34:15,449] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:15,563] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:34:15,579] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:34:15,582] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.215 seconds
[2020-07-22 12:34:29,077] {scheduler_job.py:153} INFO - Started process (PID=266189) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:29,081] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:34:29,082] {logging_mixin.py:112} INFO - [2020-07-22 12:34:29,082] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:29,388] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:34:29,392] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:29,514] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:34:29,545] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:34:29,550] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.473 seconds
[2020-07-22 12:34:37,557] {scheduler_job.py:153} INFO - Started process (PID=266441) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:37,561] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:34:37,562] {logging_mixin.py:112} INFO - [2020-07-22 12:34:37,562] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:37,667] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:34:37,670] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:37,788] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:34:37,803] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:34:37,805] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.248 seconds
[2020-07-22 12:34:45,508] {scheduler_job.py:153} INFO - Started process (PID=266669) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:45,511] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:34:45,512] {logging_mixin.py:112} INFO - [2020-07-22 12:34:45,512] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:45,575] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:34:45,578] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:45,702] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:34:45,731] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:34:45,734] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.225 seconds
[2020-07-22 12:34:55,522] {scheduler_job.py:153} INFO - Started process (PID=266895) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:55,525] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:34:55,525] {logging_mixin.py:112} INFO - [2020-07-22 12:34:55,525] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:55,589] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:34:55,592] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:34:55,711] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:34:55,726] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:34:55,729] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.207 seconds
[2020-07-22 12:35:08,289] {scheduler_job.py:153} INFO - Started process (PID=267206) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:08,300] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:35:08,301] {logging_mixin.py:112} INFO - [2020-07-22 12:35:08,301] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:08,420] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:35:08,425] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:08,628] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:35:08,653] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:35:08,658] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.369 seconds
[2020-07-22 12:35:17,767] {scheduler_job.py:153} INFO - Started process (PID=267511) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:17,771] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:35:17,771] {logging_mixin.py:112} INFO - [2020-07-22 12:35:17,771] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:17,844] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:35:17,847] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:17,966] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:35:17,981] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:35:17,983] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-22 12:35:25,543] {scheduler_job.py:153} INFO - Started process (PID=267708) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:25,546] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:35:25,546] {logging_mixin.py:112} INFO - [2020-07-22 12:35:25,546] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:25,613] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:35:25,616] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:25,780] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:35:25,795] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:35:25,798] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.255 seconds
[2020-07-22 12:35:36,409] {scheduler_job.py:153} INFO - Started process (PID=267954) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:36,412] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:35:36,412] {logging_mixin.py:112} INFO - [2020-07-22 12:35:36,412] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:36,477] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:35:36,480] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:36,624] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:35:36,639] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:35:36,642] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.233 seconds
[2020-07-22 12:35:46,096] {scheduler_job.py:153} INFO - Started process (PID=268229) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:46,100] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:35:46,101] {logging_mixin.py:112} INFO - [2020-07-22 12:35:46,101] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:46,210] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:35:46,214] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:46,322] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:35:46,340] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:35:46,344] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.248 seconds
[2020-07-22 12:35:57,311] {scheduler_job.py:153} INFO - Started process (PID=268539) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:57,314] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:35:57,314] {logging_mixin.py:112} INFO - [2020-07-22 12:35:57,314] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:57,379] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:35:57,382] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:35:57,491] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:35:57,507] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:35:57,509] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.198 seconds
[2020-07-22 12:36:06,190] {scheduler_job.py:153} INFO - Started process (PID=268757) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:06,194] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:36:06,195] {logging_mixin.py:112} INFO - [2020-07-22 12:36:06,194] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:06,264] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:36:06,267] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:06,527] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:36:06,543] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:36:06,545] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.355 seconds
[2020-07-22 12:36:15,707] {scheduler_job.py:153} INFO - Started process (PID=269001) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:15,710] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:36:15,711] {logging_mixin.py:112} INFO - [2020-07-22 12:36:15,711] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:15,775] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:36:15,778] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:15,917] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:36:15,946] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:36:15,951] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.244 seconds
[2020-07-22 12:36:26,347] {scheduler_job.py:153} INFO - Started process (PID=269270) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:26,351] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:36:26,351] {logging_mixin.py:112} INFO - [2020-07-22 12:36:26,351] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:26,471] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:36:26,476] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:26,689] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:36:26,710] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:36:26,713] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.366 seconds
[2020-07-22 12:36:37,839] {scheduler_job.py:153} INFO - Started process (PID=269591) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:37,843] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:36:37,844] {logging_mixin.py:112} INFO - [2020-07-22 12:36:37,844] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:37,919] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:36:37,922] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:38,034] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:36:38,050] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:36:38,053] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.214 seconds
[2020-07-22 12:36:45,540] {scheduler_job.py:153} INFO - Started process (PID=269820) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:45,543] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:36:45,543] {logging_mixin.py:112} INFO - [2020-07-22 12:36:45,543] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:45,606] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:36:45,609] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:45,728] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:36:45,743] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:36:45,745] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.205 seconds
[2020-07-22 12:36:55,550] {scheduler_job.py:153} INFO - Started process (PID=270046) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:55,553] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:36:55,553] {logging_mixin.py:112} INFO - [2020-07-22 12:36:55,553] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:55,619] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:36:55,622] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:36:55,731] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:36:55,746] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:36:55,749] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.199 seconds
[2020-07-22 12:37:05,988] {scheduler_job.py:153} INFO - Started process (PID=270307) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:05,992] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:37:05,992] {logging_mixin.py:112} INFO - [2020-07-22 12:37:05,992] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:06,081] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:37:06,086] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:06,257] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:37:06,274] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:37:06,276] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.288 seconds
[2020-07-22 12:37:18,817] {scheduler_job.py:153} INFO - Started process (PID=270664) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:18,820] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:37:18,820] {logging_mixin.py:112} INFO - [2020-07-22 12:37:18,820] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:18,887] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:37:18,890] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:19,014] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:37:19,031] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:37:19,034] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-22 12:37:25,865] {scheduler_job.py:153} INFO - Started process (PID=270861) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:25,869] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:37:25,869] {logging_mixin.py:112} INFO - [2020-07-22 12:37:25,869] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:25,937] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:37:25,940] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:26,052] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:37:26,068] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:37:26,070] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.206 seconds
[2020-07-22 12:37:35,769] {scheduler_job.py:153} INFO - Started process (PID=271077) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:35,773] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:37:35,774] {logging_mixin.py:112} INFO - [2020-07-22 12:37:35,773] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:35,863] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:37:35,868] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:36,043] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:37:36,058] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:37:36,061] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.292 seconds
[2020-07-22 12:37:46,311] {scheduler_job.py:153} INFO - Started process (PID=271348) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:46,314] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:37:46,314] {logging_mixin.py:112} INFO - [2020-07-22 12:37:46,314] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:46,382] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:37:46,385] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:46,493] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:37:46,510] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:37:46,513] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.202 seconds
[2020-07-22 12:37:59,181] {scheduler_job.py:153} INFO - Started process (PID=271732) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:59,202] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:37:59,206] {logging_mixin.py:112} INFO - [2020-07-22 12:37:59,206] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:59,846] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:37:59,850] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:37:59,955] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:37:59,978] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:37:59,983] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.802 seconds
[2020-07-22 12:38:09,345] {scheduler_job.py:153} INFO - Started process (PID=271983) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:09,360] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:38:09,360] {logging_mixin.py:112} INFO - [2020-07-22 12:38:09,360] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:09,557] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:38:09,564] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:10,143] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:38:10,160] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:38:10,163] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.819 seconds
[2020-07-22 12:38:21,319] {scheduler_job.py:153} INFO - Started process (PID=272259) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:21,324] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:38:21,325] {logging_mixin.py:112} INFO - [2020-07-22 12:38:21,324] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:21,485] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:38:21,509] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:21,678] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:38:21,696] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:38:21,699] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.380 seconds
[2020-07-22 12:38:33,356] {scheduler_job.py:153} INFO - Started process (PID=272575) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:33,361] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:38:33,362] {logging_mixin.py:112} INFO - [2020-07-22 12:38:33,362] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:33,493] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:38:33,498] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:33,627] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:38:33,673] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:38:33,679] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.322 seconds
[2020-07-22 12:38:46,591] {scheduler_job.py:153} INFO - Started process (PID=272909) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:46,594] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:38:46,594] {logging_mixin.py:112} INFO - [2020-07-22 12:38:46,594] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:46,662] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:38:46,666] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:47,310] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:38:47,566] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:38:47,569] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.978 seconds
[2020-07-22 12:38:55,674] {scheduler_job.py:153} INFO - Started process (PID=273155) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:55,679] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:38:55,679] {logging_mixin.py:112} INFO - [2020-07-22 12:38:55,679] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:55,760] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:38:55,763] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:38:55,870] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:38:55,885] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:38:55,887] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.213 seconds
[2020-07-22 12:39:03,441] {scheduler_job.py:153} INFO - Started process (PID=273356) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:03,446] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:39:03,446] {logging_mixin.py:112} INFO - [2020-07-22 12:39:03,446] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:03,513] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:39:03,516] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:03,636] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:39:03,651] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:39:03,654] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.213 seconds
[2020-07-22 12:39:10,921] {scheduler_job.py:153} INFO - Started process (PID=273546) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:10,924] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:39:10,924] {logging_mixin.py:112} INFO - [2020-07-22 12:39:10,924] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:10,989] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:39:10,991] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:11,101] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:39:11,117] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:39:11,119] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.198 seconds
[2020-07-22 12:39:21,922] {scheduler_job.py:153} INFO - Started process (PID=273849) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:21,926] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:39:21,927] {logging_mixin.py:112} INFO - [2020-07-22 12:39:21,927] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:22,059] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:39:22,064] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:22,196] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:39:22,227] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:39:22,231] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.309 seconds
[2020-07-22 12:39:33,306] {scheduler_job.py:153} INFO - Started process (PID=274154) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:33,310] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:39:33,310] {logging_mixin.py:112} INFO - [2020-07-22 12:39:33,310] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:33,442] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:39:33,447] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:33,701] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:39:33,718] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:39:33,722] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.416 seconds
[2020-07-22 12:39:42,184] {scheduler_job.py:153} INFO - Started process (PID=274371) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:42,187] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:39:42,187] {logging_mixin.py:112} INFO - [2020-07-22 12:39:42,187] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:42,251] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:39:42,254] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:42,387] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:39:42,405] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:39:42,407] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.223 seconds
[2020-07-22 12:39:49,962] {scheduler_job.py:153} INFO - Started process (PID=274600) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:49,965] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:39:49,966] {logging_mixin.py:112} INFO - [2020-07-22 12:39:49,965] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:50,030] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:39:50,033] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:50,148] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:39:50,164] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:39:50,166] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 12:39:57,659] {scheduler_job.py:153} INFO - Started process (PID=274794) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:57,662] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:39:57,663] {logging_mixin.py:112} INFO - [2020-07-22 12:39:57,663] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:57,734] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:39:57,737] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:39:58,393] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:39:58,408] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:39:58,410] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.751 seconds
[2020-07-22 12:40:09,475] {scheduler_job.py:153} INFO - Started process (PID=275123) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:09,478] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:40:09,478] {logging_mixin.py:112} INFO - [2020-07-22 12:40:09,478] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:09,572] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:40:09,578] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:09,710] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:40:09,731] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:40:09,734] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.259 seconds
[2020-07-22 12:40:18,654] {scheduler_job.py:153} INFO - Started process (PID=275379) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:18,659] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:40:18,660] {logging_mixin.py:112} INFO - [2020-07-22 12:40:18,659] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:18,761] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:40:18,763] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:18,929] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:40:18,946] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:40:18,950] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.296 seconds
[2020-07-22 12:40:26,517] {scheduler_job.py:153} INFO - Started process (PID=275613) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:26,520] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:40:26,521] {logging_mixin.py:112} INFO - [2020-07-22 12:40:26,520] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:26,588] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:40:26,591] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:26,795] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:40:26,815] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:40:26,817] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.300 seconds
[2020-07-22 12:40:36,746] {scheduler_job.py:153} INFO - Started process (PID=275845) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:36,749] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:40:36,749] {logging_mixin.py:112} INFO - [2020-07-22 12:40:36,749] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:36,813] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:40:36,816] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:36,932] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:40:36,947] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:40:36,949] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.203 seconds
[2020-07-22 12:40:52,472] {scheduler_job.py:153} INFO - Started process (PID=276233) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:52,475] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:40:52,476] {logging_mixin.py:112} INFO - [2020-07-22 12:40:52,476] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:52,641] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:40:52,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:40:52,766] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:40:52,793] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:40:52,798] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.326 seconds
[2020-07-22 12:41:03,250] {scheduler_job.py:153} INFO - Started process (PID=276514) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:03,253] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:41:03,254] {logging_mixin.py:112} INFO - [2020-07-22 12:41:03,254] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:03,338] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:41:03,342] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:03,461] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:41:03,484] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:41:03,488] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.238 seconds
[2020-07-22 12:41:11,827] {scheduler_job.py:153} INFO - Started process (PID=276729) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:11,832] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:41:11,832] {logging_mixin.py:112} INFO - [2020-07-22 12:41:11,832] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:11,968] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:41:11,972] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:12,092] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:41:12,108] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:41:12,111] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.284 seconds
[2020-07-22 12:41:21,129] {scheduler_job.py:153} INFO - Started process (PID=276953) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:21,134] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:41:21,134] {logging_mixin.py:112} INFO - [2020-07-22 12:41:21,134] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:21,204] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:41:21,207] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:21,345] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:41:21,361] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:41:21,364] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.235 seconds
[2020-07-22 12:41:30,157] {scheduler_job.py:153} INFO - Started process (PID=277222) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:30,175] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:41:30,175] {logging_mixin.py:112} INFO - [2020-07-22 12:41:30,175] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:30,360] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:41:30,365] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:30,484] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:41:30,505] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:41:30,508] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.351 seconds
[2020-07-22 12:41:42,700] {scheduler_job.py:153} INFO - Started process (PID=277555) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:42,705] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:41:42,706] {logging_mixin.py:112} INFO - [2020-07-22 12:41:42,706] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:42,791] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:41:42,794] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:42,927] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:41:42,944] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:41:42,947] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.247 seconds
[2020-07-22 12:41:51,376] {scheduler_job.py:153} INFO - Started process (PID=277774) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:51,381] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:41:51,382] {logging_mixin.py:112} INFO - [2020-07-22 12:41:51,382] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:51,475] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:41:51,478] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:51,598] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:41:51,614] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:41:51,617] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.241 seconds
[2020-07-22 12:41:59,874] {scheduler_job.py:153} INFO - Started process (PID=278007) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:59,878] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:41:59,879] {logging_mixin.py:112} INFO - [2020-07-22 12:41:59,879] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:41:59,945] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:41:59,949] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:00,100] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:42:00,116] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:42:00,118] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.244 seconds
[2020-07-22 12:42:08,675] {scheduler_job.py:153} INFO - Started process (PID=278225) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:08,680] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:42:08,680] {logging_mixin.py:112} INFO - [2020-07-22 12:42:08,680] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:08,816] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:42:08,822] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:08,949] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:42:08,977] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:42:08,981] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.307 seconds
[2020-07-22 12:42:22,227] {scheduler_job.py:153} INFO - Started process (PID=278570) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:22,230] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:42:22,231] {logging_mixin.py:112} INFO - [2020-07-22 12:42:22,231] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:22,348] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:42:22,353] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:22,547] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:42:22,584] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:42:22,590] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.362 seconds
[2020-07-22 12:42:31,332] {scheduler_job.py:153} INFO - Started process (PID=278835) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:31,336] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:42:31,337] {logging_mixin.py:112} INFO - [2020-07-22 12:42:31,337] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:31,423] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:42:31,426] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:31,537] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:42:31,552] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:42:31,555] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.223 seconds
[2020-07-22 12:42:39,634] {scheduler_job.py:153} INFO - Started process (PID=279044) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:39,640] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:42:39,641] {logging_mixin.py:112} INFO - [2020-07-22 12:42:39,640] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:39,710] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:42:39,713] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:39,822] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:42:39,844] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:42:39,848] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.215 seconds
[2020-07-22 12:42:48,322] {scheduler_job.py:153} INFO - Started process (PID=279265) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:48,326] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:42:48,327] {logging_mixin.py:112} INFO - [2020-07-22 12:42:48,327] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:48,421] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:42:48,424] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:48,550] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:42:48,565] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:42:48,568] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.246 seconds
[2020-07-22 12:42:58,854] {scheduler_job.py:153} INFO - Started process (PID=279552) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:58,857] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:42:58,858] {logging_mixin.py:112} INFO - [2020-07-22 12:42:58,857] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:58,958] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:42:58,963] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:42:59,158] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:42:59,181] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:42:59,184] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.330 seconds
[2020-07-22 12:43:10,406] {scheduler_job.py:153} INFO - Started process (PID=279863) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:10,413] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:43:10,414] {logging_mixin.py:112} INFO - [2020-07-22 12:43:10,413] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:10,567] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:43:10,571] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:10,692] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:43:10,710] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:43:10,713] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.307 seconds
[2020-07-22 12:43:19,686] {scheduler_job.py:153} INFO - Started process (PID=280094) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:19,696] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:43:19,697] {logging_mixin.py:112} INFO - [2020-07-22 12:43:19,697] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:19,880] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:43:19,884] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:20,045] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:43:20,083] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:43:20,095] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.409 seconds
[2020-07-22 12:43:30,612] {scheduler_job.py:153} INFO - Started process (PID=280354) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:30,616] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:43:30,616] {logging_mixin.py:112} INFO - [2020-07-22 12:43:30,616] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:30,702] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:43:30,707] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:30,902] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:43:30,922] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:43:30,925] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.313 seconds
[2020-07-22 12:43:39,484] {scheduler_job.py:153} INFO - Started process (PID=280577) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:39,488] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:43:39,488] {logging_mixin.py:112} INFO - [2020-07-22 12:43:39,488] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:39,573] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:43:39,577] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:39,697] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:43:39,722] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:43:39,726] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.242 seconds
[2020-07-22 12:43:52,979] {scheduler_job.py:153} INFO - Started process (PID=280924) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:52,982] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:43:52,982] {logging_mixin.py:112} INFO - [2020-07-22 12:43:52,982] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:53,060] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:43:53,063] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:43:53,431] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:43:53,446] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:43:53,448] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.469 seconds
[2020-07-22 12:44:01,794] {scheduler_job.py:153} INFO - Started process (PID=281159) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:01,802] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:44:01,803] {logging_mixin.py:112} INFO - [2020-07-22 12:44:01,803] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:01,887] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:44:01,890] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:01,991] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:44:02,017] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:44:02,021] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.227 seconds
[2020-07-22 12:44:09,765] {scheduler_job.py:153} INFO - Started process (PID=281361) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:09,768] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:44:09,768] {logging_mixin.py:112} INFO - [2020-07-22 12:44:09,768] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:09,838] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:44:09,841] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:09,952] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:44:09,967] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:44:09,969] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 12:44:18,986] {scheduler_job.py:153} INFO - Started process (PID=281573) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:18,991] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:44:18,992] {logging_mixin.py:112} INFO - [2020-07-22 12:44:18,992] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:19,117] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:44:19,121] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:19,403] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:44:19,427] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:44:19,429] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.444 seconds
[2020-07-22 12:44:30,428] {scheduler_job.py:153} INFO - Started process (PID=281899) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:30,434] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:44:30,435] {logging_mixin.py:112} INFO - [2020-07-22 12:44:30,435] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:30,552] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:44:30,564] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:30,794] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:44:30,852] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:44:30,856] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.428 seconds
[2020-07-22 12:44:39,715] {scheduler_job.py:153} INFO - Started process (PID=282174) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:39,721] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:44:39,721] {logging_mixin.py:112} INFO - [2020-07-22 12:44:39,721] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:39,817] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:44:39,820] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:39,945] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:44:39,960] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:44:39,963] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.247 seconds
[2020-07-22 12:44:48,431] {scheduler_job.py:153} INFO - Started process (PID=282376) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:48,435] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:44:48,435] {logging_mixin.py:112} INFO - [2020-07-22 12:44:48,435] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:48,531] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:44:48,535] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:48,667] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:44:48,683] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:44:48,686] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.256 seconds
[2020-07-22 12:44:56,711] {scheduler_job.py:153} INFO - Started process (PID=282587) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:56,714] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:44:56,715] {logging_mixin.py:112} INFO - [2020-07-22 12:44:56,715] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:56,812] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:44:56,817] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:44:57,059] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:44:57,089] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:44:57,094] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.383 seconds
[2020-07-22 12:45:07,546] {scheduler_job.py:153} INFO - Started process (PID=282890) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:07,551] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:45:07,551] {logging_mixin.py:112} INFO - [2020-07-22 12:45:07,551] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:07,663] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:45:07,668] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:07,818] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:45:07,841] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:45:07,844] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.299 seconds
[2020-07-22 12:45:19,340] {scheduler_job.py:153} INFO - Started process (PID=283210) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:19,343] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:45:19,344] {logging_mixin.py:112} INFO - [2020-07-22 12:45:19,344] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:19,412] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:45:19,415] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:19,517] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:45:19,534] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:45:19,537] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.197 seconds
[2020-07-22 12:45:26,998] {scheduler_job.py:153} INFO - Started process (PID=283402) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:27,001] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:45:27,001] {logging_mixin.py:112} INFO - [2020-07-22 12:45:27,001] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:27,069] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:45:27,073] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:27,180] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:45:27,210] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:45:27,215] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.218 seconds
[2020-07-22 12:45:36,813] {scheduler_job.py:153} INFO - Started process (PID=283661) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:36,815] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:45:36,816] {logging_mixin.py:112} INFO - [2020-07-22 12:45:36,816] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:36,883] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:45:36,886] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:36,991] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:45:37,007] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:45:37,009] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.197 seconds
[2020-07-22 12:45:47,143] {scheduler_job.py:153} INFO - Started process (PID=283887) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:47,147] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:45:47,147] {logging_mixin.py:112} INFO - [2020-07-22 12:45:47,147] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:47,217] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:45:47,220] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:45:47,325] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:45:47,341] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:45:47,343] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.201 seconds
[2020-07-22 12:46:01,332] {scheduler_job.py:153} INFO - Started process (PID=284288) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:01,335] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:46:01,335] {logging_mixin.py:112} INFO - [2020-07-22 12:46:01,335] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:01,409] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:46:01,412] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:01,532] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:46:01,550] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:46:01,552] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.220 seconds
[2020-07-22 12:46:10,028] {scheduler_job.py:153} INFO - Started process (PID=284502) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:10,032] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:46:10,032] {logging_mixin.py:112} INFO - [2020-07-22 12:46:10,032] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:10,113] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:46:10,116] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:10,244] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:46:10,266] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:46:10,269] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.240 seconds
[2020-07-22 12:46:18,546] {scheduler_job.py:153} INFO - Started process (PID=284716) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:18,551] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:46:18,551] {logging_mixin.py:112} INFO - [2020-07-22 12:46:18,551] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:18,621] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:46:18,624] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:18,771] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:46:18,793] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:46:18,798] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.252 seconds
[2020-07-22 12:46:27,807] {scheduler_job.py:153} INFO - Started process (PID=284931) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:27,812] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:46:27,813] {logging_mixin.py:112} INFO - [2020-07-22 12:46:27,813] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:27,888] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:46:27,891] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:28,029] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:46:28,055] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:46:28,059] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.252 seconds
[2020-07-22 12:46:39,964] {scheduler_job.py:153} INFO - Started process (PID=285268) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:39,968] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:46:39,969] {logging_mixin.py:112} INFO - [2020-07-22 12:46:39,969] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:40,053] {logging_mixin.py:112} INFO - ~/spark-test/spark_test.py
[2020-07-22 12:46:40,056] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:40,180] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:46:40,227] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:46:40,244] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.279 seconds
[2020-07-22 12:46:49,662] {scheduler_job.py:153} INFO - Started process (PID=285545) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:49,664] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:46:49,665] {logging_mixin.py:112} INFO - [2020-07-22 12:46:49,665] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:49,789] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:49,944] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:46:49,960] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:46:49,962] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.301 seconds
[2020-07-22 12:46:57,532] {scheduler_job.py:153} INFO - Started process (PID=285750) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:57,535] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:46:57,536] {logging_mixin.py:112} INFO - [2020-07-22 12:46:57,536] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:57,604] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:46:57,704] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:46:57,720] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:46:57,722] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.190 seconds
[2020-07-22 12:47:06,983] {scheduler_job.py:153} INFO - Started process (PID=285988) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:06,986] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:47:06,987] {logging_mixin.py:112} INFO - [2020-07-22 12:47:06,987] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:07,054] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:07,241] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:47:07,256] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:47:07,258] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.275 seconds
[2020-07-22 12:47:19,108] {scheduler_job.py:153} INFO - Started process (PID=286284) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:19,113] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:47:19,115] {logging_mixin.py:112} INFO - [2020-07-22 12:47:19,114] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:19,236] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:19,370] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:47:19,401] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:47:19,406] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.297 seconds
[2020-07-22 12:47:32,038] {scheduler_job.py:153} INFO - Started process (PID=286619) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:32,042] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:47:32,042] {logging_mixin.py:112} INFO - [2020-07-22 12:47:32,042] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:32,116] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:32,220] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:47:32,235] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:47:32,238] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-22 12:47:40,511] {scheduler_job.py:153} INFO - Started process (PID=286849) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:40,514] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:47:40,515] {logging_mixin.py:112} INFO - [2020-07-22 12:47:40,515] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:40,600] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:40,727] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:47:40,745] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:47:40,747] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.236 seconds
[2020-07-22 12:47:49,987] {scheduler_job.py:153} INFO - Started process (PID=287067) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:49,990] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:47:49,991] {logging_mixin.py:112} INFO - [2020-07-22 12:47:49,991] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:50,110] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:50,219] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:47:50,244] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:47:50,246] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.259 seconds
[2020-07-22 12:47:58,453] {scheduler_job.py:153} INFO - Started process (PID=287276) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:58,455] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:47:58,456] {logging_mixin.py:112} INFO - [2020-07-22 12:47:58,456] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:58,525] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:47:58,680] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:47:58,697] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:47:58,699] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.247 seconds
[2020-07-22 12:48:11,777] {scheduler_job.py:153} INFO - Started process (PID=287645) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:11,780] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:48:11,780] {logging_mixin.py:112} INFO - [2020-07-22 12:48:11,780] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:11,868] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:11,973] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:48:12,180] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:48:12,183] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.406 seconds
[2020-07-22 12:48:20,765] {scheduler_job.py:153} INFO - Started process (PID=287889) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:20,769] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:48:20,770] {logging_mixin.py:112} INFO - [2020-07-22 12:48:20,769] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:20,847] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:20,947] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:48:20,967] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:48:20,970] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.204 seconds
[2020-07-22 12:48:28,639] {scheduler_job.py:153} INFO - Started process (PID=288088) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:28,643] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:48:28,643] {logging_mixin.py:112} INFO - [2020-07-22 12:48:28,643] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:28,721] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:28,876] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:48:28,892] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:48:28,895] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.256 seconds
[2020-07-22 12:48:36,749] {scheduler_job.py:153} INFO - Started process (PID=288315) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:36,754] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:48:36,754] {logging_mixin.py:112} INFO - [2020-07-22 12:48:36,754] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:36,866] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:37,032] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:48:37,047] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:48:37,050] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.301 seconds
[2020-07-22 12:48:49,364] {scheduler_job.py:153} INFO - Started process (PID=288615) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:49,369] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:48:49,370] {logging_mixin.py:112} INFO - [2020-07-22 12:48:49,369] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:49,480] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:49,605] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:48:49,664] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:48:49,674] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.310 seconds
[2020-07-22 12:48:59,363] {scheduler_job.py:153} INFO - Started process (PID=288902) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:59,365] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:48:59,366] {logging_mixin.py:112} INFO - [2020-07-22 12:48:59,366] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:59,450] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:48:59,608] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:48:59,627] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:48:59,631] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.268 seconds
[2020-07-22 12:49:07,333] {scheduler_job.py:153} INFO - Started process (PID=289129) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:07,336] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:49:07,337] {logging_mixin.py:112} INFO - [2020-07-22 12:49:07,337] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:07,417] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:07,519] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:49:07,540] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:49:07,543] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.209 seconds
[2020-07-22 12:49:18,034] {scheduler_job.py:153} INFO - Started process (PID=289365) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:18,037] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:49:18,037] {logging_mixin.py:112} INFO - [2020-07-22 12:49:18,037] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:18,197] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:18,314] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:49:18,332] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:49:18,334] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.301 seconds
[2020-07-22 12:49:28,335] {scheduler_job.py:153} INFO - Started process (PID=289629) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:28,338] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:49:28,339] {logging_mixin.py:112} INFO - [2020-07-22 12:49:28,339] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:28,425] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:28,541] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:49:28,573] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:49:28,576] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.241 seconds
[2020-07-22 12:49:41,854] {scheduler_job.py:153} INFO - Started process (PID=290006) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:41,858] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:49:41,859] {logging_mixin.py:112} INFO - [2020-07-22 12:49:41,859] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:42,103] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:42,542] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:49:42,557] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:49:42,561] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.708 seconds
[2020-07-22 12:49:50,293] {scheduler_job.py:153} INFO - Started process (PID=290215) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:50,296] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:49:50,296] {logging_mixin.py:112} INFO - [2020-07-22 12:49:50,296] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:50,371] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:49:50,459] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:49:50,474] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:49:50,477] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.184 seconds
[2020-07-22 12:50:02,576] {scheduler_job.py:153} INFO - Started process (PID=290468) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:02,579] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:50:02,579] {logging_mixin.py:112} INFO - [2020-07-22 12:50:02,579] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:02,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:02,747] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:50:02,762] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:50:02,765] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.189 seconds
[2020-07-22 12:50:10,766] {scheduler_job.py:153} INFO - Started process (PID=290729) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:10,783] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:50:10,784] {logging_mixin.py:112} INFO - [2020-07-22 12:50:10,783] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:10,872] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:10,980] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:50:11,005] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:50:11,008] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.242 seconds
[2020-07-22 12:50:21,271] {scheduler_job.py:153} INFO - Started process (PID=291024) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:21,274] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:50:21,275] {logging_mixin.py:112} INFO - [2020-07-22 12:50:21,274] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:21,353] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:21,456] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:50:21,485] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:50:21,490] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.219 seconds
[2020-07-22 12:50:28,725] {scheduler_job.py:153} INFO - Started process (PID=291229) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:28,728] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:50:28,729] {logging_mixin.py:112} INFO - [2020-07-22 12:50:28,729] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:28,802] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:28,900] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:50:28,923] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:50:28,926] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.201 seconds
[2020-07-22 12:50:36,719] {scheduler_job.py:153} INFO - Started process (PID=291435) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:36,723] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:50:36,724] {logging_mixin.py:112} INFO - [2020-07-22 12:50:36,724] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:36,796] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:36,905] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:50:36,923] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:50:36,927] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 12:50:47,968] {scheduler_job.py:153} INFO - Started process (PID=291700) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:47,971] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:50:47,972] {logging_mixin.py:112} INFO - [2020-07-22 12:50:47,972] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:48,040] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:48,154] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:50:48,305] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:50:48,308] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.341 seconds
[2020-07-22 12:50:59,665] {scheduler_job.py:153} INFO - Started process (PID=292024) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:59,669] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:50:59,670] {logging_mixin.py:112} INFO - [2020-07-22 12:50:59,669] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:59,788] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:50:59,913] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:50:59,940] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:50:59,944] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.279 seconds
[2020-07-22 12:51:07,944] {scheduler_job.py:153} INFO - Started process (PID=292256) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:07,948] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:51:07,948] {logging_mixin.py:112} INFO - [2020-07-22 12:51:07,948] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:08,036] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:08,161] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:51:08,186] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:51:08,190] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.246 seconds
[2020-07-22 12:51:17,052] {scheduler_job.py:153} INFO - Started process (PID=292495) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:17,055] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:51:17,056] {logging_mixin.py:112} INFO - [2020-07-22 12:51:17,056] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:17,122] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:17,264] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:51:17,290] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:51:17,293] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.241 seconds
[2020-07-22 12:51:29,264] {scheduler_job.py:153} INFO - Started process (PID=292749) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:29,267] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:51:29,268] {logging_mixin.py:112} INFO - [2020-07-22 12:51:29,268] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:29,350] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:29,546] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:51:29,562] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:51:29,565] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.301 seconds
[2020-07-22 12:51:44,527] {scheduler_job.py:153} INFO - Started process (PID=293173) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:44,532] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:51:44,532] {logging_mixin.py:112} INFO - [2020-07-22 12:51:44,532] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:44,607] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:44,776] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:51:44,799] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:51:44,804] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.277 seconds
[2020-07-22 12:51:52,963] {scheduler_job.py:153} INFO - Started process (PID=293387) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:52,966] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:51:52,967] {logging_mixin.py:112} INFO - [2020-07-22 12:51:52,967] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:53,034] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:51:53,141] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:51:53,156] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:51:53,159] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.196 seconds
[2020-07-22 12:52:05,088] {scheduler_job.py:153} INFO - Started process (PID=293639) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:52:05,092] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:52:05,093] {logging_mixin.py:112} INFO - [2020-07-22 12:52:05,093] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:52:05,169] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:52:05,278] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:52:05,293] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:52:05,296] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.208 seconds
[2020-07-22 12:52:18,949] {scheduler_job.py:153} INFO - Started process (PID=293975) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:52:18,953] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:52:18,953] {logging_mixin.py:112} INFO - [2020-07-22 12:52:18,953] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:52:19,045] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:52:19,164] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:52:19,214] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:52:19,229] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.280 seconds
[2020-07-22 12:52:29,440] {scheduler_job.py:153} INFO - Started process (PID=294275) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:52:29,443] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:52:29,444] {logging_mixin.py:112} INFO - [2020-07-22 12:52:29,444] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:52:29,530] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:52:29,632] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:52:29,655] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:52:29,657] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.218 seconds
[2020-07-22 12:52:45,982] {scheduler_job.py:153} INFO - Started process (PID=294611) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:52:45,986] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:52:45,986] {logging_mixin.py:112} INFO - [2020-07-22 12:52:45,986] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:52:46,053] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:52:46,155] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:52:46,173] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:52:46,179] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.197 seconds
[2020-07-22 12:53:00,724] {scheduler_job.py:153} INFO - Started process (PID=294928) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:00,728] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:53:00,728] {logging_mixin.py:112} INFO - [2020-07-22 12:53:00,728] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:00,866] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:00,993] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:53:01,018] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:53:01,022] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.298 seconds
[2020-07-22 12:53:10,120] {scheduler_job.py:153} INFO - Started process (PID=295219) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:10,123] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:53:10,124] {logging_mixin.py:112} INFO - [2020-07-22 12:53:10,123] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:10,188] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:10,303] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:53:10,318] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:53:10,321] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.201 seconds
[2020-07-22 12:53:18,677] {scheduler_job.py:153} INFO - Started process (PID=295455) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:18,680] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:53:18,680] {logging_mixin.py:112} INFO - [2020-07-22 12:53:18,680] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:18,751] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:18,871] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:53:18,886] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:53:18,889] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.212 seconds
[2020-07-22 12:53:30,426] {scheduler_job.py:153} INFO - Started process (PID=295715) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:30,430] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:53:30,431] {logging_mixin.py:112} INFO - [2020-07-22 12:53:30,431] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:30,686] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:30,804] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:53:30,820] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:53:30,823] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.397 seconds
[2020-07-22 12:53:45,918] {scheduler_job.py:153} INFO - Started process (PID=296072) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:45,921] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:53:45,922] {logging_mixin.py:112} INFO - [2020-07-22 12:53:45,921] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:46,012] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:46,175] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:53:46,195] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:53:46,199] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.282 seconds
[2020-07-22 12:53:57,644] {scheduler_job.py:153} INFO - Started process (PID=296374) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:57,646] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:53:57,647] {logging_mixin.py:112} INFO - [2020-07-22 12:53:57,646] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:57,727] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:53:57,941] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:53:57,958] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:53:57,961] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.318 seconds
[2020-07-22 12:54:06,729] {scheduler_job.py:153} INFO - Started process (PID=296594) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:06,732] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:54:06,732] {logging_mixin.py:112} INFO - [2020-07-22 12:54:06,732] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:06,808] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:06,930] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:54:06,948] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:54:06,951] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.222 seconds
[2020-07-22 12:54:20,246] {scheduler_job.py:153} INFO - Started process (PID=296892) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:20,250] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:54:20,250] {logging_mixin.py:112} INFO - [2020-07-22 12:54:20,250] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:20,367] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:20,483] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:54:20,508] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:54:20,513] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.274 seconds
[2020-07-22 12:54:34,901] {scheduler_job.py:153} INFO - Started process (PID=297236) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:34,908] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:54:34,908] {logging_mixin.py:112} INFO - [2020-07-22 12:54:34,908] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:35,033] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:35,246] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:54:35,282] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:54:35,286] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.385 seconds
[2020-07-22 12:54:44,210] {scheduler_job.py:153} INFO - Started process (PID=297496) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:44,214] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:54:44,214] {logging_mixin.py:112} INFO - [2020-07-22 12:54:44,214] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:44,288] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:44,391] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:54:44,406] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:54:44,409] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.199 seconds
[2020-07-22 12:54:54,344] {scheduler_job.py:153} INFO - Started process (PID=297755) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:54,347] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:54:54,347] {logging_mixin.py:112} INFO - [2020-07-22 12:54:54,347] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:54,436] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:54:54,542] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-22 12:54:54,561] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-22 12:54:54,693] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.350 seconds
[2020-07-22 12:55:08,953] {scheduler_job.py:153} INFO - Started process (PID=298045) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:55:08,957] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:55:08,958] {logging_mixin.py:112} INFO - [2020-07-22 12:55:08,958] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:55:09,147] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:55:09,254] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.301 seconds
[2020-07-22 12:55:28,362] {scheduler_job.py:153} INFO - Started process (PID=298498) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:55:28,366] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:55:28,367] {logging_mixin.py:112} INFO - [2020-07-22 12:55:28,367] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:55:28,698] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:55:28,846] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.484 seconds
[2020-07-22 12:55:40,298] {scheduler_job.py:153} INFO - Started process (PID=298788) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:55:40,301] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:55:40,301] {logging_mixin.py:112} INFO - [2020-07-22 12:55:40,301] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:55:40,376] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:55:40,467] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.170 seconds
[2020-07-22 12:56:25,963] {scheduler_job.py:153} INFO - Started process (PID=299834) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:56:25,967] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:56:25,968] {logging_mixin.py:112} INFO - [2020-07-22 12:56:25,967] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:56:26,170] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:56:26,272] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.309 seconds
[2020-07-22 12:57:07,643] {scheduler_job.py:153} INFO - Started process (PID=300669) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:57:07,694] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:57:07,694] {logging_mixin.py:112} INFO - [2020-07-22 12:57:07,694] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:57:07,899] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:57:08,003] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.360 seconds
[2020-07-22 12:57:33,233] {scheduler_job.py:153} INFO - Started process (PID=301234) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:57:33,237] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:57:33,237] {logging_mixin.py:112} INFO - [2020-07-22 12:57:33,237] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:57:33,548] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:57:33,657] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.424 seconds
[2020-07-22 12:57:58,823] {scheduler_job.py:153} INFO - Started process (PID=301834) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:57:58,825] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:57:58,826] {logging_mixin.py:112} INFO - [2020-07-22 12:57:58,826] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:57:59,031] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:57:59,835] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.012 seconds
[2020-07-22 12:58:34,957] {scheduler_job.py:153} INFO - Started process (PID=302648) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:58:34,962] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:58:34,963] {logging_mixin.py:112} INFO - [2020-07-22 12:58:34,962] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:58:35,234] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:58:35,341] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.384 seconds
[2020-07-22 12:59:06,384] {scheduler_job.py:153} INFO - Started process (PID=303304) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:59:06,387] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:59:06,388] {logging_mixin.py:112} INFO - [2020-07-22 12:59:06,388] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:59:06,598] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:59:06,745] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.361 seconds
[2020-07-22 12:59:31,284] {scheduler_job.py:153} INFO - Started process (PID=303910) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:59:31,287] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 12:59:31,287] {logging_mixin.py:112} INFO - [2020-07-22 12:59:31,287] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:59:31,624] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 12:59:31,767] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.484 seconds
[2020-07-22 13:00:02,535] {scheduler_job.py:153} INFO - Started process (PID=304628) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:00:02,538] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:00:02,538] {logging_mixin.py:112} INFO - [2020-07-22 13:00:02,538] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:00:02,735] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:00:02,873] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.339 seconds
[2020-07-22 13:00:33,146] {scheduler_job.py:153} INFO - Started process (PID=305263) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:00:33,151] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:00:33,152] {logging_mixin.py:112} INFO - [2020-07-22 13:00:33,151] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:00:33,432] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:00:33,595] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.449 seconds
[2020-07-22 13:00:57,204] {scheduler_job.py:153} INFO - Started process (PID=305823) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:00:57,207] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:00:57,208] {logging_mixin.py:112} INFO - [2020-07-22 13:00:57,208] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:00:57,412] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:00:57,509] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.305 seconds
[2020-07-22 13:01:27,155] {scheduler_job.py:153} INFO - Started process (PID=306506) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:01:27,158] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:01:27,158] {logging_mixin.py:112} INFO - [2020-07-22 13:01:27,158] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:01:27,433] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:01:27,565] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.410 seconds
[2020-07-22 13:01:56,743] {scheduler_job.py:153} INFO - Started process (PID=307134) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:01:56,748] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:01:56,748] {logging_mixin.py:112} INFO - [2020-07-22 13:01:56,748] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:01:57,012] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:01:57,133] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.390 seconds
[2020-07-22 13:02:26,330] {scheduler_job.py:153} INFO - Started process (PID=307780) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:02:26,333] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:02:26,333] {logging_mixin.py:112} INFO - [2020-07-22 13:02:26,333] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:02:26,603] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:02:26,698] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.367 seconds
[2020-07-22 13:02:56,836] {scheduler_job.py:153} INFO - Started process (PID=308471) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:02:56,840] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:02:56,841] {logging_mixin.py:112} INFO - [2020-07-22 13:02:56,841] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:02:57,092] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:02:57,213] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.376 seconds
[2020-07-22 13:03:21,186] {scheduler_job.py:153} INFO - Started process (PID=309028) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:03:21,189] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:03:21,190] {logging_mixin.py:112} INFO - [2020-07-22 13:03:21,189] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:03:21,422] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:03:21,560] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.374 seconds
[2020-07-22 13:03:45,473] {scheduler_job.py:153} INFO - Started process (PID=309609) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:03:45,476] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:03:45,476] {logging_mixin.py:112} INFO - [2020-07-22 13:03:45,476] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:03:45,677] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:03:45,780] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.307 seconds
[2020-07-22 13:04:14,852] {scheduler_job.py:153} INFO - Started process (PID=310296) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:04:14,855] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:04:14,856] {logging_mixin.py:112} INFO - [2020-07-22 13:04:14,856] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:04:15,106] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:04:15,201] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.349 seconds
[2020-07-22 13:04:39,368] {scheduler_job.py:153} INFO - Started process (PID=310825) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:04:39,378] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:04:39,379] {logging_mixin.py:112} INFO - [2020-07-22 13:04:39,379] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:04:39,606] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:04:39,713] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.344 seconds
[2020-07-22 13:05:11,913] {scheduler_job.py:153} INFO - Started process (PID=311563) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:05:11,916] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:05:11,917] {logging_mixin.py:112} INFO - [2020-07-22 13:05:11,916] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:05:12,117] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:05:12,228] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.315 seconds
[2020-07-22 13:05:41,166] {scheduler_job.py:153} INFO - Started process (PID=312305) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:05:41,170] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:05:41,170] {logging_mixin.py:112} INFO - [2020-07-22 13:05:41,170] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:05:41,381] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:05:41,516] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.350 seconds
[2020-07-22 13:06:05,269] {scheduler_job.py:153} INFO - Started process (PID=312803) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:06:05,272] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:06:05,272] {logging_mixin.py:112} INFO - [2020-07-22 13:06:05,272] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:06:05,780] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:06:06,018] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.750 seconds
[2020-07-22 13:06:36,502] {scheduler_job.py:153} INFO - Started process (PID=313559) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:06:36,507] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:06:36,508] {logging_mixin.py:112} INFO - [2020-07-22 13:06:36,508] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:06:36,865] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:06:37,030] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.528 seconds
[2020-07-22 13:07:13,039] {scheduler_job.py:153} INFO - Started process (PID=314383) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:07:13,043] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:07:13,044] {logging_mixin.py:112} INFO - [2020-07-22 13:07:13,044] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:07:13,296] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:07:13,404] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.365 seconds
[2020-07-22 13:07:37,174] {scheduler_job.py:153} INFO - Started process (PID=314939) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:07:37,177] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:07:37,177] {logging_mixin.py:112} INFO - [2020-07-22 13:07:37,177] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:07:37,428] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:07:37,609] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.435 seconds
[2020-07-22 13:08:01,842] {scheduler_job.py:153} INFO - Started process (PID=315537) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:08:01,845] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:08:01,845] {logging_mixin.py:112} INFO - [2020-07-22 13:08:01,845] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:08:02,061] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:08:02,176] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.334 seconds
[2020-07-22 13:08:31,377] {scheduler_job.py:153} INFO - Started process (PID=316261) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:08:31,380] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:08:31,381] {logging_mixin.py:112} INFO - [2020-07-22 13:08:31,381] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:08:31,635] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:08:31,772] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.394 seconds
[2020-07-22 13:08:55,317] {scheduler_job.py:153} INFO - Started process (PID=316803) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:08:55,320] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:08:55,321] {logging_mixin.py:112} INFO - [2020-07-22 13:08:55,320] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:08:55,589] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:08:55,744] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.428 seconds
[2020-07-22 13:09:25,796] {scheduler_job.py:153} INFO - Started process (PID=317546) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:09:25,842] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:09:25,843] {logging_mixin.py:112} INFO - [2020-07-22 13:09:25,843] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:09:26,167] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:09:26,301] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.505 seconds
[2020-07-22 13:09:56,384] {scheduler_job.py:153} INFO - Started process (PID=318277) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:09:56,387] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:09:56,388] {logging_mixin.py:112} INFO - [2020-07-22 13:09:56,388] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:09:56,599] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:09:56,763] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.379 seconds
[2020-07-22 13:10:26,575] {scheduler_job.py:153} INFO - Started process (PID=318905) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:10:26,581] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:10:26,582] {logging_mixin.py:112} INFO - [2020-07-22 13:10:26,581] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:10:26,839] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:10:26,966] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.391 seconds
[2020-07-22 13:10:59,036] {scheduler_job.py:153} INFO - Started process (PID=319624) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:10:59,043] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:10:59,045] {logging_mixin.py:112} INFO - [2020-07-22 13:10:59,044] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:10:59,420] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:10:59,543] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.508 seconds
[2020-07-22 13:11:33,765] {scheduler_job.py:153} INFO - Started process (PID=320376) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:11:33,768] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:11:33,769] {logging_mixin.py:112} INFO - [2020-07-22 13:11:33,769] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:11:33,842] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:11:33,971] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.206 seconds
[2020-07-22 13:12:04,053] {scheduler_job.py:153} INFO - Started process (PID=321045) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:12:04,056] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:12:04,057] {logging_mixin.py:112} INFO - [2020-07-22 13:12:04,057] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:12:04,377] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:12:04,488] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.436 seconds
[2020-07-22 13:12:28,305] {scheduler_job.py:153} INFO - Started process (PID=321603) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:12:28,309] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:12:28,309] {logging_mixin.py:112} INFO - [2020-07-22 13:12:28,309] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:12:28,562] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:12:28,660] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.355 seconds
[2020-07-22 13:12:59,527] {scheduler_job.py:153} INFO - Started process (PID=322306) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:12:59,530] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:12:59,530] {logging_mixin.py:112} INFO - [2020-07-22 13:12:59,530] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:12:59,792] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:12:59,875] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.348 seconds
[2020-07-22 13:13:25,665] {scheduler_job.py:153} INFO - Started process (PID=322877) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:13:25,671] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:13:25,672] {logging_mixin.py:112} INFO - [2020-07-22 13:13:25,672] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:13:25,975] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:13:26,064] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.399 seconds
[2020-07-22 13:13:56,696] {scheduler_job.py:153} INFO - Started process (PID=323553) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:13:56,700] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:13:56,701] {logging_mixin.py:112} INFO - [2020-07-22 13:13:56,700] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:13:57,028] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:13:57,544] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.847 seconds
[2020-07-22 13:14:26,192] {scheduler_job.py:153} INFO - Started process (PID=324248) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:14:26,195] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:14:26,196] {logging_mixin.py:112} INFO - [2020-07-22 13:14:26,196] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:14:26,400] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:14:26,500] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.308 seconds
[2020-07-22 13:14:50,206] {scheduler_job.py:153} INFO - Started process (PID=324731) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:14:50,208] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:14:50,209] {logging_mixin.py:112} INFO - [2020-07-22 13:14:50,209] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:14:50,448] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:14:50,552] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.346 seconds
[2020-07-22 13:15:15,320] {scheduler_job.py:153} INFO - Started process (PID=325381) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:15:15,326] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:15:15,327] {logging_mixin.py:112} INFO - [2020-07-22 13:15:15,326] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:15:15,547] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:15:15,647] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.327 seconds
[2020-07-22 13:15:45,444] {scheduler_job.py:153} INFO - Started process (PID=326084) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:15:45,448] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:15:45,448] {logging_mixin.py:112} INFO - [2020-07-22 13:15:45,448] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:15:45,629] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:15:45,737] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.293 seconds
[2020-07-22 13:16:15,025] {scheduler_job.py:153} INFO - Started process (PID=326706) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:16:15,029] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:16:15,030] {logging_mixin.py:112} INFO - [2020-07-22 13:16:15,030] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:16:15,306] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:16:15,436] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.411 seconds
[2020-07-22 13:16:45,259] {scheduler_job.py:153} INFO - Started process (PID=327361) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:16:45,262] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:16:45,262] {logging_mixin.py:112} INFO - [2020-07-22 13:16:45,262] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:16:45,539] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:16:45,641] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.383 seconds
[2020-07-22 13:17:14,825] {scheduler_job.py:153} INFO - Started process (PID=328049) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:17:14,828] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:17:14,828] {logging_mixin.py:112} INFO - [2020-07-22 13:17:14,828] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:17:15,086] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:17:15,183] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.358 seconds
[2020-07-22 13:17:38,978] {scheduler_job.py:153} INFO - Started process (PID=328580) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:17:38,990] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:17:38,991] {logging_mixin.py:112} INFO - [2020-07-22 13:17:38,991] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:17:39,223] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:17:39,368] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.390 seconds
[2020-07-22 13:18:04,059] {scheduler_job.py:153} INFO - Started process (PID=329210) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:18:04,061] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:18:04,062] {logging_mixin.py:112} INFO - [2020-07-22 13:18:04,061] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:18:04,262] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:18:04,375] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.316 seconds
[2020-07-22 13:18:33,909] {scheduler_job.py:153} INFO - Started process (PID=329980) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:18:33,914] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:18:33,915] {logging_mixin.py:112} INFO - [2020-07-22 13:18:33,914] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:18:34,391] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:18:34,551] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.642 seconds
[2020-07-22 13:18:57,969] {scheduler_job.py:153} INFO - Started process (PID=330502) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:18:57,972] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:18:57,972] {logging_mixin.py:112} INFO - [2020-07-22 13:18:57,972] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:18:58,174] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:18:58,277] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.308 seconds
[2020-07-22 13:19:29,667] {scheduler_job.py:153} INFO - Started process (PID=331228) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:19:29,669] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:19:29,670] {logging_mixin.py:112} INFO - [2020-07-22 13:19:29,669] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:19:29,847] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:19:29,957] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.290 seconds
[2020-07-22 13:19:58,982] {scheduler_job.py:153} INFO - Started process (PID=331906) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:19:58,985] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:19:58,986] {logging_mixin.py:112} INFO - [2020-07-22 13:19:58,986] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:19:59,294] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:19:59,394] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.412 seconds
[2020-07-22 13:20:23,531] {scheduler_job.py:153} INFO - Started process (PID=332429) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:20:23,535] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:20:23,536] {logging_mixin.py:112} INFO - [2020-07-22 13:20:23,536] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:20:23,746] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:20:23,841] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.310 seconds
[2020-07-22 13:20:48,842] {scheduler_job.py:153} INFO - Started process (PID=333061) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:20:48,845] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:20:48,846] {logging_mixin.py:112} INFO - [2020-07-22 13:20:48,846] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:20:49,151] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:20:49,271] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.429 seconds
[2020-07-22 13:21:18,690] {scheduler_job.py:153} INFO - Started process (PID=333750) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:21:18,694] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:21:18,694] {logging_mixin.py:112} INFO - [2020-07-22 13:21:18,694] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:21:18,895] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:21:18,993] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.303 seconds
[2020-07-22 13:21:43,570] {scheduler_job.py:153} INFO - Started process (PID=334275) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:21:43,573] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:21:43,573] {logging_mixin.py:112} INFO - [2020-07-22 13:21:43,573] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:21:43,779] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:21:43,945] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.376 seconds
[2020-07-22 13:22:13,643] {scheduler_job.py:153} INFO - Started process (PID=334971) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:22:13,646] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:22:13,646] {logging_mixin.py:112} INFO - [2020-07-22 13:22:13,646] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:22:13,897] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:22:14,016] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.373 seconds
[2020-07-22 13:22:37,666] {scheduler_job.py:153} INFO - Started process (PID=335556) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:22:37,669] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:22:37,670] {logging_mixin.py:112} INFO - [2020-07-22 13:22:37,670] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:22:37,924] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:22:38,030] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.364 seconds
[2020-07-22 13:23:01,681] {scheduler_job.py:153} INFO - Started process (PID=336069) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:23:01,685] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:23:01,686] {logging_mixin.py:112} INFO - [2020-07-22 13:23:01,685] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:23:01,885] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:23:01,987] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.306 seconds
[2020-07-22 13:23:32,745] {scheduler_job.py:153} INFO - Started process (PID=336776) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:23:32,748] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:23:32,749] {logging_mixin.py:112} INFO - [2020-07-22 13:23:32,749] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:23:33,046] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:23:33,155] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.409 seconds
[2020-07-22 13:23:57,901] {scheduler_job.py:153} INFO - Started process (PID=337370) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:23:57,908] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:23:57,908] {logging_mixin.py:112} INFO - [2020-07-22 13:23:57,908] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:23:58,127] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:23:58,230] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.329 seconds
[2020-07-22 13:24:22,222] {scheduler_job.py:153} INFO - Started process (PID=337932) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:24:22,225] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:24:22,226] {logging_mixin.py:112} INFO - [2020-07-22 13:24:22,226] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:24:22,477] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:24:22,574] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.353 seconds
[2020-07-22 13:24:51,719] {scheduler_job.py:153} INFO - Started process (PID=338616) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:24:51,723] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:24:51,724] {logging_mixin.py:112} INFO - [2020-07-22 13:24:51,724] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:24:51,900] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:24:52,012] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.293 seconds
[2020-07-22 13:25:15,785] {scheduler_job.py:153} INFO - Started process (PID=339171) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:25:15,787] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:25:15,788] {logging_mixin.py:112} INFO - [2020-07-22 13:25:15,788] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:25:15,995] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:25:16,097] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.312 seconds
[2020-07-22 13:25:40,433] {scheduler_job.py:153} INFO - Started process (PID=339736) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:25:40,437] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:25:40,437] {logging_mixin.py:112} INFO - [2020-07-22 13:25:40,437] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:25:40,714] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:25:40,824] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.392 seconds
[2020-07-22 13:26:09,762] {scheduler_job.py:153} INFO - Started process (PID=340426) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:26:09,766] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:26:09,766] {logging_mixin.py:112} INFO - [2020-07-22 13:26:09,766] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:26:09,971] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:26:10,073] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.311 seconds
[2020-07-22 13:26:34,588] {scheduler_job.py:153} INFO - Started process (PID=340987) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:26:34,591] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:26:34,592] {logging_mixin.py:112} INFO - [2020-07-22 13:26:34,591] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:26:34,835] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:26:34,945] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.357 seconds
[2020-07-22 13:27:03,753] {scheduler_job.py:153} INFO - Started process (PID=341619) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:27:03,758] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:27:03,758] {logging_mixin.py:112} INFO - [2020-07-22 13:27:03,758] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:27:04,038] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:27:04,140] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.386 seconds
[2020-07-22 13:27:28,051] {scheduler_job.py:153} INFO - Started process (PID=342141) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:27:28,056] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:27:28,057] {logging_mixin.py:112} INFO - [2020-07-22 13:27:28,057] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:27:28,269] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:27:28,372] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.321 seconds
[2020-07-22 13:27:53,205] {scheduler_job.py:153} INFO - Started process (PID=342763) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:27:53,208] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:27:53,209] {logging_mixin.py:112} INFO - [2020-07-22 13:27:53,209] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:27:53,614] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:27:53,722] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.517 seconds
[2020-07-22 13:28:22,589] {scheduler_job.py:153} INFO - Started process (PID=343443) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:28:22,592] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:28:22,592] {logging_mixin.py:112} INFO - [2020-07-22 13:28:22,592] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:28:22,797] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:28:22,933] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.344 seconds
[2020-07-22 13:28:46,809] {scheduler_job.py:153} INFO - Started process (PID=343945) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:28:46,811] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:28:46,812] {logging_mixin.py:112} INFO - [2020-07-22 13:28:46,811] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:28:47,058] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:28:47,393] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.584 seconds
[2020-07-22 13:29:17,097] {scheduler_job.py:153} INFO - Started process (PID=344646) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:29:17,099] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:29:17,100] {logging_mixin.py:112} INFO - [2020-07-22 13:29:17,099] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:29:17,306] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:29:17,404] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.307 seconds
[2020-07-22 13:29:46,267] {scheduler_job.py:153} INFO - Started process (PID=345315) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:29:46,273] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:29:46,274] {logging_mixin.py:112} INFO - [2020-07-22 13:29:46,274] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:29:46,601] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:29:46,737] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.469 seconds
[2020-07-22 13:30:10,518] {scheduler_job.py:153} INFO - Started process (PID=345836) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:30:10,523] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:30:10,523] {logging_mixin.py:112} INFO - [2020-07-22 13:30:10,523] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:30:10,789] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:30:10,957] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.439 seconds
[2020-07-22 13:30:44,144] {scheduler_job.py:153} INFO - Started process (PID=346673) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:30:44,149] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:30:44,150] {logging_mixin.py:112} INFO - [2020-07-22 13:30:44,149] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:30:44,548] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:30:44,702] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.559 seconds
[2020-07-22 13:31:16,096] {scheduler_job.py:153} INFO - Started process (PID=347464) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:31:16,103] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:31:16,104] {logging_mixin.py:112} INFO - [2020-07-22 13:31:16,104] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:31:16,217] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:31:16,560] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.465 seconds
[2020-07-22 13:31:46,125] {scheduler_job.py:153} INFO - Started process (PID=348124) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:31:46,129] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:31:46,130] {logging_mixin.py:112} INFO - [2020-07-22 13:31:46,129] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:31:46,429] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:31:46,558] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.434 seconds
[2020-07-22 13:32:15,525] {scheduler_job.py:153} INFO - Started process (PID=348778) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:32:15,528] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:32:15,528] {logging_mixin.py:112} INFO - [2020-07-22 13:32:15,528] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:32:15,732] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:32:15,839] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.314 seconds
[2020-07-22 13:32:51,183] {scheduler_job.py:153} INFO - Started process (PID=349536) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:32:51,186] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:32:51,186] {logging_mixin.py:112} INFO - [2020-07-22 13:32:51,186] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:32:51,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:32:51,835] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.652 seconds
[2020-07-22 13:33:16,265] {scheduler_job.py:153} INFO - Started process (PID=350124) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:33:16,272] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:33:16,273] {logging_mixin.py:112} INFO - [2020-07-22 13:33:16,273] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:33:16,756] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:33:16,870] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.605 seconds
[2020-07-22 13:33:46,104] {scheduler_job.py:153} INFO - Started process (PID=350811) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:33:46,108] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:33:46,108] {logging_mixin.py:112} INFO - [2020-07-22 13:33:46,108] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:33:46,366] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:33:46,505] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.401 seconds
[2020-07-22 13:34:21,470] {scheduler_job.py:153} INFO - Started process (PID=351658) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:34:21,485] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:34:21,486] {logging_mixin.py:112} INFO - [2020-07-22 13:34:21,486] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:34:21,764] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:34:21,868] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.398 seconds
[2020-07-22 13:34:50,676] {scheduler_job.py:153} INFO - Started process (PID=352352) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:34:50,680] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:34:50,681] {logging_mixin.py:112} INFO - [2020-07-22 13:34:50,680] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:34:50,891] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:34:51,040] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.364 seconds
[2020-07-22 13:35:20,126] {scheduler_job.py:153} INFO - Started process (PID=353086) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:35:20,129] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:35:20,129] {logging_mixin.py:112} INFO - [2020-07-22 13:35:20,129] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:35:20,380] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:35:20,475] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.349 seconds
[2020-07-22 13:35:51,238] {scheduler_job.py:153} INFO - Started process (PID=353802) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:35:51,241] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:35:51,242] {logging_mixin.py:112} INFO - [2020-07-22 13:35:51,242] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:35:51,753] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:35:51,912] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.674 seconds
[2020-07-22 13:36:22,284] {scheduler_job.py:153} INFO - Started process (PID=354623) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:36:22,288] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:36:22,288] {logging_mixin.py:112} INFO - [2020-07-22 13:36:22,288] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:36:22,603] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:36:22,773] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.489 seconds
[2020-07-22 13:36:52,761] {scheduler_job.py:153} INFO - Started process (PID=355384) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:36:52,766] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:36:52,767] {logging_mixin.py:112} INFO - [2020-07-22 13:36:52,767] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:36:53,004] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:36:53,140] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.379 seconds
[2020-07-22 13:37:23,493] {scheduler_job.py:153} INFO - Started process (PID=356055) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:37:23,496] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:37:23,496] {logging_mixin.py:112} INFO - [2020-07-22 13:37:23,496] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:37:23,780] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:37:23,923] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.431 seconds
[2020-07-22 13:37:58,809] {scheduler_job.py:153} INFO - Started process (PID=356814) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:37:58,811] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:37:58,812] {logging_mixin.py:112} INFO - [2020-07-22 13:37:58,812] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:37:59,065] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:37:59,157] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.348 seconds
[2020-07-22 13:38:28,842] {scheduler_job.py:153} INFO - Started process (PID=357601) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:38:28,844] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:38:28,845] {logging_mixin.py:112} INFO - [2020-07-22 13:38:28,845] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:38:29,060] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:38:29,152] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.310 seconds
[2020-07-22 13:38:52,973] {scheduler_job.py:153} INFO - Started process (PID=358117) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:38:52,976] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:38:52,976] {logging_mixin.py:112} INFO - [2020-07-22 13:38:52,976] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:38:53,226] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:38:53,393] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.420 seconds
[2020-07-22 13:39:23,710] {scheduler_job.py:153} INFO - Started process (PID=358829) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:39:23,714] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:39:23,714] {logging_mixin.py:112} INFO - [2020-07-22 13:39:23,714] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:39:23,928] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:39:24,044] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.333 seconds
[2020-07-22 13:39:53,088] {scheduler_job.py:153} INFO - Started process (PID=359513) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:39:53,090] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:39:53,091] {logging_mixin.py:112} INFO - [2020-07-22 13:39:53,091] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:39:53,344] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:39:53,481] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.394 seconds
[2020-07-22 13:40:18,684] {scheduler_job.py:153} INFO - Started process (PID=360165) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:40:18,687] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:40:18,688] {logging_mixin.py:112} INFO - [2020-07-22 13:40:18,688] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:40:18,919] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:40:19,051] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.367 seconds
[2020-07-22 13:40:55,126] {scheduler_job.py:153} INFO - Started process (PID=361047) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:40:55,130] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:40:55,130] {logging_mixin.py:112} INFO - [2020-07-22 13:40:55,130] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:40:55,330] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:40:55,421] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.295 seconds
[2020-07-22 13:41:25,431] {scheduler_job.py:153} INFO - Started process (PID=361748) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:41:25,435] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:41:25,435] {logging_mixin.py:112} INFO - [2020-07-22 13:41:25,435] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:41:25,628] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:41:25,745] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.313 seconds
[2020-07-22 13:41:56,749] {scheduler_job.py:153} INFO - Started process (PID=362425) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:41:56,752] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:41:56,753] {logging_mixin.py:112} INFO - [2020-07-22 13:41:56,753] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:41:57,016] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:41:57,135] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.387 seconds
[2020-07-22 13:42:21,555] {scheduler_job.py:153} INFO - Started process (PID=362972) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:42:21,558] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:42:21,558] {logging_mixin.py:112} INFO - [2020-07-22 13:42:21,558] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:42:22,865] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:42:23,039] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.484 seconds
[2020-07-22 13:42:51,442] {scheduler_job.py:153} INFO - Started process (PID=363652) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:42:51,445] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:42:51,445] {logging_mixin.py:112} INFO - [2020-07-22 13:42:51,445] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:42:51,848] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:42:52,061] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.620 seconds
[2020-07-22 13:43:20,906] {scheduler_job.py:153} INFO - Started process (PID=364406) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:43:20,909] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:43:20,910] {logging_mixin.py:112} INFO - [2020-07-22 13:43:20,910] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:43:21,143] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:43:21,296] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.390 seconds
[2020-07-22 13:43:45,263] {scheduler_job.py:153} INFO - Started process (PID=364972) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:43:45,266] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:43:45,266] {logging_mixin.py:112} INFO - [2020-07-22 13:43:45,266] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:43:45,569] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:43:45,678] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.415 seconds
[2020-07-22 13:44:14,856] {scheduler_job.py:153} INFO - Started process (PID=365652) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:44:14,860] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:44:14,860] {logging_mixin.py:112} INFO - [2020-07-22 13:44:14,860] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:44:15,060] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:44:15,159] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.303 seconds
[2020-07-22 13:44:39,120] {scheduler_job.py:153} INFO - Started process (PID=366180) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:44:39,125] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:44:39,125] {logging_mixin.py:112} INFO - [2020-07-22 13:44:39,125] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:44:39,347] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:44:39,445] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.325 seconds
[2020-07-22 13:45:04,009] {scheduler_job.py:153} INFO - Started process (PID=366804) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:45:04,012] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:45:04,012] {logging_mixin.py:112} INFO - [2020-07-22 13:45:04,012] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:45:04,219] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:45:04,371] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.362 seconds
[2020-07-22 13:45:39,915] {scheduler_job.py:153} INFO - Started process (PID=367607) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:45:39,919] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:45:39,919] {logging_mixin.py:112} INFO - [2020-07-22 13:45:39,919] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:45:40,147] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:45:40,272] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.357 seconds
[2020-07-22 13:46:04,276] {scheduler_job.py:153} INFO - Started process (PID=368137) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:46:04,279] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:46:04,279] {logging_mixin.py:112} INFO - [2020-07-22 13:46:04,279] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:46:04,490] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:46:04,586] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.310 seconds
[2020-07-22 13:46:35,431] {scheduler_job.py:153} INFO - Started process (PID=368832) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:46:35,434] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:46:35,435] {logging_mixin.py:112} INFO - [2020-07-22 13:46:35,435] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:46:35,878] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:46:36,068] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.637 seconds
[2020-07-22 13:47:10,492] {scheduler_job.py:153} INFO - Started process (PID=369581) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:47:10,495] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:47:10,495] {logging_mixin.py:112} INFO - [2020-07-22 13:47:10,495] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:47:10,752] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:47:10,865] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.373 seconds
[2020-07-22 13:47:40,190] {scheduler_job.py:153} INFO - Started process (PID=370214) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:47:40,196] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:47:40,196] {logging_mixin.py:112} INFO - [2020-07-22 13:47:40,196] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:47:40,414] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:47:40,505] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.314 seconds
[2020-07-22 13:48:06,004] {scheduler_job.py:153} INFO - Started process (PID=370816) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:48:06,007] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:48:06,008] {logging_mixin.py:112} INFO - [2020-07-22 13:48:06,008] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:48:06,209] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:48:06,319] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.315 seconds
[2020-07-22 13:48:40,324] {scheduler_job.py:153} INFO - Started process (PID=371556) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:48:40,327] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:48:40,327] {logging_mixin.py:112} INFO - [2020-07-22 13:48:40,327] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:48:40,529] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:48:40,635] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.310 seconds
[2020-07-22 13:49:09,829] {scheduler_job.py:153} INFO - Started process (PID=372226) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:49:09,838] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:49:09,854] {logging_mixin.py:112} INFO - [2020-07-22 13:49:09,839] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:49:10,154] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:49:10,280] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.451 seconds
[2020-07-22 13:49:39,617] {scheduler_job.py:153} INFO - Started process (PID=372837) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:49:39,622] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:49:39,625] {logging_mixin.py:112} INFO - [2020-07-22 13:49:39,623] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:49:39,874] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:49:40,010] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.394 seconds
[2020-07-22 13:50:10,008] {scheduler_job.py:153} INFO - Started process (PID=373533) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:50:10,011] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:50:10,011] {logging_mixin.py:112} INFO - [2020-07-22 13:50:10,011] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:50:10,229] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:50:10,339] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.331 seconds
[2020-07-22 13:50:39,174] {scheduler_job.py:153} INFO - Started process (PID=374208) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:50:39,177] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:50:39,177] {logging_mixin.py:112} INFO - [2020-07-22 13:50:39,177] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:50:39,408] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:50:39,552] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.377 seconds
[2020-07-22 13:51:03,526] {scheduler_job.py:153} INFO - Started process (PID=374704) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:51:03,532] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:51:03,533] {logging_mixin.py:112} INFO - [2020-07-22 13:51:03,533] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:51:03,793] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:51:03,931] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.405 seconds
[2020-07-22 13:51:39,400] {scheduler_job.py:153} INFO - Started process (PID=375538) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:51:39,405] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:51:39,405] {logging_mixin.py:112} INFO - [2020-07-22 13:51:39,405] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:51:39,661] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:51:39,787] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.388 seconds
[2020-07-22 13:52:09,542] {scheduler_job.py:153} INFO - Started process (PID=376237) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:52:09,546] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:52:09,546] {logging_mixin.py:112} INFO - [2020-07-22 13:52:09,546] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:52:09,943] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:52:10,047] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.504 seconds
[2020-07-22 13:52:39,405] {scheduler_job.py:153} INFO - Started process (PID=376849) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:52:39,412] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:52:39,413] {logging_mixin.py:112} INFO - [2020-07-22 13:52:39,412] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:52:39,829] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:52:40,822] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.417 seconds
[2020-07-22 13:53:04,889] {scheduler_job.py:153} INFO - Started process (PID=377453) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:53:04,892] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:53:04,892] {logging_mixin.py:112} INFO - [2020-07-22 13:53:04,892] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:53:05,091] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:53:05,215] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.327 seconds
[2020-07-22 13:53:34,743] {scheduler_job.py:153} INFO - Started process (PID=378199) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:53:34,747] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:53:34,748] {logging_mixin.py:112} INFO - [2020-07-22 13:53:34,747] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:53:34,981] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:53:35,085] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.342 seconds
[2020-07-22 13:54:05,111] {scheduler_job.py:153} INFO - Started process (PID=378928) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:54:05,115] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:54:05,116] {logging_mixin.py:112} INFO - [2020-07-22 13:54:05,115] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:54:05,349] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:54:05,541] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.431 seconds
[2020-07-22 13:54:35,617] {scheduler_job.py:153} INFO - Started process (PID=379726) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:54:35,621] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:54:35,621] {logging_mixin.py:112} INFO - [2020-07-22 13:54:35,621] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:54:35,840] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:54:36,015] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.398 seconds
[2020-07-22 13:55:05,863] {scheduler_job.py:153} INFO - Started process (PID=380430) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:55:05,866] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:55:05,867] {logging_mixin.py:112} INFO - [2020-07-22 13:55:05,867] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:55:06,121] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:55:06,237] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.374 seconds
[2020-07-22 13:55:35,319] {scheduler_job.py:153} INFO - Started process (PID=381103) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:55:35,324] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:55:35,325] {logging_mixin.py:112} INFO - [2020-07-22 13:55:35,324] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:55:35,619] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:55:35,783] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.464 seconds
[2020-07-22 13:55:59,558] {scheduler_job.py:153} INFO - Started process (PID=381652) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:55:59,563] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:55:59,564] {logging_mixin.py:112} INFO - [2020-07-22 13:55:59,564] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:55:59,772] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:55:59,885] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.327 seconds
[2020-07-22 13:56:35,842] {scheduler_job.py:153} INFO - Started process (PID=382472) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:56:35,846] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:56:35,847] {logging_mixin.py:112} INFO - [2020-07-22 13:56:35,847] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:56:36,066] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:56:36,210] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.369 seconds
[2020-07-22 13:57:05,568] {scheduler_job.py:153} INFO - Started process (PID=383144) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:57:05,574] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:57:05,575] {logging_mixin.py:112} INFO - [2020-07-22 13:57:05,575] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:57:05,824] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:57:05,930] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.362 seconds
[2020-07-22 13:57:30,483] {scheduler_job.py:153} INFO - Started process (PID=383699) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:57:30,486] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:57:30,487] {logging_mixin.py:112} INFO - [2020-07-22 13:57:30,487] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:57:30,746] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:57:30,833] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.351 seconds
[2020-07-22 13:58:01,498] {scheduler_job.py:153} INFO - Started process (PID=384401) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:58:01,501] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:58:01,502] {logging_mixin.py:112} INFO - [2020-07-22 13:58:01,502] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:58:01,772] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:58:01,881] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.383 seconds
[2020-07-22 13:58:25,955] {scheduler_job.py:153} INFO - Started process (PID=384868) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:58:25,958] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:58:25,958] {logging_mixin.py:112} INFO - [2020-07-22 13:58:25,958] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:58:26,234] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:58:26,347] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.393 seconds
[2020-07-22 13:58:52,617] {scheduler_job.py:153} INFO - Started process (PID=385481) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:58:52,622] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:58:52,623] {logging_mixin.py:112} INFO - [2020-07-22 13:58:52,622] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:58:52,850] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:58:52,967] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.350 seconds
[2020-07-22 13:59:17,000] {scheduler_job.py:153} INFO - Started process (PID=385917) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:59:17,003] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:59:17,003] {logging_mixin.py:112} INFO - [2020-07-22 13:59:17,003] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:59:17,269] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:59:17,383] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.383 seconds
[2020-07-22 13:59:42,205] {scheduler_job.py:153} INFO - Started process (PID=386479) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:59:42,209] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 13:59:42,210] {logging_mixin.py:112} INFO - [2020-07-22 13:59:42,210] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:59:42,463] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 13:59:42,666] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.461 seconds
[2020-07-22 14:00:12,454] {scheduler_job.py:153} INFO - Started process (PID=387107) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:00:12,458] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:00:12,458] {logging_mixin.py:112} INFO - [2020-07-22 14:00:12,458] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:00:13,186] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:00:13,328] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.874 seconds
[2020-07-22 14:00:55,542] {scheduler_job.py:153} INFO - Started process (PID=388053) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:00:55,545] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:00:55,545] {logging_mixin.py:112} INFO - [2020-07-22 14:00:55,545] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:00:55,750] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:00:55,847] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.305 seconds
[2020-07-22 14:01:26,134] {scheduler_job.py:153} INFO - Started process (PID=388747) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:01:26,139] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:01:26,140] {logging_mixin.py:112} INFO - [2020-07-22 14:01:26,140] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:01:26,440] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:01:26,560] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.426 seconds
[2020-07-22 14:01:56,035] {scheduler_job.py:153} INFO - Started process (PID=389473) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:01:56,040] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:01:56,041] {logging_mixin.py:112} INFO - [2020-07-22 14:01:56,040] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:01:56,345] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:01:56,471] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.436 seconds
[2020-07-22 14:02:20,129] {scheduler_job.py:153} INFO - Started process (PID=390028) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:02:20,132] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:02:20,132] {logging_mixin.py:112} INFO - [2020-07-22 14:02:20,132] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:02:20,444] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:02:20,552] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.424 seconds
[2020-07-22 14:02:50,749] {scheduler_job.py:153} INFO - Started process (PID=390724) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:02:50,754] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:02:50,754] {logging_mixin.py:112} INFO - [2020-07-22 14:02:50,754] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:02:50,957] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:02:51,068] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.319 seconds
[2020-07-22 14:03:20,072] {scheduler_job.py:153} INFO - Started process (PID=391376) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:03:20,076] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:03:20,077] {logging_mixin.py:112} INFO - [2020-07-22 14:03:20,077] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:03:20,392] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:03:20,500] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.428 seconds
[2020-07-22 14:03:44,383] {scheduler_job.py:153} INFO - Started process (PID=391972) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:03:44,387] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:03:44,388] {logging_mixin.py:112} INFO - [2020-07-22 14:03:44,388] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:03:44,592] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:03:44,707] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.325 seconds
[2020-07-22 14:04:13,603] {scheduler_job.py:153} INFO - Started process (PID=392644) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:04:13,606] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:04:13,606] {logging_mixin.py:112} INFO - [2020-07-22 14:04:13,606] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:04:13,827] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:04:13,926] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.324 seconds
[2020-07-22 14:04:43,914] {scheduler_job.py:153} INFO - Started process (PID=393309) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:04:43,918] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:04:43,919] {logging_mixin.py:112} INFO - [2020-07-22 14:04:43,919] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:04:44,163] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:04:44,308] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.393 seconds
[2020-07-22 14:05:08,151] {scheduler_job.py:153} INFO - Started process (PID=393864) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:05:08,154] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:05:08,154] {logging_mixin.py:112} INFO - [2020-07-22 14:05:08,154] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:05:08,355] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:05:08,470] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.320 seconds
[2020-07-22 14:05:37,901] {scheduler_job.py:153} INFO - Started process (PID=394556) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:05:37,904] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:05:37,904] {logging_mixin.py:112} INFO - [2020-07-22 14:05:37,904] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:05:38,107] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:05:38,214] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.313 seconds
[2020-07-22 14:06:01,932] {scheduler_job.py:153} INFO - Started process (PID=395086) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:06:01,940] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:06:01,940] {logging_mixin.py:112} INFO - [2020-07-22 14:06:01,940] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:06:02,183] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:06:02,296] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.364 seconds
[2020-07-22 14:06:26,202] {scheduler_job.py:153} INFO - Started process (PID=395672) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:06:26,205] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:06:26,205] {logging_mixin.py:112} INFO - [2020-07-22 14:06:26,205] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:06:26,403] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:06:26,521] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.319 seconds
[2020-07-22 14:06:55,744] {scheduler_job.py:153} INFO - Started process (PID=396359) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:06:55,746] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:06:55,748] {logging_mixin.py:112} INFO - [2020-07-22 14:06:55,747] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:06:55,981] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:06:56,128] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.384 seconds
[2020-07-22 14:07:19,528] {scheduler_job.py:153} INFO - Started process (PID=396869) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:07:19,530] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:07:19,531] {logging_mixin.py:112} INFO - [2020-07-22 14:07:19,531] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:07:19,745] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:07:19,878] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.351 seconds
[2020-07-22 14:07:44,733] {scheduler_job.py:153} INFO - Started process (PID=397510) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:07:44,738] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:07:44,738] {logging_mixin.py:112} INFO - [2020-07-22 14:07:44,738] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:07:44,938] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:07:45,053] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.320 seconds
[2020-07-22 14:08:08,669] {scheduler_job.py:153} INFO - Started process (PID=398088) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:08:08,672] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:08:08,672] {logging_mixin.py:112} INFO - [2020-07-22 14:08:08,672] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:08:09,378] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:08:09,488] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.820 seconds
[2020-07-22 14:08:32,658] {scheduler_job.py:153} INFO - Started process (PID=398610) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:08:32,660] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:08:32,661] {logging_mixin.py:112} INFO - [2020-07-22 14:08:32,661] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:08:32,862] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:08:32,969] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.311 seconds
[2020-07-22 14:09:02,661] {scheduler_job.py:153} INFO - Started process (PID=399298) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:09:02,664] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:09:02,665] {logging_mixin.py:112} INFO - [2020-07-22 14:09:02,665] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:09:02,913] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:09:03,012] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.351 seconds
[2020-07-22 14:09:28,181] {scheduler_job.py:153} INFO - Started process (PID=399876) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:09:28,185] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:09:28,186] {logging_mixin.py:112} INFO - [2020-07-22 14:09:28,185] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:09:28,446] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:09:28,549] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.368 seconds
[2020-07-22 14:09:52,720] {scheduler_job.py:153} INFO - Started process (PID=400467) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:09:52,723] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:09:52,723] {logging_mixin.py:112} INFO - [2020-07-22 14:09:52,723] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:09:52,923] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:09:53,031] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.311 seconds
[2020-07-22 14:10:21,882] {scheduler_job.py:153} INFO - Started process (PID=401131) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:10:21,884] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:10:21,884] {logging_mixin.py:112} INFO - [2020-07-22 14:10:21,884] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:10:22,153] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:10:22,267] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.385 seconds
[2020-07-22 14:10:46,338] {scheduler_job.py:153} INFO - Started process (PID=401679) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:10:46,342] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:10:46,342] {logging_mixin.py:112} INFO - [2020-07-22 14:10:46,342] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:10:46,572] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:10:46,723] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.385 seconds
[2020-07-22 14:11:10,806] {scheduler_job.py:153} INFO - Started process (PID=402252) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:11:10,808] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:11:10,809] {logging_mixin.py:112} INFO - [2020-07-22 14:11:10,809] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:11:11,062] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:11:11,171] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.365 seconds
[2020-07-22 14:11:35,244] {scheduler_job.py:153} INFO - Started process (PID=402908) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:11:35,247] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:11:35,247] {logging_mixin.py:112} INFO - [2020-07-22 14:11:35,247] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:11:35,454] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:11:35,584] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.340 seconds
[2020-07-22 14:11:59,233] {scheduler_job.py:153} INFO - Started process (PID=403419) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:11:59,236] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:11:59,237] {logging_mixin.py:112} INFO - [2020-07-22 14:11:59,236] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:11:59,437] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:11:59,556] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.323 seconds
[2020-07-22 14:12:29,113] {scheduler_job.py:153} INFO - Started process (PID=404105) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:12:29,116] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:12:29,117] {logging_mixin.py:112} INFO - [2020-07-22 14:12:29,117] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:12:29,389] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:12:29,521] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.408 seconds
[2020-07-22 14:12:53,319] {scheduler_job.py:153} INFO - Started process (PID=404697) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:12:53,324] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:12:53,325] {logging_mixin.py:112} INFO - [2020-07-22 14:12:53,325] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:12:53,620] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:12:53,888] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.570 seconds
[2020-07-22 14:13:17,380] {scheduler_job.py:153} INFO - Started process (PID=405240) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:13:17,383] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:13:17,384] {logging_mixin.py:112} INFO - [2020-07-22 14:13:17,383] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:13:17,578] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:13:17,744] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.364 seconds
[2020-07-22 14:13:46,720] {scheduler_job.py:153} INFO - Started process (PID=405942) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:13:46,722] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:13:46,723] {logging_mixin.py:112} INFO - [2020-07-22 14:13:46,722] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:13:47,125] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:13:47,239] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.520 seconds
[2020-07-22 14:14:10,618] {scheduler_job.py:153} INFO - Started process (PID=406486) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:14:10,621] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:14:10,621] {logging_mixin.py:112} INFO - [2020-07-22 14:14:10,621] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:14:10,882] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:14:10,970] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.352 seconds
[2020-07-22 14:14:34,881] {scheduler_job.py:153} INFO - Started process (PID=407251) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:14:34,884] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:14:34,885] {logging_mixin.py:112} INFO - [2020-07-22 14:14:34,885] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:14:35,135] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:14:35,254] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.373 seconds
[2020-07-22 14:15:03,860] {scheduler_job.py:153} INFO - Started process (PID=407941) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:15:03,863] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:15:03,863] {logging_mixin.py:112} INFO - [2020-07-22 14:15:03,863] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:15:04,085] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:15:04,178] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.318 seconds
[2020-07-22 14:15:28,566] {scheduler_job.py:153} INFO - Started process (PID=408475) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:15:28,570] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:15:28,578] {logging_mixin.py:112} INFO - [2020-07-22 14:15:28,578] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:15:28,783] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:15:28,901] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.335 seconds
[2020-07-22 14:15:53,287] {scheduler_job.py:153} INFO - Started process (PID=409075) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:15:53,291] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:15:53,291] {logging_mixin.py:112} INFO - [2020-07-22 14:15:53,291] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:15:53,484] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:15:54,299] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.011 seconds
[2020-07-22 14:16:17,471] {scheduler_job.py:153} INFO - Started process (PID=409692) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:16:17,475] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:16:17,476] {logging_mixin.py:112} INFO - [2020-07-22 14:16:17,476] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:16:17,677] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:16:17,817] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.345 seconds
[2020-07-22 14:16:42,368] {scheduler_job.py:153} INFO - Started process (PID=410215) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:16:42,371] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:16:42,372] {logging_mixin.py:112} INFO - [2020-07-22 14:16:42,372] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:16:42,573] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:16:42,671] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.302 seconds
[2020-07-22 14:17:12,434] {scheduler_job.py:153} INFO - Started process (PID=410916) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:17:12,438] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:17:12,438] {logging_mixin.py:112} INFO - [2020-07-22 14:17:12,438] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:17:12,639] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:17:12,744] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.310 seconds
[2020-07-22 14:17:37,036] {scheduler_job.py:153} INFO - Started process (PID=411491) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:17:37,040] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:17:37,041] {logging_mixin.py:112} INFO - [2020-07-22 14:17:37,041] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:17:37,245] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:17:37,345] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.309 seconds
[2020-07-22 14:18:01,697] {scheduler_job.py:153} INFO - Started process (PID=412051) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:18:01,700] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:18:01,701] {logging_mixin.py:112} INFO - [2020-07-22 14:18:01,701] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:18:01,901] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:18:01,992] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.295 seconds
[2020-07-22 14:18:30,930] {scheduler_job.py:153} INFO - Started process (PID=412735) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:18:30,933] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:18:30,933] {logging_mixin.py:112} INFO - [2020-07-22 14:18:30,933] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:18:31,139] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:18:31,250] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.320 seconds
[2020-07-22 14:18:55,185] {scheduler_job.py:153} INFO - Started process (PID=413267) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:18:55,188] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:18:55,188] {logging_mixin.py:112} INFO - [2020-07-22 14:18:55,188] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:18:55,395] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:18:55,503] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.318 seconds
[2020-07-22 14:19:19,312] {scheduler_job.py:153} INFO - Started process (PID=413849) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:19:19,315] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:19:19,316] {logging_mixin.py:112} INFO - [2020-07-22 14:19:19,315] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:19:19,529] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:19:19,630] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.319 seconds
[2020-07-22 14:19:43,592] {scheduler_job.py:153} INFO - Started process (PID=414469) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:19:43,596] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:19:43,597] {logging_mixin.py:112} INFO - [2020-07-22 14:19:43,597] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:19:43,822] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:19:43,976] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.385 seconds
[2020-07-22 14:20:09,362] {scheduler_job.py:153} INFO - Started process (PID=415007) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:20:09,365] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:20:09,366] {logging_mixin.py:112} INFO - [2020-07-22 14:20:09,365] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:20:09,666] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:20:09,868] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.506 seconds
[2020-07-22 14:20:39,507] {scheduler_job.py:153} INFO - Started process (PID=415696) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:20:39,510] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:20:39,510] {logging_mixin.py:112} INFO - [2020-07-22 14:20:39,510] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:20:39,719] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:20:39,899] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.392 seconds
[2020-07-22 14:21:03,794] {scheduler_job.py:153} INFO - Started process (PID=416294) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:21:03,798] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:21:03,798] {logging_mixin.py:112} INFO - [2020-07-22 14:21:03,798] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:21:04,021] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:21:04,123] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.329 seconds
[2020-07-22 14:21:27,736] {scheduler_job.py:153} INFO - Started process (PID=416810) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:21:27,739] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:21:27,740] {logging_mixin.py:112} INFO - [2020-07-22 14:21:27,740] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:21:27,942] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:21:28,041] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.305 seconds
[2020-07-22 14:21:57,779] {scheduler_job.py:153} INFO - Started process (PID=417499) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:21:57,782] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:21:57,782] {logging_mixin.py:112} INFO - [2020-07-22 14:21:57,782] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:21:57,984] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:21:58,086] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.307 seconds
[2020-07-22 14:22:22,412] {scheduler_job.py:153} INFO - Started process (PID=418057) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:22:22,417] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:22:22,418] {logging_mixin.py:112} INFO - [2020-07-22 14:22:22,418] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:22:22,675] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:22:22,806] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.394 seconds
[2020-07-22 14:22:46,471] {scheduler_job.py:153} INFO - Started process (PID=418639) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:22:46,473] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:22:46,474] {logging_mixin.py:112} INFO - [2020-07-22 14:22:46,474] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:22:46,673] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:22:46,768] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.297 seconds
[2020-07-22 14:23:16,408] {scheduler_job.py:153} INFO - Started process (PID=419315) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:23:16,411] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:23:16,411] {logging_mixin.py:112} INFO - [2020-07-22 14:23:16,411] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:23:16,623] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:23:16,747] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.339 seconds
[2020-07-22 14:23:41,098] {scheduler_job.py:153} INFO - Started process (PID=419881) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:23:41,101] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:23:41,102] {logging_mixin.py:112} INFO - [2020-07-22 14:23:41,101] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:23:41,322] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:23:41,435] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.337 seconds
[2020-07-22 14:24:05,289] {scheduler_job.py:153} INFO - Started process (PID=420434) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:24:05,293] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:24:05,294] {logging_mixin.py:112} INFO - [2020-07-22 14:24:05,294] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:24:05,550] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:24:05,669] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.380 seconds
[2020-07-22 14:24:29,414] {scheduler_job.py:153} INFO - Started process (PID=421050) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:24:29,417] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:24:29,418] {logging_mixin.py:112} INFO - [2020-07-22 14:24:29,418] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:24:30,223] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:24:30,352] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.938 seconds
[2020-07-22 14:24:53,496] {scheduler_job.py:153} INFO - Started process (PID=421571) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:24:53,499] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:24:53,499] {logging_mixin.py:112} INFO - [2020-07-22 14:24:53,499] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:24:53,750] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:24:53,854] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.358 seconds
[2020-07-22 14:25:23,995] {scheduler_job.py:153} INFO - Started process (PID=422303) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:25:23,999] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:25:24,000] {logging_mixin.py:112} INFO - [2020-07-22 14:25:24,000] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:25:24,519] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:25:24,800] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.805 seconds
[2020-07-22 14:25:54,276] {scheduler_job.py:153} INFO - Started process (PID=422995) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:25:54,293] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:25:54,293] {logging_mixin.py:112} INFO - [2020-07-22 14:25:54,293] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:25:54,611] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:25:54,748] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.473 seconds
[2020-07-22 14:26:18,475] {scheduler_job.py:153} INFO - Started process (PID=423528) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:26:18,478] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:26:18,478] {logging_mixin.py:112} INFO - [2020-07-22 14:26:18,478] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:26:19,295] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:26:19,468] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.993 seconds
[2020-07-22 14:26:48,565] {scheduler_job.py:153} INFO - Started process (PID=424231) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:26:48,568] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:26:48,569] {logging_mixin.py:112} INFO - [2020-07-22 14:26:48,568] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:26:48,769] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:26:48,884] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.319 seconds
[2020-07-22 14:27:12,544] {scheduler_job.py:153} INFO - Started process (PID=424761) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:27:12,552] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:27:12,553] {logging_mixin.py:112} INFO - [2020-07-22 14:27:12,552] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:27:12,893] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:27:13,395] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.851 seconds
[2020-07-22 14:27:42,320] {scheduler_job.py:153} INFO - Started process (PID=425431) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:27:42,324] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:27:42,324] {logging_mixin.py:112} INFO - [2020-07-22 14:27:42,324] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:27:42,530] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:27:42,634] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.313 seconds
[2020-07-22 14:28:18,354] {scheduler_job.py:153} INFO - Started process (PID=426228) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:28:18,357] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:28:18,357] {logging_mixin.py:112} INFO - [2020-07-22 14:28:18,357] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:28:18,616] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:28:18,725] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.371 seconds
[2020-07-22 14:28:47,946] {scheduler_job.py:153} INFO - Started process (PID=426925) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:28:47,952] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:28:47,955] {logging_mixin.py:112} INFO - [2020-07-22 14:28:47,954] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:28:48,208] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:28:48,629] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.683 seconds
[2020-07-22 14:29:17,330] {scheduler_job.py:153} INFO - Started process (PID=427526) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:29:17,333] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:29:17,333] {logging_mixin.py:112} INFO - [2020-07-22 14:29:17,333] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:29:17,539] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:29:17,628] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.298 seconds
[2020-07-22 14:30:00,190] {scheduler_job.py:153} INFO - Started process (PID=428472) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:30:00,193] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:30:00,194] {logging_mixin.py:112} INFO - [2020-07-22 14:30:00,194] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:30:00,435] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:30:00,541] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.351 seconds
[2020-07-22 14:30:30,331] {scheduler_job.py:153} INFO - Started process (PID=429154) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:30:30,334] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:30:30,334] {logging_mixin.py:112} INFO - [2020-07-22 14:30:30,334] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:30:30,541] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:30:30,618] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.287 seconds
[2020-07-22 14:30:59,871] {scheduler_job.py:153} INFO - Started process (PID=429841) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:30:59,874] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:30:59,875] {logging_mixin.py:112} INFO - [2020-07-22 14:30:59,875] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:31:00,127] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:31:00,236] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.365 seconds
[2020-07-22 14:31:24,126] {scheduler_job.py:153} INFO - Started process (PID=430381) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:31:24,131] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:31:24,132] {logging_mixin.py:112} INFO - [2020-07-22 14:31:24,132] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:31:24,398] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:31:24,630] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.504 seconds
[2020-07-22 14:31:54,766] {scheduler_job.py:153} INFO - Started process (PID=431089) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:31:54,770] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:31:54,771] {logging_mixin.py:112} INFO - [2020-07-22 14:31:54,771] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:31:54,973] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:31:55,081] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.315 seconds
[2020-07-22 14:32:30,537] {scheduler_job.py:153} INFO - Started process (PID=431856) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:32:30,541] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:32:30,542] {logging_mixin.py:112} INFO - [2020-07-22 14:32:30,542] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:32:30,804] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:32:31,008] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.472 seconds
[2020-07-22 14:33:18,387] {scheduler_job.py:153} INFO - Started process (PID=432952) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:33:18,391] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:33:18,391] {logging_mixin.py:112} INFO - [2020-07-22 14:33:18,391] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:33:18,655] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:33:18,755] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.368 seconds
[2020-07-22 14:33:47,895] {scheduler_job.py:153} INFO - Started process (PID=433586) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:33:47,899] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:33:47,900] {logging_mixin.py:112} INFO - [2020-07-22 14:33:47,899] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:33:48,195] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:33:48,357] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.462 seconds
[2020-07-22 14:34:18,325] {scheduler_job.py:153} INFO - Started process (PID=434244) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:34:18,329] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:34:18,329] {logging_mixin.py:112} INFO - [2020-07-22 14:34:18,329] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:34:18,607] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:34:18,720] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.395 seconds
[2020-07-22 14:34:55,591] {scheduler_job.py:153} INFO - Started process (PID=435022) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:34:55,594] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:34:55,595] {logging_mixin.py:112} INFO - [2020-07-22 14:34:55,594] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:34:55,820] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:34:55,905] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.314 seconds
[2020-07-22 14:35:44,557] {scheduler_job.py:153} INFO - Started process (PID=436065) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:35:44,562] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:35:44,563] {logging_mixin.py:112} INFO - [2020-07-22 14:35:44,563] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:35:44,822] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:35:44,922] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.365 seconds
[2020-07-22 14:36:14,325] {scheduler_job.py:153} INFO - Started process (PID=436754) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:36:14,328] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:36:14,328] {logging_mixin.py:112} INFO - [2020-07-22 14:36:14,328] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:36:14,641] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:36:14,757] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.432 seconds
[2020-07-22 14:36:39,467] {scheduler_job.py:153} INFO - Started process (PID=437284) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:36:39,470] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:36:39,470] {logging_mixin.py:112} INFO - [2020-07-22 14:36:39,470] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:36:39,683] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:36:39,795] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.328 seconds
[2020-07-22 14:37:09,623] {scheduler_job.py:153} INFO - Started process (PID=437982) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:37:09,626] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:37:09,627] {logging_mixin.py:112} INFO - [2020-07-22 14:37:09,627] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:37:09,894] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:37:09,995] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.372 seconds
[2020-07-22 14:37:39,910] {scheduler_job.py:153} INFO - Started process (PID=438694) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:37:39,913] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:37:39,914] {logging_mixin.py:112} INFO - [2020-07-22 14:37:39,914] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:37:40,180] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:37:40,354] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.444 seconds
[2020-07-22 14:38:10,591] {scheduler_job.py:153} INFO - Started process (PID=439432) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:38:10,595] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:38:10,596] {logging_mixin.py:112} INFO - [2020-07-22 14:38:10,595] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:38:10,812] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:38:10,905] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.314 seconds
[2020-07-22 14:38:46,024] {scheduler_job.py:153} INFO - Started process (PID=440218) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:38:46,031] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:38:46,032] {logging_mixin.py:112} INFO - [2020-07-22 14:38:46,032] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:38:46,471] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:38:46,614] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.590 seconds
[2020-07-22 14:39:22,032] {scheduler_job.py:153} INFO - Started process (PID=440967) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:39:22,034] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:39:22,035] {logging_mixin.py:112} INFO - [2020-07-22 14:39:22,035] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:39:22,287] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:39:22,393] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.361 seconds
[2020-07-22 14:40:16,551] {scheduler_job.py:153} INFO - Started process (PID=442129) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:40:16,556] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:40:16,556] {logging_mixin.py:112} INFO - [2020-07-22 14:40:16,556] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:40:16,946] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:40:17,102] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.551 seconds
[2020-07-22 14:40:48,364] {scheduler_job.py:153} INFO - Started process (PID=442840) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:40:48,368] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:40:48,369] {logging_mixin.py:112} INFO - [2020-07-22 14:40:48,369] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:40:48,698] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:40:48,827] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.463 seconds
[2020-07-22 14:41:22,688] {scheduler_job.py:153} INFO - Started process (PID=443618) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:41:22,694] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:41:22,694] {logging_mixin.py:112} INFO - [2020-07-22 14:41:22,694] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:41:22,931] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:41:23,096] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.408 seconds
[2020-07-22 14:41:52,313] {scheduler_job.py:153} INFO - Started process (PID=444297) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:41:52,317] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:41:52,318] {logging_mixin.py:112} INFO - [2020-07-22 14:41:52,318] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:41:52,670] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:41:52,866] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.552 seconds
[2020-07-22 14:42:21,888] {scheduler_job.py:153} INFO - Started process (PID=444954) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:42:21,891] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:42:21,892] {logging_mixin.py:112} INFO - [2020-07-22 14:42:21,891] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:42:22,182] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:42:22,290] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.402 seconds
[2020-07-22 14:42:57,932] {scheduler_job.py:153} INFO - Started process (PID=445946) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:42:57,935] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:42:57,936] {logging_mixin.py:112} INFO - [2020-07-22 14:42:57,936] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:42:58,140] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:42:58,242] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.310 seconds
[2020-07-22 14:43:32,294] {scheduler_job.py:153} INFO - Started process (PID=446710) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:43:32,308] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:43:32,308] {logging_mixin.py:112} INFO - [2020-07-22 14:43:32,308] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:43:32,659] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:43:32,865] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.570 seconds
[2020-07-22 14:44:01,590] {scheduler_job.py:153} INFO - Started process (PID=447403) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:44:01,595] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:44:01,596] {logging_mixin.py:112} INFO - [2020-07-22 14:44:01,595] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:44:01,906] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:44:02,031] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.441 seconds
[2020-07-22 14:44:37,382] {scheduler_job.py:153} INFO - Started process (PID=448406) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:44:37,391] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:44:37,392] {logging_mixin.py:112} INFO - [2020-07-22 14:44:37,392] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:44:38,466] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:44:38,875] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.494 seconds
[2020-07-22 14:45:33,469] {scheduler_job.py:153} INFO - Started process (PID=449651) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:45:33,474] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:45:33,474] {logging_mixin.py:112} INFO - [2020-07-22 14:45:33,474] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:45:33,748] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:45:33,881] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.413 seconds
[2020-07-22 14:46:19,468] {scheduler_job.py:153} INFO - Started process (PID=450589) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:46:19,475] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:46:19,475] {logging_mixin.py:112} INFO - [2020-07-22 14:46:19,475] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:46:19,750] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:46:19,856] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.388 seconds
[2020-07-22 14:47:06,728] {scheduler_job.py:153} INFO - Started process (PID=451542) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:47:06,732] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:47:06,733] {logging_mixin.py:112} INFO - [2020-07-22 14:47:06,732] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:47:07,047] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:47:07,187] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.459 seconds
[2020-07-22 14:47:47,831] {scheduler_job.py:153} INFO - Started process (PID=452460) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:47:47,834] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:47:47,834] {logging_mixin.py:112} INFO - [2020-07-22 14:47:47,834] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:47:48,121] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:47:48,202] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.372 seconds
[2020-07-22 14:48:34,908] {scheduler_job.py:153} INFO - Started process (PID=453458) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:48:34,916] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:48:34,917] {logging_mixin.py:112} INFO - [2020-07-22 14:48:34,917] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:48:35,189] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:48:35,384] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.476 seconds
[2020-07-22 14:49:11,667] {scheduler_job.py:153} INFO - Started process (PID=454240) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:49:11,699] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:49:11,700] {logging_mixin.py:112} INFO - [2020-07-22 14:49:11,700] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:49:12,044] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:49:12,209] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.543 seconds
[2020-07-22 14:50:01,031] {scheduler_job.py:153} INFO - Started process (PID=455452) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:50:01,036] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:50:01,036] {logging_mixin.py:112} INFO - [2020-07-22 14:50:01,036] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:50:01,375] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:50:01,557] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.526 seconds
[2020-07-22 14:50:40,956] {scheduler_job.py:153} INFO - Started process (PID=456316) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:50:40,959] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:50:40,959] {logging_mixin.py:112} INFO - [2020-07-22 14:50:40,959] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:50:41,221] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:50:41,384] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.429 seconds
[2020-07-22 14:51:21,459] {scheduler_job.py:153} INFO - Started process (PID=457156) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:51:21,464] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:51:21,468] {logging_mixin.py:112} INFO - [2020-07-22 14:51:21,468] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:51:21,704] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:51:21,970] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.511 seconds
[2020-07-22 14:51:49,346] {scheduler_job.py:153} INFO - Started process (PID=457709) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:51:49,350] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:51:49,351] {logging_mixin.py:112} INFO - [2020-07-22 14:51:49,351] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:51:49,622] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:51:49,974] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.628 seconds
[2020-07-22 14:52:22,895] {scheduler_job.py:153} INFO - Started process (PID=458468) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:52:22,899] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:52:22,899] {logging_mixin.py:112} INFO - [2020-07-22 14:52:22,899] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:52:23,106] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:52:23,211] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.316 seconds
[2020-07-22 14:53:16,993] {scheduler_job.py:153} INFO - Started process (PID=459608) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:53:16,996] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:53:16,997] {logging_mixin.py:112} INFO - [2020-07-22 14:53:16,997] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:53:17,214] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:53:17,325] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.332 seconds
[2020-07-22 14:53:52,711] {scheduler_job.py:153} INFO - Started process (PID=460389) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:53:52,714] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:53:52,714] {logging_mixin.py:112} INFO - [2020-07-22 14:53:52,714] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:53:52,915] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:53:53,028] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.317 seconds
[2020-07-22 14:54:28,070] {scheduler_job.py:153} INFO - Started process (PID=461148) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:54:28,073] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:54:28,073] {logging_mixin.py:112} INFO - [2020-07-22 14:54:28,073] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:54:28,415] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:54:28,607] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.537 seconds
[2020-07-22 14:55:03,378] {scheduler_job.py:153} INFO - Started process (PID=461955) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:55:03,385] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:55:03,385] {logging_mixin.py:112} INFO - [2020-07-22 14:55:03,385] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:55:03,623] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:55:03,746] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.368 seconds
[2020-07-22 14:55:50,128] {scheduler_job.py:153} INFO - Started process (PID=463007) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:55:50,131] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:55:50,131] {logging_mixin.py:112} INFO - [2020-07-22 14:55:50,131] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:55:50,386] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:55:50,501] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.373 seconds
[2020-07-22 14:56:19,532] {scheduler_job.py:153} INFO - Started process (PID=463671) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:56:19,536] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:56:19,537] {logging_mixin.py:112} INFO - [2020-07-22 14:56:19,537] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:56:19,753] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:56:19,874] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.342 seconds
[2020-07-22 14:56:55,350] {scheduler_job.py:153} INFO - Started process (PID=464432) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:56:55,357] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:56:55,357] {logging_mixin.py:112} INFO - [2020-07-22 14:56:55,357] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:56:55,631] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:56:55,715] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.365 seconds
[2020-07-22 14:57:34,222] {scheduler_job.py:153} INFO - Started process (PID=465350) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:57:34,228] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:57:34,228] {logging_mixin.py:112} INFO - [2020-07-22 14:57:34,228] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:57:34,531] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:57:34,662] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.440 seconds
[2020-07-22 14:58:25,580] {scheduler_job.py:153} INFO - Started process (PID=466367) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:58:25,647] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:58:25,648] {logging_mixin.py:112} INFO - [2020-07-22 14:58:25,648] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:58:26,091] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:58:26,246] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.666 seconds
[2020-07-22 14:59:42,651] {scheduler_job.py:153} INFO - Started process (PID=467753) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:59:42,655] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 14:59:42,656] {logging_mixin.py:112} INFO - [2020-07-22 14:59:42,656] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:59:42,915] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 14:59:43,251] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.600 seconds
[2020-07-22 15:00:43,032] {scheduler_job.py:153} INFO - Started process (PID=468928) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:00:43,035] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:00:43,035] {logging_mixin.py:112} INFO - [2020-07-22 15:00:43,035] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:00:43,375] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:00:43,466] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.434 seconds
[2020-07-22 15:01:19,463] {scheduler_job.py:153} INFO - Started process (PID=469719) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:01:19,468] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:01:19,469] {logging_mixin.py:112} INFO - [2020-07-22 15:01:19,468] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:01:19,782] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:01:19,913] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.450 seconds
[2020-07-22 15:01:54,210] {scheduler_job.py:153} INFO - Started process (PID=470460) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:01:54,215] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:01:54,216] {logging_mixin.py:112} INFO - [2020-07-22 15:01:54,216] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:01:54,607] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:01:54,739] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.529 seconds
[2020-07-22 15:02:30,864] {scheduler_job.py:153} INFO - Started process (PID=471223) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:02:30,870] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:02:30,871] {logging_mixin.py:112} INFO - [2020-07-22 15:02:30,871] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:02:31,302] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:02:31,466] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.603 seconds
[2020-07-22 15:03:06,232] {scheduler_job.py:153} INFO - Started process (PID=472019) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:03:06,235] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:03:06,236] {logging_mixin.py:112} INFO - [2020-07-22 15:03:06,236] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:03:06,488] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:03:06,673] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.441 seconds
[2020-07-22 15:03:48,319] {scheduler_job.py:153} INFO - Started process (PID=472907) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:03:48,325] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:03:48,327] {logging_mixin.py:112} INFO - [2020-07-22 15:03:48,326] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:03:48,632] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:03:48,719] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.400 seconds
[2020-07-22 15:04:30,743] {scheduler_job.py:153} INFO - Started process (PID=473803) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:04:30,746] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:04:30,746] {logging_mixin.py:112} INFO - [2020-07-22 15:04:30,746] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:04:30,995] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:04:31,146] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.403 seconds
[2020-07-22 15:05:00,601] {scheduler_job.py:153} INFO - Started process (PID=474499) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:05:00,606] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:05:00,608] {logging_mixin.py:112} INFO - [2020-07-22 15:05:00,607] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:05:00,937] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:05:01,085] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.484 seconds
[2020-07-22 15:05:30,282] {scheduler_job.py:153} INFO - Started process (PID=475138) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:05:30,285] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:05:30,286] {logging_mixin.py:112} INFO - [2020-07-22 15:05:30,286] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:05:30,642] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:05:30,782] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.499 seconds
[2020-07-22 15:06:02,382] {scheduler_job.py:153} INFO - Started process (PID=475860) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:06:02,385] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:06:02,386] {logging_mixin.py:112} INFO - [2020-07-22 15:06:02,386] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:06:02,637] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:06:02,766] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.384 seconds
[2020-07-22 15:06:44,133] {scheduler_job.py:153} INFO - Started process (PID=476745) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:06:44,138] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:06:44,139] {logging_mixin.py:112} INFO - [2020-07-22 15:06:44,138] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:06:44,349] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:06:44,463] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.330 seconds
[2020-07-22 15:07:37,385] {scheduler_job.py:153} INFO - Started process (PID=477852) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:07:37,388] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:07:37,389] {logging_mixin.py:112} INFO - [2020-07-22 15:07:37,389] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:07:37,610] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:07:37,856] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.471 seconds
[2020-07-22 15:08:14,078] {scheduler_job.py:153} INFO - Started process (PID=478701) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:08:14,081] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:08:14,082] {logging_mixin.py:112} INFO - [2020-07-22 15:08:14,082] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:08:14,899] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:08:15,030] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.952 seconds
[2020-07-22 15:08:54,725] {scheduler_job.py:153} INFO - Started process (PID=479567) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:08:54,728] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:08:54,728] {logging_mixin.py:112} INFO - [2020-07-22 15:08:54,728] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:08:54,936] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:08:55,042] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.318 seconds
[2020-07-22 15:09:29,411] {scheduler_job.py:153} INFO - Started process (PID=480335) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:09:29,416] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:09:29,416] {logging_mixin.py:112} INFO - [2020-07-22 15:09:29,416] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:09:29,686] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:09:29,852] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.442 seconds
[2020-07-22 15:10:09,355] {scheduler_job.py:153} INFO - Started process (PID=481124) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:10:09,358] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:10:09,359] {logging_mixin.py:112} INFO - [2020-07-22 15:10:09,358] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:10:09,577] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:10:09,680] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.325 seconds
[2020-07-22 15:11:07,726] {scheduler_job.py:153} INFO - Started process (PID=482392) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:11:07,732] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:11:07,732] {logging_mixin.py:112} INFO - [2020-07-22 15:11:07,732] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:11:08,076] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:11:08,264] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.538 seconds
[2020-07-22 15:11:58,597] {scheduler_job.py:153} INFO - Started process (PID=483207) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:11:58,669] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:11:58,670] {logging_mixin.py:112} INFO - [2020-07-22 15:11:58,670] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:11:59,632] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:12:00,201] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.604 seconds
[2020-07-22 15:12:54,184] {scheduler_job.py:153} INFO - Started process (PID=484286) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:12:54,188] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:12:54,188] {logging_mixin.py:112} INFO - [2020-07-22 15:12:54,188] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:12:54,390] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:12:54,524] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.341 seconds
[2020-07-22 15:13:30,283] {scheduler_job.py:153} INFO - Started process (PID=485100) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:13:30,288] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:13:30,289] {logging_mixin.py:112} INFO - [2020-07-22 15:13:30,289] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:13:30,544] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:13:30,663] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.380 seconds
[2020-07-22 15:14:11,802] {scheduler_job.py:153} INFO - Started process (PID=485981) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:14:11,807] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:14:11,807] {logging_mixin.py:112} INFO - [2020-07-22 15:14:11,807] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:14:12,081] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:14:12,173] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.371 seconds
[2020-07-22 15:14:42,935] {scheduler_job.py:153} INFO - Started process (PID=486645) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:14:42,938] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:14:42,938] {logging_mixin.py:112} INFO - [2020-07-22 15:14:42,938] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:14:43,380] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:14:43,546] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.611 seconds
[2020-07-22 15:15:19,523] {scheduler_job.py:153} INFO - Started process (PID=487408) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:15:19,529] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:15:19,530] {logging_mixin.py:112} INFO - [2020-07-22 15:15:19,530] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:15:19,714] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:15:19,822] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.299 seconds
[2020-07-22 15:15:56,038] {scheduler_job.py:153} INFO - Started process (PID=488243) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:15:56,041] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:15:56,041] {logging_mixin.py:112} INFO - [2020-07-22 15:15:56,041] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:15:56,456] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:15:56,628] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.590 seconds
[2020-07-22 15:16:30,738] {scheduler_job.py:153} INFO - Started process (PID=489041) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:16:30,745] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:16:30,760] {logging_mixin.py:112} INFO - [2020-07-22 15:16:30,760] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:16:30,954] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:16:31,345] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.606 seconds
[2020-07-22 15:17:05,921] {scheduler_job.py:153} INFO - Started process (PID=489812) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:17:05,925] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:17:05,925] {logging_mixin.py:112} INFO - [2020-07-22 15:17:05,925] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:17:06,168] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:17:06,324] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.403 seconds
[2020-07-22 15:17:44,168] {scheduler_job.py:153} INFO - Started process (PID=490653) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:17:44,171] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:17:44,172] {logging_mixin.py:112} INFO - [2020-07-22 15:17:44,171] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:17:44,442] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:17:44,557] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.389 seconds
[2020-07-22 15:18:18,807] {scheduler_job.py:153} INFO - Started process (PID=491394) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:18:18,815] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:18:18,816] {logging_mixin.py:112} INFO - [2020-07-22 15:18:18,815] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:18:19,104] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:18:19,302] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.495 seconds
[2020-07-22 15:18:54,552] {scheduler_job.py:153} INFO - Started process (PID=492182) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:18:54,554] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:18:54,555] {logging_mixin.py:112} INFO - [2020-07-22 15:18:54,555] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:18:54,753] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:18:54,914] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.362 seconds
[2020-07-22 15:19:26,234] {scheduler_job.py:153} INFO - Started process (PID=492926) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:19:26,236] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:19:26,237] {logging_mixin.py:112} INFO - [2020-07-22 15:19:26,237] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:19:26,630] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:19:26,903] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.669 seconds
[2020-07-22 15:20:06,422] {scheduler_job.py:153} INFO - Started process (PID=493775) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:20:06,424] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:20:06,425] {logging_mixin.py:112} INFO - [2020-07-22 15:20:06,425] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:20:06,631] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:20:06,742] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.320 seconds
[2020-07-22 15:20:41,440] {scheduler_job.py:153} INFO - Started process (PID=494545) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:20:41,443] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:20:41,444] {logging_mixin.py:112} INFO - [2020-07-22 15:20:41,443] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:20:41,697] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:20:41,808] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.368 seconds
[2020-07-22 15:21:16,125] {scheduler_job.py:153} INFO - Started process (PID=495297) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:21:16,131] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:21:16,132] {logging_mixin.py:112} INFO - [2020-07-22 15:21:16,132] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:21:16,513] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:21:16,691] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.566 seconds
[2020-07-22 15:21:51,660] {scheduler_job.py:153} INFO - Started process (PID=496050) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:21:51,664] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:21:51,665] {logging_mixin.py:112} INFO - [2020-07-22 15:21:51,665] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:21:51,881] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:21:51,983] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.323 seconds
[2020-07-22 15:22:26,666] {scheduler_job.py:153} INFO - Started process (PID=496799) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:22:26,668] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:22:26,669] {logging_mixin.py:112} INFO - [2020-07-22 15:22:26,669] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:22:27,475] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:22:28,148] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.482 seconds
[2020-07-22 15:23:01,889] {scheduler_job.py:153} INFO - Started process (PID=497591) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:23:01,892] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:23:01,893] {logging_mixin.py:112} INFO - [2020-07-22 15:23:01,893] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:23:02,108] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:23:02,218] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.329 seconds
[2020-07-22 15:23:42,257] {scheduler_job.py:153} INFO - Started process (PID=498448) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:23:42,261] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:23:42,261] {logging_mixin.py:112} INFO - [2020-07-22 15:23:42,261] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:23:42,469] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:23:42,580] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.323 seconds
[2020-07-22 15:24:23,451] {scheduler_job.py:153} INFO - Started process (PID=499297) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:24:23,454] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:24:23,455] {logging_mixin.py:112} INFO - [2020-07-22 15:24:23,455] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:24:23,719] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:24:23,858] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.407 seconds
[2020-07-22 15:24:59,287] {scheduler_job.py:153} INFO - Started process (PID=500073) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:24:59,292] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:24:59,292] {logging_mixin.py:112} INFO - [2020-07-22 15:24:59,292] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:24:59,554] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:24:59,704] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.417 seconds
[2020-07-22 15:25:28,862] {scheduler_job.py:153} INFO - Started process (PID=500716) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:25:28,897] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:25:28,898] {logging_mixin.py:112} INFO - [2020-07-22 15:25:28,898] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:25:29,413] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:25:29,699] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.837 seconds
[2020-07-22 15:26:07,156] {scheduler_job.py:153} INFO - Started process (PID=501613) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:26:07,158] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:26:07,159] {logging_mixin.py:112} INFO - [2020-07-22 15:26:07,159] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:26:07,362] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:26:07,456] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.300 seconds
[2020-07-22 15:27:00,242] {scheduler_job.py:153} INFO - Started process (PID=502576) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:27:00,245] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:27:00,245] {logging_mixin.py:112} INFO - [2020-07-22 15:27:00,245] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:27:00,814] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:27:01,108] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.866 seconds
[2020-07-22 15:27:59,710] {scheduler_job.py:153} INFO - Started process (PID=503644) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:27:59,821] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:27:59,822] {logging_mixin.py:112} INFO - [2020-07-22 15:27:59,822] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:28:00,042] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:28:00,142] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.432 seconds
[2020-07-22 15:28:35,134] {scheduler_job.py:153} INFO - Started process (PID=504405) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:28:35,137] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:28:35,138] {logging_mixin.py:112} INFO - [2020-07-22 15:28:35,138] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:28:35,439] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:28:35,553] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.419 seconds
[2020-07-22 15:29:05,044] {scheduler_job.py:153} INFO - Started process (PID=505091) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:29:05,048] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:29:05,049] {logging_mixin.py:112} INFO - [2020-07-22 15:29:05,049] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:29:05,335] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:29:05,441] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.397 seconds
[2020-07-22 15:29:34,810] {scheduler_job.py:153} INFO - Started process (PID=505743) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:29:34,814] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:29:34,815] {logging_mixin.py:112} INFO - [2020-07-22 15:29:34,815] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:29:35,017] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:29:35,111] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.301 seconds
[2020-07-22 15:30:10,420] {scheduler_job.py:153} INFO - Started process (PID=506527) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:30:10,423] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:30:10,424] {logging_mixin.py:112} INFO - [2020-07-22 15:30:10,424] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:30:10,674] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:30:10,834] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.414 seconds
[2020-07-22 15:30:50,023] {scheduler_job.py:153} INFO - Started process (PID=507370) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:30:50,026] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:30:50,026] {logging_mixin.py:112} INFO - [2020-07-22 15:30:50,026] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:30:50,282] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:30:50,375] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.352 seconds
[2020-07-22 15:31:25,618] {scheduler_job.py:153} INFO - Started process (PID=508170) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:31:25,620] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:31:25,621] {logging_mixin.py:112} INFO - [2020-07-22 15:31:25,621] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:31:25,691] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:31:26,755] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.138 seconds
[2020-07-22 15:31:55,716] {scheduler_job.py:153} INFO - Started process (PID=508844) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:31:55,720] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:31:55,721] {logging_mixin.py:112} INFO - [2020-07-22 15:31:55,721] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:31:55,977] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:31:56,132] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.416 seconds
[2020-07-22 15:32:25,001] {scheduler_job.py:153} INFO - Started process (PID=509507) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:32:25,005] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:32:25,006] {logging_mixin.py:112} INFO - [2020-07-22 15:32:25,005] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:32:25,207] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:32:25,378] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.378 seconds
[2020-07-22 15:33:01,885] {scheduler_job.py:153} INFO - Started process (PID=510325) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:33:01,890] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:33:01,891] {logging_mixin.py:112} INFO - [2020-07-22 15:33:01,890] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:33:02,311] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:33:02,424] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.540 seconds
[2020-07-22 15:33:37,472] {scheduler_job.py:153} INFO - Started process (PID=511115) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:33:37,475] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:33:37,476] {logging_mixin.py:112} INFO - [2020-07-22 15:33:37,476] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:33:37,737] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:33:37,842] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.369 seconds
[2020-07-22 15:34:07,351] {scheduler_job.py:153} INFO - Started process (PID=511778) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:34:07,356] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:34:07,357] {logging_mixin.py:112} INFO - [2020-07-22 15:34:07,356] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:34:07,638] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:34:07,895] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.544 seconds
[2020-07-22 15:34:36,561] {scheduler_job.py:153} INFO - Started process (PID=512457) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:34:36,566] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:34:36,566] {logging_mixin.py:112} INFO - [2020-07-22 15:34:36,566] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:34:36,767] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:34:36,878] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.318 seconds
[2020-07-22 15:35:12,351] {scheduler_job.py:153} INFO - Started process (PID=513257) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:35:12,354] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:35:12,355] {logging_mixin.py:112} INFO - [2020-07-22 15:35:12,355] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:35:12,561] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:35:12,670] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.319 seconds
[2020-07-22 15:35:47,018] {scheduler_job.py:153} INFO - Started process (PID=514040) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:35:47,022] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:35:47,022] {logging_mixin.py:112} INFO - [2020-07-22 15:35:47,022] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:35:47,228] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:35:47,339] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.321 seconds
[2020-07-22 15:36:16,886] {scheduler_job.py:153} INFO - Started process (PID=514695) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:36:16,896] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:36:16,896] {logging_mixin.py:112} INFO - [2020-07-22 15:36:16,896] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:36:17,226] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:36:17,804] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.918 seconds
[2020-07-22 15:36:53,258] {scheduler_job.py:153} INFO - Started process (PID=515480) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:36:53,260] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:36:53,261] {logging_mixin.py:112} INFO - [2020-07-22 15:36:53,261] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:36:53,344] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:36:53,444] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.187 seconds
[2020-07-22 15:37:31,477] {scheduler_job.py:153} INFO - Started process (PID=516305) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:37:31,480] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:37:31,481] {logging_mixin.py:112} INFO - [2020-07-22 15:37:31,481] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:37:31,774] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:37:31,879] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.402 seconds
[2020-07-22 15:38:06,834] {scheduler_job.py:153} INFO - Started process (PID=517079) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:38:06,840] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:38:06,841] {logging_mixin.py:112} INFO - [2020-07-22 15:38:06,841] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:38:07,123] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:38:07,236] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.402 seconds
[2020-07-22 15:38:42,264] {scheduler_job.py:153} INFO - Started process (PID=517886) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:38:42,267] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:38:42,267] {logging_mixin.py:112} INFO - [2020-07-22 15:38:42,267] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:38:42,336] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:38:42,461] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.198 seconds
[2020-07-22 15:39:11,671] {scheduler_job.py:153} INFO - Started process (PID=518534) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:39:11,676] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:39:11,676] {logging_mixin.py:112} INFO - [2020-07-22 15:39:11,676] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:39:11,957] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:39:12,125] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.454 seconds
[2020-07-22 15:39:46,752] {scheduler_job.py:153} INFO - Started process (PID=519319) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:39:46,756] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:39:46,757] {logging_mixin.py:112} INFO - [2020-07-22 15:39:46,757] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:39:47,310] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:39:47,421] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.669 seconds
[2020-07-22 15:40:23,293] {scheduler_job.py:153} INFO - Started process (PID=520170) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:40:23,296] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:40:23,297] {logging_mixin.py:112} INFO - [2020-07-22 15:40:23,297] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:40:23,499] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:40:23,612] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.318 seconds
[2020-07-22 15:41:02,995] {scheduler_job.py:153} INFO - Started process (PID=521015) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:41:02,999] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:41:03,000] {logging_mixin.py:112} INFO - [2020-07-22 15:41:02,999] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:41:03,408] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:41:03,706] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.712 seconds
[2020-07-22 15:41:39,079] {scheduler_job.py:153} INFO - Started process (PID=521844) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:41:39,082] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:41:39,083] {logging_mixin.py:112} INFO - [2020-07-22 15:41:39,083] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:41:39,340] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:41:39,457] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.378 seconds
[2020-07-22 15:42:14,143] {scheduler_job.py:153} INFO - Started process (PID=522573) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:42:14,152] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:42:14,154] {logging_mixin.py:112} INFO - [2020-07-22 15:42:14,154] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:42:14,445] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:42:14,586] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.443 seconds
[2020-07-22 15:42:49,604] {scheduler_job.py:153} INFO - Started process (PID=523351) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:42:49,606] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:42:49,607] {logging_mixin.py:112} INFO - [2020-07-22 15:42:49,607] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:42:49,889] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:42:50,033] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.429 seconds
[2020-07-22 15:43:26,639] {scheduler_job.py:153} INFO - Started process (PID=524195) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:43:26,643] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:43:26,643] {logging_mixin.py:112} INFO - [2020-07-22 15:43:26,643] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:43:27,248] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:43:27,358] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.720 seconds
[2020-07-22 15:44:20,931] {scheduler_job.py:153} INFO - Started process (PID=525205) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:44:20,993] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:44:20,994] {logging_mixin.py:112} INFO - [2020-07-22 15:44:20,994] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:44:21,428] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:44:21,534] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.603 seconds
[2020-07-22 15:45:00,214] {scheduler_job.py:153} INFO - Started process (PID=526111) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:45:00,223] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:45:00,223] {logging_mixin.py:112} INFO - [2020-07-22 15:45:00,223] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:45:00,688] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:45:00,835] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.621 seconds
[2020-07-22 15:45:49,150] {scheduler_job.py:153} INFO - Started process (PID=527045) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:45:49,153] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:45:49,153] {logging_mixin.py:112} INFO - [2020-07-22 15:45:49,153] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:45:49,568] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:45:49,692] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.542 seconds
[2020-07-22 15:46:25,112] {scheduler_job.py:153} INFO - Started process (PID=527795) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:46:25,115] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:46:25,116] {logging_mixin.py:112} INFO - [2020-07-22 15:46:25,116] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:46:25,319] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:46:25,424] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.311 seconds
[2020-07-22 15:47:00,823] {scheduler_job.py:153} INFO - Started process (PID=528536) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:47:00,827] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:47:00,828] {logging_mixin.py:112} INFO - [2020-07-22 15:47:00,827] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:47:01,080] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:47:01,221] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.398 seconds
[2020-07-22 15:47:36,028] {scheduler_job.py:153} INFO - Started process (PID=529283) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:47:36,031] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:47:36,031] {logging_mixin.py:112} INFO - [2020-07-22 15:47:36,031] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:47:36,236] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:47:36,414] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.386 seconds
[2020-07-22 15:48:13,294] {scheduler_job.py:153} INFO - Started process (PID=530086) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:48:13,297] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:48:13,297] {logging_mixin.py:112} INFO - [2020-07-22 15:48:13,297] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:48:13,533] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:48:13,650] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.357 seconds
[2020-07-22 15:48:48,348] {scheduler_job.py:153} INFO - Started process (PID=530899) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:48:48,355] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:48:48,356] {logging_mixin.py:112} INFO - [2020-07-22 15:48:48,356] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:48:48,588] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:48:48,676] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.329 seconds
[2020-07-22 15:49:28,846] {scheduler_job.py:153} INFO - Started process (PID=531736) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:49:28,851] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:49:28,851] {logging_mixin.py:112} INFO - [2020-07-22 15:49:28,851] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:49:29,115] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:49:29,197] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.351 seconds
[2020-07-22 15:50:03,821] {scheduler_job.py:153} INFO - Started process (PID=532504) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:50:03,825] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:50:03,826] {logging_mixin.py:112} INFO - [2020-07-22 15:50:03,826] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:50:04,063] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:50:04,222] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.401 seconds
[2020-07-22 15:50:44,124] {scheduler_job.py:153} INFO - Started process (PID=533332) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:50:44,144] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:50:44,144] {logging_mixin.py:112} INFO - [2020-07-22 15:50:44,144] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:50:44,870] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:50:45,238] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.114 seconds
[2020-07-22 15:51:18,487] {scheduler_job.py:153} INFO - Started process (PID=534042) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:51:18,493] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:51:18,494] {logging_mixin.py:112} INFO - [2020-07-22 15:51:18,494] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:51:18,964] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:51:19,109] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.622 seconds
[2020-07-22 15:51:54,601] {scheduler_job.py:153} INFO - Started process (PID=534864) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:51:54,606] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:51:54,606] {logging_mixin.py:112} INFO - [2020-07-22 15:51:54,606] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:51:54,913] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:51:55,035] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.434 seconds
[2020-07-22 15:52:34,682] {scheduler_job.py:153} INFO - Started process (PID=535707) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:52:34,690] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:52:34,691] {logging_mixin.py:112} INFO - [2020-07-22 15:52:34,691] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:52:34,958] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:52:35,107] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.425 seconds
[2020-07-22 15:53:15,757] {scheduler_job.py:153} INFO - Started process (PID=536631) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:53:15,760] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:53:15,761] {logging_mixin.py:112} INFO - [2020-07-22 15:53:15,760] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:53:16,062] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:53:16,168] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.412 seconds
[2020-07-22 15:53:57,222] {scheduler_job.py:153} INFO - Started process (PID=537502) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:53:57,226] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:53:57,227] {logging_mixin.py:112} INFO - [2020-07-22 15:53:57,227] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:53:57,656] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:53:57,897] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.675 seconds
[2020-07-22 15:54:34,323] {scheduler_job.py:153} INFO - Started process (PID=538270) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:54:34,346] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:54:34,346] {logging_mixin.py:112} INFO - [2020-07-22 15:54:34,346] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:54:34,611] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:54:34,773] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.454 seconds
[2020-07-22 15:55:10,319] {scheduler_job.py:153} INFO - Started process (PID=539036) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:55:10,324] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:55:10,325] {logging_mixin.py:112} INFO - [2020-07-22 15:55:10,324] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:55:10,601] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:55:10,709] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.390 seconds
[2020-07-22 15:55:48,935] {scheduler_job.py:153} INFO - Started process (PID=539842) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:55:48,939] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:55:48,939] {logging_mixin.py:112} INFO - [2020-07-22 15:55:48,939] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:55:49,198] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:55:49,289] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.354 seconds
[2020-07-22 15:56:29,865] {scheduler_job.py:153} INFO - Started process (PID=540696) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:56:29,868] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:56:29,869] {logging_mixin.py:112} INFO - [2020-07-22 15:56:29,869] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:56:34,627] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:56:35,445] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 5.581 seconds
[2020-07-22 15:57:08,003] {scheduler_job.py:153} INFO - Started process (PID=541452) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:57:08,007] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:57:08,007] {logging_mixin.py:112} INFO - [2020-07-22 15:57:08,007] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:57:08,083] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:57:08,700] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.696 seconds
[2020-07-22 15:57:29,851] {scheduler_job.py:153} INFO - Started process (PID=541915) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:57:29,863] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:57:29,864] {logging_mixin.py:112} INFO - [2020-07-22 15:57:29,864] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:57:29,974] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:57:30,691] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.840 seconds
[2020-07-22 15:58:45,955] {scheduler_job.py:153} INFO - Started process (PID=543461) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:58:46,011] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:58:46,012] {logging_mixin.py:112} INFO - [2020-07-22 15:58:46,012] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:58:47,830] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:58:48,149] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 2.194 seconds
[2020-07-22 15:59:13,039] {scheduler_job.py:153} INFO - Started process (PID=544003) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:59:13,047] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 15:59:13,048] {logging_mixin.py:112} INFO - [2020-07-22 15:59:13,048] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:59:13,454] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 15:59:13,620] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.581 seconds
[2020-07-22 16:00:09,444] {scheduler_job.py:153} INFO - Started process (PID=545269) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:00:09,447] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:00:09,447] {logging_mixin.py:112} INFO - [2020-07-22 16:00:09,447] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:00:09,699] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:00:09,830] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.386 seconds
[2020-07-22 16:00:57,987] {scheduler_job.py:153} INFO - Started process (PID=546593) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:00:57,998] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:00:57,999] {logging_mixin.py:112} INFO - [2020-07-22 16:00:57,999] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:00:58,279] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:00:58,384] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.397 seconds
[2020-07-22 16:01:33,266] {scheduler_job.py:153} INFO - Started process (PID=547332) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:01:33,270] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:01:33,270] {logging_mixin.py:112} INFO - [2020-07-22 16:01:33,270] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:01:33,545] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:01:33,678] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.413 seconds
[2020-07-22 16:02:20,879] {scheduler_job.py:153} INFO - Started process (PID=548288) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:02:20,908] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:02:20,908] {logging_mixin.py:112} INFO - [2020-07-22 16:02:20,908] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:02:21,338] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:02:21,466] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.636 seconds
[2020-07-22 16:03:04,670] {scheduler_job.py:153} INFO - Started process (PID=549193) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:03:04,719] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:03:04,736] {logging_mixin.py:112} INFO - [2020-07-22 16:03:04,735] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:03:05,332] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:03:05,520] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.850 seconds
[2020-07-22 16:04:00,289] {scheduler_job.py:153} INFO - Started process (PID=550209) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:04:00,293] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:04:00,293] {logging_mixin.py:112} INFO - [2020-07-22 16:04:00,293] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:04:00,502] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:04:00,598] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.309 seconds
[2020-07-22 16:04:37,964] {scheduler_job.py:153} INFO - Started process (PID=550983) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:04:37,969] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:04:37,969] {logging_mixin.py:112} INFO - [2020-07-22 16:04:37,969] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:04:38,420] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:04:38,525] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.561 seconds
[2020-07-22 16:05:11,919] {scheduler_job.py:153} INFO - Started process (PID=551638) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:05:11,925] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:05:11,928] {logging_mixin.py:112} INFO - [2020-07-22 16:05:11,928] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:05:12,237] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:05:12,478] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.559 seconds
[2020-07-22 16:05:48,925] {scheduler_job.py:153} INFO - Started process (PID=552347) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:05:48,928] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:05:48,928] {logging_mixin.py:112} INFO - [2020-07-22 16:05:48,928] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:05:49,233] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:05:49,396] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.472 seconds
[2020-07-22 16:06:22,310] {scheduler_job.py:153} INFO - Started process (PID=553000) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:06:22,313] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:06:22,314] {logging_mixin.py:112} INFO - [2020-07-22 16:06:22,314] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:06:22,524] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:06:22,629] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.319 seconds
[2020-07-22 16:06:53,771] {scheduler_job.py:153} INFO - Started process (PID=553641) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:06:53,802] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:06:53,807] {logging_mixin.py:112} INFO - [2020-07-22 16:06:53,807] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:06:54,167] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:06:54,374] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.602 seconds
[2020-07-22 16:07:21,259] {scheduler_job.py:153} INFO - Started process (PID=554208) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:07:21,265] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:07:21,265] {logging_mixin.py:112} INFO - [2020-07-22 16:07:21,265] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:07:22,159] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:07:22,306] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.047 seconds
[2020-07-22 16:07:58,047] {scheduler_job.py:153} INFO - Started process (PID=554952) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:07:58,051] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:07:58,051] {logging_mixin.py:112} INFO - [2020-07-22 16:07:58,051] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:07:58,496] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:07:58,612] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.564 seconds
[2020-07-22 16:08:44,936] {scheduler_job.py:153} INFO - Started process (PID=555894) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:08:44,940] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:08:44,941] {logging_mixin.py:112} INFO - [2020-07-22 16:08:44,941] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:08:45,372] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:08:45,553] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.617 seconds
[2020-07-22 16:09:27,518] {scheduler_job.py:153} INFO - Started process (PID=556769) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:09:27,523] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:09:27,523] {logging_mixin.py:112} INFO - [2020-07-22 16:09:27,523] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:09:28,050] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:09:28,175] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.657 seconds
[2020-07-22 16:10:00,308] {scheduler_job.py:153} INFO - Started process (PID=557389) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:10:00,313] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:10:00,314] {logging_mixin.py:112} INFO - [2020-07-22 16:10:00,314] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:10:00,587] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:10:00,796] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.488 seconds
[2020-07-22 16:10:34,239] {scheduler_job.py:153} INFO - Started process (PID=558045) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:10:34,243] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:10:34,243] {logging_mixin.py:112} INFO - [2020-07-22 16:10:34,243] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:10:34,530] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:10:34,696] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.458 seconds
[2020-07-22 16:11:05,294] {scheduler_job.py:153} INFO - Started process (PID=558677) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:11:05,320] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:11:05,321] {logging_mixin.py:112} INFO - [2020-07-22 16:11:05,320] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:11:05,779] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:11:05,986] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.692 seconds
[2020-07-22 16:11:38,931] {scheduler_job.py:153} INFO - Started process (PID=559317) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:11:38,961] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:11:38,962] {logging_mixin.py:112} INFO - [2020-07-22 16:11:38,962] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:11:39,347] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:11:39,488] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.556 seconds
[2020-07-22 16:13:03,582] {scheduler_job.py:153} INFO - Started process (PID=560828) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:13:03,601] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:13:03,602] {logging_mixin.py:112} INFO - [2020-07-22 16:13:03,602] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:13:04,033] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:13:04,321] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.739 seconds
[2020-07-22 16:14:09,164] {scheduler_job.py:153} INFO - Started process (PID=562052) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:14:09,169] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:14:09,169] {logging_mixin.py:112} INFO - [2020-07-22 16:14:09,169] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:14:09,696] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:14:09,852] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.688 seconds
[2020-07-22 16:15:28,667] {scheduler_job.py:153} INFO - Started process (PID=563671) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:15:28,670] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:15:28,671] {logging_mixin.py:112} INFO - [2020-07-22 16:15:28,671] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:15:28,949] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:15:29,104] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.437 seconds
[2020-07-22 16:16:15,404] {scheduler_job.py:153} INFO - Started process (PID=564581) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:16:15,409] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:16:15,409] {logging_mixin.py:112} INFO - [2020-07-22 16:16:15,409] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:16:15,662] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:16:15,806] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.401 seconds
[2020-07-22 16:17:12,289] {scheduler_job.py:153} INFO - Started process (PID=565731) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:17:12,293] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:17:12,294] {logging_mixin.py:112} INFO - [2020-07-22 16:17:12,293] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:17:12,613] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:17:12,726] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.437 seconds
[2020-07-22 16:18:19,271] {scheduler_job.py:153} INFO - Started process (PID=566941) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:18:19,274] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:18:19,274] {logging_mixin.py:112} INFO - [2020-07-22 16:18:19,274] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:18:19,644] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:18:19,842] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.571 seconds
[2020-07-22 16:19:04,321] {scheduler_job.py:153} INFO - Started process (PID=567868) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:19:04,324] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:19:04,324] {logging_mixin.py:112} INFO - [2020-07-22 16:19:04,324] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:19:05,129] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:19:05,233] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.912 seconds
[2020-07-22 16:19:49,983] {scheduler_job.py:153} INFO - Started process (PID=568797) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:19:49,986] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:19:49,986] {logging_mixin.py:112} INFO - [2020-07-22 16:19:49,986] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:19:50,246] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:19:50,359] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.376 seconds
[2020-07-22 16:20:46,300] {scheduler_job.py:153} INFO - Started process (PID=569882) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:20:46,304] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:20:46,305] {logging_mixin.py:112} INFO - [2020-07-22 16:20:46,305] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:20:46,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:20:46,848] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.547 seconds
[2020-07-22 16:21:47,467] {scheduler_job.py:153} INFO - Started process (PID=571017) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:21:47,470] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:21:47,470] {logging_mixin.py:112} INFO - [2020-07-22 16:21:47,470] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:21:47,686] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:21:47,834] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.367 seconds
[2020-07-22 16:22:17,864] {scheduler_job.py:153} INFO - Started process (PID=571651) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:22:17,888] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:22:17,889] {logging_mixin.py:112} INFO - [2020-07-22 16:22:17,888] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:22:18,291] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:22:18,495] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.631 seconds
[2020-07-22 16:22:55,348] {scheduler_job.py:153} INFO - Started process (PID=572417) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:22:55,354] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:22:55,355] {logging_mixin.py:112} INFO - [2020-07-22 16:22:55,354] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:22:55,654] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:22:55,763] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.415 seconds
[2020-07-22 16:23:19,699] {scheduler_job.py:153} INFO - Started process (PID=572968) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:23:19,706] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:23:19,706] {logging_mixin.py:112} INFO - [2020-07-22 16:23:19,706] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:23:19,976] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:23:20,079] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.380 seconds
[2020-07-22 16:23:44,114] {scheduler_job.py:153} INFO - Started process (PID=573548) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:23:44,117] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:23:44,118] {logging_mixin.py:112} INFO - [2020-07-22 16:23:44,118] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:23:44,329] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:23:44,445] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.331 seconds
[2020-07-22 16:24:26,903] {scheduler_job.py:153} INFO - Started process (PID=574425) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:24:26,906] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:24:26,909] {logging_mixin.py:112} INFO - [2020-07-22 16:24:26,909] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:24:27,430] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:24:27,535] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.633 seconds
[2020-07-22 16:24:51,013] {scheduler_job.py:153} INFO - Started process (PID=574900) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:24:51,016] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:24:51,017] {logging_mixin.py:112} INFO - [2020-07-22 16:24:51,016] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:24:51,218] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:24:51,326] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.313 seconds
[2020-07-22 16:25:22,344] {scheduler_job.py:153} INFO - Started process (PID=575567) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:25:22,347] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:25:22,347] {logging_mixin.py:112} INFO - [2020-07-22 16:25:22,347] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:25:22,655] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:25:22,766] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.423 seconds
[2020-07-22 16:25:46,429] {scheduler_job.py:153} INFO - Started process (PID=576060) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:25:46,432] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:25:46,433] {logging_mixin.py:112} INFO - [2020-07-22 16:25:46,432] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:25:46,691] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:25:47,172] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.743 seconds
[2020-07-22 16:26:10,384] {scheduler_job.py:153} INFO - Started process (PID=576613) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:26:10,387] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:26:10,388] {logging_mixin.py:112} INFO - [2020-07-22 16:26:10,388] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:26:10,617] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:26:10,737] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.353 seconds
[2020-07-22 16:26:58,893] {scheduler_job.py:153} INFO - Started process (PID=577519) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:26:58,898] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:26:58,898] {logging_mixin.py:112} INFO - [2020-07-22 16:26:58,898] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:26:59,111] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:26:59,249] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.356 seconds
[2020-07-22 16:27:37,072] {scheduler_job.py:153} INFO - Started process (PID=578325) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:27:37,079] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:27:37,079] {logging_mixin.py:112} INFO - [2020-07-22 16:27:37,079] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:27:37,266] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:27:37,378] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.306 seconds
[2020-07-22 16:28:09,904] {scheduler_job.py:153} INFO - Started process (PID=578953) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:28:09,908] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:28:09,908] {logging_mixin.py:112} INFO - [2020-07-22 16:28:09,908] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:28:10,149] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:28:10,370] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.467 seconds
[2020-07-22 16:28:34,585] {scheduler_job.py:153} INFO - Started process (PID=579518) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:28:34,588] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:28:34,588] {logging_mixin.py:112} INFO - [2020-07-22 16:28:34,588] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:28:34,808] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:28:34,966] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.381 seconds
[2020-07-22 16:29:05,575] {scheduler_job.py:153} INFO - Started process (PID=580175) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:29:05,581] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:29:05,582] {logging_mixin.py:112} INFO - [2020-07-22 16:29:05,582] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:29:05,874] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:29:06,067] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.493 seconds
[2020-07-22 16:29:44,943] {scheduler_job.py:153} INFO - Started process (PID=580995) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:29:44,948] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:29:44,949] {logging_mixin.py:112} INFO - [2020-07-22 16:29:44,948] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:29:45,165] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:29:45,269] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.326 seconds
[2020-07-22 16:30:32,521] {scheduler_job.py:153} INFO - Started process (PID=582102) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:30:32,525] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:30:32,525] {logging_mixin.py:112} INFO - [2020-07-22 16:30:32,525] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:30:32,832] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:30:33,008] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.487 seconds
[2020-07-22 16:31:07,696] {scheduler_job.py:153} INFO - Started process (PID=582832) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:31:07,757] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:31:07,757] {logging_mixin.py:112} INFO - [2020-07-22 16:31:07,757] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:31:08,126] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:31:08,217] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.521 seconds
[2020-07-22 16:31:55,942] {scheduler_job.py:153} INFO - Started process (PID=583742) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:31:55,946] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:31:55,946] {logging_mixin.py:112} INFO - [2020-07-22 16:31:55,946] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:31:56,461] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:31:56,616] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.674 seconds
[2020-07-22 16:32:48,577] {scheduler_job.py:153} INFO - Started process (PID=584788) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:32:48,588] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:32:48,589] {logging_mixin.py:112} INFO - [2020-07-22 16:32:48,588] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:32:48,878] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:32:49,010] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.433 seconds
[2020-07-22 16:34:19,309] {scheduler_job.py:153} INFO - Started process (PID=586569) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:34:19,313] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:34:19,314] {logging_mixin.py:112} INFO - [2020-07-22 16:34:19,313] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:34:19,570] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:34:19,672] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.363 seconds
[2020-07-22 16:35:10,081] {scheduler_job.py:153} INFO - Started process (PID=587562) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:35:10,085] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:35:10,086] {logging_mixin.py:112} INFO - [2020-07-22 16:35:10,086] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:35:10,319] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:35:10,427] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.346 seconds
[2020-07-22 16:36:21,592] {scheduler_job.py:153} INFO - Started process (PID=589020) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:36:21,597] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:36:21,597] {logging_mixin.py:112} INFO - [2020-07-22 16:36:21,597] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:36:21,864] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:36:21,977] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.385 seconds
[2020-07-22 16:37:01,294] {scheduler_job.py:153} INFO - Started process (PID=589866) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:37:01,300] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:37:01,301] {logging_mixin.py:112} INFO - [2020-07-22 16:37:01,301] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:37:01,540] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:37:01,653] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.359 seconds
[2020-07-22 16:37:51,903] {scheduler_job.py:153} INFO - Started process (PID=590912) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:37:51,907] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:37:51,907] {logging_mixin.py:112} INFO - [2020-07-22 16:37:51,907] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:37:52,136] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:37:52,243] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.340 seconds
[2020-07-22 16:38:31,586] {scheduler_job.py:153} INFO - Started process (PID=591760) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:38:31,589] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:38:31,590] {logging_mixin.py:112} INFO - [2020-07-22 16:38:31,590] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:38:31,823] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:38:31,928] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.341 seconds
[2020-07-22 16:39:11,505] {scheduler_job.py:153} INFO - Started process (PID=592616) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:39:11,509] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:39:11,509] {logging_mixin.py:112} INFO - [2020-07-22 16:39:11,509] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:39:11,768] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:39:11,869] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.364 seconds
[2020-07-22 16:39:51,636] {scheduler_job.py:153} INFO - Started process (PID=593489) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:39:51,640] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:39:51,641] {logging_mixin.py:112} INFO - [2020-07-22 16:39:51,641] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:39:51,906] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:39:52,018] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.382 seconds
[2020-07-22 16:40:31,921] {scheduler_job.py:153} INFO - Started process (PID=594344) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:40:31,925] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:40:31,925] {logging_mixin.py:112} INFO - [2020-07-22 16:40:31,925] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:40:32,180] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:40:32,318] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.397 seconds
[2020-07-22 16:41:11,995] {scheduler_job.py:153} INFO - Started process (PID=595194) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:41:11,998] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:41:11,999] {logging_mixin.py:112} INFO - [2020-07-22 16:41:11,999] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:41:12,206] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:41:12,387] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.392 seconds
[2020-07-22 16:41:51,955] {scheduler_job.py:153} INFO - Started process (PID=596077) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:41:51,958] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:41:51,959] {logging_mixin.py:112} INFO - [2020-07-22 16:41:51,959] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:41:52,222] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:41:52,335] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.380 seconds
[2020-07-22 16:42:32,105] {scheduler_job.py:153} INFO - Started process (PID=596929) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:42:32,108] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:42:32,109] {logging_mixin.py:112} INFO - [2020-07-22 16:42:32,109] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:42:32,323] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:42:32,439] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.335 seconds
[2020-07-22 16:43:12,737] {scheduler_job.py:153} INFO - Started process (PID=597801) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:43:12,741] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:43:12,741] {logging_mixin.py:112} INFO - [2020-07-22 16:43:12,741] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:43:13,006] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:43:13,105] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.368 seconds
[2020-07-22 16:43:58,421] {scheduler_job.py:153} INFO - Started process (PID=598742) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:43:58,425] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:43:58,425] {logging_mixin.py:112} INFO - [2020-07-22 16:43:58,425] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:43:58,676] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:43:59,293] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.873 seconds
[2020-07-22 16:44:38,310] {scheduler_job.py:153} INFO - Started process (PID=599582) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:44:38,314] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:44:38,315] {logging_mixin.py:112} INFO - [2020-07-22 16:44:38,315] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:44:38,616] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:44:38,720] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.409 seconds
[2020-07-22 16:45:18,710] {scheduler_job.py:153} INFO - Started process (PID=600487) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:45:18,712] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:45:18,713] {logging_mixin.py:112} INFO - [2020-07-22 16:45:18,713] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:45:18,925] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:45:19,057] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.348 seconds
[2020-07-22 16:45:58,847] {scheduler_job.py:153} INFO - Started process (PID=601328) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:45:58,852] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:45:58,853] {logging_mixin.py:112} INFO - [2020-07-22 16:45:58,853] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:45:59,209] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:45:59,322] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.475 seconds
[2020-07-22 16:47:01,357] {scheduler_job.py:153} INFO - Started process (PID=602576) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:47:01,435] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:47:01,449] {logging_mixin.py:112} INFO - [2020-07-22 16:47:01,449] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:47:01,812] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:47:02,039] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.682 seconds
[2020-07-22 16:48:22,783] {scheduler_job.py:153} INFO - Started process (PID=603977) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:48:22,790] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:48:22,791] {logging_mixin.py:112} INFO - [2020-07-22 16:48:22,790] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:48:23,405] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:48:23,654] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.871 seconds
[2020-07-22 16:49:16,317] {scheduler_job.py:153} INFO - Started process (PID=605007) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:49:16,320] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:49:16,321] {logging_mixin.py:112} INFO - [2020-07-22 16:49:16,321] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:49:16,555] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:49:16,655] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.339 seconds
[2020-07-22 16:50:01,867] {scheduler_job.py:153} INFO - Started process (PID=605931) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:50:01,870] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:50:01,870] {logging_mixin.py:112} INFO - [2020-07-22 16:50:01,870] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:50:02,080] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:50:02,368] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.501 seconds
[2020-07-22 16:50:58,078] {scheduler_job.py:153} INFO - Started process (PID=607024) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:50:58,082] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:50:58,082] {logging_mixin.py:112} INFO - [2020-07-22 16:50:58,082] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:50:58,685] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:50:58,983] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.905 seconds
[2020-07-22 16:52:12,252] {scheduler_job.py:153} INFO - Started process (PID=608393) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:52:12,323] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:52:12,323] {logging_mixin.py:112} INFO - [2020-07-22 16:52:12,323] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:52:12,880] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:52:13,053] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.801 seconds
[2020-07-22 16:53:17,908] {scheduler_job.py:153} INFO - Started process (PID=609634) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:53:17,956] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:53:17,956] {logging_mixin.py:112} INFO - [2020-07-22 16:53:17,956] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:53:18,253] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:53:18,400] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.493 seconds
[2020-07-22 16:54:30,976] {scheduler_job.py:153} INFO - Started process (PID=610927) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:54:30,980] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:54:30,980] {logging_mixin.py:112} INFO - [2020-07-22 16:54:30,980] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:54:31,235] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:54:31,405] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.429 seconds
[2020-07-22 16:55:35,281] {scheduler_job.py:153} INFO - Started process (PID=612106) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:55:35,285] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:55:35,287] {logging_mixin.py:112} INFO - [2020-07-22 16:55:35,286] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:55:35,629] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:55:35,786] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.505 seconds
[2020-07-22 16:56:49,489] {scheduler_job.py:153} INFO - Started process (PID=613436) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:56:49,492] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:56:49,492] {logging_mixin.py:112} INFO - [2020-07-22 16:56:49,492] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:56:49,744] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:56:49,886] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.397 seconds
[2020-07-22 16:57:20,623] {scheduler_job.py:153} INFO - Started process (PID=614109) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:57:20,628] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:57:20,629] {logging_mixin.py:112} INFO - [2020-07-22 16:57:20,628] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:57:20,882] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:57:21,206] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.583 seconds
[2020-07-22 16:57:46,106] {scheduler_job.py:153} INFO - Started process (PID=614648) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:57:46,111] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:57:46,111] {logging_mixin.py:112} INFO - [2020-07-22 16:57:46,111] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:57:46,407] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:57:46,546] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.440 seconds
[2020-07-22 16:58:10,838] {scheduler_job.py:153} INFO - Started process (PID=615157) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:58:10,841] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:58:10,842] {logging_mixin.py:112} INFO - [2020-07-22 16:58:10,842] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:58:11,109] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:58:11,224] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.386 seconds
[2020-07-22 16:58:40,125] {scheduler_job.py:153} INFO - Started process (PID=615796) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:58:40,128] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:58:40,129] {logging_mixin.py:112} INFO - [2020-07-22 16:58:40,129] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:58:40,382] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:58:40,497] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.372 seconds
[2020-07-22 16:59:04,205] {scheduler_job.py:153} INFO - Started process (PID=616274) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:59:04,210] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:59:04,211] {logging_mixin.py:112} INFO - [2020-07-22 16:59:04,210] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:59:04,466] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:59:04,587] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.382 seconds
[2020-07-22 16:59:29,900] {scheduler_job.py:153} INFO - Started process (PID=616860) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:59:29,903] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:59:29,903] {logging_mixin.py:112} INFO - [2020-07-22 16:59:29,903] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:59:30,124] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:59:30,234] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.335 seconds
[2020-07-22 16:59:56,535] {scheduler_job.py:153} INFO - Started process (PID=617463) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:59:56,539] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 16:59:56,540] {logging_mixin.py:112} INFO - [2020-07-22 16:59:56,539] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:59:56,818] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 16:59:57,062] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.528 seconds
[2020-07-22 17:00:20,769] {scheduler_job.py:153} INFO - Started process (PID=618000) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:00:20,772] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:00:20,773] {logging_mixin.py:112} INFO - [2020-07-22 17:00:20,772] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:00:21,027] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:00:21,131] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.362 seconds
[2020-07-22 17:00:51,409] {scheduler_job.py:153} INFO - Started process (PID=618665) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:00:51,412] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:00:51,413] {logging_mixin.py:112} INFO - [2020-07-22 17:00:51,413] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:00:51,668] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:00:51,796] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.388 seconds
[2020-07-22 17:01:15,753] {scheduler_job.py:153} INFO - Started process (PID=619143) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:01:15,756] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:01:15,757] {logging_mixin.py:112} INFO - [2020-07-22 17:01:15,757] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:01:16,077] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:01:16,224] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.471 seconds
[2020-07-22 17:01:46,660] {scheduler_job.py:153} INFO - Started process (PID=619798) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:01:46,664] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:01:46,666] {logging_mixin.py:112} INFO - [2020-07-22 17:01:46,666] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:01:47,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:01:47,167] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.508 seconds
[2020-07-22 17:02:20,788] {scheduler_job.py:153} INFO - Started process (PID=620484) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:02:20,815] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:02:20,817] {logging_mixin.py:112} INFO - [2020-07-22 17:02:20,817] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:02:21,260] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:02:21,425] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.638 seconds
[2020-07-22 17:03:23,749] {scheduler_job.py:153} INFO - Started process (PID=621709) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:03:23,754] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:03:23,755] {logging_mixin.py:112} INFO - [2020-07-22 17:03:23,755] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:03:23,980] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:03:24,107] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.358 seconds
[2020-07-22 17:04:57,659] {scheduler_job.py:153} INFO - Started process (PID=623514) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:04:57,662] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:04:57,663] {logging_mixin.py:112} INFO - [2020-07-22 17:04:57,662] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:04:57,929] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:04:58,044] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.385 seconds
[2020-07-22 17:05:37,813] {scheduler_job.py:153} INFO - Started process (PID=624381) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:05:37,816] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:05:37,816] {logging_mixin.py:112} INFO - [2020-07-22 17:05:37,816] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:05:38,136] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:05:38,245] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.432 seconds
[2020-07-22 17:06:36,018] {scheduler_job.py:153} INFO - Started process (PID=625712) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:06:36,022] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:06:36,023] {logging_mixin.py:112} INFO - [2020-07-22 17:06:36,022] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:06:36,255] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:06:37,642] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.625 seconds
[2020-07-22 17:07:35,314] {scheduler_job.py:153} INFO - Started process (PID=627137) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:07:35,319] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:07:35,320] {logging_mixin.py:112} INFO - [2020-07-22 17:07:35,320] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:07:35,883] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:07:36,161] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.847 seconds
[2020-07-22 17:08:27,457] {scheduler_job.py:153} INFO - Started process (PID=628207) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:08:27,463] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:08:27,465] {logging_mixin.py:112} INFO - [2020-07-22 17:08:27,464] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:08:27,947] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:08:28,604] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.147 seconds
[2020-07-22 17:09:13,092] {scheduler_job.py:153} INFO - Started process (PID=629186) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:09:13,096] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:09:13,096] {logging_mixin.py:112} INFO - [2020-07-22 17:09:13,096] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:09:13,177] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:09:13,409] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.317 seconds
[2020-07-22 17:09:58,022] {scheduler_job.py:153} INFO - Started process (PID=630152) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:09:58,026] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:09:58,026] {logging_mixin.py:112} INFO - [2020-07-22 17:09:58,026] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:09:58,232] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:09:58,335] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.313 seconds
[2020-07-22 17:10:37,703] {scheduler_job.py:153} INFO - Started process (PID=631059) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:10:37,707] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:10:37,708] {logging_mixin.py:112} INFO - [2020-07-22 17:10:37,707] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:10:37,960] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:10:38,068] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.365 seconds
[2020-07-22 17:11:17,571] {scheduler_job.py:153} INFO - Started process (PID=631999) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:11:17,575] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:11:17,576] {logging_mixin.py:112} INFO - [2020-07-22 17:11:17,576] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:11:17,783] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:11:17,914] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.343 seconds
[2020-07-22 17:11:57,625] {scheduler_job.py:153} INFO - Started process (PID=632877) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:11:57,629] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:11:57,629] {logging_mixin.py:112} INFO - [2020-07-22 17:11:57,629] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:11:57,869] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:11:58,025] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.400 seconds
[2020-07-22 17:12:37,163] {scheduler_job.py:153} INFO - Started process (PID=633733) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:12:37,166] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:12:37,166] {logging_mixin.py:112} INFO - [2020-07-22 17:12:37,166] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:12:37,365] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:12:37,486] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.323 seconds
[2020-07-22 17:13:17,178] {scheduler_job.py:153} INFO - Started process (PID=634600) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:13:17,184] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:13:17,184] {logging_mixin.py:112} INFO - [2020-07-22 17:13:17,184] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:13:17,363] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:13:17,465] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.287 seconds
[2020-07-22 17:13:56,870] {scheduler_job.py:153} INFO - Started process (PID=635468) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:13:56,874] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:13:56,874] {logging_mixin.py:112} INFO - [2020-07-22 17:13:56,874] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:13:57,133] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:13:57,234] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.365 seconds
[2020-07-22 17:14:36,405] {scheduler_job.py:153} INFO - Started process (PID=636322) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:14:36,409] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:14:36,409] {logging_mixin.py:112} INFO - [2020-07-22 17:14:36,409] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:14:36,614] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:14:36,736] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.330 seconds
[2020-07-22 17:15:21,653] {scheduler_job.py:153} INFO - Started process (PID=637238) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:15:21,656] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:15:21,656] {logging_mixin.py:112} INFO - [2020-07-22 17:15:21,656] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:15:21,875] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:15:21,991] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.338 seconds
[2020-07-22 17:16:01,509] {scheduler_job.py:153} INFO - Started process (PID=638112) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:16:01,512] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:16:01,513] {logging_mixin.py:112} INFO - [2020-07-22 17:16:01,512] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:16:01,793] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:16:01,975] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.466 seconds
[2020-07-22 17:16:41,130] {scheduler_job.py:153} INFO - Started process (PID=638961) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:16:41,133] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:16:41,134] {logging_mixin.py:112} INFO - [2020-07-22 17:16:41,134] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:16:41,379] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:16:41,504] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.374 seconds
[2020-07-22 17:17:20,911] {scheduler_job.py:153} INFO - Started process (PID=639833) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:17:20,914] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:17:20,914] {logging_mixin.py:112} INFO - [2020-07-22 17:17:20,914] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:17:21,720] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:17:21,830] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.919 seconds
[2020-07-22 17:18:07,387] {scheduler_job.py:153} INFO - Started process (PID=640909) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:18:07,391] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:18:07,391] {logging_mixin.py:112} INFO - [2020-07-22 17:18:07,391] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:18:07,607] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:18:07,744] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.358 seconds
[2020-07-22 17:19:03,050] {scheduler_job.py:153} INFO - Started process (PID=642021) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:19:03,054] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:19:03,054] {logging_mixin.py:112} INFO - [2020-07-22 17:19:03,054] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:19:03,261] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:19:03,370] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.320 seconds
[2020-07-22 17:19:49,133] {scheduler_job.py:153} INFO - Started process (PID=642955) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:19:49,136] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:19:49,137] {logging_mixin.py:112} INFO - [2020-07-22 17:19:49,137] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:19:49,343] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:19:49,492] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.359 seconds
[2020-07-22 17:20:28,671] {scheduler_job.py:153} INFO - Started process (PID=643795) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:20:28,678] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:20:28,678] {logging_mixin.py:112} INFO - [2020-07-22 17:20:28,678] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:20:28,943] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:20:29,050] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.379 seconds
[2020-07-22 17:21:10,271] {scheduler_job.py:153} INFO - Started process (PID=644711) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:21:10,275] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:21:10,275] {logging_mixin.py:112} INFO - [2020-07-22 17:21:10,275] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:21:10,613] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:21:10,769] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.498 seconds
[2020-07-22 17:21:50,661] {scheduler_job.py:153} INFO - Started process (PID=645573) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:21:50,664] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:21:50,664] {logging_mixin.py:112} INFO - [2020-07-22 17:21:50,664] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:21:50,974] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:21:51,123] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.462 seconds
[2020-07-22 17:22:41,158] {scheduler_job.py:153} INFO - Started process (PID=646698) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:22:41,160] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:22:41,161] {logging_mixin.py:112} INFO - [2020-07-22 17:22:41,161] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:22:41,429] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:22:41,679] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.522 seconds
[2020-07-22 17:23:22,093] {scheduler_job.py:153} INFO - Started process (PID=647592) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:23:22,096] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:23:22,097] {logging_mixin.py:112} INFO - [2020-07-22 17:23:22,097] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:23:22,351] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:23:22,502] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.409 seconds
[2020-07-22 17:24:06,760] {scheduler_job.py:153} INFO - Started process (PID=648517) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:24:06,765] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:24:06,766] {logging_mixin.py:112} INFO - [2020-07-22 17:24:06,766] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:24:07,101] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:24:07,258] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.497 seconds
[2020-07-22 17:24:52,792] {scheduler_job.py:153} INFO - Started process (PID=649483) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:24:52,796] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:24:52,797] {logging_mixin.py:112} INFO - [2020-07-22 17:24:52,797] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:24:53,003] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:24:53,192] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.400 seconds
[2020-07-22 17:25:38,032] {scheduler_job.py:153} INFO - Started process (PID=650511) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:25:38,035] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:25:38,035] {logging_mixin.py:112} INFO - [2020-07-22 17:25:38,035] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:25:38,282] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:25:38,383] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.351 seconds
[2020-07-22 17:26:36,056] {scheduler_job.py:153} INFO - Started process (PID=651669) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:26:36,060] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:26:36,061] {logging_mixin.py:112} INFO - [2020-07-22 17:26:36,061] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:26:36,395] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:26:36,554] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.498 seconds
[2020-07-22 17:27:16,187] {scheduler_job.py:153} INFO - Started process (PID=652523) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:27:16,190] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:27:16,191] {logging_mixin.py:112} INFO - [2020-07-22 17:27:16,190] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:27:16,605] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:27:16,688] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.501 seconds
[2020-07-22 17:27:57,489] {scheduler_job.py:153} INFO - Started process (PID=653421) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:27:57,492] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:27:57,493] {logging_mixin.py:112} INFO - [2020-07-22 17:27:57,493] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:27:57,778] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:27:57,882] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.392 seconds
[2020-07-22 17:28:32,276] {scheduler_job.py:153} INFO - Started process (PID=654180) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:28:32,279] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:28:32,280] {logging_mixin.py:112} INFO - [2020-07-22 17:28:32,280] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:28:32,498] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:28:32,610] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.335 seconds
[2020-07-22 17:29:06,500] {scheduler_job.py:153} INFO - Started process (PID=654927) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:29:06,506] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:29:06,506] {logging_mixin.py:112} INFO - [2020-07-22 17:29:06,506] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:29:06,776] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:29:06,885] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.385 seconds
[2020-07-22 17:29:40,566] {scheduler_job.py:153} INFO - Started process (PID=655675) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:29:40,569] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:29:40,570] {logging_mixin.py:112} INFO - [2020-07-22 17:29:40,569] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:29:40,857] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:29:41,032] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.466 seconds
[2020-07-22 17:30:20,411] {scheduler_job.py:153} INFO - Started process (PID=656546) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:30:20,414] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:30:20,414] {logging_mixin.py:112} INFO - [2020-07-22 17:30:20,414] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:30:20,625] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:30:20,718] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.308 seconds
[2020-07-22 17:31:06,118] {scheduler_job.py:153} INFO - Started process (PID=657563) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:31:06,154] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:31:06,155] {logging_mixin.py:112} INFO - [2020-07-22 17:31:06,155] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:31:06,613] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:31:06,792] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.674 seconds
[2020-07-22 17:31:44,215] {scheduler_job.py:153} INFO - Started process (PID=658383) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:31:44,219] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:31:44,220] {logging_mixin.py:112} INFO - [2020-07-22 17:31:44,220] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:31:44,519] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:31:44,629] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.414 seconds
[2020-07-22 17:32:30,358] {scheduler_job.py:153} INFO - Started process (PID=659386) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:32:30,362] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:32:30,362] {logging_mixin.py:112} INFO - [2020-07-22 17:32:30,362] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:32:30,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:32:30,799] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.441 seconds
[2020-07-22 17:33:16,711] {scheduler_job.py:153} INFO - Started process (PID=660358) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:33:16,715] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:33:16,715] {logging_mixin.py:112} INFO - [2020-07-22 17:33:16,715] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:33:17,067] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:33:17,184] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.473 seconds
[2020-07-22 17:33:58,424] {scheduler_job.py:153} INFO - Started process (PID=661231) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:33:58,428] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:33:58,428] {logging_mixin.py:112} INFO - [2020-07-22 17:33:58,428] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:33:58,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:33:58,755] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.331 seconds
[2020-07-22 17:34:43,465] {scheduler_job.py:153} INFO - Started process (PID=662189) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:34:43,468] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:34:43,469] {logging_mixin.py:112} INFO - [2020-07-22 17:34:43,468] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:34:43,676] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:34:43,793] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.328 seconds
[2020-07-22 17:35:23,242] {scheduler_job.py:153} INFO - Started process (PID=663055) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:35:23,245] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:35:23,247] {logging_mixin.py:112} INFO - [2020-07-22 17:35:23,246] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:35:23,483] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:35:23,593] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.351 seconds
[2020-07-22 17:36:03,293] {scheduler_job.py:153} INFO - Started process (PID=663908) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:36:03,298] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:36:03,299] {logging_mixin.py:112} INFO - [2020-07-22 17:36:03,298] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:36:03,559] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:36:03,669] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.376 seconds
[2020-07-22 17:36:43,763] {scheduler_job.py:153} INFO - Started process (PID=664778) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:36:43,767] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:36:43,768] {logging_mixin.py:112} INFO - [2020-07-22 17:36:43,768] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:36:44,084] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:36:44,708] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.946 seconds
[2020-07-22 17:37:28,790] {scheduler_job.py:153} INFO - Started process (PID=665698) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:37:28,794] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:37:28,795] {logging_mixin.py:112} INFO - [2020-07-22 17:37:28,795] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:37:29,052] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:37:29,180] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.390 seconds
[2020-07-22 17:38:09,006] {scheduler_job.py:153} INFO - Started process (PID=666540) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:38:09,010] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:38:09,010] {logging_mixin.py:112} INFO - [2020-07-22 17:38:09,010] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:38:09,210] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:38:09,313] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.307 seconds
[2020-07-22 17:38:49,685] {scheduler_job.py:153} INFO - Started process (PID=667419) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:38:49,688] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:38:49,688] {logging_mixin.py:112} INFO - [2020-07-22 17:38:49,688] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:38:49,900] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:38:50,012] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.328 seconds
[2020-07-22 17:39:29,796] {scheduler_job.py:153} INFO - Started process (PID=668270) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:39:29,801] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:39:29,802] {logging_mixin.py:112} INFO - [2020-07-22 17:39:29,802] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:39:30,060] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:39:30,178] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.382 seconds
[2020-07-22 17:40:09,690] {scheduler_job.py:153} INFO - Started process (PID=669121) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:40:09,693] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:40:09,693] {logging_mixin.py:112} INFO - [2020-07-22 17:40:09,693] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:40:09,901] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:40:10,013] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.323 seconds
[2020-07-22 17:40:43,979] {scheduler_job.py:153} INFO - Started process (PID=669870) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:40:43,983] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:40:43,984] {logging_mixin.py:112} INFO - [2020-07-22 17:40:43,983] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:40:44,293] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:40:44,402] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.423 seconds
[2020-07-22 17:41:18,732] {scheduler_job.py:153} INFO - Started process (PID=670618) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:41:18,736] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:41:18,737] {logging_mixin.py:112} INFO - [2020-07-22 17:41:18,737] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:41:19,000] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:41:19,165] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.434 seconds
[2020-07-22 17:41:52,833] {scheduler_job.py:153} INFO - Started process (PID=671386) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:41:52,836] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:41:52,836] {logging_mixin.py:112} INFO - [2020-07-22 17:41:52,836] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:41:53,062] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:41:53,230] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.398 seconds
[2020-07-22 17:42:29,220] {scheduler_job.py:153} INFO - Started process (PID=672193) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:42:29,223] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:42:29,224] {logging_mixin.py:112} INFO - [2020-07-22 17:42:29,224] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:42:29,475] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:42:29,581] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.361 seconds
[2020-07-22 17:43:09,740] {scheduler_job.py:153} INFO - Started process (PID=673049) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:43:09,743] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:43:09,744] {logging_mixin.py:112} INFO - [2020-07-22 17:43:09,744] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:43:09,956] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:43:10,092] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.352 seconds
[2020-07-22 17:43:49,987] {scheduler_job.py:153} INFO - Started process (PID=673890) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:43:49,990] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:43:49,991] {logging_mixin.py:112} INFO - [2020-07-22 17:43:49,991] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:43:50,203] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:43:50,321] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.334 seconds
[2020-07-22 17:44:30,559] {scheduler_job.py:153} INFO - Started process (PID=674775) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:44:30,562] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:44:30,563] {logging_mixin.py:112} INFO - [2020-07-22 17:44:30,562] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:44:30,862] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:44:30,967] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.409 seconds
[2020-07-22 17:45:10,358] {scheduler_job.py:153} INFO - Started process (PID=675620) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:45:10,361] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:45:10,362] {logging_mixin.py:112} INFO - [2020-07-22 17:45:10,362] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:45:10,668] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:45:10,827] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.469 seconds
[2020-07-22 17:45:55,330] {scheduler_job.py:153} INFO - Started process (PID=676544) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:45:55,335] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:45:55,336] {logging_mixin.py:112} INFO - [2020-07-22 17:45:55,335] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:45:55,521] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:45:55,629] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.299 seconds
[2020-07-22 17:46:41,343] {scheduler_job.py:153} INFO - Started process (PID=677493) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:46:41,348] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:46:41,349] {logging_mixin.py:112} INFO - [2020-07-22 17:46:41,349] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:46:41,688] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:46:41,824] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.480 seconds
[2020-07-22 17:47:26,563] {scheduler_job.py:153} INFO - Started process (PID=678408) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:47:26,569] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:47:26,570] {logging_mixin.py:112} INFO - [2020-07-22 17:47:26,570] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:47:26,826] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:47:27,004] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.442 seconds
[2020-07-22 17:48:07,169] {scheduler_job.py:153} INFO - Started process (PID=679286) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:48:07,171] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:48:07,172] {logging_mixin.py:112} INFO - [2020-07-22 17:48:07,172] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:48:07,380] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:48:07,495] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.327 seconds
[2020-07-22 17:48:46,725] {scheduler_job.py:153} INFO - Started process (PID=680128) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:48:46,728] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:48:46,728] {logging_mixin.py:112} INFO - [2020-07-22 17:48:46,728] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:48:47,009] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:48:47,197] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.472 seconds
[2020-07-22 17:49:32,712] {scheduler_job.py:153} INFO - Started process (PID=681053) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:49:32,716] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:49:32,716] {logging_mixin.py:112} INFO - [2020-07-22 17:49:32,716] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:49:32,976] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:49:33,119] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.406 seconds
[2020-07-22 17:50:12,537] {scheduler_job.py:153} INFO - Started process (PID=681924) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:50:12,541] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:50:12,542] {logging_mixin.py:112} INFO - [2020-07-22 17:50:12,541] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:50:12,803] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:50:13,102] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.565 seconds
[2020-07-22 17:50:52,239] {scheduler_job.py:153} INFO - Started process (PID=682774) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:50:52,244] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:50:52,244] {logging_mixin.py:112} INFO - [2020-07-22 17:50:52,244] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:50:52,502] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:50:52,612] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.373 seconds
[2020-07-22 17:51:26,993] {scheduler_job.py:153} INFO - Started process (PID=683537) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:51:26,996] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:51:26,996] {logging_mixin.py:112} INFO - [2020-07-22 17:51:26,996] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:51:27,233] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:51:27,341] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.348 seconds
[2020-07-22 17:52:06,681] {scheduler_job.py:153} INFO - Started process (PID=684398) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:52:06,685] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:52:06,686] {logging_mixin.py:112} INFO - [2020-07-22 17:52:06,686] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:52:06,943] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:52:07,135] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.455 seconds
[2020-07-22 17:52:41,621] {scheduler_job.py:153} INFO - Started process (PID=685183) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:52:41,627] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:52:41,628] {logging_mixin.py:112} INFO - [2020-07-22 17:52:41,628] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:52:41,884] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:52:42,040] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.419 seconds
[2020-07-22 17:53:17,442] {scheduler_job.py:153} INFO - Started process (PID=685956) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:53:17,447] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:53:17,448] {logging_mixin.py:112} INFO - [2020-07-22 17:53:17,447] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:53:17,696] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:53:17,824] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.382 seconds
[2020-07-22 17:53:57,935] {scheduler_job.py:153} INFO - Started process (PID=686828) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:53:57,940] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:53:57,941] {logging_mixin.py:112} INFO - [2020-07-22 17:53:57,941] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:53:58,145] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:53:58,250] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.315 seconds
[2020-07-22 17:54:38,790] {scheduler_job.py:153} INFO - Started process (PID=687692) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:54:38,795] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:54:38,795] {logging_mixin.py:112} INFO - [2020-07-22 17:54:38,795] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:54:39,046] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:54:39,162] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.372 seconds
[2020-07-22 17:55:23,897] {scheduler_job.py:153} INFO - Started process (PID=688649) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:55:23,901] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:55:23,902] {logging_mixin.py:112} INFO - [2020-07-22 17:55:23,902] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:55:24,116] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:55:24,219] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.322 seconds
[2020-07-22 17:56:09,140] {scheduler_job.py:153} INFO - Started process (PID=689660) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:56:09,145] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:56:09,145] {logging_mixin.py:112} INFO - [2020-07-22 17:56:09,145] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:56:09,412] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:56:09,709] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.569 seconds
[2020-07-22 17:56:44,763] {scheduler_job.py:153} INFO - Started process (PID=690403) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:56:44,766] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:56:44,766] {logging_mixin.py:112} INFO - [2020-07-22 17:56:44,766] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:56:44,838] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:56:45,432] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.670 seconds
[2020-07-22 17:57:19,835] {scheduler_job.py:153} INFO - Started process (PID=691171) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:57:19,839] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:57:19,840] {logging_mixin.py:112} INFO - [2020-07-22 17:57:19,840] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:57:20,054] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:57:20,166] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.331 seconds
[2020-07-22 17:57:55,166] {scheduler_job.py:153} INFO - Started process (PID=691878) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:57:55,170] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:57:55,171] {logging_mixin.py:112} INFO - [2020-07-22 17:57:55,171] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:57:55,489] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:57:55,595] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.429 seconds
[2020-07-22 17:58:29,386] {scheduler_job.py:153} INFO - Started process (PID=692581) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:58:29,389] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:58:29,389] {logging_mixin.py:112} INFO - [2020-07-22 17:58:29,389] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:58:29,645] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:58:29,755] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.370 seconds
[2020-07-22 17:59:15,354] {scheduler_job.py:153} INFO - Started process (PID=693485) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:59:15,359] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:59:15,360] {logging_mixin.py:112} INFO - [2020-07-22 17:59:15,359] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:59:15,601] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:59:15,763] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.410 seconds
[2020-07-22 17:59:50,282] {scheduler_job.py:153} INFO - Started process (PID=694191) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:59:50,285] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 17:59:50,285] {logging_mixin.py:112} INFO - [2020-07-22 17:59:50,285] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:59:50,494] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 17:59:50,593] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.311 seconds
[2020-07-22 18:00:25,076] {scheduler_job.py:153} INFO - Started process (PID=694943) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:00:25,079] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:00:25,079] {logging_mixin.py:112} INFO - [2020-07-22 18:00:25,079] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:00:25,292] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:00:25,395] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.319 seconds
[2020-07-22 18:01:06,757] {scheduler_job.py:153} INFO - Started process (PID=695818) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:01:06,760] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:01:06,761] {logging_mixin.py:112} INFO - [2020-07-22 18:01:06,760] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:01:07,069] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:01:07,251] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.494 seconds
[2020-07-22 18:01:41,208] {scheduler_job.py:153} INFO - Started process (PID=696577) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:01:41,210] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:01:41,211] {logging_mixin.py:112} INFO - [2020-07-22 18:01:41,211] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:01:41,467] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:01:41,572] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.364 seconds
[2020-07-22 18:02:21,641] {scheduler_job.py:153} INFO - Started process (PID=697405) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:02:21,644] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:02:21,645] {logging_mixin.py:112} INFO - [2020-07-22 18:02:21,645] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:02:21,851] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:02:21,953] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.312 seconds
[2020-07-22 18:03:01,499] {scheduler_job.py:153} INFO - Started process (PID=699046) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:03:01,502] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:03:01,503] {logging_mixin.py:112} INFO - [2020-07-22 18:03:01,502] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:03:01,716] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:03:01,832] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.333 seconds
[2020-07-22 18:03:42,536] {scheduler_job.py:153} INFO - Started process (PID=699876) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:03:42,539] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:03:42,539] {logging_mixin.py:112} INFO - [2020-07-22 18:03:42,539] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:03:42,744] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:03:42,855] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.320 seconds
[2020-07-22 18:04:22,337] {scheduler_job.py:153} INFO - Started process (PID=700635) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:04:22,341] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:04:22,342] {logging_mixin.py:112} INFO - [2020-07-22 18:04:22,342] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:04:22,556] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:04:22,721] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.384 seconds
[2020-07-22 18:04:57,813] {scheduler_job.py:153} INFO - Started process (PID=701342) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:04:57,816] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:04:57,817] {logging_mixin.py:112} INFO - [2020-07-22 18:04:57,817] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:04:58,017] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:04:58,137] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.325 seconds
[2020-07-22 18:05:32,163] {scheduler_job.py:153} INFO - Started process (PID=702039) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:05:32,166] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:05:32,167] {logging_mixin.py:112} INFO - [2020-07-22 18:05:32,167] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:05:32,369] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:05:32,472] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.309 seconds
[2020-07-22 18:06:06,656] {scheduler_job.py:153} INFO - Started process (PID=702772) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:06:06,660] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:06:06,661] {logging_mixin.py:112} INFO - [2020-07-22 18:06:06,661] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:06:06,889] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:06:07,009] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.353 seconds
[2020-07-22 18:07:03,158] {scheduler_job.py:153} INFO - Started process (PID=703877) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:07:03,163] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:07:03,163] {logging_mixin.py:112} INFO - [2020-07-22 18:07:03,163] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:07:03,438] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:07:03,557] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.399 seconds
[2020-07-22 18:07:44,041] {scheduler_job.py:153} INFO - Started process (PID=704671) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:07:44,046] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:07:44,047] {logging_mixin.py:112} INFO - [2020-07-22 18:07:44,046] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:07:44,325] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:07:44,450] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.410 seconds
[2020-07-22 18:08:23,767] {scheduler_job.py:153} INFO - Started process (PID=706107) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:08:23,772] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:08:23,772] {logging_mixin.py:112} INFO - [2020-07-22 18:08:23,772] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:08:24,030] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:08:24,173] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.406 seconds
[2020-07-22 18:08:58,699] {scheduler_job.py:153} INFO - Started process (PID=706779) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:08:58,703] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:08:58,704] {logging_mixin.py:112} INFO - [2020-07-22 18:08:58,703] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:08:59,115] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:08:59,229] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.530 seconds
[2020-07-22 18:09:38,548] {scheduler_job.py:153} INFO - Started process (PID=707514) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:09:38,551] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:09:38,552] {logging_mixin.py:112} INFO - [2020-07-22 18:09:38,552] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:09:38,807] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:09:38,939] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.391 seconds
[2020-07-22 18:10:12,905] {scheduler_job.py:153} INFO - Started process (PID=708189) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:10:12,908] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:10:12,909] {logging_mixin.py:112} INFO - [2020-07-22 18:10:12,909] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:10:13,162] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:10:13,291] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.386 seconds
[2020-07-22 18:10:47,185] {scheduler_job.py:153} INFO - Started process (PID=708913) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:10:47,188] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:10:47,189] {logging_mixin.py:112} INFO - [2020-07-22 18:10:47,189] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:10:47,440] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:10:47,549] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.364 seconds
[2020-07-22 18:11:21,897] {scheduler_job.py:153} INFO - Started process (PID=709616) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:11:21,900] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:11:21,900] {logging_mixin.py:112} INFO - [2020-07-22 18:11:21,900] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:11:22,151] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:11:22,320] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.423 seconds
[2020-07-22 18:12:00,107] {scheduler_job.py:153} INFO - Started process (PID=710409) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:12:00,112] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:12:00,112] {logging_mixin.py:112} INFO - [2020-07-22 18:12:00,112] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:12:00,432] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:12:00,575] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.468 seconds
[2020-07-22 18:12:35,344] {scheduler_job.py:153} INFO - Started process (PID=711389) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:12:35,348] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:12:35,348] {logging_mixin.py:112} INFO - [2020-07-22 18:12:35,348] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:12:35,557] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:12:35,655] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.311 seconds
[2020-07-22 18:13:15,432] {scheduler_job.py:153} INFO - Started process (PID=712712) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:13:15,436] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:13:15,436] {logging_mixin.py:112} INFO - [2020-07-22 18:13:15,436] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:13:15,689] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:13:15,802] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.370 seconds
[2020-07-22 18:13:50,282] {scheduler_job.py:153} INFO - Started process (PID=713392) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:13:50,285] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:13:50,286] {logging_mixin.py:112} INFO - [2020-07-22 18:13:50,286] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:13:50,543] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:13:50,648] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.365 seconds
[2020-07-22 18:14:24,953] {scheduler_job.py:153} INFO - Started process (PID=714145) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:14:24,956] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:14:24,957] {logging_mixin.py:112} INFO - [2020-07-22 18:14:24,957] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:14:25,259] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:14:25,926] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.973 seconds
[2020-07-22 18:15:04,834] {scheduler_job.py:153} INFO - Started process (PID=715488) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:15:04,838] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:15:04,838] {logging_mixin.py:112} INFO - [2020-07-22 18:15:04,838] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:15:05,132] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:15:05,311] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.477 seconds
[2020-07-22 18:15:44,937] {scheduler_job.py:153} INFO - Started process (PID=716243) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:15:44,942] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:15:44,943] {logging_mixin.py:112} INFO - [2020-07-22 18:15:44,942] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:15:45,202] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:15:45,330] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.393 seconds
[2020-07-22 18:16:25,301] {scheduler_job.py:153} INFO - Started process (PID=717056) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:16:25,305] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:16:25,305] {logging_mixin.py:112} INFO - [2020-07-22 18:16:25,305] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:16:25,549] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:16:25,711] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.409 seconds
[2020-07-22 18:17:06,745] {scheduler_job.py:153} INFO - Started process (PID=717854) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:17:06,748] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:17:06,748] {logging_mixin.py:112} INFO - [2020-07-22 18:17:06,748] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:17:06,999] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:17:07,096] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.351 seconds
[2020-07-22 18:17:41,650] {scheduler_job.py:153} INFO - Started process (PID=718548) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:17:41,653] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:17:41,654] {logging_mixin.py:112} INFO - [2020-07-22 18:17:41,654] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:17:41,963] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:17:42,070] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.420 seconds
[2020-07-22 18:18:21,288] {scheduler_job.py:153} INFO - Started process (PID=719305) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:18:21,292] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:18:21,293] {logging_mixin.py:112} INFO - [2020-07-22 18:18:21,293] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:18:21,559] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:18:21,702] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.414 seconds
[2020-07-22 18:19:01,835] {scheduler_job.py:153} INFO - Started process (PID=720093) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:19:01,840] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:19:01,840] {logging_mixin.py:112} INFO - [2020-07-22 18:19:01,840] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:19:02,125] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:19:02,263] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.428 seconds
[2020-07-22 18:19:36,548] {scheduler_job.py:153} INFO - Started process (PID=720775) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:19:36,553] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:19:36,553] {logging_mixin.py:112} INFO - [2020-07-22 18:19:36,553] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:19:36,960] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:19:37,077] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.528 seconds
[2020-07-22 18:20:16,059] {scheduler_job.py:153} INFO - Started process (PID=721546) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:20:16,064] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:20:16,064] {logging_mixin.py:112} INFO - [2020-07-22 18:20:16,064] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:20:16,337] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:20:16,544] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.485 seconds
[2020-07-22 18:20:56,022] {scheduler_job.py:153} INFO - Started process (PID=722296) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:20:56,030] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:20:56,030] {logging_mixin.py:112} INFO - [2020-07-22 18:20:56,030] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:20:56,257] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:20:56,412] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.390 seconds
[2020-07-22 18:21:30,670] {scheduler_job.py:153} INFO - Started process (PID=723029) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:21:30,675] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:21:30,676] {logging_mixin.py:112} INFO - [2020-07-22 18:21:30,676] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:21:30,936] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:21:31,057] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.387 seconds
[2020-07-22 18:22:05,202] {scheduler_job.py:153} INFO - Started process (PID=723718) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:22:05,205] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:22:05,206] {logging_mixin.py:112} INFO - [2020-07-22 18:22:05,206] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:22:05,917] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:22:06,385] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.182 seconds
[2020-07-22 18:22:44,894] {scheduler_job.py:153} INFO - Started process (PID=724527) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:22:44,900] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:22:44,900] {logging_mixin.py:112} INFO - [2020-07-22 18:22:44,900] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:22:45,171] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:22:45,273] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.379 seconds
[2020-07-22 18:23:24,819] {scheduler_job.py:153} INFO - Started process (PID=725314) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:23:24,822] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:23:24,823] {logging_mixin.py:112} INFO - [2020-07-22 18:23:24,823] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:23:25,083] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:23:25,196] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.377 seconds
[2020-07-22 18:24:05,530] {scheduler_job.py:153} INFO - Started process (PID=726092) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:24:05,533] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:24:05,533] {logging_mixin.py:112} INFO - [2020-07-22 18:24:05,533] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:24:05,722] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:24:05,829] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.299 seconds
[2020-07-22 18:24:45,651] {scheduler_job.py:153} INFO - Started process (PID=726848) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:24:45,655] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:24:45,656] {logging_mixin.py:112} INFO - [2020-07-22 18:24:45,655] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:24:45,870] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:24:45,988] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.337 seconds
[2020-07-22 18:25:25,337] {scheduler_job.py:153} INFO - Started process (PID=727652) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:25:25,341] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:25:25,342] {logging_mixin.py:112} INFO - [2020-07-22 18:25:25,342] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:25:25,651] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:25:25,744] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.407 seconds
[2020-07-22 18:26:00,052] {scheduler_job.py:153} INFO - Started process (PID=728361) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:26:00,056] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:26:00,056] {logging_mixin.py:112} INFO - [2020-07-22 18:26:00,056] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:26:00,260] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:26:00,359] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.307 seconds
[2020-07-22 18:26:39,785] {scheduler_job.py:153} INFO - Started process (PID=729147) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:26:39,790] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:26:39,790] {logging_mixin.py:112} INFO - [2020-07-22 18:26:39,790] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:26:40,052] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:26:40,183] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.398 seconds
[2020-07-22 18:27:35,851] {scheduler_job.py:153} INFO - Started process (PID=730278) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:27:35,859] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:27:35,859] {logging_mixin.py:112} INFO - [2020-07-22 18:27:35,859] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:27:36,256] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:27:36,450] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.600 seconds
[2020-07-22 18:28:27,273] {scheduler_job.py:153} INFO - Started process (PID=731602) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:28:27,276] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:28:27,277] {logging_mixin.py:112} INFO - [2020-07-22 18:28:27,277] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:28:27,649] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:28:27,937] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.664 seconds
[2020-07-22 18:29:19,025] {scheduler_job.py:153} INFO - Started process (PID=733224) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:29:19,030] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:29:19,030] {logging_mixin.py:112} INFO - [2020-07-22 18:29:19,030] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:29:20,459] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:29:21,099] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 2.074 seconds
[2020-07-22 18:30:11,507] {scheduler_job.py:153} INFO - Started process (PID=734195) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:30:11,511] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:30:11,511] {logging_mixin.py:112} INFO - [2020-07-22 18:30:11,511] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:30:11,729] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:30:11,875] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.368 seconds
[2020-07-22 18:30:56,839] {scheduler_job.py:153} INFO - Started process (PID=735068) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:30:56,843] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:30:56,844] {logging_mixin.py:112} INFO - [2020-07-22 18:30:56,844] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:30:57,117] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:30:57,240] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.401 seconds
[2020-07-22 18:31:37,134] {scheduler_job.py:153} INFO - Started process (PID=735818) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:31:37,139] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:31:37,140] {logging_mixin.py:112} INFO - [2020-07-22 18:31:37,140] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:31:37,453] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:31:37,572] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.438 seconds
[2020-07-22 18:32:17,487] {scheduler_job.py:153} INFO - Started process (PID=737335) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:32:17,494] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:32:17,495] {logging_mixin.py:112} INFO - [2020-07-22 18:32:17,495] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:32:17,771] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:32:17,905] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.417 seconds
[2020-07-22 18:33:22,085] {scheduler_job.py:153} INFO - Started process (PID=738754) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:33:22,088] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:33:22,089] {logging_mixin.py:112} INFO - [2020-07-22 18:33:22,088] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:33:22,396] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:33:22,496] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.411 seconds
[2020-07-22 18:34:02,292] {scheduler_job.py:153} INFO - Started process (PID=739547) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:34:02,296] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:34:02,296] {logging_mixin.py:112} INFO - [2020-07-22 18:34:02,296] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:34:02,594] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:34:02,709] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.417 seconds
[2020-07-22 18:34:42,187] {scheduler_job.py:153} INFO - Started process (PID=740303) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:34:42,192] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:34:42,192] {logging_mixin.py:112} INFO - [2020-07-22 18:34:42,192] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:34:42,399] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:34:42,492] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.305 seconds
[2020-07-22 18:35:28,624] {scheduler_job.py:153} INFO - Started process (PID=741205) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:35:28,628] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:35:28,628] {logging_mixin.py:112} INFO - [2020-07-22 18:35:28,628] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:35:28,915] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:35:29,051] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.427 seconds
[2020-07-22 18:36:09,273] {scheduler_job.py:153} INFO - Started process (PID=742006) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:36:09,276] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:36:09,276] {logging_mixin.py:112} INFO - [2020-07-22 18:36:09,276] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:36:09,346] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:36:09,537] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.264 seconds
[2020-07-22 18:36:43,685] {scheduler_job.py:153} INFO - Started process (PID=742694) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:36:43,689] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:36:43,690] {logging_mixin.py:112} INFO - [2020-07-22 18:36:43,690] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:36:44,104] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:36:44,195] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.510 seconds
[2020-07-22 18:37:18,460] {scheduler_job.py:153} INFO - Started process (PID=743407) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:37:18,464] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:37:18,465] {logging_mixin.py:112} INFO - [2020-07-22 18:37:18,465] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:37:18,725] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:37:18,896] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.436 seconds
[2020-07-22 18:37:52,897] {scheduler_job.py:153} INFO - Started process (PID=744082) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:37:52,901] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:37:52,901] {logging_mixin.py:112} INFO - [2020-07-22 18:37:52,901] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:37:53,157] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:37:53,253] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.356 seconds
[2020-07-22 18:38:27,516] {scheduler_job.py:153} INFO - Started process (PID=744764) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:38:27,520] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:38:27,520] {logging_mixin.py:112} INFO - [2020-07-22 18:38:27,520] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:38:27,726] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:38:27,828] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.312 seconds
[2020-07-22 18:39:01,686] {scheduler_job.py:153} INFO - Started process (PID=746130) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:39:01,690] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:39:01,690] {logging_mixin.py:112} INFO - [2020-07-22 18:39:01,690] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:39:01,978] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:39:02,100] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.414 seconds
[2020-07-22 18:39:36,627] {scheduler_job.py:153} INFO - Started process (PID=747490) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:39:36,630] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:39:36,630] {logging_mixin.py:112} INFO - [2020-07-22 18:39:36,630] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:39:36,885] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:39:37,046] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.419 seconds
[2020-07-22 18:40:17,252] {scheduler_job.py:153} INFO - Started process (PID=748319) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:40:17,256] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:40:17,256] {logging_mixin.py:112} INFO - [2020-07-22 18:40:17,256] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:40:17,554] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:40:17,670] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.418 seconds
[2020-07-22 18:41:15,773] {scheduler_job.py:153} INFO - Started process (PID=750631) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:41:15,796] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:41:15,797] {logging_mixin.py:112} INFO - [2020-07-22 18:41:15,796] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:41:16,365] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:41:16,816] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.042 seconds
[2020-07-22 18:42:02,278] {scheduler_job.py:153} INFO - Started process (PID=751542) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:42:02,282] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:42:02,282] {logging_mixin.py:112} INFO - [2020-07-22 18:42:02,282] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:42:02,540] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:42:02,673] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.395 seconds
[2020-07-22 18:42:42,757] {scheduler_job.py:153} INFO - Started process (PID=753249) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:42:42,761] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-22 18:42:42,762] {logging_mixin.py:112} INFO - [2020-07-22 18:42:42,762] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:42:43,094] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-22 18:42:43,499] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.743 seconds
