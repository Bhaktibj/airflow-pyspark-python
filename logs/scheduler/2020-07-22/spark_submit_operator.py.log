[2020-07-22 12:51:20,196] {scheduler_job.py:153} INFO - Started process (PID=292535) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:51:20,200] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:51:20,200] {logging_mixin.py:112} INFO - [2020-07-22 12:51:20,200] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:51:20,209] {logging_mixin.py:112} INFO - [2020-07-22 12:51:20,207] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:51:20,209] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:51:20,367] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.172 seconds
[2020-07-22 12:51:32,204] {scheduler_job.py:153} INFO - Started process (PID=292809) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:51:32,210] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:51:32,210] {logging_mixin.py:112} INFO - [2020-07-22 12:51:32,210] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:51:32,219] {logging_mixin.py:112} INFO - [2020-07-22 12:51:32,218] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:51:32,220] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:51:32,368] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.164 seconds
[2020-07-22 12:51:45,242] {scheduler_job.py:153} INFO - Started process (PID=293187) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:51:45,246] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:51:45,246] {logging_mixin.py:112} INFO - [2020-07-22 12:51:45,246] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:51:45,254] {logging_mixin.py:112} INFO - [2020-07-22 12:51:45,252] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:51:45,254] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:51:45,347] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.105 seconds
[2020-07-22 12:51:56,241] {scheduler_job.py:153} INFO - Started process (PID=293426) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:51:56,244] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:51:56,244] {logging_mixin.py:112} INFO - [2020-07-22 12:51:56,244] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:51:56,251] {logging_mixin.py:112} INFO - [2020-07-22 12:51:56,250] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:51:56,251] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:51:56,381] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.140 seconds
[2020-07-22 12:52:08,254] {scheduler_job.py:153} INFO - Started process (PID=293685) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:52:08,257] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:52:08,257] {logging_mixin.py:112} INFO - [2020-07-22 12:52:08,257] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:52:08,267] {logging_mixin.py:112} INFO - [2020-07-22 12:52:08,265] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:52:08,267] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:52:08,359] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.104 seconds
[2020-07-22 12:52:20,287] {scheduler_job.py:153} INFO - Started process (PID=294012) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:52:20,295] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:52:20,296] {logging_mixin.py:112} INFO - [2020-07-22 12:52:20,296] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:52:20,310] {logging_mixin.py:112} INFO - [2020-07-22 12:52:20,305] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:52:20,310] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:52:20,492] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.205 seconds
[2020-07-22 12:52:32,292] {scheduler_job.py:153} INFO - Started process (PID=294306) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:52:32,294] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:52:32,295] {logging_mixin.py:112} INFO - [2020-07-22 12:52:32,295] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:52:32,301] {logging_mixin.py:112} INFO - [2020-07-22 12:52:32,300] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:52:32,301] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:52:32,449] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.157 seconds
[2020-07-22 12:52:46,694] {scheduler_job.py:153} INFO - Started process (PID=294623) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:52:46,697] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:52:46,698] {logging_mixin.py:112} INFO - [2020-07-22 12:52:46,698] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:52:46,705] {logging_mixin.py:112} INFO - [2020-07-22 12:52:46,704] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:52:46,705] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:52:46,827] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.133 seconds
[2020-07-22 12:53:01,635] {scheduler_job.py:153} INFO - Started process (PID=294948) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:01,640] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:53:01,640] {logging_mixin.py:112} INFO - [2020-07-22 12:53:01,640] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:01,648] {logging_mixin.py:112} INFO - [2020-07-22 12:53:01,646] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:53:01,648] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:01,776] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.141 seconds
[2020-07-22 12:53:10,938] {scheduler_job.py:153} INFO - Started process (PID=295228) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:10,942] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:53:10,943] {logging_mixin.py:112} INFO - [2020-07-22 12:53:10,943] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:10,955] {logging_mixin.py:112} INFO - [2020-07-22 12:53:10,953] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:53:10,956] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:11,062] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.124 seconds
[2020-07-22 12:53:20,355] {scheduler_job.py:153} INFO - Started process (PID=295478) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:20,357] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:53:20,358] {logging_mixin.py:112} INFO - [2020-07-22 12:53:20,358] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:20,365] {logging_mixin.py:112} INFO - [2020-07-22 12:53:20,364] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:53:20,365] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:20,462] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.107 seconds
[2020-07-22 12:53:32,362] {scheduler_job.py:153} INFO - Started process (PID=295738) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:32,374] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:53:32,375] {logging_mixin.py:112} INFO - [2020-07-22 12:53:32,375] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:32,393] {logging_mixin.py:112} INFO - [2020-07-22 12:53:32,389] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:53:32,393] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:32,585] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.223 seconds
[2020-07-22 12:53:46,730] {scheduler_job.py:153} INFO - Started process (PID=296096) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:46,735] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:53:46,736] {logging_mixin.py:112} INFO - [2020-07-22 12:53:46,735] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:46,755] {logging_mixin.py:112} INFO - [2020-07-22 12:53:46,753] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:53:46,756] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:46,840] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.111 seconds
[2020-07-22 12:53:58,450] {scheduler_job.py:153} INFO - Started process (PID=296388) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:58,453] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:53:58,454] {logging_mixin.py:112} INFO - [2020-07-22 12:53:58,453] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:58,461] {logging_mixin.py:112} INFO - [2020-07-22 12:53:58,459] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:53:58,461] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:53:58,551] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.101 seconds
[2020-07-22 12:54:08,418] {scheduler_job.py:153} INFO - Started process (PID=296621) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:08,420] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:54:08,421] {logging_mixin.py:112} INFO - [2020-07-22 12:54:08,421] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:08,429] {logging_mixin.py:112} INFO - [2020-07-22 12:54:08,427] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:54:08,429] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:08,568] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.150 seconds
[2020-07-22 12:54:20,964] {scheduler_job.py:153} INFO - Started process (PID=296900) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:20,968] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:54:20,969] {logging_mixin.py:112} INFO - [2020-07-22 12:54:20,969] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:20,984] {logging_mixin.py:112} INFO - [2020-07-22 12:54:20,981] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:54:20,984] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:21,085] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.121 seconds
[2020-07-22 12:54:36,128] {scheduler_job.py:153} INFO - Started process (PID=297266) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:36,132] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:54:36,133] {logging_mixin.py:112} INFO - [2020-07-22 12:54:36,133] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:36,148] {logging_mixin.py:112} INFO - [2020-07-22 12:54:36,145] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:54:36,148] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:36,251] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.124 seconds
[2020-07-22 12:54:45,331] {scheduler_job.py:153} INFO - Started process (PID=297533) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:45,333] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:54:45,334] {logging_mixin.py:112} INFO - [2020-07-22 12:54:45,333] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:45,340] {logging_mixin.py:112} INFO - [2020-07-22 12:54:45,339] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/spark_submit_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/spark_submit_operator.py", line 13, in <module>
    spark_submit_local = SparkSubmitOperator(application='/home/bhakti/airflow/spark_jobs/python/spark_test.py',
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/contrib/operators/spark_submit_operator.py", line 127, in __init__
    super(SparkSubmitOperator, self).__init__(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['task_id'] is required
[2020-07-22 12:54:45,341] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:45,663] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.333 seconds
[2020-07-22 12:54:56,483] {scheduler_job.py:153} INFO - Started process (PID=297782) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:56,489] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:54:56,490] {logging_mixin.py:112} INFO - [2020-07-22 12:54:56,490] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:56,509] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:54:56,530] {logging_mixin.py:112} INFO - [2020-07-22 12:54:56,530] {dag.py:1501} INFO - Creating ORM DAG for submit_data
[2020-07-22 12:54:56,807] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.324 seconds
[2020-07-22 12:55:10,387] {scheduler_job.py:153} INFO - Started process (PID=298075) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:55:10,394] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:55:10,395] {logging_mixin.py:112} INFO - [2020-07-22 12:55:10,395] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:55:10,414] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:55:10,549] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.162 seconds
[2020-07-22 12:55:29,781] {scheduler_job.py:153} INFO - Started process (PID=298521) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:55:29,784] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:55:29,785] {logging_mixin.py:112} INFO - [2020-07-22 12:55:29,785] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:55:29,793] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:55:29,925] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 12:55:30,495] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20 00:00:00+00:00: scheduled__2020-07-20T00:00:00+00:00, externally triggered: False>
[2020-07-22 12:55:30,501] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:00:00+00:00: scheduled__2020-07-20T00:00:00+00:00, externally triggered: False>
[2020-07-22 12:55:30,520] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 12:55:30,527] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:00:00+00:00 [scheduled]> in ORM
[2020-07-22 12:55:30,888] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.107 seconds
[2020-07-22 12:55:41,112] {scheduler_job.py:153} INFO - Started process (PID=298802) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:55:41,116] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:55:41,117] {logging_mixin.py:112} INFO - [2020-07-22 12:55:41,117] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:55:41,130] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:55:41,292] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 12:55:41,644] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:01:00+00:00: scheduled__2020-07-20T00:01:00+00:00, externally triggered: False>
[2020-07-22 12:55:41,662] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:00:00+00:00: scheduled__2020-07-20T00:00:00+00:00, externally triggered: False>
[2020-07-22 12:55:41,686] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:01:00+00:00: scheduled__2020-07-20T00:01:00+00:00, externally triggered: False>
[2020-07-22 12:55:41,703] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 07:25:34.217495+00:00: manual__2020-07-22T07:25:34.217495+00:00, externally triggered: True>
[2020-07-22 12:55:41,742] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 12:55:41,748] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:01:00+00:00 [scheduled]> in ORM
[2020-07-22 12:55:41,756] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 07:25:34.217495+00:00 [scheduled]> in ORM
[2020-07-22 12:55:41,932] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.820 seconds
[2020-07-22 12:56:29,972] {scheduler_job.py:153} INFO - Started process (PID=299884) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:56:29,976] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:56:29,977] {logging_mixin.py:112} INFO - [2020-07-22 12:56:29,977] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:56:29,986] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:56:30,103] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 12:56:30,592] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:02:00+00:00: scheduled__2020-07-20T00:02:00+00:00, externally triggered: False>
[2020-07-22 12:56:30,597] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:00:00+00:00: scheduled__2020-07-20T00:00:00+00:00, externally triggered: False>
[2020-07-22 12:56:30,608] {logging_mixin.py:112} INFO - [2020-07-22 12:56:30,608] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:00:00+00:00: scheduled__2020-07-20T00:00:00+00:00, externally triggered: False> failed
[2020-07-22 12:56:30,758] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:01:00+00:00: scheduled__2020-07-20T00:01:00+00:00, externally triggered: False>
[2020-07-22 12:56:30,770] {logging_mixin.py:112} INFO - [2020-07-22 12:56:30,770] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:01:00+00:00: scheduled__2020-07-20T00:01:00+00:00, externally triggered: False> failed
[2020-07-22 12:56:30,924] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:02:00+00:00: scheduled__2020-07-20T00:02:00+00:00, externally triggered: False>
[2020-07-22 12:56:30,940] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 07:25:34.217495+00:00: manual__2020-07-22T07:25:34.217495+00:00, externally triggered: True>
[2020-07-22 12:56:30,948] {logging_mixin.py:112} INFO - [2020-07-22 12:56:30,948] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-22 07:25:34.217495+00:00: manual__2020-07-22T07:25:34.217495+00:00, externally triggered: True> failed
[2020-07-22 12:56:31,066] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 12:56:31,074] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:02:00+00:00 [scheduled]> in ORM
[2020-07-22 12:56:31,351] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.379 seconds
[2020-07-22 12:57:11,649] {scheduler_job.py:153} INFO - Started process (PID=300719) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:57:11,653] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:57:11,653] {logging_mixin.py:112} INFO - [2020-07-22 12:57:11,653] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:57:11,663] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:57:11,794] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 12:57:12,187] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:03:00+00:00: scheduled__2020-07-20T00:03:00+00:00, externally triggered: False>
[2020-07-22 12:57:12,192] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:02:00+00:00: scheduled__2020-07-20T00:02:00+00:00, externally triggered: False>
[2020-07-22 12:57:12,201] {logging_mixin.py:112} INFO - [2020-07-22 12:57:12,201] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:02:00+00:00: scheduled__2020-07-20T00:02:00+00:00, externally triggered: False> failed
[2020-07-22 12:57:12,305] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:03:00+00:00: scheduled__2020-07-20T00:03:00+00:00, externally triggered: False>
[2020-07-22 12:57:12,326] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 12:57:12,330] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:03:00+00:00 [scheduled]> in ORM
[2020-07-22 12:57:12,582] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.934 seconds
[2020-07-22 12:57:37,237] {scheduler_job.py:153} INFO - Started process (PID=301320) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:57:37,251] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:57:37,251] {logging_mixin.py:112} INFO - [2020-07-22 12:57:37,251] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:57:37,269] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:57:37,451] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 12:57:37,821] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:04:00+00:00: scheduled__2020-07-20T00:04:00+00:00, externally triggered: False>
[2020-07-22 12:57:37,854] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:03:00+00:00: scheduled__2020-07-20T00:03:00+00:00, externally triggered: False>
[2020-07-22 12:57:37,892] {logging_mixin.py:112} INFO - [2020-07-22 12:57:37,892] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:03:00+00:00: scheduled__2020-07-20T00:03:00+00:00, externally triggered: False> failed
[2020-07-22 12:57:38,038] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:04:00+00:00: scheduled__2020-07-20T00:04:00+00:00, externally triggered: False>
[2020-07-22 12:57:38,063] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 12:57:38,071] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:04:00+00:00 [scheduled]> in ORM
[2020-07-22 12:57:38,223] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.985 seconds
[2020-07-22 12:58:02,824] {scheduler_job.py:153} INFO - Started process (PID=301884) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:58:02,827] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:58:02,828] {logging_mixin.py:112} INFO - [2020-07-22 12:58:02,827] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:58:02,843] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:58:02,995] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 12:58:03,326] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:05:00+00:00: scheduled__2020-07-20T00:05:00+00:00, externally triggered: False>
[2020-07-22 12:58:03,336] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:04:00+00:00: scheduled__2020-07-20T00:04:00+00:00, externally triggered: False>
[2020-07-22 12:58:03,351] {logging_mixin.py:112} INFO - [2020-07-22 12:58:03,350] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:04:00+00:00: scheduled__2020-07-20T00:04:00+00:00, externally triggered: False> failed
[2020-07-22 12:58:03,494] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:05:00+00:00: scheduled__2020-07-20T00:05:00+00:00, externally triggered: False>
[2020-07-22 12:58:03,507] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 12:58:03,511] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:05:00+00:00 [scheduled]> in ORM
[2020-07-22 12:58:03,655] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.830 seconds
[2020-07-22 12:58:38,959] {scheduler_job.py:153} INFO - Started process (PID=302700) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:58:38,964] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:58:38,964] {logging_mixin.py:112} INFO - [2020-07-22 12:58:38,964] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:58:38,974] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:58:39,101] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 12:58:39,501] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:06:00+00:00: scheduled__2020-07-20T00:06:00+00:00, externally triggered: False>
[2020-07-22 12:58:39,505] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:05:00+00:00: scheduled__2020-07-20T00:05:00+00:00, externally triggered: False>
[2020-07-22 12:58:39,513] {logging_mixin.py:112} INFO - [2020-07-22 12:58:39,513] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:05:00+00:00: scheduled__2020-07-20T00:05:00+00:00, externally triggered: False> failed
[2020-07-22 12:58:39,617] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:06:00+00:00: scheduled__2020-07-20T00:06:00+00:00, externally triggered: False>
[2020-07-22 12:58:39,635] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 12:58:39,639] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:06:00+00:00 [scheduled]> in ORM
[2020-07-22 12:58:39,778] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.819 seconds
[2020-07-22 12:59:10,391] {scheduler_job.py:153} INFO - Started process (PID=303399) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:59:10,406] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:59:10,407] {logging_mixin.py:112} INFO - [2020-07-22 12:59:10,407] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:59:10,433] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:59:10,631] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 12:59:11,084] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:07:00+00:00: scheduled__2020-07-20T00:07:00+00:00, externally triggered: False>
[2020-07-22 12:59:11,089] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:06:00+00:00: scheduled__2020-07-20T00:06:00+00:00, externally triggered: False>
[2020-07-22 12:59:11,097] {logging_mixin.py:112} INFO - [2020-07-22 12:59:11,097] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:06:00+00:00: scheduled__2020-07-20T00:06:00+00:00, externally triggered: False> failed
[2020-07-22 12:59:11,385] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:07:00+00:00: scheduled__2020-07-20T00:07:00+00:00, externally triggered: False>
[2020-07-22 12:59:11,406] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 12:59:11,411] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:07:00+00:00 [scheduled]> in ORM
[2020-07-22 12:59:11,545] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.154 seconds
[2020-07-22 12:59:35,297] {scheduler_job.py:153} INFO - Started process (PID=303956) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:59:35,303] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 12:59:35,303] {logging_mixin.py:112} INFO - [2020-07-22 12:59:35,303] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:59:35,323] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 12:59:35,471] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 12:59:35,814] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:08:00+00:00: scheduled__2020-07-20T00:08:00+00:00, externally triggered: False>
[2020-07-22 12:59:35,817] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:07:00+00:00: scheduled__2020-07-20T00:07:00+00:00, externally triggered: False>
[2020-07-22 12:59:35,831] {logging_mixin.py:112} INFO - [2020-07-22 12:59:35,831] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:07:00+00:00: scheduled__2020-07-20T00:07:00+00:00, externally triggered: False> failed
[2020-07-22 12:59:35,940] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:08:00+00:00: scheduled__2020-07-20T00:08:00+00:00, externally triggered: False>
[2020-07-22 12:59:35,966] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 12:59:35,973] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:08:00+00:00 [scheduled]> in ORM
[2020-07-22 12:59:36,128] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.832 seconds
[2020-07-22 13:00:06,538] {scheduler_job.py:153} INFO - Started process (PID=304682) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:00:06,543] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:00:06,544] {logging_mixin.py:112} INFO - [2020-07-22 13:00:06,544] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:00:06,559] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:00:06,741] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:00:07,180] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:09:00+00:00: scheduled__2020-07-20T00:09:00+00:00, externally triggered: False>
[2020-07-22 13:00:07,183] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:08:00+00:00: scheduled__2020-07-20T00:08:00+00:00, externally triggered: False>
[2020-07-22 13:00:07,193] {logging_mixin.py:112} INFO - [2020-07-22 13:00:07,192] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:08:00+00:00: scheduled__2020-07-20T00:08:00+00:00, externally triggered: False> failed
[2020-07-22 13:00:07,296] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:09:00+00:00: scheduled__2020-07-20T00:09:00+00:00, externally triggered: False>
[2020-07-22 13:00:07,314] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:00:07,319] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:09:00+00:00 [scheduled]> in ORM
[2020-07-22 13:00:07,471] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.933 seconds
[2020-07-22 13:00:37,146] {scheduler_job.py:153} INFO - Started process (PID=305358) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:00:37,149] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:00:37,150] {logging_mixin.py:112} INFO - [2020-07-22 13:00:37,149] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:00:37,158] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:00:37,300] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:00:37,731] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:10:00+00:00: scheduled__2020-07-20T00:10:00+00:00, externally triggered: False>
[2020-07-22 13:00:37,735] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:09:00+00:00: scheduled__2020-07-20T00:09:00+00:00, externally triggered: False>
[2020-07-22 13:00:37,743] {logging_mixin.py:112} INFO - [2020-07-22 13:00:37,743] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:09:00+00:00: scheduled__2020-07-20T00:09:00+00:00, externally triggered: False> failed
[2020-07-22 13:00:37,852] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:10:00+00:00: scheduled__2020-07-20T00:10:00+00:00, externally triggered: False>
[2020-07-22 13:00:37,872] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:00:37,877] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:10:00+00:00 [scheduled]> in ORM
[2020-07-22 13:00:38,035] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.890 seconds
[2020-07-22 13:01:01,208] {scheduler_job.py:153} INFO - Started process (PID=305899) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:01:01,212] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:01:01,212] {logging_mixin.py:112} INFO - [2020-07-22 13:01:01,212] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:01:01,222] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:01:01,341] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:01:01,668] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:11:00+00:00: scheduled__2020-07-20T00:11:00+00:00, externally triggered: False>
[2020-07-22 13:01:01,673] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:10:00+00:00: scheduled__2020-07-20T00:10:00+00:00, externally triggered: False>
[2020-07-22 13:01:01,689] {logging_mixin.py:112} INFO - [2020-07-22 13:01:01,688] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:10:00+00:00: scheduled__2020-07-20T00:10:00+00:00, externally triggered: False> failed
[2020-07-22 13:01:01,810] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:11:00+00:00: scheduled__2020-07-20T00:11:00+00:00, externally triggered: False>
[2020-07-22 13:01:01,837] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:01:01,843] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:11:00+00:00 [scheduled]> in ORM
[2020-07-22 13:01:02,023] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.815 seconds
[2020-07-22 13:01:31,161] {scheduler_job.py:153} INFO - Started process (PID=306580) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:01:31,164] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:01:31,165] {logging_mixin.py:112} INFO - [2020-07-22 13:01:31,165] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:01:31,175] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:01:31,388] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:01:31,787] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:12:00+00:00: scheduled__2020-07-20T00:12:00+00:00, externally triggered: False>
[2020-07-22 13:01:31,792] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:11:00+00:00: scheduled__2020-07-20T00:11:00+00:00, externally triggered: False>
[2020-07-22 13:01:31,799] {logging_mixin.py:112} INFO - [2020-07-22 13:01:31,799] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:11:00+00:00: scheduled__2020-07-20T00:11:00+00:00, externally triggered: False> failed
[2020-07-22 13:01:31,898] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:12:00+00:00: scheduled__2020-07-20T00:12:00+00:00, externally triggered: False>
[2020-07-22 13:01:31,915] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:01:31,919] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:12:00+00:00 [scheduled]> in ORM
[2020-07-22 13:01:32,104] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.942 seconds
[2020-07-22 13:02:00,757] {scheduler_job.py:153} INFO - Started process (PID=307249) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:02:00,764] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:02:00,765] {logging_mixin.py:112} INFO - [2020-07-22 13:02:00,765] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:02:00,778] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:02:00,910] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:02:01,323] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:13:00+00:00: scheduled__2020-07-20T00:13:00+00:00, externally triggered: False>
[2020-07-22 13:02:01,331] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:12:00+00:00: scheduled__2020-07-20T00:12:00+00:00, externally triggered: False>
[2020-07-22 13:02:01,353] {logging_mixin.py:112} INFO - [2020-07-22 13:02:01,353] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:12:00+00:00: scheduled__2020-07-20T00:12:00+00:00, externally triggered: False> failed
[2020-07-22 13:02:01,465] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:13:00+00:00: scheduled__2020-07-20T00:13:00+00:00, externally triggered: False>
[2020-07-22 13:02:01,477] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:02:01,481] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:13:00+00:00 [scheduled]> in ORM
[2020-07-22 13:02:01,642] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.885 seconds
[2020-07-22 13:02:30,327] {scheduler_job.py:153} INFO - Started process (PID=307845) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:02:30,330] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:02:30,330] {logging_mixin.py:112} INFO - [2020-07-22 13:02:30,330] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:02:30,339] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:02:31,263] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:02:31,589] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:14:00+00:00: scheduled__2020-07-20T00:14:00+00:00, externally triggered: False>
[2020-07-22 13:02:31,595] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:13:00+00:00: scheduled__2020-07-20T00:13:00+00:00, externally triggered: False>
[2020-07-22 13:02:31,610] {logging_mixin.py:112} INFO - [2020-07-22 13:02:31,610] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:13:00+00:00: scheduled__2020-07-20T00:13:00+00:00, externally triggered: False> failed
[2020-07-22 13:02:31,732] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:14:00+00:00: scheduled__2020-07-20T00:14:00+00:00, externally triggered: False>
[2020-07-22 13:02:31,750] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:02:31,757] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:14:00+00:00 [scheduled]> in ORM
[2020-07-22 13:02:31,939] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.612 seconds
[2020-07-22 13:03:00,840] {scheduler_job.py:153} INFO - Started process (PID=308523) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:03:00,843] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:03:00,844] {logging_mixin.py:112} INFO - [2020-07-22 13:03:00,844] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:03:00,853] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:03:00,988] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:03:01,379] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:15:00+00:00: scheduled__2020-07-20T00:15:00+00:00, externally triggered: False>
[2020-07-22 13:03:01,384] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:14:00+00:00: scheduled__2020-07-20T00:14:00+00:00, externally triggered: False>
[2020-07-22 13:03:01,391] {logging_mixin.py:112} INFO - [2020-07-22 13:03:01,391] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:14:00+00:00: scheduled__2020-07-20T00:14:00+00:00, externally triggered: False> failed
[2020-07-22 13:03:01,567] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:15:00+00:00: scheduled__2020-07-20T00:15:00+00:00, externally triggered: False>
[2020-07-22 13:03:01,586] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:03:01,590] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:15:00+00:00 [scheduled]> in ORM
[2020-07-22 13:03:01,860] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.019 seconds
[2020-07-22 13:03:25,179] {scheduler_job.py:153} INFO - Started process (PID=309120) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:03:25,182] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:03:25,182] {logging_mixin.py:112} INFO - [2020-07-22 13:03:25,182] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:03:25,192] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:03:25,305] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:03:25,734] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:16:00+00:00: scheduled__2020-07-20T00:16:00+00:00, externally triggered: False>
[2020-07-22 13:03:25,739] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:15:00+00:00: scheduled__2020-07-20T00:15:00+00:00, externally triggered: False>
[2020-07-22 13:03:25,746] {logging_mixin.py:112} INFO - [2020-07-22 13:03:25,746] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:15:00+00:00: scheduled__2020-07-20T00:15:00+00:00, externally triggered: False> failed
[2020-07-22 13:03:25,867] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:16:00+00:00: scheduled__2020-07-20T00:16:00+00:00, externally triggered: False>
[2020-07-22 13:03:25,886] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:03:25,890] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:16:00+00:00 [scheduled]> in ORM
[2020-07-22 13:03:26,051] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.872 seconds
[2020-07-22 13:03:49,479] {scheduler_job.py:153} INFO - Started process (PID=309664) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:03:49,482] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:03:49,484] {logging_mixin.py:112} INFO - [2020-07-22 13:03:49,484] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:03:49,498] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:03:49,610] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:03:50,076] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:17:00+00:00: scheduled__2020-07-20T00:17:00+00:00, externally triggered: False>
[2020-07-22 13:03:50,080] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:16:00+00:00: scheduled__2020-07-20T00:16:00+00:00, externally triggered: False>
[2020-07-22 13:03:50,088] {logging_mixin.py:112} INFO - [2020-07-22 13:03:50,088] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:16:00+00:00: scheduled__2020-07-20T00:16:00+00:00, externally triggered: False> failed
[2020-07-22 13:03:50,202] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:17:00+00:00: scheduled__2020-07-20T00:17:00+00:00, externally triggered: False>
[2020-07-22 13:03:50,216] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:03:50,221] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:17:00+00:00 [scheduled]> in ORM
[2020-07-22 13:03:50,366] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.887 seconds
[2020-07-22 13:04:18,862] {scheduler_job.py:153} INFO - Started process (PID=310346) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:04:18,869] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:04:18,870] {logging_mixin.py:112} INFO - [2020-07-22 13:04:18,870] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:04:18,886] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:04:19,036] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:04:19,390] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:18:00+00:00: scheduled__2020-07-20T00:18:00+00:00, externally triggered: False>
[2020-07-22 13:04:19,398] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:17:00+00:00: scheduled__2020-07-20T00:17:00+00:00, externally triggered: False>
[2020-07-22 13:04:19,408] {logging_mixin.py:112} INFO - [2020-07-22 13:04:19,408] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:17:00+00:00: scheduled__2020-07-20T00:17:00+00:00, externally triggered: False> failed
[2020-07-22 13:04:19,536] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:18:00+00:00: scheduled__2020-07-20T00:18:00+00:00, externally triggered: False>
[2020-07-22 13:04:19,557] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:04:19,563] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:18:00+00:00 [scheduled]> in ORM
[2020-07-22 13:04:19,728] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.866 seconds
[2020-07-22 13:04:43,377] {scheduler_job.py:153} INFO - Started process (PID=310910) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:04:43,392] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:04:43,392] {logging_mixin.py:112} INFO - [2020-07-22 13:04:43,392] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:04:43,415] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:04:43,536] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:04:43,882] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:19:00+00:00: scheduled__2020-07-20T00:19:00+00:00, externally triggered: False>
[2020-07-22 13:04:43,889] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:18:00+00:00: scheduled__2020-07-20T00:18:00+00:00, externally triggered: False>
[2020-07-22 13:04:43,904] {logging_mixin.py:112} INFO - [2020-07-22 13:04:43,904] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:18:00+00:00: scheduled__2020-07-20T00:18:00+00:00, externally triggered: False> failed
[2020-07-22 13:04:44,070] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:19:00+00:00: scheduled__2020-07-20T00:19:00+00:00, externally triggered: False>
[2020-07-22 13:04:44,092] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:04:44,097] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:19:00+00:00 [scheduled]> in ORM
[2020-07-22 13:04:44,250] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.873 seconds
[2020-07-22 13:05:15,923] {scheduler_job.py:153} INFO - Started process (PID=311615) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:05:15,925] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:05:15,926] {logging_mixin.py:112} INFO - [2020-07-22 13:05:15,926] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:05:15,935] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:05:16,057] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:05:16,453] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:20:00+00:00: scheduled__2020-07-20T00:20:00+00:00, externally triggered: False>
[2020-07-22 13:05:16,457] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:19:00+00:00: scheduled__2020-07-20T00:19:00+00:00, externally triggered: False>
[2020-07-22 13:05:16,466] {logging_mixin.py:112} INFO - [2020-07-22 13:05:16,466] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:19:00+00:00: scheduled__2020-07-20T00:19:00+00:00, externally triggered: False> failed
[2020-07-22 13:05:16,627] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:20:00+00:00: scheduled__2020-07-20T00:20:00+00:00, externally triggered: False>
[2020-07-22 13:05:16,644] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:05:16,648] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:20:00+00:00 [scheduled]> in ORM
[2020-07-22 13:05:16,829] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.907 seconds
[2020-07-22 13:05:45,168] {scheduler_job.py:153} INFO - Started process (PID=312356) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:05:45,171] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:05:45,172] {logging_mixin.py:112} INFO - [2020-07-22 13:05:45,171] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:05:45,182] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:05:45,298] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:05:45,628] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:21:00+00:00: scheduled__2020-07-20T00:21:00+00:00, externally triggered: False>
[2020-07-22 13:05:45,632] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:20:00+00:00: scheduled__2020-07-20T00:20:00+00:00, externally triggered: False>
[2020-07-22 13:05:45,639] {logging_mixin.py:112} INFO - [2020-07-22 13:05:45,639] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:20:00+00:00: scheduled__2020-07-20T00:20:00+00:00, externally triggered: False> failed
[2020-07-22 13:05:45,750] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:21:00+00:00: scheduled__2020-07-20T00:21:00+00:00, externally triggered: False>
[2020-07-22 13:05:45,766] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:05:45,770] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:21:00+00:00 [scheduled]> in ORM
[2020-07-22 13:05:45,921] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.753 seconds
[2020-07-22 13:06:09,274] {scheduler_job.py:153} INFO - Started process (PID=312928) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:06:09,280] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:06:09,281] {logging_mixin.py:112} INFO - [2020-07-22 13:06:09,281] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:06:09,297] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:06:09,975] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:06:10,679] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:22:00+00:00: scheduled__2020-07-20T00:22:00+00:00, externally triggered: False>
[2020-07-22 13:06:10,683] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:21:00+00:00: scheduled__2020-07-20T00:21:00+00:00, externally triggered: False>
[2020-07-22 13:06:10,692] {logging_mixin.py:112} INFO - [2020-07-22 13:06:10,692] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:21:00+00:00: scheduled__2020-07-20T00:21:00+00:00, externally triggered: False> failed
[2020-07-22 13:06:10,828] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:22:00+00:00: scheduled__2020-07-20T00:22:00+00:00, externally triggered: False>
[2020-07-22 13:06:10,848] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:06:10,857] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:22:00+00:00 [scheduled]> in ORM
[2020-07-22 13:06:11,008] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.734 seconds
[2020-07-22 13:06:40,494] {scheduler_job.py:153} INFO - Started process (PID=313639) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:06:40,497] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:06:40,497] {logging_mixin.py:112} INFO - [2020-07-22 13:06:40,497] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:06:40,517] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:06:40,632] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:06:41,011] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:23:00+00:00: scheduled__2020-07-20T00:23:00+00:00, externally triggered: False>
[2020-07-22 13:06:41,017] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:22:00+00:00: scheduled__2020-07-20T00:22:00+00:00, externally triggered: False>
[2020-07-22 13:06:41,036] {logging_mixin.py:112} INFO - [2020-07-22 13:06:41,035] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:22:00+00:00: scheduled__2020-07-20T00:22:00+00:00, externally triggered: False> failed
[2020-07-22 13:06:41,386] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:23:00+00:00: scheduled__2020-07-20T00:23:00+00:00, externally triggered: False>
[2020-07-22 13:06:41,413] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:06:41,421] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:23:00+00:00 [scheduled]> in ORM
[2020-07-22 13:06:41,599] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.105 seconds
[2020-07-22 13:07:17,040] {scheduler_job.py:153} INFO - Started process (PID=314436) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:07:17,042] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:07:17,043] {logging_mixin.py:112} INFO - [2020-07-22 13:07:17,043] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:07:17,052] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:07:17,223] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:07:18,409] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:24:00+00:00: scheduled__2020-07-20T00:24:00+00:00, externally triggered: False>
[2020-07-22 13:07:18,414] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:23:00+00:00: scheduled__2020-07-20T00:23:00+00:00, externally triggered: False>
[2020-07-22 13:07:18,421] {logging_mixin.py:112} INFO - [2020-07-22 13:07:18,421] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:23:00+00:00: scheduled__2020-07-20T00:23:00+00:00, externally triggered: False> failed
[2020-07-22 13:07:18,531] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:24:00+00:00: scheduled__2020-07-20T00:24:00+00:00, externally triggered: False>
[2020-07-22 13:07:18,548] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:07:18,552] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:24:00+00:00 [scheduled]> in ORM
[2020-07-22 13:07:18,713] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.673 seconds
[2020-07-22 13:07:41,191] {scheduler_job.py:153} INFO - Started process (PID=315044) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:07:41,196] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:07:41,197] {logging_mixin.py:112} INFO - [2020-07-22 13:07:41,196] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:07:41,219] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:07:41,471] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:07:41,846] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:25:00+00:00: scheduled__2020-07-20T00:25:00+00:00, externally triggered: False>
[2020-07-22 13:07:41,850] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:24:00+00:00: scheduled__2020-07-20T00:24:00+00:00, externally triggered: False>
[2020-07-22 13:07:41,876] {logging_mixin.py:112} INFO - [2020-07-22 13:07:41,876] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:24:00+00:00: scheduled__2020-07-20T00:24:00+00:00, externally triggered: False> failed
[2020-07-22 13:07:41,986] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:25:00+00:00: scheduled__2020-07-20T00:25:00+00:00, externally triggered: False>
[2020-07-22 13:07:42,002] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:07:42,007] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:25:00+00:00 [scheduled]> in ORM
[2020-07-22 13:07:42,172] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.982 seconds
[2020-07-22 13:08:05,843] {scheduler_job.py:153} INFO - Started process (PID=315589) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:08:05,845] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:08:05,846] {logging_mixin.py:112} INFO - [2020-07-22 13:08:05,846] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:08:05,856] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:08:06,041] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:08:06,414] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:26:00+00:00: scheduled__2020-07-20T00:26:00+00:00, externally triggered: False>
[2020-07-22 13:08:06,419] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:25:00+00:00: scheduled__2020-07-20T00:25:00+00:00, externally triggered: False>
[2020-07-22 13:08:06,426] {logging_mixin.py:112} INFO - [2020-07-22 13:08:06,426] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:25:00+00:00: scheduled__2020-07-20T00:25:00+00:00, externally triggered: False> failed
[2020-07-22 13:08:06,532] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:26:00+00:00: scheduled__2020-07-20T00:26:00+00:00, externally triggered: False>
[2020-07-22 13:08:06,557] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:08:06,565] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:26:00+00:00 [scheduled]> in ORM
[2020-07-22 13:08:06,776] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.934 seconds
[2020-07-22 13:08:35,383] {scheduler_job.py:153} INFO - Started process (PID=316313) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:08:35,386] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:08:35,386] {logging_mixin.py:112} INFO - [2020-07-22 13:08:35,386] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:08:35,395] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:08:35,503] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:08:35,849] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:27:00+00:00: scheduled__2020-07-20T00:27:00+00:00, externally triggered: False>
[2020-07-22 13:08:35,853] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:26:00+00:00: scheduled__2020-07-20T00:26:00+00:00, externally triggered: False>
[2020-07-22 13:08:35,860] {logging_mixin.py:112} INFO - [2020-07-22 13:08:35,860] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:26:00+00:00: scheduled__2020-07-20T00:26:00+00:00, externally triggered: False> failed
[2020-07-22 13:08:35,955] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:27:00+00:00: scheduled__2020-07-20T00:27:00+00:00, externally triggered: False>
[2020-07-22 13:08:35,973] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:08:35,977] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:27:00+00:00 [scheduled]> in ORM
[2020-07-22 13:08:36,142] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.759 seconds
[2020-07-22 13:08:59,318] {scheduler_job.py:153} INFO - Started process (PID=316889) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:08:59,322] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:08:59,322] {logging_mixin.py:112} INFO - [2020-07-22 13:08:59,322] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:08:59,338] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:08:59,523] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:08:59,927] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:28:00+00:00: scheduled__2020-07-20T00:28:00+00:00, externally triggered: False>
[2020-07-22 13:08:59,932] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:27:00+00:00: scheduled__2020-07-20T00:27:00+00:00, externally triggered: False>
[2020-07-22 13:08:59,939] {logging_mixin.py:112} INFO - [2020-07-22 13:08:59,939] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:27:00+00:00: scheduled__2020-07-20T00:27:00+00:00, externally triggered: False> failed
[2020-07-22 13:09:00,044] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:28:00+00:00: scheduled__2020-07-20T00:28:00+00:00, externally triggered: False>
[2020-07-22 13:09:00,060] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:09:00,066] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:28:00+00:00 [scheduled]> in ORM
[2020-07-22 13:09:00,233] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.915 seconds
[2020-07-22 13:09:29,798] {scheduler_job.py:153} INFO - Started process (PID=317597) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:09:29,803] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:09:29,803] {logging_mixin.py:112} INFO - [2020-07-22 13:09:29,803] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:09:29,815] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:09:30,115] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:09:30,816] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:29:00+00:00: scheduled__2020-07-20T00:29:00+00:00, externally triggered: False>
[2020-07-22 13:09:30,823] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:28:00+00:00: scheduled__2020-07-20T00:28:00+00:00, externally triggered: False>
[2020-07-22 13:09:30,836] {logging_mixin.py:112} INFO - [2020-07-22 13:09:30,836] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:28:00+00:00: scheduled__2020-07-20T00:28:00+00:00, externally triggered: False> failed
[2020-07-22 13:09:31,257] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:29:00+00:00: scheduled__2020-07-20T00:29:00+00:00, externally triggered: False>
[2020-07-22 13:09:31,284] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:09:31,292] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:29:00+00:00 [scheduled]> in ORM
[2020-07-22 13:09:31,489] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.691 seconds
[2020-07-22 13:10:00,389] {scheduler_job.py:153} INFO - Started process (PID=318327) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:10:00,393] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:10:00,394] {logging_mixin.py:112} INFO - [2020-07-22 13:10:00,393] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:10:00,402] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:10:00,643] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:10:01,027] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:30:00+00:00: scheduled__2020-07-20T00:30:00+00:00, externally triggered: False>
[2020-07-22 13:10:01,032] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:29:00+00:00: scheduled__2020-07-20T00:29:00+00:00, externally triggered: False>
[2020-07-22 13:10:01,043] {logging_mixin.py:112} INFO - [2020-07-22 13:10:01,043] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:29:00+00:00: scheduled__2020-07-20T00:29:00+00:00, externally triggered: False> failed
[2020-07-22 13:10:01,157] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:30:00+00:00: scheduled__2020-07-20T00:30:00+00:00, externally triggered: False>
[2020-07-22 13:10:01,177] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:10:01,181] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:30:00+00:00 [scheduled]> in ORM
[2020-07-22 13:10:01,335] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.947 seconds
[2020-07-22 13:10:30,574] {scheduler_job.py:153} INFO - Started process (PID=318962) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:10:30,579] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:10:30,579] {logging_mixin.py:112} INFO - [2020-07-22 13:10:30,579] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:10:30,591] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:10:30,701] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:10:31,207] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:31:00+00:00: scheduled__2020-07-20T00:31:00+00:00, externally triggered: False>
[2020-07-22 13:10:31,216] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:30:00+00:00: scheduled__2020-07-20T00:30:00+00:00, externally triggered: False>
[2020-07-22 13:10:31,233] {logging_mixin.py:112} INFO - [2020-07-22 13:10:31,232] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:30:00+00:00: scheduled__2020-07-20T00:30:00+00:00, externally triggered: False> failed
[2020-07-22 13:10:31,359] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:31:00+00:00: scheduled__2020-07-20T00:31:00+00:00, externally triggered: False>
[2020-07-22 13:10:31,415] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:10:31,425] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:31:00+00:00 [scheduled]> in ORM
[2020-07-22 13:10:31,614] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.040 seconds
[2020-07-22 13:11:02,996] {scheduler_job.py:153} INFO - Started process (PID=319677) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:11:03,001] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:11:03,001] {logging_mixin.py:112} INFO - [2020-07-22 13:11:03,001] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:11:03,015] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:11:03,237] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:11:03,573] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:32:00+00:00: scheduled__2020-07-20T00:32:00+00:00, externally triggered: False>
[2020-07-22 13:11:03,576] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:31:00+00:00: scheduled__2020-07-20T00:31:00+00:00, externally triggered: False>
[2020-07-22 13:11:03,584] {logging_mixin.py:112} INFO - [2020-07-22 13:11:03,584] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:31:00+00:00: scheduled__2020-07-20T00:31:00+00:00, externally triggered: False> failed
[2020-07-22 13:11:03,682] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:32:00+00:00: scheduled__2020-07-20T00:32:00+00:00, externally triggered: False>
[2020-07-22 13:11:03,700] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:11:03,704] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:32:00+00:00 [scheduled]> in ORM
[2020-07-22 13:11:03,849] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.853 seconds
[2020-07-22 13:11:37,531] {scheduler_job.py:153} INFO - Started process (PID=320421) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:11:37,535] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:11:37,536] {logging_mixin.py:112} INFO - [2020-07-22 13:11:37,536] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:11:37,548] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:11:37,710] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:11:38,142] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:33:00+00:00: scheduled__2020-07-20T00:33:00+00:00, externally triggered: False>
[2020-07-22 13:11:38,150] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:32:00+00:00: scheduled__2020-07-20T00:32:00+00:00, externally triggered: False>
[2020-07-22 13:11:38,168] {logging_mixin.py:112} INFO - [2020-07-22 13:11:38,167] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:32:00+00:00: scheduled__2020-07-20T00:32:00+00:00, externally triggered: False> failed
[2020-07-22 13:11:38,328] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:33:00+00:00: scheduled__2020-07-20T00:33:00+00:00, externally triggered: False>
[2020-07-22 13:11:38,346] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:11:38,349] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:33:00+00:00 [scheduled]> in ORM
[2020-07-22 13:11:38,507] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.976 seconds
[2020-07-22 13:12:08,058] {scheduler_job.py:153} INFO - Started process (PID=321137) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:12:08,061] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:12:08,062] {logging_mixin.py:112} INFO - [2020-07-22 13:12:08,061] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:12:08,070] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:12:08,275] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:12:08,699] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:34:00+00:00: scheduled__2020-07-20T00:34:00+00:00, externally triggered: False>
[2020-07-22 13:12:08,702] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:33:00+00:00: scheduled__2020-07-20T00:33:00+00:00, externally triggered: False>
[2020-07-22 13:12:08,709] {logging_mixin.py:112} INFO - [2020-07-22 13:12:08,709] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:33:00+00:00: scheduled__2020-07-20T00:33:00+00:00, externally triggered: False> failed
[2020-07-22 13:12:08,818] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:34:00+00:00: scheduled__2020-07-20T00:34:00+00:00, externally triggered: False>
[2020-07-22 13:12:08,833] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:12:08,837] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:34:00+00:00 [scheduled]> in ORM
[2020-07-22 13:12:09,017] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.959 seconds
[2020-07-22 13:12:32,311] {scheduler_job.py:153} INFO - Started process (PID=321654) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:12:32,313] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:12:32,314] {logging_mixin.py:112} INFO - [2020-07-22 13:12:32,314] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:12:32,323] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:12:32,484] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:12:32,923] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:35:00+00:00: scheduled__2020-07-20T00:35:00+00:00, externally triggered: False>
[2020-07-22 13:12:32,926] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:34:00+00:00: scheduled__2020-07-20T00:34:00+00:00, externally triggered: False>
[2020-07-22 13:12:32,933] {logging_mixin.py:112} INFO - [2020-07-22 13:12:32,933] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:34:00+00:00: scheduled__2020-07-20T00:34:00+00:00, externally triggered: False> failed
[2020-07-22 13:12:33,029] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:35:00+00:00: scheduled__2020-07-20T00:35:00+00:00, externally triggered: False>
[2020-07-22 13:12:33,050] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:12:33,054] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:35:00+00:00 [scheduled]> in ORM
[2020-07-22 13:12:33,207] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.897 seconds
[2020-07-22 13:13:03,532] {scheduler_job.py:153} INFO - Started process (PID=322356) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:13:03,536] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:13:03,537] {logging_mixin.py:112} INFO - [2020-07-22 13:13:03,537] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:13:03,545] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:13:03,708] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:13:04,034] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:36:00+00:00: scheduled__2020-07-20T00:36:00+00:00, externally triggered: False>
[2020-07-22 13:13:04,038] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:35:00+00:00: scheduled__2020-07-20T00:35:00+00:00, externally triggered: False>
[2020-07-22 13:13:04,045] {logging_mixin.py:112} INFO - [2020-07-22 13:13:04,045] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:35:00+00:00: scheduled__2020-07-20T00:35:00+00:00, externally triggered: False> failed
[2020-07-22 13:13:04,142] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:36:00+00:00: scheduled__2020-07-20T00:36:00+00:00, externally triggered: False>
[2020-07-22 13:13:04,160] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:13:04,164] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:36:00+00:00 [scheduled]> in ORM
[2020-07-22 13:13:04,307] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.775 seconds
[2020-07-22 13:13:29,656] {scheduler_job.py:153} INFO - Started process (PID=322954) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:13:29,660] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:13:29,661] {logging_mixin.py:112} INFO - [2020-07-22 13:13:29,661] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:13:29,674] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:13:29,818] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:13:30,253] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:37:00+00:00: scheduled__2020-07-20T00:37:00+00:00, externally triggered: False>
[2020-07-22 13:13:30,266] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:36:00+00:00: scheduled__2020-07-20T00:36:00+00:00, externally triggered: False>
[2020-07-22 13:13:30,286] {logging_mixin.py:112} INFO - [2020-07-22 13:13:30,286] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:36:00+00:00: scheduled__2020-07-20T00:36:00+00:00, externally triggered: False> failed
[2020-07-22 13:13:30,387] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:37:00+00:00: scheduled__2020-07-20T00:37:00+00:00, externally triggered: False>
[2020-07-22 13:13:30,414] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:13:30,421] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:37:00+00:00 [scheduled]> in ORM
[2020-07-22 13:13:30,620] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.964 seconds
[2020-07-22 13:14:00,702] {scheduler_job.py:153} INFO - Started process (PID=323611) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:14:00,706] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:14:00,707] {logging_mixin.py:112} INFO - [2020-07-22 13:14:00,706] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:14:00,716] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:14:00,876] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:14:01,224] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:38:00+00:00: scheduled__2020-07-20T00:38:00+00:00, externally triggered: False>
[2020-07-22 13:14:01,227] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:37:00+00:00: scheduled__2020-07-20T00:37:00+00:00, externally triggered: False>
[2020-07-22 13:14:01,236] {logging_mixin.py:112} INFO - [2020-07-22 13:14:01,236] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:37:00+00:00: scheduled__2020-07-20T00:37:00+00:00, externally triggered: False> failed
[2020-07-22 13:14:01,355] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:38:00+00:00: scheduled__2020-07-20T00:38:00+00:00, externally triggered: False>
[2020-07-22 13:14:01,389] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:14:01,398] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:38:00+00:00 [scheduled]> in ORM
[2020-07-22 13:14:01,602] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.900 seconds
[2020-07-22 13:14:30,195] {scheduler_job.py:153} INFO - Started process (PID=324300) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:14:30,198] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:14:30,199] {logging_mixin.py:112} INFO - [2020-07-22 13:14:30,199] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:14:30,209] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:14:30,386] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:14:30,741] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:39:00+00:00: scheduled__2020-07-20T00:39:00+00:00, externally triggered: False>
[2020-07-22 13:14:30,745] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:38:00+00:00: scheduled__2020-07-20T00:38:00+00:00, externally triggered: False>
[2020-07-22 13:14:30,752] {logging_mixin.py:112} INFO - [2020-07-22 13:14:30,752] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:38:00+00:00: scheduled__2020-07-20T00:38:00+00:00, externally triggered: False> failed
[2020-07-22 13:14:30,867] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:39:00+00:00: scheduled__2020-07-20T00:39:00+00:00, externally triggered: False>
[2020-07-22 13:14:30,887] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:14:30,895] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:39:00+00:00 [scheduled]> in ORM
[2020-07-22 13:14:31,123] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.928 seconds
[2020-07-22 13:14:54,208] {scheduler_job.py:153} INFO - Started process (PID=324822) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:14:54,212] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:14:54,213] {logging_mixin.py:112} INFO - [2020-07-22 13:14:54,213] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:14:54,227] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:14:55,230] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:14:55,713] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:40:00+00:00: scheduled__2020-07-20T00:40:00+00:00, externally triggered: False>
[2020-07-22 13:14:55,718] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:39:00+00:00: scheduled__2020-07-20T00:39:00+00:00, externally triggered: False>
[2020-07-22 13:14:55,729] {logging_mixin.py:112} INFO - [2020-07-22 13:14:55,729] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:39:00+00:00: scheduled__2020-07-20T00:39:00+00:00, externally triggered: False> failed
[2020-07-22 13:14:55,834] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:40:00+00:00: scheduled__2020-07-20T00:40:00+00:00, externally triggered: False>
[2020-07-22 13:14:55,849] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:14:55,853] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:40:00+00:00 [scheduled]> in ORM
[2020-07-22 13:14:56,022] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.814 seconds
[2020-07-22 13:15:19,323] {scheduler_job.py:153} INFO - Started process (PID=325431) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:15:19,327] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:15:19,327] {logging_mixin.py:112} INFO - [2020-07-22 13:15:19,327] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:15:19,338] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:15:19,472] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:15:19,815] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:41:00+00:00: scheduled__2020-07-20T00:41:00+00:00, externally triggered: False>
[2020-07-22 13:15:19,818] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:40:00+00:00: scheduled__2020-07-20T00:40:00+00:00, externally triggered: False>
[2020-07-22 13:15:19,826] {logging_mixin.py:112} INFO - [2020-07-22 13:15:19,826] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:40:00+00:00: scheduled__2020-07-20T00:40:00+00:00, externally triggered: False> failed
[2020-07-22 13:15:20,025] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:41:00+00:00: scheduled__2020-07-20T00:41:00+00:00, externally triggered: False>
[2020-07-22 13:15:20,043] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:15:20,047] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:41:00+00:00 [scheduled]> in ORM
[2020-07-22 13:15:20,213] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.890 seconds
[2020-07-22 13:15:49,452] {scheduler_job.py:153} INFO - Started process (PID=326133) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:15:49,455] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:15:49,456] {logging_mixin.py:112} INFO - [2020-07-22 13:15:49,455] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:15:49,467] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:15:49,590] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:15:49,951] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:42:00+00:00: scheduled__2020-07-20T00:42:00+00:00, externally triggered: False>
[2020-07-22 13:15:49,954] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:41:00+00:00: scheduled__2020-07-20T00:41:00+00:00, externally triggered: False>
[2020-07-22 13:15:49,963] {logging_mixin.py:112} INFO - [2020-07-22 13:15:49,963] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:41:00+00:00: scheduled__2020-07-20T00:41:00+00:00, externally triggered: False> failed
[2020-07-22 13:15:50,126] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:42:00+00:00: scheduled__2020-07-20T00:42:00+00:00, externally triggered: False>
[2020-07-22 13:15:50,143] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:15:50,148] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:42:00+00:00 [scheduled]> in ORM
[2020-07-22 13:15:50,313] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.861 seconds
[2020-07-22 13:16:19,028] {scheduler_job.py:153} INFO - Started process (PID=326766) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:16:19,032] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:16:19,033] {logging_mixin.py:112} INFO - [2020-07-22 13:16:19,033] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:16:19,045] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:16:19,158] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:16:19,602] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:43:00+00:00: scheduled__2020-07-20T00:43:00+00:00, externally triggered: False>
[2020-07-22 13:16:19,606] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:42:00+00:00: scheduled__2020-07-20T00:42:00+00:00, externally triggered: False>
[2020-07-22 13:16:19,616] {logging_mixin.py:112} INFO - [2020-07-22 13:16:19,615] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:42:00+00:00: scheduled__2020-07-20T00:42:00+00:00, externally triggered: False> failed
[2020-07-22 13:16:19,819] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:43:00+00:00: scheduled__2020-07-20T00:43:00+00:00, externally triggered: False>
[2020-07-22 13:16:19,842] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:16:19,849] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:43:00+00:00 [scheduled]> in ORM
[2020-07-22 13:16:20,044] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.016 seconds
[2020-07-22 13:16:49,261] {scheduler_job.py:153} INFO - Started process (PID=327412) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:16:49,264] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:16:49,265] {logging_mixin.py:112} INFO - [2020-07-22 13:16:49,265] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:16:49,275] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:16:49,394] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:16:49,779] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:44:00+00:00: scheduled__2020-07-20T00:44:00+00:00, externally triggered: False>
[2020-07-22 13:16:49,782] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:43:00+00:00: scheduled__2020-07-20T00:43:00+00:00, externally triggered: False>
[2020-07-22 13:16:49,790] {logging_mixin.py:112} INFO - [2020-07-22 13:16:49,790] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:43:00+00:00: scheduled__2020-07-20T00:43:00+00:00, externally triggered: False> failed
[2020-07-22 13:16:49,904] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:44:00+00:00: scheduled__2020-07-20T00:44:00+00:00, externally triggered: False>
[2020-07-22 13:16:49,924] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:16:49,928] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:44:00+00:00 [scheduled]> in ORM
[2020-07-22 13:16:50,107] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.846 seconds
[2020-07-22 13:17:18,829] {scheduler_job.py:153} INFO - Started process (PID=328099) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:17:18,832] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:17:18,833] {logging_mixin.py:112} INFO - [2020-07-22 13:17:18,833] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:17:18,844] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:17:18,972] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:17:19,403] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:45:00+00:00: scheduled__2020-07-20T00:45:00+00:00, externally triggered: False>
[2020-07-22 13:17:19,406] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:44:00+00:00: scheduled__2020-07-20T00:44:00+00:00, externally triggered: False>
[2020-07-22 13:17:19,413] {logging_mixin.py:112} INFO - [2020-07-22 13:17:19,413] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:44:00+00:00: scheduled__2020-07-20T00:44:00+00:00, externally triggered: False> failed
[2020-07-22 13:17:19,505] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:45:00+00:00: scheduled__2020-07-20T00:45:00+00:00, externally triggered: False>
[2020-07-22 13:17:19,522] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:17:19,526] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:45:00+00:00 [scheduled]> in ORM
[2020-07-22 13:17:19,697] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.867 seconds
[2020-07-22 13:17:42,978] {scheduler_job.py:153} INFO - Started process (PID=328668) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:17:42,981] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:17:42,982] {logging_mixin.py:112} INFO - [2020-07-22 13:17:42,981] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:17:42,991] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:17:43,153] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:17:43,701] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:46:00+00:00: scheduled__2020-07-20T00:46:00+00:00, externally triggered: False>
[2020-07-22 13:17:43,706] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:45:00+00:00: scheduled__2020-07-20T00:45:00+00:00, externally triggered: False>
[2020-07-22 13:17:43,729] {logging_mixin.py:112} INFO - [2020-07-22 13:17:43,729] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:45:00+00:00: scheduled__2020-07-20T00:45:00+00:00, externally triggered: False> failed
[2020-07-22 13:17:43,839] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:46:00+00:00: scheduled__2020-07-20T00:46:00+00:00, externally triggered: False>
[2020-07-22 13:17:43,860] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:17:43,866] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:46:00+00:00 [scheduled]> in ORM
[2020-07-22 13:17:44,051] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.073 seconds
[2020-07-22 13:18:08,059] {scheduler_job.py:153} INFO - Started process (PID=329262) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:18:08,062] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:18:08,062] {logging_mixin.py:112} INFO - [2020-07-22 13:18:08,062] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:18:08,072] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:18:08,169] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:18:08,537] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:47:00+00:00: scheduled__2020-07-20T00:47:00+00:00, externally triggered: False>
[2020-07-22 13:18:08,542] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:46:00+00:00: scheduled__2020-07-20T00:46:00+00:00, externally triggered: False>
[2020-07-22 13:18:08,549] {logging_mixin.py:112} INFO - [2020-07-22 13:18:08,549] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:46:00+00:00: scheduled__2020-07-20T00:46:00+00:00, externally triggered: False> failed
[2020-07-22 13:18:08,662] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:47:00+00:00: scheduled__2020-07-20T00:47:00+00:00, externally triggered: False>
[2020-07-22 13:18:08,682] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:18:08,686] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:47:00+00:00 [scheduled]> in ORM
[2020-07-22 13:18:08,854] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.795 seconds
[2020-07-22 13:18:37,904] {scheduler_job.py:153} INFO - Started process (PID=330062) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:18:37,907] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:18:37,907] {logging_mixin.py:112} INFO - [2020-07-22 13:18:37,907] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:18:37,917] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:18:38,273] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:18:38,689] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:48:00+00:00: scheduled__2020-07-20T00:48:00+00:00, externally triggered: False>
[2020-07-22 13:18:38,693] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:47:00+00:00: scheduled__2020-07-20T00:47:00+00:00, externally triggered: False>
[2020-07-22 13:18:38,701] {logging_mixin.py:112} INFO - [2020-07-22 13:18:38,701] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:47:00+00:00: scheduled__2020-07-20T00:47:00+00:00, externally triggered: False> failed
[2020-07-22 13:18:38,807] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:48:00+00:00: scheduled__2020-07-20T00:48:00+00:00, externally triggered: False>
[2020-07-22 13:18:38,825] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:18:38,830] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:48:00+00:00 [scheduled]> in ORM
[2020-07-22 13:18:39,044] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.140 seconds
[2020-07-22 13:19:01,971] {scheduler_job.py:153} INFO - Started process (PID=330585) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:19:01,974] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:19:01,975] {logging_mixin.py:112} INFO - [2020-07-22 13:19:01,975] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:19:01,984] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:19:02,140] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:19:02,514] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:49:00+00:00: scheduled__2020-07-20T00:49:00+00:00, externally triggered: False>
[2020-07-22 13:19:02,520] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:48:00+00:00: scheduled__2020-07-20T00:48:00+00:00, externally triggered: False>
[2020-07-22 13:19:02,529] {logging_mixin.py:112} INFO - [2020-07-22 13:19:02,528] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:48:00+00:00: scheduled__2020-07-20T00:48:00+00:00, externally triggered: False> failed
[2020-07-22 13:19:02,631] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:49:00+00:00: scheduled__2020-07-20T00:49:00+00:00, externally triggered: False>
[2020-07-22 13:19:02,646] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:19:02,651] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:49:00+00:00 [scheduled]> in ORM
[2020-07-22 13:19:02,826] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.854 seconds
[2020-07-22 13:19:33,673] {scheduler_job.py:153} INFO - Started process (PID=331279) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:19:33,676] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:19:33,677] {logging_mixin.py:112} INFO - [2020-07-22 13:19:33,677] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:19:33,685] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:19:33,784] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:19:34,901] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:50:00+00:00: scheduled__2020-07-20T00:50:00+00:00, externally triggered: False>
[2020-07-22 13:19:34,904] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:49:00+00:00: scheduled__2020-07-20T00:49:00+00:00, externally triggered: False>
[2020-07-22 13:19:34,913] {logging_mixin.py:112} INFO - [2020-07-22 13:19:34,913] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:49:00+00:00: scheduled__2020-07-20T00:49:00+00:00, externally triggered: False> failed
[2020-07-22 13:19:35,176] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:50:00+00:00: scheduled__2020-07-20T00:50:00+00:00, externally triggered: False>
[2020-07-22 13:19:35,194] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:19:35,198] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:50:00+00:00 [scheduled]> in ORM
[2020-07-22 13:19:35,368] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.695 seconds
[2020-07-22 13:20:02,990] {scheduler_job.py:153} INFO - Started process (PID=331950) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:20:02,994] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:20:02,995] {logging_mixin.py:112} INFO - [2020-07-22 13:20:02,995] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:20:03,009] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:20:03,197] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:20:03,553] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:51:00+00:00: scheduled__2020-07-20T00:51:00+00:00, externally triggered: False>
[2020-07-22 13:20:03,557] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:50:00+00:00: scheduled__2020-07-20T00:50:00+00:00, externally triggered: False>
[2020-07-22 13:20:03,564] {logging_mixin.py:112} INFO - [2020-07-22 13:20:03,564] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:50:00+00:00: scheduled__2020-07-20T00:50:00+00:00, externally triggered: False> failed
[2020-07-22 13:20:03,678] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:51:00+00:00: scheduled__2020-07-20T00:51:00+00:00, externally triggered: False>
[2020-07-22 13:20:03,697] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:20:03,701] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:51:00+00:00 [scheduled]> in ORM
[2020-07-22 13:20:03,877] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.887 seconds
[2020-07-22 13:20:27,531] {scheduler_job.py:153} INFO - Started process (PID=332515) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:20:27,535] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:20:27,535] {logging_mixin.py:112} INFO - [2020-07-22 13:20:27,535] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:20:27,550] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:20:27,674] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:20:28,092] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:52:00+00:00: scheduled__2020-07-20T00:52:00+00:00, externally triggered: False>
[2020-07-22 13:20:28,096] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:51:00+00:00: scheduled__2020-07-20T00:51:00+00:00, externally triggered: False>
[2020-07-22 13:20:28,104] {logging_mixin.py:112} INFO - [2020-07-22 13:20:28,103] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:51:00+00:00: scheduled__2020-07-20T00:51:00+00:00, externally triggered: False> failed
[2020-07-22 13:20:28,223] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:52:00+00:00: scheduled__2020-07-20T00:52:00+00:00, externally triggered: False>
[2020-07-22 13:20:28,249] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:20:28,253] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:52:00+00:00 [scheduled]> in ORM
[2020-07-22 13:20:28,436] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.904 seconds
[2020-07-22 13:20:52,851] {scheduler_job.py:153} INFO - Started process (PID=333104) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:20:52,856] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:20:52,857] {logging_mixin.py:112} INFO - [2020-07-22 13:20:52,857] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:20:52,871] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:20:53,047] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:20:53,455] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:53:00+00:00: scheduled__2020-07-20T00:53:00+00:00, externally triggered: False>
[2020-07-22 13:20:53,460] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:52:00+00:00: scheduled__2020-07-20T00:52:00+00:00, externally triggered: False>
[2020-07-22 13:20:53,467] {logging_mixin.py:112} INFO - [2020-07-22 13:20:53,467] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:52:00+00:00: scheduled__2020-07-20T00:52:00+00:00, externally triggered: False> failed
[2020-07-22 13:20:53,568] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:53:00+00:00: scheduled__2020-07-20T00:53:00+00:00, externally triggered: False>
[2020-07-22 13:20:53,585] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:20:53,589] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:53:00+00:00 [scheduled]> in ORM
[2020-07-22 13:20:53,760] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.909 seconds
[2020-07-22 13:21:22,695] {scheduler_job.py:153} INFO - Started process (PID=333800) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:21:22,700] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:21:22,701] {logging_mixin.py:112} INFO - [2020-07-22 13:21:22,700] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:21:22,708] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:21:22,834] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:21:23,188] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:54:00+00:00: scheduled__2020-07-20T00:54:00+00:00, externally triggered: False>
[2020-07-22 13:21:23,192] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:53:00+00:00: scheduled__2020-07-20T00:53:00+00:00, externally triggered: False>
[2020-07-22 13:21:23,200] {logging_mixin.py:112} INFO - [2020-07-22 13:21:23,200] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:53:00+00:00: scheduled__2020-07-20T00:53:00+00:00, externally triggered: False> failed
[2020-07-22 13:21:23,314] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:54:00+00:00: scheduled__2020-07-20T00:54:00+00:00, externally triggered: False>
[2020-07-22 13:21:23,334] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:21:23,337] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:54:00+00:00 [scheduled]> in ORM
[2020-07-22 13:21:23,508] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.813 seconds
[2020-07-22 13:21:47,572] {scheduler_job.py:153} INFO - Started process (PID=334361) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:21:47,576] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:21:47,577] {logging_mixin.py:112} INFO - [2020-07-22 13:21:47,577] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:21:47,588] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:21:47,705] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:21:48,132] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:55:00+00:00: scheduled__2020-07-20T00:55:00+00:00, externally triggered: False>
[2020-07-22 13:21:48,137] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:54:00+00:00: scheduled__2020-07-20T00:54:00+00:00, externally triggered: False>
[2020-07-22 13:21:48,150] {logging_mixin.py:112} INFO - [2020-07-22 13:21:48,150] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:54:00+00:00: scheduled__2020-07-20T00:54:00+00:00, externally triggered: False> failed
[2020-07-22 13:21:48,259] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:55:00+00:00: scheduled__2020-07-20T00:55:00+00:00, externally triggered: False>
[2020-07-22 13:21:48,279] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:21:48,285] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:55:00+00:00 [scheduled]> in ORM
[2020-07-22 13:21:48,459] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.887 seconds
[2020-07-22 13:22:17,648] {scheduler_job.py:153} INFO - Started process (PID=335022) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:22:17,651] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:22:17,652] {logging_mixin.py:112} INFO - [2020-07-22 13:22:17,652] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:22:17,661] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:22:17,792] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:22:18,190] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:56:00+00:00: scheduled__2020-07-20T00:56:00+00:00, externally triggered: False>
[2020-07-22 13:22:18,194] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:55:00+00:00: scheduled__2020-07-20T00:55:00+00:00, externally triggered: False>
[2020-07-22 13:22:18,202] {logging_mixin.py:112} INFO - [2020-07-22 13:22:18,202] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:55:00+00:00: scheduled__2020-07-20T00:55:00+00:00, externally triggered: False> failed
[2020-07-22 13:22:18,316] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:56:00+00:00: scheduled__2020-07-20T00:56:00+00:00, externally triggered: False>
[2020-07-22 13:22:18,336] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:22:18,339] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:56:00+00:00 [scheduled]> in ORM
[2020-07-22 13:22:18,506] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.858 seconds
[2020-07-22 13:22:41,673] {scheduler_job.py:153} INFO - Started process (PID=335629) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:22:41,676] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:22:41,677] {logging_mixin.py:112} INFO - [2020-07-22 13:22:41,677] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:22:41,685] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:22:41,800] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:22:42,280] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:57:00+00:00: scheduled__2020-07-20T00:57:00+00:00, externally triggered: False>
[2020-07-22 13:22:42,283] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:56:00+00:00: scheduled__2020-07-20T00:56:00+00:00, externally triggered: False>
[2020-07-22 13:22:42,290] {logging_mixin.py:112} INFO - [2020-07-22 13:22:42,290] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:56:00+00:00: scheduled__2020-07-20T00:56:00+00:00, externally triggered: False> failed
[2020-07-22 13:22:42,452] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:57:00+00:00: scheduled__2020-07-20T00:57:00+00:00, externally triggered: False>
[2020-07-22 13:22:42,474] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:22:42,480] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:57:00+00:00 [scheduled]> in ORM
[2020-07-22 13:22:42,653] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.980 seconds
[2020-07-22 13:23:05,685] {scheduler_job.py:153} INFO - Started process (PID=336120) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:23:05,688] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:23:05,689] {logging_mixin.py:112} INFO - [2020-07-22 13:23:05,688] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:23:05,697] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:23:05,863] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:23:06,193] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:58:00+00:00: scheduled__2020-07-20T00:58:00+00:00, externally triggered: False>
[2020-07-22 13:23:06,201] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:57:00+00:00: scheduled__2020-07-20T00:57:00+00:00, externally triggered: False>
[2020-07-22 13:23:06,213] {logging_mixin.py:112} INFO - [2020-07-22 13:23:06,212] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:57:00+00:00: scheduled__2020-07-20T00:57:00+00:00, externally triggered: False> failed
[2020-07-22 13:23:06,395] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:58:00+00:00: scheduled__2020-07-20T00:58:00+00:00, externally triggered: False>
[2020-07-22 13:23:06,412] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:23:06,416] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:58:00+00:00 [scheduled]> in ORM
[2020-07-22 13:23:06,598] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.914 seconds
[2020-07-22 13:23:36,749] {scheduler_job.py:153} INFO - Started process (PID=336826) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:23:36,752] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:23:36,752] {logging_mixin.py:112} INFO - [2020-07-22 13:23:36,752] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:23:36,761] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:23:36,893] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:23:37,392] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T00:59:00+00:00: scheduled__2020-07-20T00:59:00+00:00, externally triggered: False>
[2020-07-22 13:23:37,396] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:58:00+00:00: scheduled__2020-07-20T00:58:00+00:00, externally triggered: False>
[2020-07-22 13:23:37,403] {logging_mixin.py:112} INFO - [2020-07-22 13:23:37,403] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:58:00+00:00: scheduled__2020-07-20T00:58:00+00:00, externally triggered: False> failed
[2020-07-22 13:23:37,508] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:59:00+00:00: scheduled__2020-07-20T00:59:00+00:00, externally triggered: False>
[2020-07-22 13:23:37,525] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:23:37,529] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 00:59:00+00:00 [scheduled]> in ORM
[2020-07-22 13:23:37,699] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.951 seconds
[2020-07-22 13:24:01,896] {scheduler_job.py:153} INFO - Started process (PID=337458) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:24:01,901] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:24:01,902] {logging_mixin.py:112} INFO - [2020-07-22 13:24:01,902] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:24:01,916] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:24:02,088] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:24:02,598] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:00:00+00:00: scheduled__2020-07-20T01:00:00+00:00, externally triggered: False>
[2020-07-22 13:24:02,605] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 00:59:00+00:00: scheduled__2020-07-20T00:59:00+00:00, externally triggered: False>
[2020-07-22 13:24:02,613] {logging_mixin.py:112} INFO - [2020-07-22 13:24:02,613] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 00:59:00+00:00: scheduled__2020-07-20T00:59:00+00:00, externally triggered: False> failed
[2020-07-22 13:24:02,709] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:00:00+00:00: scheduled__2020-07-20T01:00:00+00:00, externally triggered: False>
[2020-07-22 13:24:02,726] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:24:02,729] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:00:00+00:00 [scheduled]> in ORM
[2020-07-22 13:24:02,878] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.982 seconds
[2020-07-22 13:24:26,220] {scheduler_job.py:153} INFO - Started process (PID=337982) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:24:26,224] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:24:26,224] {logging_mixin.py:112} INFO - [2020-07-22 13:24:26,224] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:24:26,234] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:24:26,376] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:24:26,740] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:01:00+00:00: scheduled__2020-07-20T01:01:00+00:00, externally triggered: False>
[2020-07-22 13:24:26,746] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:00:00+00:00: scheduled__2020-07-20T01:00:00+00:00, externally triggered: False>
[2020-07-22 13:24:26,758] {logging_mixin.py:112} INFO - [2020-07-22 13:24:26,758] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:00:00+00:00: scheduled__2020-07-20T01:00:00+00:00, externally triggered: False> failed
[2020-07-22 13:24:26,899] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:01:00+00:00: scheduled__2020-07-20T01:01:00+00:00, externally triggered: False>
[2020-07-22 13:24:26,925] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:24:26,929] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:01:00+00:00 [scheduled]> in ORM
[2020-07-22 13:24:27,090] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.870 seconds
[2020-07-22 13:24:55,721] {scheduler_job.py:153} INFO - Started process (PID=338666) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:24:55,725] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:24:55,726] {logging_mixin.py:112} INFO - [2020-07-22 13:24:55,726] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:24:55,736] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:24:55,865] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:24:56,210] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:02:00+00:00: scheduled__2020-07-20T01:02:00+00:00, externally triggered: False>
[2020-07-22 13:24:56,213] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:01:00+00:00: scheduled__2020-07-20T01:01:00+00:00, externally triggered: False>
[2020-07-22 13:24:56,220] {logging_mixin.py:112} INFO - [2020-07-22 13:24:56,220] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:01:00+00:00: scheduled__2020-07-20T01:01:00+00:00, externally triggered: False> failed
[2020-07-22 13:24:56,378] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:02:00+00:00: scheduled__2020-07-20T01:02:00+00:00, externally triggered: False>
[2020-07-22 13:24:56,400] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:24:56,407] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:02:00+00:00 [scheduled]> in ORM
[2020-07-22 13:24:56,591] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.871 seconds
[2020-07-22 13:25:19,800] {scheduler_job.py:153} INFO - Started process (PID=339253) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:25:19,805] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:25:19,806] {logging_mixin.py:112} INFO - [2020-07-22 13:25:19,805] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:25:19,822] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:25:19,959] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:25:20,309] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:03:00+00:00: scheduled__2020-07-20T01:03:00+00:00, externally triggered: False>
[2020-07-22 13:25:20,315] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:02:00+00:00: scheduled__2020-07-20T01:02:00+00:00, externally triggered: False>
[2020-07-22 13:25:20,333] {logging_mixin.py:112} INFO - [2020-07-22 13:25:20,332] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:02:00+00:00: scheduled__2020-07-20T01:02:00+00:00, externally triggered: False> failed
[2020-07-22 13:25:20,480] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:03:00+00:00: scheduled__2020-07-20T01:03:00+00:00, externally triggered: False>
[2020-07-22 13:25:20,505] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:25:20,513] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:03:00+00:00 [scheduled]> in ORM
[2020-07-22 13:25:20,684] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.885 seconds
[2020-07-22 13:25:44,437] {scheduler_job.py:153} INFO - Started process (PID=339794) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:25:44,440] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:25:44,440] {logging_mixin.py:112} INFO - [2020-07-22 13:25:44,440] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:25:44,449] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:25:44,612] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:25:44,965] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:04:00+00:00: scheduled__2020-07-20T01:04:00+00:00, externally triggered: False>
[2020-07-22 13:25:44,969] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:03:00+00:00: scheduled__2020-07-20T01:03:00+00:00, externally triggered: False>
[2020-07-22 13:25:44,977] {logging_mixin.py:112} INFO - [2020-07-22 13:25:44,977] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:03:00+00:00: scheduled__2020-07-20T01:03:00+00:00, externally triggered: False> failed
[2020-07-22 13:25:45,412] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:04:00+00:00: scheduled__2020-07-20T01:04:00+00:00, externally triggered: False>
[2020-07-22 13:25:45,424] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:25:45,428] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:04:00+00:00 [scheduled]> in ORM
[2020-07-22 13:25:45,590] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.153 seconds
[2020-07-22 13:26:13,773] {scheduler_job.py:153} INFO - Started process (PID=340480) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:26:13,778] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:26:13,778] {logging_mixin.py:112} INFO - [2020-07-22 13:26:13,778] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:26:13,789] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:26:13,926] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:26:14,277] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:05:00+00:00: scheduled__2020-07-20T01:05:00+00:00, externally triggered: False>
[2020-07-22 13:26:14,281] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:04:00+00:00: scheduled__2020-07-20T01:04:00+00:00, externally triggered: False>
[2020-07-22 13:26:14,290] {logging_mixin.py:112} INFO - [2020-07-22 13:26:14,290] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:04:00+00:00: scheduled__2020-07-20T01:04:00+00:00, externally triggered: False> failed
[2020-07-22 13:26:14,414] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:05:00+00:00: scheduled__2020-07-20T01:05:00+00:00, externally triggered: False>
[2020-07-22 13:26:14,432] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:26:14,436] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:05:00+00:00 [scheduled]> in ORM
[2020-07-22 13:26:14,616] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.843 seconds
[2020-07-22 13:26:38,593] {scheduler_job.py:153} INFO - Started process (PID=341038) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:26:38,596] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:26:38,596] {logging_mixin.py:112} INFO - [2020-07-22 13:26:38,596] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:26:38,604] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:26:38,749] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:26:39,133] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:06:00+00:00: scheduled__2020-07-20T01:06:00+00:00, externally triggered: False>
[2020-07-22 13:26:39,138] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:05:00+00:00: scheduled__2020-07-20T01:05:00+00:00, externally triggered: False>
[2020-07-22 13:26:39,154] {logging_mixin.py:112} INFO - [2020-07-22 13:26:39,153] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:05:00+00:00: scheduled__2020-07-20T01:05:00+00:00, externally triggered: False> failed
[2020-07-22 13:26:39,294] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:06:00+00:00: scheduled__2020-07-20T01:06:00+00:00, externally triggered: False>
[2020-07-22 13:26:39,316] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:26:39,323] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:06:00+00:00 [scheduled]> in ORM
[2020-07-22 13:26:39,506] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.914 seconds
[2020-07-22 13:27:07,760] {scheduler_job.py:153} INFO - Started process (PID=341673) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:27:07,762] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:27:07,763] {logging_mixin.py:112} INFO - [2020-07-22 13:27:07,763] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:27:07,773] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:27:07,948] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:27:08,281] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:07:00+00:00: scheduled__2020-07-20T01:07:00+00:00, externally triggered: False>
[2020-07-22 13:27:08,285] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:06:00+00:00: scheduled__2020-07-20T01:06:00+00:00, externally triggered: False>
[2020-07-22 13:27:08,292] {logging_mixin.py:112} INFO - [2020-07-22 13:27:08,291] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:06:00+00:00: scheduled__2020-07-20T01:06:00+00:00, externally triggered: False> failed
[2020-07-22 13:27:08,605] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:07:00+00:00: scheduled__2020-07-20T01:07:00+00:00, externally triggered: False>
[2020-07-22 13:27:08,624] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:27:08,627] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:07:00+00:00 [scheduled]> in ORM
[2020-07-22 13:27:08,818] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.058 seconds
[2020-07-22 13:27:32,035] {scheduler_job.py:153} INFO - Started process (PID=342224) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:27:32,040] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:27:32,040] {logging_mixin.py:112} INFO - [2020-07-22 13:27:32,040] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:27:32,076] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:27:32,207] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:27:32,554] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:08:00+00:00: scheduled__2020-07-20T01:08:00+00:00, externally triggered: False>
[2020-07-22 13:27:32,557] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:07:00+00:00: scheduled__2020-07-20T01:07:00+00:00, externally triggered: False>
[2020-07-22 13:27:32,571] {logging_mixin.py:112} INFO - [2020-07-22 13:27:32,571] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:07:00+00:00: scheduled__2020-07-20T01:07:00+00:00, externally triggered: False> failed
[2020-07-22 13:27:32,810] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:08:00+00:00: scheduled__2020-07-20T01:08:00+00:00, externally triggered: False>
[2020-07-22 13:27:32,834] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:27:32,838] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:08:00+00:00 [scheduled]> in ORM
[2020-07-22 13:27:33,030] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.995 seconds
[2020-07-22 13:27:57,208] {scheduler_job.py:153} INFO - Started process (PID=342813) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:27:57,212] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:27:57,212] {logging_mixin.py:112} INFO - [2020-07-22 13:27:57,212] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:27:57,221] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:27:57,343] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:27:57,749] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:09:00+00:00: scheduled__2020-07-20T01:09:00+00:00, externally triggered: False>
[2020-07-22 13:27:57,754] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:08:00+00:00: scheduled__2020-07-20T01:08:00+00:00, externally triggered: False>
[2020-07-22 13:27:57,768] {logging_mixin.py:112} INFO - [2020-07-22 13:27:57,768] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:08:00+00:00: scheduled__2020-07-20T01:08:00+00:00, externally triggered: False> failed
[2020-07-22 13:27:57,887] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:09:00+00:00: scheduled__2020-07-20T01:09:00+00:00, externally triggered: False>
[2020-07-22 13:27:57,907] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:27:57,911] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:09:00+00:00 [scheduled]> in ORM
[2020-07-22 13:27:58,076] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.868 seconds
[2020-07-22 13:28:26,597] {scheduler_job.py:153} INFO - Started process (PID=343493) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:28:26,600] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:28:26,601] {logging_mixin.py:112} INFO - [2020-07-22 13:28:26,601] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:28:26,609] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:28:26,769] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:28:27,185] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:10:00+00:00: scheduled__2020-07-20T01:10:00+00:00, externally triggered: False>
[2020-07-22 13:28:27,188] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:09:00+00:00: scheduled__2020-07-20T01:09:00+00:00, externally triggered: False>
[2020-07-22 13:28:27,197] {logging_mixin.py:112} INFO - [2020-07-22 13:28:27,197] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:09:00+00:00: scheduled__2020-07-20T01:09:00+00:00, externally triggered: False> failed
[2020-07-22 13:28:27,348] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:10:00+00:00: scheduled__2020-07-20T01:10:00+00:00, externally triggered: False>
[2020-07-22 13:28:27,368] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:28:27,372] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:10:00+00:00 [scheduled]> in ORM
[2020-07-22 13:28:27,529] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.932 seconds
[2020-07-22 13:28:50,815] {scheduler_job.py:153} INFO - Started process (PID=344030) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:28:50,819] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:28:50,819] {logging_mixin.py:112} INFO - [2020-07-22 13:28:50,819] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:28:50,829] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:28:51,019] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:28:51,517] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:11:00+00:00: scheduled__2020-07-20T01:11:00+00:00, externally triggered: False>
[2020-07-22 13:28:51,534] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:10:00+00:00: scheduled__2020-07-20T01:10:00+00:00, externally triggered: False>
[2020-07-22 13:28:51,549] {logging_mixin.py:112} INFO - [2020-07-22 13:28:51,549] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:10:00+00:00: scheduled__2020-07-20T01:10:00+00:00, externally triggered: False> failed
[2020-07-22 13:28:51,686] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:11:00+00:00: scheduled__2020-07-20T01:11:00+00:00, externally triggered: False>
[2020-07-22 13:28:51,717] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:28:51,726] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:11:00+00:00 [scheduled]> in ORM
[2020-07-22 13:28:51,964] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.148 seconds
[2020-07-22 13:29:21,103] {scheduler_job.py:153} INFO - Started process (PID=344696) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:29:21,106] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:29:21,106] {logging_mixin.py:112} INFO - [2020-07-22 13:29:21,106] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:29:21,114] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:29:21,269] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:29:21,644] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:12:00+00:00: scheduled__2020-07-20T01:12:00+00:00, externally triggered: False>
[2020-07-22 13:29:21,647] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:11:00+00:00: scheduled__2020-07-20T01:11:00+00:00, externally triggered: False>
[2020-07-22 13:29:21,654] {logging_mixin.py:112} INFO - [2020-07-22 13:29:21,654] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:11:00+00:00: scheduled__2020-07-20T01:11:00+00:00, externally triggered: False> failed
[2020-07-22 13:29:21,814] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:12:00+00:00: scheduled__2020-07-20T01:12:00+00:00, externally triggered: False>
[2020-07-22 13:29:21,850] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:29:21,859] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:12:00+00:00 [scheduled]> in ORM
[2020-07-22 13:29:22,636] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.533 seconds
[2020-07-22 13:29:50,275] {scheduler_job.py:153} INFO - Started process (PID=345366) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:29:50,278] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:29:50,278] {logging_mixin.py:112} INFO - [2020-07-22 13:29:50,278] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:29:50,287] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:29:50,472] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:29:50,828] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:13:00+00:00: scheduled__2020-07-20T01:13:00+00:00, externally triggered: False>
[2020-07-22 13:29:50,832] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:12:00+00:00: scheduled__2020-07-20T01:12:00+00:00, externally triggered: False>
[2020-07-22 13:29:50,839] {logging_mixin.py:112} INFO - [2020-07-22 13:29:50,839] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:12:00+00:00: scheduled__2020-07-20T01:12:00+00:00, externally triggered: False> failed
[2020-07-22 13:29:51,096] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:13:00+00:00: scheduled__2020-07-20T01:13:00+00:00, externally triggered: False>
[2020-07-22 13:29:51,114] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:29:51,118] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:13:00+00:00 [scheduled]> in ORM
[2020-07-22 13:29:51,277] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.002 seconds
[2020-07-22 13:30:14,510] {scheduler_job.py:153} INFO - Started process (PID=345926) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:30:14,516] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:30:14,517] {logging_mixin.py:112} INFO - [2020-07-22 13:30:14,517] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:30:14,533] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:30:14,683] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:30:15,108] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:14:00+00:00: scheduled__2020-07-20T01:14:00+00:00, externally triggered: False>
[2020-07-22 13:30:15,130] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:13:00+00:00: scheduled__2020-07-20T01:13:00+00:00, externally triggered: False>
[2020-07-22 13:30:15,167] {logging_mixin.py:112} INFO - [2020-07-22 13:30:15,167] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:13:00+00:00: scheduled__2020-07-20T01:13:00+00:00, externally triggered: False> failed
[2020-07-22 13:30:15,322] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:14:00+00:00: scheduled__2020-07-20T01:14:00+00:00, externally triggered: False>
[2020-07-22 13:30:15,346] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:30:15,354] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:14:00+00:00 [scheduled]> in ORM
[2020-07-22 13:30:15,529] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.019 seconds
[2020-07-22 13:30:48,145] {scheduler_job.py:153} INFO - Started process (PID=346724) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:30:48,149] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:30:48,150] {logging_mixin.py:112} INFO - [2020-07-22 13:30:48,150] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:30:48,170] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:30:48,358] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:30:49,893] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:15:00+00:00: scheduled__2020-07-20T01:15:00+00:00, externally triggered: False>
[2020-07-22 13:30:49,900] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:14:00+00:00: scheduled__2020-07-20T01:14:00+00:00, externally triggered: False>
[2020-07-22 13:30:49,908] {logging_mixin.py:112} INFO - [2020-07-22 13:30:49,908] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:14:00+00:00: scheduled__2020-07-20T01:14:00+00:00, externally triggered: False> failed
[2020-07-22 13:30:50,182] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:15:00+00:00: scheduled__2020-07-20T01:15:00+00:00, externally triggered: False>
[2020-07-22 13:30:50,552] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:30:50,564] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:15:00+00:00 [scheduled]> in ORM
[2020-07-22 13:30:50,771] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.627 seconds
[2020-07-22 13:31:20,075] {scheduler_job.py:153} INFO - Started process (PID=347509) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:31:20,090] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:31:20,092] {logging_mixin.py:112} INFO - [2020-07-22 13:31:20,090] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:31:20,118] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:31:20,377] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:31:20,811] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:16:00+00:00: scheduled__2020-07-20T01:16:00+00:00, externally triggered: False>
[2020-07-22 13:31:20,819] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:15:00+00:00: scheduled__2020-07-20T01:15:00+00:00, externally triggered: False>
[2020-07-22 13:31:20,831] {logging_mixin.py:112} INFO - [2020-07-22 13:31:20,831] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:15:00+00:00: scheduled__2020-07-20T01:15:00+00:00, externally triggered: False> failed
[2020-07-22 13:31:20,966] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:16:00+00:00: scheduled__2020-07-20T01:16:00+00:00, externally triggered: False>
[2020-07-22 13:31:20,987] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:31:20,991] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:16:00+00:00 [scheduled]> in ORM
[2020-07-22 13:31:21,486] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.411 seconds
[2020-07-22 13:31:50,123] {scheduler_job.py:153} INFO - Started process (PID=348216) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:31:50,128] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:31:50,129] {logging_mixin.py:112} INFO - [2020-07-22 13:31:50,129] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:31:50,149] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:31:50,311] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:31:50,695] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:17:00+00:00: scheduled__2020-07-20T01:17:00+00:00, externally triggered: False>
[2020-07-22 13:31:50,701] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:16:00+00:00: scheduled__2020-07-20T01:16:00+00:00, externally triggered: False>
[2020-07-22 13:31:50,714] {logging_mixin.py:112} INFO - [2020-07-22 13:31:50,714] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:16:00+00:00: scheduled__2020-07-20T01:16:00+00:00, externally triggered: False> failed
[2020-07-22 13:31:50,859] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:17:00+00:00: scheduled__2020-07-20T01:17:00+00:00, externally triggered: False>
[2020-07-22 13:31:50,877] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:31:50,881] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:17:00+00:00 [scheduled]> in ORM
[2020-07-22 13:31:51,180] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.057 seconds
[2020-07-22 13:32:19,531] {scheduler_job.py:153} INFO - Started process (PID=348829) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:32:19,534] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:32:19,535] {logging_mixin.py:112} INFO - [2020-07-22 13:32:19,535] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:32:19,544] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:32:19,662] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:32:19,984] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:18:00+00:00: scheduled__2020-07-20T01:18:00+00:00, externally triggered: False>
[2020-07-22 13:32:19,989] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:17:00+00:00: scheduled__2020-07-20T01:17:00+00:00, externally triggered: False>
[2020-07-22 13:32:19,997] {logging_mixin.py:112} INFO - [2020-07-22 13:32:19,997] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:17:00+00:00: scheduled__2020-07-20T01:17:00+00:00, externally triggered: False> failed
[2020-07-22 13:32:20,109] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:18:00+00:00: scheduled__2020-07-20T01:18:00+00:00, externally triggered: False>
[2020-07-22 13:32:20,132] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:32:20,136] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:18:00+00:00 [scheduled]> in ORM
[2020-07-22 13:32:20,296] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.765 seconds
[2020-07-22 13:32:55,188] {scheduler_job.py:153} INFO - Started process (PID=349599) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:32:55,191] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:32:55,191] {logging_mixin.py:112} INFO - [2020-07-22 13:32:55,191] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:32:55,202] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:32:55,368] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:32:55,689] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:19:00+00:00: scheduled__2020-07-20T01:19:00+00:00, externally triggered: False>
[2020-07-22 13:32:55,694] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:18:00+00:00: scheduled__2020-07-20T01:18:00+00:00, externally triggered: False>
[2020-07-22 13:32:55,702] {logging_mixin.py:112} INFO - [2020-07-22 13:32:55,701] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:18:00+00:00: scheduled__2020-07-20T01:18:00+00:00, externally triggered: False> failed
[2020-07-22 13:32:55,813] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:19:00+00:00: scheduled__2020-07-20T01:19:00+00:00, externally triggered: False>
[2020-07-22 13:32:55,832] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:32:55,836] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:19:00+00:00 [scheduled]> in ORM
[2020-07-22 13:32:56,014] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.827 seconds
[2020-07-22 13:33:20,266] {scheduler_job.py:153} INFO - Started process (PID=350220) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:33:20,271] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:33:20,271] {logging_mixin.py:112} INFO - [2020-07-22 13:33:20,271] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:33:20,285] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:33:20,501] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:33:21,057] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:20:00+00:00: scheduled__2020-07-20T01:20:00+00:00, externally triggered: False>
[2020-07-22 13:33:21,060] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:19:00+00:00: scheduled__2020-07-20T01:19:00+00:00, externally triggered: False>
[2020-07-22 13:33:21,071] {logging_mixin.py:112} INFO - [2020-07-22 13:33:21,070] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:19:00+00:00: scheduled__2020-07-20T01:19:00+00:00, externally triggered: False> failed
[2020-07-22 13:33:21,440] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:20:00+00:00: scheduled__2020-07-20T01:20:00+00:00, externally triggered: False>
[2020-07-22 13:33:21,490] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:33:21,591] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:20:00+00:00 [scheduled]> in ORM
[2020-07-22 13:33:21,762] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.496 seconds
[2020-07-22 13:33:50,103] {scheduler_job.py:153} INFO - Started process (PID=350868) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:33:50,107] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:33:50,107] {logging_mixin.py:112} INFO - [2020-07-22 13:33:50,107] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:33:50,120] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:33:50,273] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:33:50,650] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:21:00+00:00: scheduled__2020-07-20T01:21:00+00:00, externally triggered: False>
[2020-07-22 13:33:50,654] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:20:00+00:00: scheduled__2020-07-20T01:20:00+00:00, externally triggered: False>
[2020-07-22 13:33:50,663] {logging_mixin.py:112} INFO - [2020-07-22 13:33:50,663] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:20:00+00:00: scheduled__2020-07-20T01:20:00+00:00, externally triggered: False> failed
[2020-07-22 13:33:50,775] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:21:00+00:00: scheduled__2020-07-20T01:21:00+00:00, externally triggered: False>
[2020-07-22 13:33:50,797] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:33:50,808] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:21:00+00:00 [scheduled]> in ORM
[2020-07-22 13:33:50,969] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.866 seconds
[2020-07-22 13:34:25,468] {scheduler_job.py:153} INFO - Started process (PID=351737) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:34:25,472] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:34:25,472] {logging_mixin.py:112} INFO - [2020-07-22 13:34:25,472] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:34:25,484] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:34:25,663] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:34:26,481] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:22:00+00:00: scheduled__2020-07-20T01:22:00+00:00, externally triggered: False>
[2020-07-22 13:34:26,487] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:21:00+00:00: scheduled__2020-07-20T01:21:00+00:00, externally triggered: False>
[2020-07-22 13:34:26,503] {logging_mixin.py:112} INFO - [2020-07-22 13:34:26,502] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:21:00+00:00: scheduled__2020-07-20T01:21:00+00:00, externally triggered: False> failed
[2020-07-22 13:34:27,026] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:22:00+00:00: scheduled__2020-07-20T01:22:00+00:00, externally triggered: False>
[2020-07-22 13:34:27,042] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:34:27,046] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:22:00+00:00 [scheduled]> in ORM
[2020-07-22 13:34:27,183] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.714 seconds
[2020-07-22 13:34:54,674] {scheduler_job.py:153} INFO - Started process (PID=352433) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:34:54,678] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:34:54,678] {logging_mixin.py:112} INFO - [2020-07-22 13:34:54,678] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:34:54,688] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:34:54,858] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:34:55,235] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:23:00+00:00: scheduled__2020-07-20T01:23:00+00:00, externally triggered: False>
[2020-07-22 13:34:55,241] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:22:00+00:00: scheduled__2020-07-20T01:22:00+00:00, externally triggered: False>
[2020-07-22 13:34:55,257] {logging_mixin.py:112} INFO - [2020-07-22 13:34:55,257] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:22:00+00:00: scheduled__2020-07-20T01:22:00+00:00, externally triggered: False> failed
[2020-07-22 13:34:55,361] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:23:00+00:00: scheduled__2020-07-20T01:23:00+00:00, externally triggered: False>
[2020-07-22 13:34:55,387] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:34:55,395] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:23:00+00:00 [scheduled]> in ORM
[2020-07-22 13:34:55,574] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.900 seconds
[2020-07-22 13:35:24,127] {scheduler_job.py:153} INFO - Started process (PID=353173) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:35:24,130] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:35:24,131] {logging_mixin.py:112} INFO - [2020-07-22 13:35:24,130] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:35:24,141] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:35:24,276] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:35:24,636] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:24:00+00:00: scheduled__2020-07-20T01:24:00+00:00, externally triggered: False>
[2020-07-22 13:35:24,639] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:23:00+00:00: scheduled__2020-07-20T01:23:00+00:00, externally triggered: False>
[2020-07-22 13:35:24,651] {logging_mixin.py:112} INFO - [2020-07-22 13:35:24,651] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:23:00+00:00: scheduled__2020-07-20T01:23:00+00:00, externally triggered: False> failed
[2020-07-22 13:35:24,787] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:24:00+00:00: scheduled__2020-07-20T01:24:00+00:00, externally triggered: False>
[2020-07-22 13:35:24,809] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:35:24,815] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:24:00+00:00 [scheduled]> in ORM
[2020-07-22 13:35:24,965] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.838 seconds
[2020-07-22 13:35:55,244] {scheduler_job.py:153} INFO - Started process (PID=353852) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:35:55,249] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:35:55,249] {logging_mixin.py:112} INFO - [2020-07-22 13:35:55,249] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:35:55,260] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:35:55,375] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:35:55,744] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:25:00+00:00: scheduled__2020-07-20T01:25:00+00:00, externally triggered: False>
[2020-07-22 13:35:55,750] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:24:00+00:00: scheduled__2020-07-20T01:24:00+00:00, externally triggered: False>
[2020-07-22 13:35:55,764] {logging_mixin.py:112} INFO - [2020-07-22 13:35:55,764] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:24:00+00:00: scheduled__2020-07-20T01:24:00+00:00, externally triggered: False> failed
[2020-07-22 13:35:55,880] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:25:00+00:00: scheduled__2020-07-20T01:25:00+00:00, externally triggered: False>
[2020-07-22 13:35:55,904] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:35:55,908] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:25:00+00:00 [scheduled]> in ORM
[2020-07-22 13:35:56,048] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.804 seconds
[2020-07-22 13:36:26,289] {scheduler_job.py:153} INFO - Started process (PID=354694) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:36:26,292] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:36:26,292] {logging_mixin.py:112} INFO - [2020-07-22 13:36:26,292] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:36:26,302] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:36:26,468] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:36:26,956] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:26:00+00:00: scheduled__2020-07-20T01:26:00+00:00, externally triggered: False>
[2020-07-22 13:36:26,960] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:25:00+00:00: scheduled__2020-07-20T01:25:00+00:00, externally triggered: False>
[2020-07-22 13:36:26,972] {logging_mixin.py:112} INFO - [2020-07-22 13:36:26,972] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:25:00+00:00: scheduled__2020-07-20T01:25:00+00:00, externally triggered: False> failed
[2020-07-22 13:36:27,082] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:26:00+00:00: scheduled__2020-07-20T01:26:00+00:00, externally triggered: False>
[2020-07-22 13:36:27,101] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:36:27,105] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:26:00+00:00 [scheduled]> in ORM
[2020-07-22 13:36:27,239] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.950 seconds
[2020-07-22 13:36:56,758] {scheduler_job.py:153} INFO - Started process (PID=355457) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:36:56,761] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:36:56,762] {logging_mixin.py:112} INFO - [2020-07-22 13:36:56,762] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:36:56,771] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:36:56,952] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:36:57,271] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:27:00+00:00: scheduled__2020-07-20T01:27:00+00:00, externally triggered: False>
[2020-07-22 13:36:57,291] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:26:00+00:00: scheduled__2020-07-20T01:26:00+00:00, externally triggered: False>
[2020-07-22 13:36:57,326] {logging_mixin.py:112} INFO - [2020-07-22 13:36:57,326] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:26:00+00:00: scheduled__2020-07-20T01:26:00+00:00, externally triggered: False> failed
[2020-07-22 13:36:57,474] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:27:00+00:00: scheduled__2020-07-20T01:27:00+00:00, externally triggered: False>
[2020-07-22 13:36:57,506] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:36:57,513] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:27:00+00:00 [scheduled]> in ORM
[2020-07-22 13:36:57,643] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.884 seconds
[2020-07-22 13:37:27,498] {scheduler_job.py:153} INFO - Started process (PID=356107) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:37:27,501] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:37:27,501] {logging_mixin.py:112} INFO - [2020-07-22 13:37:27,501] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:37:27,511] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:37:27,690] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:37:28,063] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:28:00+00:00: scheduled__2020-07-20T01:28:00+00:00, externally triggered: False>
[2020-07-22 13:37:28,068] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:27:00+00:00: scheduled__2020-07-20T01:27:00+00:00, externally triggered: False>
[2020-07-22 13:37:28,076] {logging_mixin.py:112} INFO - [2020-07-22 13:37:28,076] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:27:00+00:00: scheduled__2020-07-20T01:27:00+00:00, externally triggered: False> failed
[2020-07-22 13:37:28,223] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:28:00+00:00: scheduled__2020-07-20T01:28:00+00:00, externally triggered: False>
[2020-07-22 13:37:28,243] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:37:28,247] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:28:00+00:00 [scheduled]> in ORM
[2020-07-22 13:37:28,414] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.916 seconds
[2020-07-22 13:38:02,816] {scheduler_job.py:153} INFO - Started process (PID=356905) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:38:02,820] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:38:02,821] {logging_mixin.py:112} INFO - [2020-07-22 13:38:02,821] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:38:02,835] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:38:02,992] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:38:03,328] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:29:00+00:00: scheduled__2020-07-20T01:29:00+00:00, externally triggered: False>
[2020-07-22 13:38:03,331] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:28:00+00:00: scheduled__2020-07-20T01:28:00+00:00, externally triggered: False>
[2020-07-22 13:38:03,340] {logging_mixin.py:112} INFO - [2020-07-22 13:38:03,339] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:28:00+00:00: scheduled__2020-07-20T01:28:00+00:00, externally triggered: False> failed
[2020-07-22 13:38:03,458] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:29:00+00:00: scheduled__2020-07-20T01:29:00+00:00, externally triggered: False>
[2020-07-22 13:38:03,489] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:38:03,505] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:29:00+00:00 [scheduled]> in ORM
[2020-07-22 13:38:03,718] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.903 seconds
[2020-07-22 13:38:32,847] {scheduler_job.py:153} INFO - Started process (PID=357652) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:38:32,849] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:38:32,850] {logging_mixin.py:112} INFO - [2020-07-22 13:38:32,850] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:38:32,858] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:38:33,037] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:38:33,415] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:30:00+00:00: scheduled__2020-07-20T01:30:00+00:00, externally triggered: False>
[2020-07-22 13:38:33,418] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:29:00+00:00: scheduled__2020-07-20T01:29:00+00:00, externally triggered: False>
[2020-07-22 13:38:33,425] {logging_mixin.py:112} INFO - [2020-07-22 13:38:33,425] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:29:00+00:00: scheduled__2020-07-20T01:29:00+00:00, externally triggered: False> failed
[2020-07-22 13:38:33,539] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:30:00+00:00: scheduled__2020-07-20T01:30:00+00:00, externally triggered: False>
[2020-07-22 13:38:33,556] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:38:33,560] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:30:00+00:00 [scheduled]> in ORM
[2020-07-22 13:38:33,753] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.907 seconds
[2020-07-22 13:38:56,994] {scheduler_job.py:153} INFO - Started process (PID=358202) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:38:56,998] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:38:56,998] {logging_mixin.py:112} INFO - [2020-07-22 13:38:56,998] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:38:57,022] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:38:57,203] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:38:57,614] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:31:00+00:00: scheduled__2020-07-20T01:31:00+00:00, externally triggered: False>
[2020-07-22 13:38:57,628] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:30:00+00:00: scheduled__2020-07-20T01:30:00+00:00, externally triggered: False>
[2020-07-22 13:38:57,657] {logging_mixin.py:112} INFO - [2020-07-22 13:38:57,656] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:30:00+00:00: scheduled__2020-07-20T01:30:00+00:00, externally triggered: False> failed
[2020-07-22 13:38:57,832] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:31:00+00:00: scheduled__2020-07-20T01:31:00+00:00, externally triggered: False>
[2020-07-22 13:38:57,861] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:38:57,877] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:31:00+00:00 [scheduled]> in ORM
[2020-07-22 13:38:58,021] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.027 seconds
[2020-07-22 13:39:27,712] {scheduler_job.py:153} INFO - Started process (PID=358879) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:39:27,715] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:39:27,715] {logging_mixin.py:112} INFO - [2020-07-22 13:39:27,715] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:39:27,724] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:39:27,833] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:39:28,196] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:32:00+00:00: scheduled__2020-07-20T01:32:00+00:00, externally triggered: False>
[2020-07-22 13:39:28,200] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:31:00+00:00: scheduled__2020-07-20T01:31:00+00:00, externally triggered: False>
[2020-07-22 13:39:28,208] {logging_mixin.py:112} INFO - [2020-07-22 13:39:28,207] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:31:00+00:00: scheduled__2020-07-20T01:31:00+00:00, externally triggered: False> failed
[2020-07-22 13:39:28,398] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:32:00+00:00: scheduled__2020-07-20T01:32:00+00:00, externally triggered: False>
[2020-07-22 13:39:28,417] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:39:28,421] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:32:00+00:00 [scheduled]> in ORM
[2020-07-22 13:39:28,571] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.859 seconds
[2020-07-22 13:39:57,087] {scheduler_job.py:153} INFO - Started process (PID=359602) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:39:57,091] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:39:57,092] {logging_mixin.py:112} INFO - [2020-07-22 13:39:57,092] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:39:57,106] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:39:57,262] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:39:57,655] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:33:00+00:00: scheduled__2020-07-20T01:33:00+00:00, externally triggered: False>
[2020-07-22 13:39:57,663] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:32:00+00:00: scheduled__2020-07-20T01:32:00+00:00, externally triggered: False>
[2020-07-22 13:39:57,696] {logging_mixin.py:112} INFO - [2020-07-22 13:39:57,696] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:32:00+00:00: scheduled__2020-07-20T01:32:00+00:00, externally triggered: False> failed
[2020-07-22 13:39:57,825] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:33:00+00:00: scheduled__2020-07-20T01:33:00+00:00, externally triggered: False>
[2020-07-22 13:39:57,847] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:39:57,855] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:33:00+00:00 [scheduled]> in ORM
[2020-07-22 13:39:58,039] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.951 seconds
[2020-07-22 13:40:22,683] {scheduler_job.py:153} INFO - Started process (PID=360252) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:40:22,687] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:40:22,687] {logging_mixin.py:112} INFO - [2020-07-22 13:40:22,687] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:40:22,696] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:40:22,901] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:40:23,373] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:34:00+00:00: scheduled__2020-07-20T01:34:00+00:00, externally triggered: False>
[2020-07-22 13:40:23,379] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:33:00+00:00: scheduled__2020-07-20T01:33:00+00:00, externally triggered: False>
[2020-07-22 13:40:23,392] {logging_mixin.py:112} INFO - [2020-07-22 13:40:23,391] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:33:00+00:00: scheduled__2020-07-20T01:33:00+00:00, externally triggered: False> failed
[2020-07-22 13:40:23,483] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:34:00+00:00: scheduled__2020-07-20T01:34:00+00:00, externally triggered: False>
[2020-07-22 13:40:23,502] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:40:23,506] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:34:00+00:00 [scheduled]> in ORM
[2020-07-22 13:40:23,662] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.979 seconds
[2020-07-22 13:40:59,134] {scheduler_job.py:153} INFO - Started process (PID=361097) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:40:59,137] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:40:59,138] {logging_mixin.py:112} INFO - [2020-07-22 13:40:59,138] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:40:59,146] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:40:59,241] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:40:59,625] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:35:00+00:00: scheduled__2020-07-20T01:35:00+00:00, externally triggered: False>
[2020-07-22 13:40:59,631] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:34:00+00:00: scheduled__2020-07-20T01:34:00+00:00, externally triggered: False>
[2020-07-22 13:40:59,642] {logging_mixin.py:112} INFO - [2020-07-22 13:40:59,642] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:34:00+00:00: scheduled__2020-07-20T01:34:00+00:00, externally triggered: False> failed
[2020-07-22 13:40:59,775] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:35:00+00:00: scheduled__2020-07-20T01:35:00+00:00, externally triggered: False>
[2020-07-22 13:40:59,797] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:40:59,805] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:35:00+00:00 [scheduled]> in ORM
[2020-07-22 13:40:59,954] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.820 seconds
[2020-07-22 13:41:29,434] {scheduler_job.py:153} INFO - Started process (PID=361800) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:41:29,440] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:41:29,441] {logging_mixin.py:112} INFO - [2020-07-22 13:41:29,441] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:41:29,450] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:41:29,599] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:41:29,952] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:36:00+00:00: scheduled__2020-07-20T01:36:00+00:00, externally triggered: False>
[2020-07-22 13:41:29,955] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:35:00+00:00: scheduled__2020-07-20T01:35:00+00:00, externally triggered: False>
[2020-07-22 13:41:29,962] {logging_mixin.py:112} INFO - [2020-07-22 13:41:29,962] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:35:00+00:00: scheduled__2020-07-20T01:35:00+00:00, externally triggered: False> failed
[2020-07-22 13:41:30,067] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:36:00+00:00: scheduled__2020-07-20T01:36:00+00:00, externally triggered: False>
[2020-07-22 13:41:30,083] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:41:30,088] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:36:00+00:00 [scheduled]> in ORM
[2020-07-22 13:41:30,245] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.811 seconds
[2020-07-22 13:42:00,756] {scheduler_job.py:153} INFO - Started process (PID=362509) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:42:00,760] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:42:00,760] {logging_mixin.py:112} INFO - [2020-07-22 13:42:00,760] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:42:00,768] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:42:00,986] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:42:01,389] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:37:00+00:00: scheduled__2020-07-20T01:37:00+00:00, externally triggered: False>
[2020-07-22 13:42:01,393] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:36:00+00:00: scheduled__2020-07-20T01:36:00+00:00, externally triggered: False>
[2020-07-22 13:42:01,400] {logging_mixin.py:112} INFO - [2020-07-22 13:42:01,400] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:36:00+00:00: scheduled__2020-07-20T01:36:00+00:00, externally triggered: False> failed
[2020-07-22 13:42:01,514] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:37:00+00:00: scheduled__2020-07-20T01:37:00+00:00, externally triggered: False>
[2020-07-22 13:42:01,533] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:42:01,538] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:37:00+00:00 [scheduled]> in ORM
[2020-07-22 13:42:01,694] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.938 seconds
[2020-07-22 13:42:25,806] {scheduler_job.py:153} INFO - Started process (PID=363043) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:42:25,809] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:42:25,809] {logging_mixin.py:112} INFO - [2020-07-22 13:42:25,809] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:42:25,817] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:42:25,994] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:42:26,345] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:38:00+00:00: scheduled__2020-07-20T01:38:00+00:00, externally triggered: False>
[2020-07-22 13:42:26,348] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:37:00+00:00: scheduled__2020-07-20T01:37:00+00:00, externally triggered: False>
[2020-07-22 13:42:26,356] {logging_mixin.py:112} INFO - [2020-07-22 13:42:26,356] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:37:00+00:00: scheduled__2020-07-20T01:37:00+00:00, externally triggered: False> failed
[2020-07-22 13:42:26,494] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:38:00+00:00: scheduled__2020-07-20T01:38:00+00:00, externally triggered: False>
[2020-07-22 13:42:26,519] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:42:26,525] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:38:00+00:00 [scheduled]> in ORM
[2020-07-22 13:42:26,663] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.857 seconds
[2020-07-22 13:42:55,439] {scheduler_job.py:153} INFO - Started process (PID=363728) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:42:55,442] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:42:55,443] {logging_mixin.py:112} INFO - [2020-07-22 13:42:55,443] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:42:55,453] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:42:55,630] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:42:56,082] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:39:00+00:00: scheduled__2020-07-20T01:39:00+00:00, externally triggered: False>
[2020-07-22 13:42:56,088] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:38:00+00:00: scheduled__2020-07-20T01:38:00+00:00, externally triggered: False>
[2020-07-22 13:42:56,099] {logging_mixin.py:112} INFO - [2020-07-22 13:42:56,098] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:38:00+00:00: scheduled__2020-07-20T01:38:00+00:00, externally triggered: False> failed
[2020-07-22 13:42:56,229] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:39:00+00:00: scheduled__2020-07-20T01:39:00+00:00, externally triggered: False>
[2020-07-22 13:42:56,248] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:42:56,252] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:39:00+00:00 [scheduled]> in ORM
[2020-07-22 13:42:56,410] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.971 seconds
[2020-07-22 13:43:24,911] {scheduler_job.py:153} INFO - Started process (PID=364527) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:43:24,916] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:43:24,917] {logging_mixin.py:112} INFO - [2020-07-22 13:43:24,916] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:43:24,927] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:43:25,064] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:43:25,411] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:40:00+00:00: scheduled__2020-07-20T01:40:00+00:00, externally triggered: False>
[2020-07-22 13:43:25,414] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:39:00+00:00: scheduled__2020-07-20T01:39:00+00:00, externally triggered: False>
[2020-07-22 13:43:25,421] {logging_mixin.py:112} INFO - [2020-07-22 13:43:25,421] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:39:00+00:00: scheduled__2020-07-20T01:39:00+00:00, externally triggered: False> failed
[2020-07-22 13:43:25,531] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:40:00+00:00: scheduled__2020-07-20T01:40:00+00:00, externally triggered: False>
[2020-07-22 13:43:25,544] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:43:25,548] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:40:00+00:00 [scheduled]> in ORM
[2020-07-22 13:43:25,731] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.820 seconds
[2020-07-22 13:43:49,271] {scheduler_job.py:153} INFO - Started process (PID=365027) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:43:49,276] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:43:49,277] {logging_mixin.py:112} INFO - [2020-07-22 13:43:49,276] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:43:49,287] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:43:49,457] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:43:49,875] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:41:00+00:00: scheduled__2020-07-20T01:41:00+00:00, externally triggered: False>
[2020-07-22 13:43:49,880] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:40:00+00:00: scheduled__2020-07-20T01:40:00+00:00, externally triggered: False>
[2020-07-22 13:43:49,889] {logging_mixin.py:112} INFO - [2020-07-22 13:43:49,889] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:40:00+00:00: scheduled__2020-07-20T01:40:00+00:00, externally triggered: False> failed
[2020-07-22 13:43:50,011] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:41:00+00:00: scheduled__2020-07-20T01:41:00+00:00, externally triggered: False>
[2020-07-22 13:43:50,038] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:43:50,045] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:41:00+00:00 [scheduled]> in ORM
[2020-07-22 13:43:50,201] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.930 seconds
[2020-07-22 13:44:18,862] {scheduler_job.py:153} INFO - Started process (PID=365705) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:44:18,865] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:44:18,866] {logging_mixin.py:112} INFO - [2020-07-22 13:44:18,865] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:44:18,874] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:44:18,991] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:44:19,336] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:42:00+00:00: scheduled__2020-07-20T01:42:00+00:00, externally triggered: False>
[2020-07-22 13:44:19,340] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:41:00+00:00: scheduled__2020-07-20T01:41:00+00:00, externally triggered: False>
[2020-07-22 13:44:19,349] {logging_mixin.py:112} INFO - [2020-07-22 13:44:19,348] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:41:00+00:00: scheduled__2020-07-20T01:41:00+00:00, externally triggered: False> failed
[2020-07-22 13:44:19,447] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:42:00+00:00: scheduled__2020-07-20T01:42:00+00:00, externally triggered: False>
[2020-07-22 13:44:19,472] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:44:19,479] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:42:00+00:00 [scheduled]> in ORM
[2020-07-22 13:44:19,692] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.830 seconds
[2020-07-22 13:44:43,116] {scheduler_job.py:153} INFO - Started process (PID=366259) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:44:43,119] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:44:43,120] {logging_mixin.py:112} INFO - [2020-07-22 13:44:43,120] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:44:43,132] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:44:43,251] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:44:43,710] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:43:00+00:00: scheduled__2020-07-20T01:43:00+00:00, externally triggered: False>
[2020-07-22 13:44:43,715] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:42:00+00:00: scheduled__2020-07-20T01:42:00+00:00, externally triggered: False>
[2020-07-22 13:44:43,736] {logging_mixin.py:112} INFO - [2020-07-22 13:44:43,736] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:42:00+00:00: scheduled__2020-07-20T01:42:00+00:00, externally triggered: False> failed
[2020-07-22 13:44:43,837] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:43:00+00:00: scheduled__2020-07-20T01:43:00+00:00, externally triggered: False>
[2020-07-22 13:44:43,865] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:44:43,871] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:43:00+00:00 [scheduled]> in ORM
[2020-07-22 13:44:44,056] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.940 seconds
[2020-07-22 13:45:08,005] {scheduler_job.py:153} INFO - Started process (PID=366867) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:45:08,008] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:45:08,008] {logging_mixin.py:112} INFO - [2020-07-22 13:45:08,008] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:45:08,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:45:08,174] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:45:08,582] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:44:00+00:00: scheduled__2020-07-20T01:44:00+00:00, externally triggered: False>
[2020-07-22 13:45:08,585] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:43:00+00:00: scheduled__2020-07-20T01:43:00+00:00, externally triggered: False>
[2020-07-22 13:45:08,593] {logging_mixin.py:112} INFO - [2020-07-22 13:45:08,593] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:43:00+00:00: scheduled__2020-07-20T01:43:00+00:00, externally triggered: False> failed
[2020-07-22 13:45:08,906] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:44:00+00:00: scheduled__2020-07-20T01:44:00+00:00, externally triggered: False>
[2020-07-22 13:45:08,923] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:45:08,927] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:44:00+00:00 [scheduled]> in ORM
[2020-07-22 13:45:09,198] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.193 seconds
[2020-07-22 13:45:43,918] {scheduler_job.py:153} INFO - Started process (PID=367669) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:45:43,921] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:45:43,921] {logging_mixin.py:112} INFO - [2020-07-22 13:45:43,921] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:45:43,930] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:45:44,241] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:45:44,641] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:45:00+00:00: scheduled__2020-07-20T01:45:00+00:00, externally triggered: False>
[2020-07-22 13:45:44,651] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:44:00+00:00: scheduled__2020-07-20T01:44:00+00:00, externally triggered: False>
[2020-07-22 13:45:44,667] {logging_mixin.py:112} INFO - [2020-07-22 13:45:44,667] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:44:00+00:00: scheduled__2020-07-20T01:44:00+00:00, externally triggered: False> failed
[2020-07-22 13:45:44,864] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:45:00+00:00: scheduled__2020-07-20T01:45:00+00:00, externally triggered: False>
[2020-07-22 13:45:44,884] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:45:44,888] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:45:00+00:00 [scheduled]> in ORM
[2020-07-22 13:45:45,172] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.254 seconds
[2020-07-22 13:46:08,281] {scheduler_job.py:153} INFO - Started process (PID=368188) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:46:08,283] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:46:08,284] {logging_mixin.py:112} INFO - [2020-07-22 13:46:08,284] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:46:08,293] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:46:08,436] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:46:08,854] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:46:00+00:00: scheduled__2020-07-20T01:46:00+00:00, externally triggered: False>
[2020-07-22 13:46:08,859] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:45:00+00:00: scheduled__2020-07-20T01:45:00+00:00, externally triggered: False>
[2020-07-22 13:46:08,867] {logging_mixin.py:112} INFO - [2020-07-22 13:46:08,867] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:45:00+00:00: scheduled__2020-07-20T01:45:00+00:00, externally triggered: False> failed
[2020-07-22 13:46:09,066] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:46:00+00:00: scheduled__2020-07-20T01:46:00+00:00, externally triggered: False>
[2020-07-22 13:46:09,085] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:46:09,088] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:46:00+00:00 [scheduled]> in ORM
[2020-07-22 13:46:09,235] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.955 seconds
[2020-07-22 13:46:39,436] {scheduler_job.py:153} INFO - Started process (PID=368890) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:46:39,439] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:46:39,439] {logging_mixin.py:112} INFO - [2020-07-22 13:46:39,439] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:46:39,449] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:46:39,566] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:46:40,054] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:47:00+00:00: scheduled__2020-07-20T01:47:00+00:00, externally triggered: False>
[2020-07-22 13:46:40,058] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:46:00+00:00: scheduled__2020-07-20T01:46:00+00:00, externally triggered: False>
[2020-07-22 13:46:40,066] {logging_mixin.py:112} INFO - [2020-07-22 13:46:40,066] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:46:00+00:00: scheduled__2020-07-20T01:46:00+00:00, externally triggered: False> failed
[2020-07-22 13:46:40,357] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:47:00+00:00: scheduled__2020-07-20T01:47:00+00:00, externally triggered: False>
[2020-07-22 13:46:40,372] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:46:40,376] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:47:00+00:00 [scheduled]> in ORM
[2020-07-22 13:46:40,503] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.068 seconds
[2020-07-22 13:47:14,493] {scheduler_job.py:153} INFO - Started process (PID=369637) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:47:14,496] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:47:14,497] {logging_mixin.py:112} INFO - [2020-07-22 13:47:14,497] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:47:14,508] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:47:14,657] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:47:15,012] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:48:00+00:00: scheduled__2020-07-20T01:48:00+00:00, externally triggered: False>
[2020-07-22 13:47:15,015] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:47:00+00:00: scheduled__2020-07-20T01:47:00+00:00, externally triggered: False>
[2020-07-22 13:47:15,023] {logging_mixin.py:112} INFO - [2020-07-22 13:47:15,022] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:47:00+00:00: scheduled__2020-07-20T01:47:00+00:00, externally triggered: False> failed
[2020-07-22 13:47:15,193] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:48:00+00:00: scheduled__2020-07-20T01:48:00+00:00, externally triggered: False>
[2020-07-22 13:47:15,211] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:47:15,215] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:48:00+00:00 [scheduled]> in ORM
[2020-07-22 13:47:15,395] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.902 seconds
[2020-07-22 13:47:44,212] {scheduler_job.py:153} INFO - Started process (PID=370310) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:47:44,226] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:47:44,228] {logging_mixin.py:112} INFO - [2020-07-22 13:47:44,227] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:47:44,264] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:47:44,419] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:47:44,841] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:49:00+00:00: scheduled__2020-07-20T01:49:00+00:00, externally triggered: False>
[2020-07-22 13:47:44,847] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:48:00+00:00: scheduled__2020-07-20T01:48:00+00:00, externally triggered: False>
[2020-07-22 13:47:44,860] {logging_mixin.py:112} INFO - [2020-07-22 13:47:44,860] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:48:00+00:00: scheduled__2020-07-20T01:48:00+00:00, externally triggered: False> failed
[2020-07-22 13:47:44,961] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:49:00+00:00: scheduled__2020-07-20T01:49:00+00:00, externally triggered: False>
[2020-07-22 13:47:44,984] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:47:44,992] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:49:00+00:00 [scheduled]> in ORM
[2020-07-22 13:47:45,123] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.911 seconds
[2020-07-22 13:48:10,004] {scheduler_job.py:153} INFO - Started process (PID=370868) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:48:10,007] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:48:10,007] {logging_mixin.py:112} INFO - [2020-07-22 13:48:10,007] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:48:10,016] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:48:10,128] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:48:10,598] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:50:00+00:00: scheduled__2020-07-20T01:50:00+00:00, externally triggered: False>
[2020-07-22 13:48:10,603] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:49:00+00:00: scheduled__2020-07-20T01:49:00+00:00, externally triggered: False>
[2020-07-22 13:48:10,614] {logging_mixin.py:112} INFO - [2020-07-22 13:48:10,614] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:49:00+00:00: scheduled__2020-07-20T01:49:00+00:00, externally triggered: False> failed
[2020-07-22 13:48:10,764] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:50:00+00:00: scheduled__2020-07-20T01:50:00+00:00, externally triggered: False>
[2020-07-22 13:48:10,784] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:48:10,788] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:50:00+00:00 [scheduled]> in ORM
[2020-07-22 13:48:10,933] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.929 seconds
[2020-07-22 13:48:44,330] {scheduler_job.py:153} INFO - Started process (PID=371607) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:48:44,334] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:48:44,335] {logging_mixin.py:112} INFO - [2020-07-22 13:48:44,335] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:48:44,346] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:48:44,459] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:48:44,881] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:51:00+00:00: scheduled__2020-07-20T01:51:00+00:00, externally triggered: False>
[2020-07-22 13:48:44,886] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:50:00+00:00: scheduled__2020-07-20T01:50:00+00:00, externally triggered: False>
[2020-07-22 13:48:44,896] {logging_mixin.py:112} INFO - [2020-07-22 13:48:44,896] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:50:00+00:00: scheduled__2020-07-20T01:50:00+00:00, externally triggered: False> failed
[2020-07-22 13:48:44,988] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:51:00+00:00: scheduled__2020-07-20T01:51:00+00:00, externally triggered: False>
[2020-07-22 13:48:45,006] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:48:45,010] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:51:00+00:00 [scheduled]> in ORM
[2020-07-22 13:48:45,215] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.885 seconds
[2020-07-22 13:49:13,814] {scheduler_job.py:153} INFO - Started process (PID=372302) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:49:13,817] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:49:13,817] {logging_mixin.py:112} INFO - [2020-07-22 13:49:13,817] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:49:13,827] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:49:13,969] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:49:14,289] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:52:00+00:00: scheduled__2020-07-20T01:52:00+00:00, externally triggered: False>
[2020-07-22 13:49:14,294] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:51:00+00:00: scheduled__2020-07-20T01:51:00+00:00, externally triggered: False>
[2020-07-22 13:49:14,303] {logging_mixin.py:112} INFO - [2020-07-22 13:49:14,303] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:51:00+00:00: scheduled__2020-07-20T01:51:00+00:00, externally triggered: False> failed
[2020-07-22 13:49:14,435] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:52:00+00:00: scheduled__2020-07-20T01:52:00+00:00, externally triggered: False>
[2020-07-22 13:49:14,455] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:49:14,459] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:52:00+00:00 [scheduled]> in ORM
[2020-07-22 13:49:14,615] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.801 seconds
[2020-07-22 13:49:43,615] {scheduler_job.py:153} INFO - Started process (PID=372922) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:49:43,619] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:49:43,620] {logging_mixin.py:112} INFO - [2020-07-22 13:49:43,620] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:49:43,639] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:49:43,962] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:49:44,359] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:53:00+00:00: scheduled__2020-07-20T01:53:00+00:00, externally triggered: False>
[2020-07-22 13:49:44,365] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:52:00+00:00: scheduled__2020-07-20T01:52:00+00:00, externally triggered: False>
[2020-07-22 13:49:44,391] {logging_mixin.py:112} INFO - [2020-07-22 13:49:44,391] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:52:00+00:00: scheduled__2020-07-20T01:52:00+00:00, externally triggered: False> failed
[2020-07-22 13:49:44,581] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:53:00+00:00: scheduled__2020-07-20T01:53:00+00:00, externally triggered: False>
[2020-07-22 13:49:44,598] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:49:44,602] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:53:00+00:00 [scheduled]> in ORM
[2020-07-22 13:49:44,741] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.126 seconds
[2020-07-22 13:50:14,022] {scheduler_job.py:153} INFO - Started process (PID=373581) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:50:14,028] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:50:14,029] {logging_mixin.py:112} INFO - [2020-07-22 13:50:14,029] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:50:14,051] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:50:14,193] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:50:14,551] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:54:00+00:00: scheduled__2020-07-20T01:54:00+00:00, externally triggered: False>
[2020-07-22 13:50:14,558] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:53:00+00:00: scheduled__2020-07-20T01:53:00+00:00, externally triggered: False>
[2020-07-22 13:50:14,574] {logging_mixin.py:112} INFO - [2020-07-22 13:50:14,574] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:53:00+00:00: scheduled__2020-07-20T01:53:00+00:00, externally triggered: False> failed
[2020-07-22 13:50:14,694] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:54:00+00:00: scheduled__2020-07-20T01:54:00+00:00, externally triggered: False>
[2020-07-22 13:50:14,722] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:50:14,730] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:54:00+00:00 [scheduled]> in ORM
[2020-07-22 13:50:14,951] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.930 seconds
[2020-07-22 13:50:43,182] {scheduler_job.py:153} INFO - Started process (PID=374259) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:50:43,185] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:50:43,185] {logging_mixin.py:112} INFO - [2020-07-22 13:50:43,185] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:50:43,194] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:50:43,352] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:50:43,711] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:55:00+00:00: scheduled__2020-07-20T01:55:00+00:00, externally triggered: False>
[2020-07-22 13:50:43,714] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:54:00+00:00: scheduled__2020-07-20T01:54:00+00:00, externally triggered: False>
[2020-07-22 13:50:43,722] {logging_mixin.py:112} INFO - [2020-07-22 13:50:43,722] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:54:00+00:00: scheduled__2020-07-20T01:54:00+00:00, externally triggered: False> failed
[2020-07-22 13:50:43,852] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:55:00+00:00: scheduled__2020-07-20T01:55:00+00:00, externally triggered: False>
[2020-07-22 13:50:43,872] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:50:43,879] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:55:00+00:00 [scheduled]> in ORM
[2020-07-22 13:50:44,011] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.830 seconds
[2020-07-22 13:51:07,534] {scheduler_job.py:153} INFO - Started process (PID=374814) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:51:07,540] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:51:07,541] {logging_mixin.py:112} INFO - [2020-07-22 13:51:07,541] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:51:07,553] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:51:07,681] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:51:07,997] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:56:00+00:00: scheduled__2020-07-20T01:56:00+00:00, externally triggered: False>
[2020-07-22 13:51:08,002] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:55:00+00:00: scheduled__2020-07-20T01:55:00+00:00, externally triggered: False>
[2020-07-22 13:51:08,022] {logging_mixin.py:112} INFO - [2020-07-22 13:51:08,022] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:55:00+00:00: scheduled__2020-07-20T01:55:00+00:00, externally triggered: False> failed
[2020-07-22 13:51:08,226] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:56:00+00:00: scheduled__2020-07-20T01:56:00+00:00, externally triggered: False>
[2020-07-22 13:51:08,256] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:51:08,263] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:56:00+00:00 [scheduled]> in ORM
[2020-07-22 13:51:08,444] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.910 seconds
[2020-07-22 13:51:43,401] {scheduler_job.py:153} INFO - Started process (PID=375590) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:51:43,405] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:51:43,405] {logging_mixin.py:112} INFO - [2020-07-22 13:51:43,405] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:51:43,413] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:51:43,573] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:51:44,067] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:57:00+00:00: scheduled__2020-07-20T01:57:00+00:00, externally triggered: False>
[2020-07-22 13:51:44,071] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:56:00+00:00: scheduled__2020-07-20T01:56:00+00:00, externally triggered: False>
[2020-07-22 13:51:44,085] {logging_mixin.py:112} INFO - [2020-07-22 13:51:44,085] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:56:00+00:00: scheduled__2020-07-20T01:56:00+00:00, externally triggered: False> failed
[2020-07-22 13:51:44,244] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:57:00+00:00: scheduled__2020-07-20T01:57:00+00:00, externally triggered: False>
[2020-07-22 13:51:44,263] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:51:44,268] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:57:00+00:00 [scheduled]> in ORM
[2020-07-22 13:51:44,400] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.999 seconds
[2020-07-22 13:52:13,554] {scheduler_job.py:153} INFO - Started process (PID=376291) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:52:13,558] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:52:13,559] {logging_mixin.py:112} INFO - [2020-07-22 13:52:13,559] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:52:13,568] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:52:13,712] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:52:14,038] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:58:00+00:00: scheduled__2020-07-20T01:58:00+00:00, externally triggered: False>
[2020-07-22 13:52:14,041] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:57:00+00:00: scheduled__2020-07-20T01:57:00+00:00, externally triggered: False>
[2020-07-22 13:52:14,048] {logging_mixin.py:112} INFO - [2020-07-22 13:52:14,048] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:57:00+00:00: scheduled__2020-07-20T01:57:00+00:00, externally triggered: False> failed
[2020-07-22 13:52:14,158] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:58:00+00:00: scheduled__2020-07-20T01:58:00+00:00, externally triggered: False>
[2020-07-22 13:52:14,176] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:52:14,180] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:58:00+00:00 [scheduled]> in ORM
[2020-07-22 13:52:14,349] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.795 seconds
[2020-07-22 13:52:43,400] {scheduler_job.py:153} INFO - Started process (PID=376951) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:52:43,411] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:52:43,412] {logging_mixin.py:112} INFO - [2020-07-22 13:52:43,412] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:52:43,432] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:52:43,614] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:52:44,015] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T01:59:00+00:00: scheduled__2020-07-20T01:59:00+00:00, externally triggered: False>
[2020-07-22 13:52:44,021] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:58:00+00:00: scheduled__2020-07-20T01:58:00+00:00, externally triggered: False>
[2020-07-22 13:52:44,046] {logging_mixin.py:112} INFO - [2020-07-22 13:52:44,045] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:58:00+00:00: scheduled__2020-07-20T01:58:00+00:00, externally triggered: False> failed
[2020-07-22 13:52:44,170] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:59:00+00:00: scheduled__2020-07-20T01:59:00+00:00, externally triggered: False>
[2020-07-22 13:52:44,226] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:52:44,244] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 01:59:00+00:00 [scheduled]> in ORM
[2020-07-22 13:52:44,383] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.983 seconds
[2020-07-22 13:53:08,896] {scheduler_job.py:153} INFO - Started process (PID=377504) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:53:08,898] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:53:08,899] {logging_mixin.py:112} INFO - [2020-07-22 13:53:08,899] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:53:08,907] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:53:09,152] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:53:09,479] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:00:00+00:00: scheduled__2020-07-20T02:00:00+00:00, externally triggered: False>
[2020-07-22 13:53:09,482] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 01:59:00+00:00: scheduled__2020-07-20T01:59:00+00:00, externally triggered: False>
[2020-07-22 13:53:09,490] {logging_mixin.py:112} INFO - [2020-07-22 13:53:09,490] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 01:59:00+00:00: scheduled__2020-07-20T01:59:00+00:00, externally triggered: False> failed
[2020-07-22 13:53:09,628] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:00:00+00:00: scheduled__2020-07-20T02:00:00+00:00, externally triggered: False>
[2020-07-22 13:53:09,648] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:53:09,652] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:00:00+00:00 [scheduled]> in ORM
[2020-07-22 13:53:09,805] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.910 seconds
[2020-07-22 13:53:38,745] {scheduler_job.py:153} INFO - Started process (PID=378276) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:53:38,750] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:53:38,750] {logging_mixin.py:112} INFO - [2020-07-22 13:53:38,750] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:53:38,774] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:53:38,975] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:53:39,348] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:01:00+00:00: scheduled__2020-07-20T02:01:00+00:00, externally triggered: False>
[2020-07-22 13:53:39,355] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:00:00+00:00: scheduled__2020-07-20T02:00:00+00:00, externally triggered: False>
[2020-07-22 13:53:39,367] {logging_mixin.py:112} INFO - [2020-07-22 13:53:39,367] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:00:00+00:00: scheduled__2020-07-20T02:00:00+00:00, externally triggered: False> failed
[2020-07-22 13:53:39,474] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:01:00+00:00: scheduled__2020-07-20T02:01:00+00:00, externally triggered: False>
[2020-07-22 13:53:39,514] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:53:39,525] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:01:00+00:00 [scheduled]> in ORM
[2020-07-22 13:53:39,697] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.951 seconds
[2020-07-22 13:54:09,103] {scheduler_job.py:153} INFO - Started process (PID=379020) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:54:09,105] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:54:09,106] {logging_mixin.py:112} INFO - [2020-07-22 13:54:09,106] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:54:09,115] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:54:09,512] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:54:09,981] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:02:00+00:00: scheduled__2020-07-20T02:02:00+00:00, externally triggered: False>
[2020-07-22 13:54:09,986] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:01:00+00:00: scheduled__2020-07-20T02:01:00+00:00, externally triggered: False>
[2020-07-22 13:54:09,997] {logging_mixin.py:112} INFO - [2020-07-22 13:54:09,997] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:01:00+00:00: scheduled__2020-07-20T02:01:00+00:00, externally triggered: False> failed
[2020-07-22 13:54:10,154] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:02:00+00:00: scheduled__2020-07-20T02:02:00+00:00, externally triggered: False>
[2020-07-22 13:54:10,173] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:54:10,177] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:02:00+00:00 [scheduled]> in ORM
[2020-07-22 13:54:10,322] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.219 seconds
[2020-07-22 13:54:39,613] {scheduler_job.py:153} INFO - Started process (PID=379778) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:54:39,616] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:54:39,617] {logging_mixin.py:112} INFO - [2020-07-22 13:54:39,616] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:54:39,626] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:54:39,766] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:54:41,066] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:03:00+00:00: scheduled__2020-07-20T02:03:00+00:00, externally triggered: False>
[2020-07-22 13:54:41,070] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:02:00+00:00: scheduled__2020-07-20T02:02:00+00:00, externally triggered: False>
[2020-07-22 13:54:41,079] {logging_mixin.py:112} INFO - [2020-07-22 13:54:41,079] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:02:00+00:00: scheduled__2020-07-20T02:02:00+00:00, externally triggered: False> failed
[2020-07-22 13:54:41,189] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:03:00+00:00: scheduled__2020-07-20T02:03:00+00:00, externally triggered: False>
[2020-07-22 13:54:41,206] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:54:41,210] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:03:00+00:00 [scheduled]> in ORM
[2020-07-22 13:54:41,347] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.734 seconds
[2020-07-22 13:55:09,870] {scheduler_job.py:153} INFO - Started process (PID=380487) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:55:09,873] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:55:09,873] {logging_mixin.py:112} INFO - [2020-07-22 13:55:09,873] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:55:09,881] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:55:10,045] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:55:10,360] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:04:00+00:00: scheduled__2020-07-20T02:04:00+00:00, externally triggered: False>
[2020-07-22 13:55:10,366] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:03:00+00:00: scheduled__2020-07-20T02:03:00+00:00, externally triggered: False>
[2020-07-22 13:55:10,382] {logging_mixin.py:112} INFO - [2020-07-22 13:55:10,382] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:03:00+00:00: scheduled__2020-07-20T02:03:00+00:00, externally triggered: False> failed
[2020-07-22 13:55:10,546] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:04:00+00:00: scheduled__2020-07-20T02:04:00+00:00, externally triggered: False>
[2020-07-22 13:55:10,564] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:55:10,568] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:04:00+00:00 [scheduled]> in ORM
[2020-07-22 13:55:10,748] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.878 seconds
[2020-07-22 13:55:39,327] {scheduler_job.py:153} INFO - Started process (PID=381180) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:55:39,331] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:55:39,331] {logging_mixin.py:112} INFO - [2020-07-22 13:55:39,331] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:55:39,340] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:55:39,516] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:55:39,849] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:05:00+00:00: scheduled__2020-07-20T02:05:00+00:00, externally triggered: False>
[2020-07-22 13:55:39,855] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:04:00+00:00: scheduled__2020-07-20T02:04:00+00:00, externally triggered: False>
[2020-07-22 13:55:39,863] {logging_mixin.py:112} INFO - [2020-07-22 13:55:39,863] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:04:00+00:00: scheduled__2020-07-20T02:04:00+00:00, externally triggered: False> failed
[2020-07-22 13:55:40,004] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:05:00+00:00: scheduled__2020-07-20T02:05:00+00:00, externally triggered: False>
[2020-07-22 13:55:40,026] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:55:40,031] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:05:00+00:00 [scheduled]> in ORM
[2020-07-22 13:55:40,160] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.834 seconds
[2020-07-22 13:56:03,564] {scheduler_job.py:153} INFO - Started process (PID=381705) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:56:03,567] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:56:03,568] {logging_mixin.py:112} INFO - [2020-07-22 13:56:03,567] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:56:03,576] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:56:04,355] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:56:04,824] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:06:00+00:00: scheduled__2020-07-20T02:06:00+00:00, externally triggered: False>
[2020-07-22 13:56:04,827] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:05:00+00:00: scheduled__2020-07-20T02:05:00+00:00, externally triggered: False>
[2020-07-22 13:56:04,837] {logging_mixin.py:112} INFO - [2020-07-22 13:56:04,837] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:05:00+00:00: scheduled__2020-07-20T02:05:00+00:00, externally triggered: False> failed
[2020-07-22 13:56:04,983] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:06:00+00:00: scheduled__2020-07-20T02:06:00+00:00, externally triggered: False>
[2020-07-22 13:56:05,002] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:56:05,006] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:06:00+00:00 [scheduled]> in ORM
[2020-07-22 13:56:05,142] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.578 seconds
[2020-07-22 13:56:39,850] {scheduler_job.py:153} INFO - Started process (PID=382535) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:56:39,856] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:56:39,856] {logging_mixin.py:112} INFO - [2020-07-22 13:56:39,856] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:56:39,867] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:56:40,193] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:56:40,689] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:07:00+00:00: scheduled__2020-07-20T02:07:00+00:00, externally triggered: False>
[2020-07-22 13:56:40,693] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:06:00+00:00: scheduled__2020-07-20T02:06:00+00:00, externally triggered: False>
[2020-07-22 13:56:40,701] {logging_mixin.py:112} INFO - [2020-07-22 13:56:40,701] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:06:00+00:00: scheduled__2020-07-20T02:06:00+00:00, externally triggered: False> failed
[2020-07-22 13:56:40,829] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:07:00+00:00: scheduled__2020-07-20T02:07:00+00:00, externally triggered: False>
[2020-07-22 13:56:40,842] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:56:40,846] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:07:00+00:00 [scheduled]> in ORM
[2020-07-22 13:56:41,020] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.170 seconds
[2020-07-22 13:57:09,576] {scheduler_job.py:153} INFO - Started process (PID=383219) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:57:09,580] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:57:09,581] {logging_mixin.py:112} INFO - [2020-07-22 13:57:09,581] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:57:09,595] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:57:09,770] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:57:10,146] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:08:00+00:00: scheduled__2020-07-20T02:08:00+00:00, externally triggered: False>
[2020-07-22 13:57:10,150] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:07:00+00:00: scheduled__2020-07-20T02:07:00+00:00, externally triggered: False>
[2020-07-22 13:57:10,157] {logging_mixin.py:112} INFO - [2020-07-22 13:57:10,157] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:07:00+00:00: scheduled__2020-07-20T02:07:00+00:00, externally triggered: False> failed
[2020-07-22 13:57:10,276] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:08:00+00:00: scheduled__2020-07-20T02:08:00+00:00, externally triggered: False>
[2020-07-22 13:57:10,294] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:57:10,297] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:08:00+00:00 [scheduled]> in ORM
[2020-07-22 13:57:10,445] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.870 seconds
[2020-07-22 13:57:34,482] {scheduler_job.py:153} INFO - Started process (PID=383748) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:57:34,488] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:57:34,488] {logging_mixin.py:112} INFO - [2020-07-22 13:57:34,488] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:57:34,511] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:57:34,667] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:57:35,438] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:09:00+00:00: scheduled__2020-07-20T02:09:00+00:00, externally triggered: False>
[2020-07-22 13:57:35,442] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:08:00+00:00: scheduled__2020-07-20T02:08:00+00:00, externally triggered: False>
[2020-07-22 13:57:35,449] {logging_mixin.py:112} INFO - [2020-07-22 13:57:35,449] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:08:00+00:00: scheduled__2020-07-20T02:08:00+00:00, externally triggered: False> failed
[2020-07-22 13:57:35,567] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:09:00+00:00: scheduled__2020-07-20T02:09:00+00:00, externally triggered: False>
[2020-07-22 13:57:35,585] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:57:35,589] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:09:00+00:00 [scheduled]> in ORM
[2020-07-22 13:57:35,747] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.265 seconds
[2020-07-22 13:58:05,502] {scheduler_job.py:153} INFO - Started process (PID=384454) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:58:05,506] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:58:05,506] {logging_mixin.py:112} INFO - [2020-07-22 13:58:05,506] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:58:05,516] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:58:05,708] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:58:06,091] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:10:00+00:00: scheduled__2020-07-20T02:10:00+00:00, externally triggered: False>
[2020-07-22 13:58:06,094] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:09:00+00:00: scheduled__2020-07-20T02:09:00+00:00, externally triggered: False>
[2020-07-22 13:58:06,102] {logging_mixin.py:112} INFO - [2020-07-22 13:58:06,101] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:09:00+00:00: scheduled__2020-07-20T02:09:00+00:00, externally triggered: False> failed
[2020-07-22 13:58:06,252] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:10:00+00:00: scheduled__2020-07-20T02:10:00+00:00, externally triggered: False>
[2020-07-22 13:58:06,277] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:58:06,284] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:10:00+00:00 [scheduled]> in ORM
[2020-07-22 13:58:06,470] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.968 seconds
[2020-07-22 13:58:29,954] {scheduler_job.py:153} INFO - Started process (PID=384918) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:58:29,957] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:58:29,957] {logging_mixin.py:112} INFO - [2020-07-22 13:58:29,957] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:58:29,969] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:58:30,138] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:58:30,557] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:11:00+00:00: scheduled__2020-07-20T02:11:00+00:00, externally triggered: False>
[2020-07-22 13:58:30,562] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:10:00+00:00: scheduled__2020-07-20T02:10:00+00:00, externally triggered: False>
[2020-07-22 13:58:30,575] {logging_mixin.py:112} INFO - [2020-07-22 13:58:30,575] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:10:00+00:00: scheduled__2020-07-20T02:10:00+00:00, externally triggered: False> failed
[2020-07-22 13:58:30,894] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:11:00+00:00: scheduled__2020-07-20T02:11:00+00:00, externally triggered: False>
[2020-07-22 13:58:30,913] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:58:30,919] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:11:00+00:00 [scheduled]> in ORM
[2020-07-22 13:58:31,195] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.242 seconds
[2020-07-22 13:58:56,628] {scheduler_job.py:153} INFO - Started process (PID=385525) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:58:56,633] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:58:56,633] {logging_mixin.py:112} INFO - [2020-07-22 13:58:56,633] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:58:56,646] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:58:56,871] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:58:57,198] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:12:00+00:00: scheduled__2020-07-20T02:12:00+00:00, externally triggered: False>
[2020-07-22 13:58:57,202] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:11:00+00:00: scheduled__2020-07-20T02:11:00+00:00, externally triggered: False>
[2020-07-22 13:58:57,211] {logging_mixin.py:112} INFO - [2020-07-22 13:58:57,211] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:11:00+00:00: scheduled__2020-07-20T02:11:00+00:00, externally triggered: False> failed
[2020-07-22 13:58:57,316] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:12:00+00:00: scheduled__2020-07-20T02:12:00+00:00, externally triggered: False>
[2020-07-22 13:58:57,336] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:58:57,340] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:12:00+00:00 [scheduled]> in ORM
[2020-07-22 13:58:57,482] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.855 seconds
[2020-07-22 13:59:21,000] {scheduler_job.py:153} INFO - Started process (PID=386008) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:59:21,002] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:59:21,003] {logging_mixin.py:112} INFO - [2020-07-22 13:59:21,003] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:59:21,014] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:59:21,171] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:59:21,631] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:13:00+00:00: scheduled__2020-07-20T02:13:00+00:00, externally triggered: False>
[2020-07-22 13:59:21,638] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:12:00+00:00: scheduled__2020-07-20T02:12:00+00:00, externally triggered: False>
[2020-07-22 13:59:21,648] {logging_mixin.py:112} INFO - [2020-07-22 13:59:21,648] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:12:00+00:00: scheduled__2020-07-20T02:12:00+00:00, externally triggered: False> failed
[2020-07-22 13:59:21,764] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:13:00+00:00: scheduled__2020-07-20T02:13:00+00:00, externally triggered: False>
[2020-07-22 13:59:21,803] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:59:21,812] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:13:00+00:00 [scheduled]> in ORM
[2020-07-22 13:59:21,951] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.952 seconds
[2020-07-22 13:59:46,204] {scheduler_job.py:153} INFO - Started process (PID=386555) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:59:46,207] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 13:59:46,208] {logging_mixin.py:112} INFO - [2020-07-22 13:59:46,208] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:59:46,220] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 13:59:46,400] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 13:59:47,007] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:14:00+00:00: scheduled__2020-07-20T02:14:00+00:00, externally triggered: False>
[2020-07-22 13:59:47,011] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:13:00+00:00: scheduled__2020-07-20T02:13:00+00:00, externally triggered: False>
[2020-07-22 13:59:47,021] {logging_mixin.py:112} INFO - [2020-07-22 13:59:47,020] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:13:00+00:00: scheduled__2020-07-20T02:13:00+00:00, externally triggered: False> failed
[2020-07-22 13:59:47,285] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:14:00+00:00: scheduled__2020-07-20T02:14:00+00:00, externally triggered: False>
[2020-07-22 13:59:47,304] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 13:59:47,308] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:14:00+00:00 [scheduled]> in ORM
[2020-07-22 13:59:47,456] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.252 seconds
[2020-07-22 14:00:16,468] {scheduler_job.py:153} INFO - Started process (PID=387168) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:00:16,473] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:00:16,474] {logging_mixin.py:112} INFO - [2020-07-22 14:00:16,473] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:00:16,486] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:00:16,661] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:00:16,985] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:15:00+00:00: scheduled__2020-07-20T02:15:00+00:00, externally triggered: False>
[2020-07-22 14:00:16,992] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:14:00+00:00: scheduled__2020-07-20T02:14:00+00:00, externally triggered: False>
[2020-07-22 14:00:17,003] {logging_mixin.py:112} INFO - [2020-07-22 14:00:17,003] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:14:00+00:00: scheduled__2020-07-20T02:14:00+00:00, externally triggered: False> failed
[2020-07-22 14:00:17,109] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:15:00+00:00: scheduled__2020-07-20T02:15:00+00:00, externally triggered: False>
[2020-07-22 14:00:17,119] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 08:30:03.383936+00:00: manual__2020-07-22T08:30:03.383936+00:00, externally triggered: True>
[2020-07-22 14:00:17,139] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:00:17,144] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:15:00+00:00 [scheduled]> in ORM
[2020-07-22 14:00:17,148] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 08:30:03.383936+00:00 [scheduled]> in ORM
[2020-07-22 14:00:17,311] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.843 seconds
[2020-07-22 14:00:59,547] {scheduler_job.py:153} INFO - Started process (PID=388127) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:00:59,550] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:00:59,550] {logging_mixin.py:112} INFO - [2020-07-22 14:00:59,550] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:00:59,559] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:00:59,668] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:01:00,041] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:16:00+00:00: scheduled__2020-07-20T02:16:00+00:00, externally triggered: False>
[2020-07-22 14:01:00,045] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:15:00+00:00: scheduled__2020-07-20T02:15:00+00:00, externally triggered: False>
[2020-07-22 14:01:00,059] {logging_mixin.py:112} INFO - [2020-07-22 14:01:00,059] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:15:00+00:00: scheduled__2020-07-20T02:15:00+00:00, externally triggered: False> failed
[2020-07-22 14:01:00,234] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:16:00+00:00: scheduled__2020-07-20T02:16:00+00:00, externally triggered: False>
[2020-07-22 14:01:00,252] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 08:30:03.383936+00:00: manual__2020-07-22T08:30:03.383936+00:00, externally triggered: True>
[2020-07-22 14:01:00,264] {logging_mixin.py:112} INFO - [2020-07-22 14:01:00,263] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-22 08:30:03.383936+00:00: manual__2020-07-22T08:30:03.383936+00:00, externally triggered: True> failed
[2020-07-22 14:01:00,378] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:01:00,385] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:16:00+00:00 [scheduled]> in ORM
[2020-07-22 14:01:00,526] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.979 seconds
[2020-07-22 14:01:30,135] {scheduler_job.py:153} INFO - Started process (PID=388822) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:01:30,138] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:01:30,138] {logging_mixin.py:112} INFO - [2020-07-22 14:01:30,138] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:01:30,147] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:01:30,370] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:01:30,773] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:17:00+00:00: scheduled__2020-07-20T02:17:00+00:00, externally triggered: False>
[2020-07-22 14:01:30,776] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:16:00+00:00: scheduled__2020-07-20T02:16:00+00:00, externally triggered: False>
[2020-07-22 14:01:30,785] {logging_mixin.py:112} INFO - [2020-07-22 14:01:30,785] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:16:00+00:00: scheduled__2020-07-20T02:16:00+00:00, externally triggered: False> failed
[2020-07-22 14:01:31,100] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:17:00+00:00: scheduled__2020-07-20T02:17:00+00:00, externally triggered: False>
[2020-07-22 14:01:31,126] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:01:31,131] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:17:00+00:00 [scheduled]> in ORM
[2020-07-22 14:01:31,350] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.215 seconds
[2020-07-22 14:02:00,038] {scheduler_job.py:153} INFO - Started process (PID=389579) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:02:00,042] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:02:00,043] {logging_mixin.py:112} INFO - [2020-07-22 14:02:00,042] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:02:00,052] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:02:00,195] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:02:00,602] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:18:00+00:00: scheduled__2020-07-20T02:18:00+00:00, externally triggered: False>
[2020-07-22 14:02:00,606] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:17:00+00:00: scheduled__2020-07-20T02:17:00+00:00, externally triggered: False>
[2020-07-22 14:02:00,613] {logging_mixin.py:112} INFO - [2020-07-22 14:02:00,613] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:17:00+00:00: scheduled__2020-07-20T02:17:00+00:00, externally triggered: False> failed
[2020-07-22 14:02:00,727] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:18:00+00:00: scheduled__2020-07-20T02:18:00+00:00, externally triggered: False>
[2020-07-22 14:02:00,745] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:02:00,749] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:18:00+00:00 [scheduled]> in ORM
[2020-07-22 14:02:00,907] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.870 seconds
[2020-07-22 14:02:24,139] {scheduler_job.py:153} INFO - Started process (PID=390076) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:02:24,143] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:02:24,143] {logging_mixin.py:112} INFO - [2020-07-22 14:02:24,143] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:02:24,152] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:02:24,279] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:02:24,627] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:19:00+00:00: scheduled__2020-07-20T02:19:00+00:00, externally triggered: False>
[2020-07-22 14:02:24,632] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:18:00+00:00: scheduled__2020-07-20T02:18:00+00:00, externally triggered: False>
[2020-07-22 14:02:24,648] {logging_mixin.py:112} INFO - [2020-07-22 14:02:24,648] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:18:00+00:00: scheduled__2020-07-20T02:18:00+00:00, externally triggered: False> failed
[2020-07-22 14:02:24,885] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:19:00+00:00: scheduled__2020-07-20T02:19:00+00:00, externally triggered: False>
[2020-07-22 14:02:24,903] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:02:24,908] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:19:00+00:00 [scheduled]> in ORM
[2020-07-22 14:02:25,087] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.948 seconds
[2020-07-22 14:02:54,754] {scheduler_job.py:153} INFO - Started process (PID=390777) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:02:54,757] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:02:54,758] {logging_mixin.py:112} INFO - [2020-07-22 14:02:54,758] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:02:54,766] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:02:54,932] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:02:55,235] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:20:00+00:00: scheduled__2020-07-20T02:20:00+00:00, externally triggered: False>
[2020-07-22 14:02:55,238] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:19:00+00:00: scheduled__2020-07-20T02:19:00+00:00, externally triggered: False>
[2020-07-22 14:02:55,248] {logging_mixin.py:112} INFO - [2020-07-22 14:02:55,248] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:19:00+00:00: scheduled__2020-07-20T02:19:00+00:00, externally triggered: False> failed
[2020-07-22 14:02:55,343] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:20:00+00:00: scheduled__2020-07-20T02:20:00+00:00, externally triggered: False>
[2020-07-22 14:02:55,357] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:02:55,361] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:20:00+00:00 [scheduled]> in ORM
[2020-07-22 14:02:55,535] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.781 seconds
[2020-07-22 14:03:24,074] {scheduler_job.py:153} INFO - Started process (PID=391468) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:03:24,078] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:03:24,079] {logging_mixin.py:112} INFO - [2020-07-22 14:03:24,078] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:03:24,087] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:03:24,198] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:03:24,523] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:21:00+00:00: scheduled__2020-07-20T02:21:00+00:00, externally triggered: False>
[2020-07-22 14:03:24,526] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:20:00+00:00: scheduled__2020-07-20T02:20:00+00:00, externally triggered: False>
[2020-07-22 14:03:24,534] {logging_mixin.py:112} INFO - [2020-07-22 14:03:24,534] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:20:00+00:00: scheduled__2020-07-20T02:20:00+00:00, externally triggered: False> failed
[2020-07-22 14:03:24,680] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:21:00+00:00: scheduled__2020-07-20T02:21:00+00:00, externally triggered: False>
[2020-07-22 14:03:24,701] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:03:24,706] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:21:00+00:00 [scheduled]> in ORM
[2020-07-22 14:03:24,871] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.797 seconds
[2020-07-22 14:03:48,383] {scheduler_job.py:153} INFO - Started process (PID=392024) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:03:48,388] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:03:48,388] {logging_mixin.py:112} INFO - [2020-07-22 14:03:48,388] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:03:48,401] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:03:48,528] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:03:48,957] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:22:00+00:00: scheduled__2020-07-20T02:22:00+00:00, externally triggered: False>
[2020-07-22 14:03:48,963] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:21:00+00:00: scheduled__2020-07-20T02:21:00+00:00, externally triggered: False>
[2020-07-22 14:03:48,978] {logging_mixin.py:112} INFO - [2020-07-22 14:03:48,978] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:21:00+00:00: scheduled__2020-07-20T02:21:00+00:00, externally triggered: False> failed
[2020-07-22 14:03:49,093] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:22:00+00:00: scheduled__2020-07-20T02:22:00+00:00, externally triggered: False>
[2020-07-22 14:03:49,115] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:03:49,126] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:22:00+00:00 [scheduled]> in ORM
[2020-07-22 14:03:49,285] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.902 seconds
[2020-07-22 14:04:17,607] {scheduler_job.py:153} INFO - Started process (PID=392698) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:04:17,610] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:04:17,611] {logging_mixin.py:112} INFO - [2020-07-22 14:04:17,611] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:04:17,619] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:04:17,729] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:04:18,070] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:23:00+00:00: scheduled__2020-07-20T02:23:00+00:00, externally triggered: False>
[2020-07-22 14:04:18,074] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:22:00+00:00: scheduled__2020-07-20T02:22:00+00:00, externally triggered: False>
[2020-07-22 14:04:18,083] {logging_mixin.py:112} INFO - [2020-07-22 14:04:18,082] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:22:00+00:00: scheduled__2020-07-20T02:22:00+00:00, externally triggered: False> failed
[2020-07-22 14:04:18,241] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:23:00+00:00: scheduled__2020-07-20T02:23:00+00:00, externally triggered: False>
[2020-07-22 14:04:18,264] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:04:18,269] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:23:00+00:00 [scheduled]> in ORM
[2020-07-22 14:04:18,422] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.815 seconds
[2020-07-22 14:04:47,916] {scheduler_job.py:153} INFO - Started process (PID=393394) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:04:47,920] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:04:47,920] {logging_mixin.py:112} INFO - [2020-07-22 14:04:47,920] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:04:47,929] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:04:48,067] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:04:48,453] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:24:00+00:00: scheduled__2020-07-20T02:24:00+00:00, externally triggered: False>
[2020-07-22 14:04:48,459] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:23:00+00:00: scheduled__2020-07-20T02:23:00+00:00, externally triggered: False>
[2020-07-22 14:04:48,471] {logging_mixin.py:112} INFO - [2020-07-22 14:04:48,471] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:23:00+00:00: scheduled__2020-07-20T02:23:00+00:00, externally triggered: False> failed
[2020-07-22 14:04:48,589] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:24:00+00:00: scheduled__2020-07-20T02:24:00+00:00, externally triggered: False>
[2020-07-22 14:04:48,606] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:04:48,609] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:24:00+00:00 [scheduled]> in ORM
[2020-07-22 14:04:48,747] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.831 seconds
[2020-07-22 14:05:12,156] {scheduler_job.py:153} INFO - Started process (PID=393918) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:05:12,158] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:05:12,159] {logging_mixin.py:112} INFO - [2020-07-22 14:05:12,159] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:05:12,168] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:05:12,324] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:05:12,632] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:25:00+00:00: scheduled__2020-07-20T02:25:00+00:00, externally triggered: False>
[2020-07-22 14:05:12,636] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:24:00+00:00: scheduled__2020-07-20T02:24:00+00:00, externally triggered: False>
[2020-07-22 14:05:12,643] {logging_mixin.py:112} INFO - [2020-07-22 14:05:12,643] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:24:00+00:00: scheduled__2020-07-20T02:24:00+00:00, externally triggered: False> failed
[2020-07-22 14:05:12,758] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:25:00+00:00: scheduled__2020-07-20T02:25:00+00:00, externally triggered: False>
[2020-07-22 14:05:12,776] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:05:12,781] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:25:00+00:00 [scheduled]> in ORM
[2020-07-22 14:05:12,994] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.839 seconds
[2020-07-22 14:05:41,906] {scheduler_job.py:153} INFO - Started process (PID=394610) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:05:41,911] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:05:41,911] {logging_mixin.py:112} INFO - [2020-07-22 14:05:41,911] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:05:41,919] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:05:42,070] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:05:42,515] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:26:00+00:00: scheduled__2020-07-20T02:26:00+00:00, externally triggered: False>
[2020-07-22 14:05:42,520] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:25:00+00:00: scheduled__2020-07-20T02:25:00+00:00, externally triggered: False>
[2020-07-22 14:05:42,527] {logging_mixin.py:112} INFO - [2020-07-22 14:05:42,527] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:25:00+00:00: scheduled__2020-07-20T02:25:00+00:00, externally triggered: False> failed
[2020-07-22 14:05:42,639] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:26:00+00:00: scheduled__2020-07-20T02:26:00+00:00, externally triggered: False>
[2020-07-22 14:05:42,659] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:05:42,663] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:26:00+00:00 [scheduled]> in ORM
[2020-07-22 14:05:42,808] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.902 seconds
[2020-07-22 14:06:05,930] {scheduler_job.py:153} INFO - Started process (PID=395198) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:06:05,933] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:06:05,934] {logging_mixin.py:112} INFO - [2020-07-22 14:06:05,934] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:06:05,948] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:06:06,119] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:06:06,459] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:27:00+00:00: scheduled__2020-07-20T02:27:00+00:00, externally triggered: False>
[2020-07-22 14:06:06,465] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:26:00+00:00: scheduled__2020-07-20T02:26:00+00:00, externally triggered: False>
[2020-07-22 14:06:06,477] {logging_mixin.py:112} INFO - [2020-07-22 14:06:06,477] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:26:00+00:00: scheduled__2020-07-20T02:26:00+00:00, externally triggered: False> failed
[2020-07-22 14:06:06,619] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:27:00+00:00: scheduled__2020-07-20T02:27:00+00:00, externally triggered: False>
[2020-07-22 14:06:06,639] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:06:06,645] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:27:00+00:00 [scheduled]> in ORM
[2020-07-22 14:06:06,834] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.904 seconds
[2020-07-22 14:06:30,206] {scheduler_job.py:153} INFO - Started process (PID=395722) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:06:30,211] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:06:30,211] {logging_mixin.py:112} INFO - [2020-07-22 14:06:30,211] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:06:30,220] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:06:30,353] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:06:30,663] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:28:00+00:00: scheduled__2020-07-20T02:28:00+00:00, externally triggered: False>
[2020-07-22 14:06:30,666] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:27:00+00:00: scheduled__2020-07-20T02:27:00+00:00, externally triggered: False>
[2020-07-22 14:06:30,673] {logging_mixin.py:112} INFO - [2020-07-22 14:06:30,673] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:27:00+00:00: scheduled__2020-07-20T02:27:00+00:00, externally triggered: False> failed
[2020-07-22 14:06:30,777] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:28:00+00:00: scheduled__2020-07-20T02:28:00+00:00, externally triggered: False>
[2020-07-22 14:06:30,794] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:06:30,797] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:28:00+00:00 [scheduled]> in ORM
[2020-07-22 14:06:30,935] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.729 seconds
[2020-07-22 14:06:59,744] {scheduler_job.py:153} INFO - Started process (PID=396412) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:06:59,751] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:06:59,752] {logging_mixin.py:112} INFO - [2020-07-22 14:06:59,752] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:06:59,763] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:06:59,904] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:07:00,225] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:29:00+00:00: scheduled__2020-07-20T02:29:00+00:00, externally triggered: False>
[2020-07-22 14:07:00,230] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:28:00+00:00: scheduled__2020-07-20T02:28:00+00:00, externally triggered: False>
[2020-07-22 14:07:00,243] {logging_mixin.py:112} INFO - [2020-07-22 14:07:00,243] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:28:00+00:00: scheduled__2020-07-20T02:28:00+00:00, externally triggered: False> failed
[2020-07-22 14:07:00,335] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:29:00+00:00: scheduled__2020-07-20T02:29:00+00:00, externally triggered: False>
[2020-07-22 14:07:00,353] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:07:00,357] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:29:00+00:00 [scheduled]> in ORM
[2020-07-22 14:07:00,494] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.750 seconds
[2020-07-22 14:07:23,548] {scheduler_job.py:153} INFO - Started process (PID=396957) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:07:23,552] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:07:23,552] {logging_mixin.py:112} INFO - [2020-07-22 14:07:23,552] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:07:23,565] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:07:23,794] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:07:24,188] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:30:00+00:00: scheduled__2020-07-20T02:30:00+00:00, externally triggered: False>
[2020-07-22 14:07:24,194] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:29:00+00:00: scheduled__2020-07-20T02:29:00+00:00, externally triggered: False>
[2020-07-22 14:07:24,215] {logging_mixin.py:112} INFO - [2020-07-22 14:07:24,215] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:29:00+00:00: scheduled__2020-07-20T02:29:00+00:00, externally triggered: False> failed
[2020-07-22 14:07:24,326] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:30:00+00:00: scheduled__2020-07-20T02:30:00+00:00, externally triggered: False>
[2020-07-22 14:07:24,345] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:07:24,351] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:30:00+00:00 [scheduled]> in ORM
[2020-07-22 14:07:24,516] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.969 seconds
[2020-07-22 14:07:48,740] {scheduler_job.py:153} INFO - Started process (PID=397562) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:07:48,745] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:07:48,746] {logging_mixin.py:112} INFO - [2020-07-22 14:07:48,746] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:07:48,758] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:07:48,916] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:07:49,214] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:31:00+00:00: scheduled__2020-07-20T02:31:00+00:00, externally triggered: False>
[2020-07-22 14:07:49,218] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:30:00+00:00: scheduled__2020-07-20T02:30:00+00:00, externally triggered: False>
[2020-07-22 14:07:49,226] {logging_mixin.py:112} INFO - [2020-07-22 14:07:49,226] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:30:00+00:00: scheduled__2020-07-20T02:30:00+00:00, externally triggered: False> failed
[2020-07-22 14:07:49,362] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:31:00+00:00: scheduled__2020-07-20T02:31:00+00:00, externally triggered: False>
[2020-07-22 14:07:49,381] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:07:49,384] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:31:00+00:00 [scheduled]> in ORM
[2020-07-22 14:07:49,546] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.806 seconds
[2020-07-22 14:08:12,672] {scheduler_job.py:153} INFO - Started process (PID=398169) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:08:12,685] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:08:12,686] {logging_mixin.py:112} INFO - [2020-07-22 14:08:12,686] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:08:12,700] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:08:12,848] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:08:13,235] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:32:00+00:00: scheduled__2020-07-20T02:32:00+00:00, externally triggered: False>
[2020-07-22 14:08:13,238] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:31:00+00:00: scheduled__2020-07-20T02:31:00+00:00, externally triggered: False>
[2020-07-22 14:08:13,246] {logging_mixin.py:112} INFO - [2020-07-22 14:08:13,246] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:31:00+00:00: scheduled__2020-07-20T02:31:00+00:00, externally triggered: False> failed
[2020-07-22 14:08:13,364] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:32:00+00:00: scheduled__2020-07-20T02:32:00+00:00, externally triggered: False>
[2020-07-22 14:08:13,377] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:08:13,381] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:32:00+00:00 [scheduled]> in ORM
[2020-07-22 14:08:13,520] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.847 seconds
[2020-07-22 14:08:36,662] {scheduler_job.py:153} INFO - Started process (PID=398661) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:08:36,665] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:08:36,666] {logging_mixin.py:112} INFO - [2020-07-22 14:08:36,666] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:08:36,675] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:08:36,844] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:08:37,176] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:33:00+00:00: scheduled__2020-07-20T02:33:00+00:00, externally triggered: False>
[2020-07-22 14:08:37,181] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:32:00+00:00: scheduled__2020-07-20T02:32:00+00:00, externally triggered: False>
[2020-07-22 14:08:37,188] {logging_mixin.py:112} INFO - [2020-07-22 14:08:37,187] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:32:00+00:00: scheduled__2020-07-20T02:32:00+00:00, externally triggered: False> failed
[2020-07-22 14:08:37,373] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:33:00+00:00: scheduled__2020-07-20T02:33:00+00:00, externally triggered: False>
[2020-07-22 14:08:37,394] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:08:37,402] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:33:00+00:00 [scheduled]> in ORM
[2020-07-22 14:08:37,558] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.897 seconds
[2020-07-22 14:09:06,665] {scheduler_job.py:153} INFO - Started process (PID=399351) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:09:06,668] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:09:06,669] {logging_mixin.py:112} INFO - [2020-07-22 14:09:06,669] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:09:06,678] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:09:06,870] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:09:07,277] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:34:00+00:00: scheduled__2020-07-20T02:34:00+00:00, externally triggered: False>
[2020-07-22 14:09:07,281] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:33:00+00:00: scheduled__2020-07-20T02:33:00+00:00, externally triggered: False>
[2020-07-22 14:09:07,290] {logging_mixin.py:112} INFO - [2020-07-22 14:09:07,290] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:33:00+00:00: scheduled__2020-07-20T02:33:00+00:00, externally triggered: False> failed
[2020-07-22 14:09:07,392] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:34:00+00:00: scheduled__2020-07-20T02:34:00+00:00, externally triggered: False>
[2020-07-22 14:09:07,411] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:09:07,415] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:34:00+00:00 [scheduled]> in ORM
[2020-07-22 14:09:07,561] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.897 seconds
[2020-07-22 14:09:32,182] {scheduler_job.py:153} INFO - Started process (PID=399981) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:09:32,187] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:09:32,188] {logging_mixin.py:112} INFO - [2020-07-22 14:09:32,187] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:09:32,206] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:09:32,407] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:09:32,695] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:35:00+00:00: scheduled__2020-07-20T02:35:00+00:00, externally triggered: False>
[2020-07-22 14:09:32,698] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:34:00+00:00: scheduled__2020-07-20T02:34:00+00:00, externally triggered: False>
[2020-07-22 14:09:32,708] {logging_mixin.py:112} INFO - [2020-07-22 14:09:32,708] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:34:00+00:00: scheduled__2020-07-20T02:34:00+00:00, externally triggered: False> failed
[2020-07-22 14:09:32,794] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:35:00+00:00: scheduled__2020-07-20T02:35:00+00:00, externally triggered: False>
[2020-07-22 14:09:32,813] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:09:32,817] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:35:00+00:00 [scheduled]> in ORM
[2020-07-22 14:09:32,941] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.759 seconds
[2020-07-22 14:09:56,720] {scheduler_job.py:153} INFO - Started process (PID=400515) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:09:56,723] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:09:56,723] {logging_mixin.py:112} INFO - [2020-07-22 14:09:56,723] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:09:56,736] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:09:56,851] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:09:57,261] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:36:00+00:00: scheduled__2020-07-20T02:36:00+00:00, externally triggered: False>
[2020-07-22 14:09:57,265] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:35:00+00:00: scheduled__2020-07-20T02:35:00+00:00, externally triggered: False>
[2020-07-22 14:09:57,272] {logging_mixin.py:112} INFO - [2020-07-22 14:09:57,272] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:35:00+00:00: scheduled__2020-07-20T02:35:00+00:00, externally triggered: False> failed
[2020-07-22 14:09:57,363] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:36:00+00:00: scheduled__2020-07-20T02:36:00+00:00, externally triggered: False>
[2020-07-22 14:09:57,384] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:09:57,387] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:36:00+00:00 [scheduled]> in ORM
[2020-07-22 14:09:57,510] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.790 seconds
[2020-07-22 14:10:25,880] {scheduler_job.py:153} INFO - Started process (PID=401186) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:10:25,883] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:10:25,883] {logging_mixin.py:112} INFO - [2020-07-22 14:10:25,883] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:10:25,893] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:10:26,020] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:10:26,408] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:37:00+00:00: scheduled__2020-07-20T02:37:00+00:00, externally triggered: False>
[2020-07-22 14:10:26,412] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:36:00+00:00: scheduled__2020-07-20T02:36:00+00:00, externally triggered: False>
[2020-07-22 14:10:26,419] {logging_mixin.py:112} INFO - [2020-07-22 14:10:26,419] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:36:00+00:00: scheduled__2020-07-20T02:36:00+00:00, externally triggered: False> failed
[2020-07-22 14:10:26,532] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:37:00+00:00: scheduled__2020-07-20T02:37:00+00:00, externally triggered: False>
[2020-07-22 14:10:26,552] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:10:26,555] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:37:00+00:00 [scheduled]> in ORM
[2020-07-22 14:10:26,702] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.822 seconds
[2020-07-22 14:10:50,337] {scheduler_job.py:153} INFO - Started process (PID=401758) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:10:50,340] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:10:50,341] {logging_mixin.py:112} INFO - [2020-07-22 14:10:50,340] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:10:50,350] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:10:50,506] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:10:50,862] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:38:00+00:00: scheduled__2020-07-20T02:38:00+00:00, externally triggered: False>
[2020-07-22 14:10:50,867] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:37:00+00:00: scheduled__2020-07-20T02:37:00+00:00, externally triggered: False>
[2020-07-22 14:10:50,879] {logging_mixin.py:112} INFO - [2020-07-22 14:10:50,879] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:37:00+00:00: scheduled__2020-07-20T02:37:00+00:00, externally triggered: False> failed
[2020-07-22 14:10:50,989] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:38:00+00:00: scheduled__2020-07-20T02:38:00+00:00, externally triggered: False>
[2020-07-22 14:10:51,008] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:10:51,014] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:38:00+00:00 [scheduled]> in ORM
[2020-07-22 14:10:51,147] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.809 seconds
[2020-07-22 14:11:14,811] {scheduler_job.py:153} INFO - Started process (PID=402344) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:11:14,814] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:11:14,814] {logging_mixin.py:112} INFO - [2020-07-22 14:11:14,814] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:11:14,824] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:11:15,460] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:11:16,102] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:39:00+00:00: scheduled__2020-07-20T02:39:00+00:00, externally triggered: False>
[2020-07-22 14:11:16,107] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:38:00+00:00: scheduled__2020-07-20T02:38:00+00:00, externally triggered: False>
[2020-07-22 14:11:16,116] {logging_mixin.py:112} INFO - [2020-07-22 14:11:16,116] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:38:00+00:00: scheduled__2020-07-20T02:38:00+00:00, externally triggered: False> failed
[2020-07-22 14:11:16,425] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:39:00+00:00: scheduled__2020-07-20T02:39:00+00:00, externally triggered: False>
[2020-07-22 14:11:16,445] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:11:16,449] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:39:00+00:00 [scheduled]> in ORM
[2020-07-22 14:11:16,621] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.810 seconds
[2020-07-22 14:11:39,248] {scheduler_job.py:153} INFO - Started process (PID=402958) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:11:39,251] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:11:39,251] {logging_mixin.py:112} INFO - [2020-07-22 14:11:39,251] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:11:39,262] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:11:40,116] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:11:40,486] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:40:00+00:00: scheduled__2020-07-20T02:40:00+00:00, externally triggered: False>
[2020-07-22 14:11:40,490] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:39:00+00:00: scheduled__2020-07-20T02:39:00+00:00, externally triggered: False>
[2020-07-22 14:11:40,501] {logging_mixin.py:112} INFO - [2020-07-22 14:11:40,501] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:39:00+00:00: scheduled__2020-07-20T02:39:00+00:00, externally triggered: False> failed
[2020-07-22 14:11:40,630] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:40:00+00:00: scheduled__2020-07-20T02:40:00+00:00, externally triggered: False>
[2020-07-22 14:11:40,649] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:11:40,653] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:40:00+00:00 [scheduled]> in ORM
[2020-07-22 14:11:40,797] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.549 seconds
[2020-07-22 14:12:03,232] {scheduler_job.py:153} INFO - Started process (PID=403474) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:12:03,235] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:12:03,235] {logging_mixin.py:112} INFO - [2020-07-22 14:12:03,235] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:12:03,244] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:12:03,345] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:12:03,720] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:41:00+00:00: scheduled__2020-07-20T02:41:00+00:00, externally triggered: False>
[2020-07-22 14:12:03,724] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:40:00+00:00: scheduled__2020-07-20T02:40:00+00:00, externally triggered: False>
[2020-07-22 14:12:03,731] {logging_mixin.py:112} INFO - [2020-07-22 14:12:03,731] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:40:00+00:00: scheduled__2020-07-20T02:40:00+00:00, externally triggered: False> failed
[2020-07-22 14:12:03,859] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:41:00+00:00: scheduled__2020-07-20T02:41:00+00:00, externally triggered: False>
[2020-07-22 14:12:03,902] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:12:03,909] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:41:00+00:00 [scheduled]> in ORM
[2020-07-22 14:12:04,092] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.860 seconds
[2020-07-22 14:12:33,119] {scheduler_job.py:153} INFO - Started process (PID=404155) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:12:33,121] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:12:33,122] {logging_mixin.py:112} INFO - [2020-07-22 14:12:33,122] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:12:33,130] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:12:33,318] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:12:33,679] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:42:00+00:00: scheduled__2020-07-20T02:42:00+00:00, externally triggered: False>
[2020-07-22 14:12:33,684] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:41:00+00:00: scheduled__2020-07-20T02:41:00+00:00, externally triggered: False>
[2020-07-22 14:12:33,691] {logging_mixin.py:112} INFO - [2020-07-22 14:12:33,691] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:41:00+00:00: scheduled__2020-07-20T02:41:00+00:00, externally triggered: False> failed
[2020-07-22 14:12:33,838] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:42:00+00:00: scheduled__2020-07-20T02:42:00+00:00, externally triggered: False>
[2020-07-22 14:12:33,856] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:12:33,861] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:42:00+00:00 [scheduled]> in ORM
[2020-07-22 14:12:34,055] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.936 seconds
[2020-07-22 14:12:57,321] {scheduler_job.py:153} INFO - Started process (PID=404778) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:12:57,327] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:12:57,327] {logging_mixin.py:112} INFO - [2020-07-22 14:12:57,327] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:12:57,335] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:12:57,500] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:12:57,820] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:43:00+00:00: scheduled__2020-07-20T02:43:00+00:00, externally triggered: False>
[2020-07-22 14:12:57,823] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:42:00+00:00: scheduled__2020-07-20T02:42:00+00:00, externally triggered: False>
[2020-07-22 14:12:57,830] {logging_mixin.py:112} INFO - [2020-07-22 14:12:57,830] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:42:00+00:00: scheduled__2020-07-20T02:42:00+00:00, externally triggered: False> failed
[2020-07-22 14:12:58,039] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:43:00+00:00: scheduled__2020-07-20T02:43:00+00:00, externally triggered: False>
[2020-07-22 14:12:58,057] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:12:58,061] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:43:00+00:00 [scheduled]> in ORM
[2020-07-22 14:12:58,208] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.886 seconds
[2020-07-22 14:13:21,390] {scheduler_job.py:153} INFO - Started process (PID=405299) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:13:21,396] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:13:21,397] {logging_mixin.py:112} INFO - [2020-07-22 14:13:21,396] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:13:21,411] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:13:21,613] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:13:21,935] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:44:00+00:00: scheduled__2020-07-20T02:44:00+00:00, externally triggered: False>
[2020-07-22 14:13:21,938] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:43:00+00:00: scheduled__2020-07-20T02:43:00+00:00, externally triggered: False>
[2020-07-22 14:13:21,946] {logging_mixin.py:112} INFO - [2020-07-22 14:13:21,946] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:43:00+00:00: scheduled__2020-07-20T02:43:00+00:00, externally triggered: False> failed
[2020-07-22 14:13:22,060] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:44:00+00:00: scheduled__2020-07-20T02:44:00+00:00, externally triggered: False>
[2020-07-22 14:13:22,079] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:13:22,083] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:44:00+00:00 [scheduled]> in ORM
[2020-07-22 14:13:22,229] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.839 seconds
[2020-07-22 14:13:50,722] {scheduler_job.py:153} INFO - Started process (PID=406020) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:13:50,726] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:13:50,726] {logging_mixin.py:112} INFO - [2020-07-22 14:13:50,726] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:13:50,736] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:13:50,894] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:13:51,406] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:45:00+00:00: scheduled__2020-07-20T02:45:00+00:00, externally triggered: False>
[2020-07-22 14:13:51,410] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:44:00+00:00: scheduled__2020-07-20T02:44:00+00:00, externally triggered: False>
[2020-07-22 14:13:51,417] {logging_mixin.py:112} INFO - [2020-07-22 14:13:51,417] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:44:00+00:00: scheduled__2020-07-20T02:44:00+00:00, externally triggered: False> failed
[2020-07-22 14:13:51,530] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:45:00+00:00: scheduled__2020-07-20T02:45:00+00:00, externally triggered: False>
[2020-07-22 14:13:51,546] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:13:51,550] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:45:00+00:00 [scheduled]> in ORM
[2020-07-22 14:13:51,743] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.021 seconds
[2020-07-22 14:14:14,629] {scheduler_job.py:153} INFO - Started process (PID=406564) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:14:14,633] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:14:14,634] {logging_mixin.py:112} INFO - [2020-07-22 14:14:14,634] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:14:14,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:14:14,822] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:14:15,195] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:46:00+00:00: scheduled__2020-07-20T02:46:00+00:00, externally triggered: False>
[2020-07-22 14:14:15,202] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:45:00+00:00: scheduled__2020-07-20T02:45:00+00:00, externally triggered: False>
[2020-07-22 14:14:15,219] {logging_mixin.py:112} INFO - [2020-07-22 14:14:15,219] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:45:00+00:00: scheduled__2020-07-20T02:45:00+00:00, externally triggered: False> failed
[2020-07-22 14:14:15,399] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:46:00+00:00: scheduled__2020-07-20T02:46:00+00:00, externally triggered: False>
[2020-07-22 14:14:15,418] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:14:15,426] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:46:00+00:00 [scheduled]> in ORM
[2020-07-22 14:14:15,591] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.962 seconds
[2020-07-22 14:14:38,882] {scheduler_job.py:153} INFO - Started process (PID=407301) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:14:38,886] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:14:38,886] {logging_mixin.py:112} INFO - [2020-07-22 14:14:38,886] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:14:38,894] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:14:39,031] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:14:39,388] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:47:00+00:00: scheduled__2020-07-20T02:47:00+00:00, externally triggered: False>
[2020-07-22 14:14:39,394] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:46:00+00:00: scheduled__2020-07-20T02:46:00+00:00, externally triggered: False>
[2020-07-22 14:14:39,401] {logging_mixin.py:112} INFO - [2020-07-22 14:14:39,401] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:46:00+00:00: scheduled__2020-07-20T02:46:00+00:00, externally triggered: False> failed
[2020-07-22 14:14:39,511] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:47:00+00:00: scheduled__2020-07-20T02:47:00+00:00, externally triggered: False>
[2020-07-22 14:14:39,533] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:14:39,541] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:47:00+00:00 [scheduled]> in ORM
[2020-07-22 14:14:39,792] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.910 seconds
[2020-07-22 14:15:07,863] {scheduler_job.py:153} INFO - Started process (PID=407991) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:15:07,866] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:15:07,866] {logging_mixin.py:112} INFO - [2020-07-22 14:15:07,866] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:15:07,874] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:15:08,022] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:15:08,412] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:48:00+00:00: scheduled__2020-07-20T02:48:00+00:00, externally triggered: False>
[2020-07-22 14:15:08,415] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:47:00+00:00: scheduled__2020-07-20T02:47:00+00:00, externally triggered: False>
[2020-07-22 14:15:08,423] {logging_mixin.py:112} INFO - [2020-07-22 14:15:08,423] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:47:00+00:00: scheduled__2020-07-20T02:47:00+00:00, externally triggered: False> failed
[2020-07-22 14:15:08,513] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:48:00+00:00: scheduled__2020-07-20T02:48:00+00:00, externally triggered: False>
[2020-07-22 14:15:08,533] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:15:08,537] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:48:00+00:00 [scheduled]> in ORM
[2020-07-22 14:15:08,685] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.822 seconds
[2020-07-22 14:15:32,566] {scheduler_job.py:153} INFO - Started process (PID=408561) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:15:32,573] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:15:32,573] {logging_mixin.py:112} INFO - [2020-07-22 14:15:32,573] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:15:32,587] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:15:32,746] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:15:33,122] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:49:00+00:00: scheduled__2020-07-20T02:49:00+00:00, externally triggered: False>
[2020-07-22 14:15:33,125] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:48:00+00:00: scheduled__2020-07-20T02:48:00+00:00, externally triggered: False>
[2020-07-22 14:15:33,134] {logging_mixin.py:112} INFO - [2020-07-22 14:15:33,134] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:48:00+00:00: scheduled__2020-07-20T02:48:00+00:00, externally triggered: False> failed
[2020-07-22 14:15:33,370] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:49:00+00:00: scheduled__2020-07-20T02:49:00+00:00, externally triggered: False>
[2020-07-22 14:15:33,387] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:15:33,392] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:49:00+00:00 [scheduled]> in ORM
[2020-07-22 14:15:33,652] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.086 seconds
[2020-07-22 14:15:57,291] {scheduler_job.py:153} INFO - Started process (PID=409151) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:15:57,294] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:15:57,294] {logging_mixin.py:112} INFO - [2020-07-22 14:15:57,294] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:15:57,302] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:15:57,448] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:15:57,828] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:50:00+00:00: scheduled__2020-07-20T02:50:00+00:00, externally triggered: False>
[2020-07-22 14:15:57,831] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:49:00+00:00: scheduled__2020-07-20T02:49:00+00:00, externally triggered: False>
[2020-07-22 14:15:57,839] {logging_mixin.py:112} INFO - [2020-07-22 14:15:57,839] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:49:00+00:00: scheduled__2020-07-20T02:49:00+00:00, externally triggered: False> failed
[2020-07-22 14:15:57,939] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:50:00+00:00: scheduled__2020-07-20T02:50:00+00:00, externally triggered: False>
[2020-07-22 14:15:57,952] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:15:57,956] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:50:00+00:00 [scheduled]> in ORM
[2020-07-22 14:15:58,109] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.818 seconds
[2020-07-22 14:16:21,482] {scheduler_job.py:153} INFO - Started process (PID=409742) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:16:21,485] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:16:21,486] {logging_mixin.py:112} INFO - [2020-07-22 14:16:21,485] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:16:21,494] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:16:21,628] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:16:22,007] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:51:00+00:00: scheduled__2020-07-20T02:51:00+00:00, externally triggered: False>
[2020-07-22 14:16:22,010] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:50:00+00:00: scheduled__2020-07-20T02:50:00+00:00, externally triggered: False>
[2020-07-22 14:16:22,017] {logging_mixin.py:112} INFO - [2020-07-22 14:16:22,017] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:50:00+00:00: scheduled__2020-07-20T02:50:00+00:00, externally triggered: False> failed
[2020-07-22 14:16:22,130] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:51:00+00:00: scheduled__2020-07-20T02:51:00+00:00, externally triggered: False>
[2020-07-22 14:16:22,150] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:16:22,154] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:51:00+00:00 [scheduled]> in ORM
[2020-07-22 14:16:22,312] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.830 seconds
[2020-07-22 14:16:46,374] {scheduler_job.py:153} INFO - Started process (PID=410266) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:16:46,379] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:16:46,379] {logging_mixin.py:112} INFO - [2020-07-22 14:16:46,379] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:16:46,388] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:16:46,556] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:16:46,971] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:52:00+00:00: scheduled__2020-07-20T02:52:00+00:00, externally triggered: False>
[2020-07-22 14:16:46,976] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:51:00+00:00: scheduled__2020-07-20T02:51:00+00:00, externally triggered: False>
[2020-07-22 14:16:46,989] {logging_mixin.py:112} INFO - [2020-07-22 14:16:46,989] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:51:00+00:00: scheduled__2020-07-20T02:51:00+00:00, externally triggered: False> failed
[2020-07-22 14:16:47,143] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:52:00+00:00: scheduled__2020-07-20T02:52:00+00:00, externally triggered: False>
[2020-07-22 14:16:47,158] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:16:47,162] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:52:00+00:00 [scheduled]> in ORM
[2020-07-22 14:16:47,392] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.018 seconds
[2020-07-22 14:17:16,432] {scheduler_job.py:153} INFO - Started process (PID=410967) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:17:16,435] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:17:16,436] {logging_mixin.py:112} INFO - [2020-07-22 14:17:16,435] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:17:16,445] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:17:16,564] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:17:16,902] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:53:00+00:00: scheduled__2020-07-20T02:53:00+00:00, externally triggered: False>
[2020-07-22 14:17:16,905] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:52:00+00:00: scheduled__2020-07-20T02:52:00+00:00, externally triggered: False>
[2020-07-22 14:17:16,912] {logging_mixin.py:112} INFO - [2020-07-22 14:17:16,912] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:52:00+00:00: scheduled__2020-07-20T02:52:00+00:00, externally triggered: False> failed
[2020-07-22 14:17:17,079] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:53:00+00:00: scheduled__2020-07-20T02:53:00+00:00, externally triggered: False>
[2020-07-22 14:17:17,097] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:17:17,101] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:53:00+00:00 [scheduled]> in ORM
[2020-07-22 14:17:17,284] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.852 seconds
[2020-07-22 14:17:41,043] {scheduler_job.py:153} INFO - Started process (PID=411588) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:17:41,047] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:17:41,047] {logging_mixin.py:112} INFO - [2020-07-22 14:17:41,047] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:17:41,057] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:17:41,188] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:17:41,537] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:54:00+00:00: scheduled__2020-07-20T02:54:00+00:00, externally triggered: False>
[2020-07-22 14:17:41,541] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:53:00+00:00: scheduled__2020-07-20T02:53:00+00:00, externally triggered: False>
[2020-07-22 14:17:41,548] {logging_mixin.py:112} INFO - [2020-07-22 14:17:41,548] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:53:00+00:00: scheduled__2020-07-20T02:53:00+00:00, externally triggered: False> failed
[2020-07-22 14:17:41,647] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:54:00+00:00: scheduled__2020-07-20T02:54:00+00:00, externally triggered: False>
[2020-07-22 14:17:41,666] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:17:41,669] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:54:00+00:00 [scheduled]> in ORM
[2020-07-22 14:17:41,852] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.810 seconds
[2020-07-22 14:18:05,700] {scheduler_job.py:153} INFO - Started process (PID=412107) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:18:05,703] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:18:05,704] {logging_mixin.py:112} INFO - [2020-07-22 14:18:05,703] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:18:05,713] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:18:05,856] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:18:06,359] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:55:00+00:00: scheduled__2020-07-20T02:55:00+00:00, externally triggered: False>
[2020-07-22 14:18:06,364] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:54:00+00:00: scheduled__2020-07-20T02:54:00+00:00, externally triggered: False>
[2020-07-22 14:18:06,377] {logging_mixin.py:112} INFO - [2020-07-22 14:18:06,377] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:54:00+00:00: scheduled__2020-07-20T02:54:00+00:00, externally triggered: False> failed
[2020-07-22 14:18:06,493] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:55:00+00:00: scheduled__2020-07-20T02:55:00+00:00, externally triggered: False>
[2020-07-22 14:18:06,512] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:18:06,516] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:55:00+00:00 [scheduled]> in ORM
[2020-07-22 14:18:06,715] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.015 seconds
[2020-07-22 14:18:34,935] {scheduler_job.py:153} INFO - Started process (PID=412786) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:18:34,938] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:18:34,938] {logging_mixin.py:112} INFO - [2020-07-22 14:18:34,938] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:18:34,948] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:18:35,116] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:18:35,468] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:56:00+00:00: scheduled__2020-07-20T02:56:00+00:00, externally triggered: False>
[2020-07-22 14:18:35,472] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:55:00+00:00: scheduled__2020-07-20T02:55:00+00:00, externally triggered: False>
[2020-07-22 14:18:35,480] {logging_mixin.py:112} INFO - [2020-07-22 14:18:35,480] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:55:00+00:00: scheduled__2020-07-20T02:55:00+00:00, externally triggered: False> failed
[2020-07-22 14:18:35,596] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:56:00+00:00: scheduled__2020-07-20T02:56:00+00:00, externally triggered: False>
[2020-07-22 14:18:35,615] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:18:35,619] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:56:00+00:00 [scheduled]> in ORM
[2020-07-22 14:18:35,811] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.876 seconds
[2020-07-22 14:18:59,205] {scheduler_job.py:153} INFO - Started process (PID=413350) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:18:59,210] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:18:59,211] {logging_mixin.py:112} INFO - [2020-07-22 14:18:59,210] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:18:59,224] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:18:59,859] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:19:00,339] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:57:00+00:00: scheduled__2020-07-20T02:57:00+00:00, externally triggered: False>
[2020-07-22 14:19:00,344] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:56:00+00:00: scheduled__2020-07-20T02:56:00+00:00, externally triggered: False>
[2020-07-22 14:19:00,356] {logging_mixin.py:112} INFO - [2020-07-22 14:19:00,356] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:56:00+00:00: scheduled__2020-07-20T02:56:00+00:00, externally triggered: False> failed
[2020-07-22 14:19:00,512] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:57:00+00:00: scheduled__2020-07-20T02:57:00+00:00, externally triggered: False>
[2020-07-22 14:19:00,531] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:19:00,537] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:57:00+00:00 [scheduled]> in ORM
[2020-07-22 14:19:00,702] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.497 seconds
[2020-07-22 14:19:23,317] {scheduler_job.py:153} INFO - Started process (PID=413900) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:19:23,320] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:19:23,321] {logging_mixin.py:112} INFO - [2020-07-22 14:19:23,320] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:19:23,329] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:19:23,461] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:19:23,880] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:58:00+00:00: scheduled__2020-07-20T02:58:00+00:00, externally triggered: False>
[2020-07-22 14:19:23,885] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:57:00+00:00: scheduled__2020-07-20T02:57:00+00:00, externally triggered: False>
[2020-07-22 14:19:23,893] {logging_mixin.py:112} INFO - [2020-07-22 14:19:23,892] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:57:00+00:00: scheduled__2020-07-20T02:57:00+00:00, externally triggered: False> failed
[2020-07-22 14:19:23,999] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:58:00+00:00: scheduled__2020-07-20T02:58:00+00:00, externally triggered: False>
[2020-07-22 14:19:24,017] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:19:24,021] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:58:00+00:00 [scheduled]> in ORM
[2020-07-22 14:19:24,169] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.852 seconds
[2020-07-22 14:19:47,594] {scheduler_job.py:153} INFO - Started process (PID=414520) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:19:47,598] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:19:47,598] {logging_mixin.py:112} INFO - [2020-07-22 14:19:47,598] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:19:47,607] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:19:47,720] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:19:48,099] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T02:59:00+00:00: scheduled__2020-07-20T02:59:00+00:00, externally triggered: False>
[2020-07-22 14:19:48,102] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:58:00+00:00: scheduled__2020-07-20T02:58:00+00:00, externally triggered: False>
[2020-07-22 14:19:48,110] {logging_mixin.py:112} INFO - [2020-07-22 14:19:48,109] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:58:00+00:00: scheduled__2020-07-20T02:58:00+00:00, externally triggered: False> failed
[2020-07-22 14:19:48,223] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:59:00+00:00: scheduled__2020-07-20T02:59:00+00:00, externally triggered: False>
[2020-07-22 14:19:48,238] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:19:48,244] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 02:59:00+00:00 [scheduled]> in ORM
[2020-07-22 14:19:48,404] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.810 seconds
[2020-07-22 14:20:13,360] {scheduler_job.py:153} INFO - Started process (PID=415061) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:20:13,364] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:20:13,364] {logging_mixin.py:112} INFO - [2020-07-22 14:20:13,364] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:20:13,375] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:20:13,533] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:20:13,903] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:00:00+00:00: scheduled__2020-07-20T03:00:00+00:00, externally triggered: False>
[2020-07-22 14:20:13,906] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 02:59:00+00:00: scheduled__2020-07-20T02:59:00+00:00, externally triggered: False>
[2020-07-22 14:20:13,914] {logging_mixin.py:112} INFO - [2020-07-22 14:20:13,914] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 02:59:00+00:00: scheduled__2020-07-20T02:59:00+00:00, externally triggered: False> failed
[2020-07-22 14:20:14,047] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:00:00+00:00: scheduled__2020-07-20T03:00:00+00:00, externally triggered: False>
[2020-07-22 14:20:14,064] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:20:14,071] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:00:00+00:00 [scheduled]> in ORM
[2020-07-22 14:20:14,261] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.901 seconds
[2020-07-22 14:20:43,514] {scheduler_job.py:153} INFO - Started process (PID=415747) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:20:43,519] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:20:43,519] {logging_mixin.py:112} INFO - [2020-07-22 14:20:43,519] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:20:43,528] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:20:43,701] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:20:44,085] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:01:00+00:00: scheduled__2020-07-20T03:01:00+00:00, externally triggered: False>
[2020-07-22 14:20:44,091] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:00:00+00:00: scheduled__2020-07-20T03:00:00+00:00, externally triggered: False>
[2020-07-22 14:20:44,098] {logging_mixin.py:112} INFO - [2020-07-22 14:20:44,098] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:00:00+00:00: scheduled__2020-07-20T03:00:00+00:00, externally triggered: False> failed
[2020-07-22 14:20:44,205] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:01:00+00:00: scheduled__2020-07-20T03:01:00+00:00, externally triggered: False>
[2020-07-22 14:20:44,223] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:20:44,226] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:01:00+00:00 [scheduled]> in ORM
[2020-07-22 14:20:44,415] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.902 seconds
[2020-07-22 14:21:07,800] {scheduler_job.py:153} INFO - Started process (PID=416368) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:21:07,803] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:21:07,804] {logging_mixin.py:112} INFO - [2020-07-22 14:21:07,803] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:21:07,813] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:21:07,960] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:21:08,350] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:02:00+00:00: scheduled__2020-07-20T03:02:00+00:00, externally triggered: False>
[2020-07-22 14:21:08,355] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:01:00+00:00: scheduled__2020-07-20T03:01:00+00:00, externally triggered: False>
[2020-07-22 14:21:08,367] {logging_mixin.py:112} INFO - [2020-07-22 14:21:08,367] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:01:00+00:00: scheduled__2020-07-20T03:01:00+00:00, externally triggered: False> failed
[2020-07-22 14:21:08,484] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:02:00+00:00: scheduled__2020-07-20T03:02:00+00:00, externally triggered: False>
[2020-07-22 14:21:08,499] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:21:08,503] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:02:00+00:00 [scheduled]> in ORM
[2020-07-22 14:21:08,644] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.844 seconds
[2020-07-22 14:21:31,740] {scheduler_job.py:153} INFO - Started process (PID=416860) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:21:31,744] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:21:31,744] {logging_mixin.py:112} INFO - [2020-07-22 14:21:31,744] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:21:31,753] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:21:31,911] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:21:32,353] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:03:00+00:00: scheduled__2020-07-20T03:03:00+00:00, externally triggered: False>
[2020-07-22 14:21:32,359] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:02:00+00:00: scheduled__2020-07-20T03:02:00+00:00, externally triggered: False>
[2020-07-22 14:21:32,366] {logging_mixin.py:112} INFO - [2020-07-22 14:21:32,366] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:02:00+00:00: scheduled__2020-07-20T03:02:00+00:00, externally triggered: False> failed
[2020-07-22 14:21:32,545] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:03:00+00:00: scheduled__2020-07-20T03:03:00+00:00, externally triggered: False>
[2020-07-22 14:21:32,564] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:21:32,568] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:03:00+00:00 [scheduled]> in ORM
[2020-07-22 14:21:32,724] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.984 seconds
[2020-07-22 14:22:01,783] {scheduler_job.py:153} INFO - Started process (PID=417554) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:22:01,787] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:22:01,788] {logging_mixin.py:112} INFO - [2020-07-22 14:22:01,788] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:22:01,796] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:22:01,921] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:22:02,331] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:04:00+00:00: scheduled__2020-07-20T03:04:00+00:00, externally triggered: False>
[2020-07-22 14:22:02,335] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:03:00+00:00: scheduled__2020-07-20T03:03:00+00:00, externally triggered: False>
[2020-07-22 14:22:02,343] {logging_mixin.py:112} INFO - [2020-07-22 14:22:02,343] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:03:00+00:00: scheduled__2020-07-20T03:03:00+00:00, externally triggered: False> failed
[2020-07-22 14:22:02,466] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:04:00+00:00: scheduled__2020-07-20T03:04:00+00:00, externally triggered: False>
[2020-07-22 14:22:02,485] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:22:02,489] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:04:00+00:00 [scheduled]> in ORM
[2020-07-22 14:22:02,676] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.894 seconds
[2020-07-22 14:22:26,404] {scheduler_job.py:153} INFO - Started process (PID=418170) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:22:26,409] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:22:26,409] {logging_mixin.py:112} INFO - [2020-07-22 14:22:26,409] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:22:26,421] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:22:26,570] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:22:27,109] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:05:00+00:00: scheduled__2020-07-20T03:05:00+00:00, externally triggered: False>
[2020-07-22 14:22:27,113] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:04:00+00:00: scheduled__2020-07-20T03:04:00+00:00, externally triggered: False>
[2020-07-22 14:22:27,121] {logging_mixin.py:112} INFO - [2020-07-22 14:22:27,121] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:04:00+00:00: scheduled__2020-07-20T03:04:00+00:00, externally triggered: False> failed
[2020-07-22 14:22:27,290] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:05:00+00:00: scheduled__2020-07-20T03:05:00+00:00, externally triggered: False>
[2020-07-22 14:22:27,306] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:22:27,311] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:05:00+00:00 [scheduled]> in ORM
[2020-07-22 14:22:27,584] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.180 seconds
[2020-07-22 14:22:50,474] {scheduler_job.py:153} INFO - Started process (PID=418689) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:22:50,477] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:22:50,477] {logging_mixin.py:112} INFO - [2020-07-22 14:22:50,477] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:22:50,485] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:22:50,642] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:22:51,025] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:06:00+00:00: scheduled__2020-07-20T03:06:00+00:00, externally triggered: False>
[2020-07-22 14:22:51,032] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:05:00+00:00: scheduled__2020-07-20T03:05:00+00:00, externally triggered: False>
[2020-07-22 14:22:51,047] {logging_mixin.py:112} INFO - [2020-07-22 14:22:51,047] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:05:00+00:00: scheduled__2020-07-20T03:05:00+00:00, externally triggered: False> failed
[2020-07-22 14:22:51,251] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:06:00+00:00: scheduled__2020-07-20T03:06:00+00:00, externally triggered: False>
[2020-07-22 14:22:51,269] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:22:51,273] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:06:00+00:00 [scheduled]> in ORM
[2020-07-22 14:22:51,453] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.978 seconds
[2020-07-22 14:23:20,414] {scheduler_job.py:153} INFO - Started process (PID=419368) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:23:20,417] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:23:20,417] {logging_mixin.py:112} INFO - [2020-07-22 14:23:20,417] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:23:20,425] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:23:20,608] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:23:21,056] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:07:00+00:00: scheduled__2020-07-20T03:07:00+00:00, externally triggered: False>
[2020-07-22 14:23:21,061] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:06:00+00:00: scheduled__2020-07-20T03:06:00+00:00, externally triggered: False>
[2020-07-22 14:23:21,068] {logging_mixin.py:112} INFO - [2020-07-22 14:23:21,068] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:06:00+00:00: scheduled__2020-07-20T03:06:00+00:00, externally triggered: False> failed
[2020-07-22 14:23:21,258] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:07:00+00:00: scheduled__2020-07-20T03:07:00+00:00, externally triggered: False>
[2020-07-22 14:23:21,277] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:23:21,281] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:07:00+00:00 [scheduled]> in ORM
[2020-07-22 14:23:21,433] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.019 seconds
[2020-07-22 14:23:45,119] {scheduler_job.py:153} INFO - Started process (PID=419962) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:23:45,132] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:23:45,133] {logging_mixin.py:112} INFO - [2020-07-22 14:23:45,133] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:23:45,152] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:23:45,284] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:23:45,748] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:08:00+00:00: scheduled__2020-07-20T03:08:00+00:00, externally triggered: False>
[2020-07-22 14:23:45,753] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:07:00+00:00: scheduled__2020-07-20T03:07:00+00:00, externally triggered: False>
[2020-07-22 14:23:45,767] {logging_mixin.py:112} INFO - [2020-07-22 14:23:45,767] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:07:00+00:00: scheduled__2020-07-20T03:07:00+00:00, externally triggered: False> failed
[2020-07-22 14:23:45,909] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:08:00+00:00: scheduled__2020-07-20T03:08:00+00:00, externally triggered: False>
[2020-07-22 14:23:45,935] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:23:45,948] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:08:00+00:00 [scheduled]> in ORM
[2020-07-22 14:23:46,234] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.115 seconds
[2020-07-22 14:24:09,295] {scheduler_job.py:153} INFO - Started process (PID=420508) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:24:09,298] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:24:09,299] {logging_mixin.py:112} INFO - [2020-07-22 14:24:09,299] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:24:09,308] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:24:09,516] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:24:10,043] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:09:00+00:00: scheduled__2020-07-20T03:09:00+00:00, externally triggered: False>
[2020-07-22 14:24:10,048] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:08:00+00:00: scheduled__2020-07-20T03:08:00+00:00, externally triggered: False>
[2020-07-22 14:24:10,055] {logging_mixin.py:112} INFO - [2020-07-22 14:24:10,055] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:08:00+00:00: scheduled__2020-07-20T03:08:00+00:00, externally triggered: False> failed
[2020-07-22 14:24:10,176] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:09:00+00:00: scheduled__2020-07-20T03:09:00+00:00, externally triggered: False>
[2020-07-22 14:24:10,194] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:24:10,197] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:09:00+00:00 [scheduled]> in ORM
[2020-07-22 14:24:10,367] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.072 seconds
[2020-07-22 14:24:33,421] {scheduler_job.py:153} INFO - Started process (PID=421100) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:24:33,424] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:24:33,425] {logging_mixin.py:112} INFO - [2020-07-22 14:24:33,425] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:24:33,433] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:24:33,550] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:24:33,987] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:10:00+00:00: scheduled__2020-07-20T03:10:00+00:00, externally triggered: False>
[2020-07-22 14:24:33,992] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:09:00+00:00: scheduled__2020-07-20T03:09:00+00:00, externally triggered: False>
[2020-07-22 14:24:34,000] {logging_mixin.py:112} INFO - [2020-07-22 14:24:34,000] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:09:00+00:00: scheduled__2020-07-20T03:09:00+00:00, externally triggered: False> failed
[2020-07-22 14:24:34,111] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:10:00+00:00: scheduled__2020-07-20T03:10:00+00:00, externally triggered: False>
[2020-07-22 14:24:34,131] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:24:34,134] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:10:00+00:00 [scheduled]> in ORM
[2020-07-22 14:24:34,293] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.873 seconds
[2020-07-22 14:24:57,500] {scheduler_job.py:153} INFO - Started process (PID=421621) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:24:57,503] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:24:57,503] {logging_mixin.py:112} INFO - [2020-07-22 14:24:57,503] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:24:57,512] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:24:57,688] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:24:58,084] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:11:00+00:00: scheduled__2020-07-20T03:11:00+00:00, externally triggered: False>
[2020-07-22 14:24:58,087] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:10:00+00:00: scheduled__2020-07-20T03:10:00+00:00, externally triggered: False>
[2020-07-22 14:24:58,095] {logging_mixin.py:112} INFO - [2020-07-22 14:24:58,095] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:10:00+00:00: scheduled__2020-07-20T03:10:00+00:00, externally triggered: False> failed
[2020-07-22 14:24:58,246] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:11:00+00:00: scheduled__2020-07-20T03:11:00+00:00, externally triggered: False>
[2020-07-22 14:24:58,267] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:24:58,274] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:11:00+00:00 [scheduled]> in ORM
[2020-07-22 14:24:58,438] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.937 seconds
[2020-07-22 14:25:28,002] {scheduler_job.py:153} INFO - Started process (PID=422356) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:25:28,006] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:25:28,007] {logging_mixin.py:112} INFO - [2020-07-22 14:25:28,007] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:25:28,015] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:25:28,156] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:25:28,459] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:12:00+00:00: scheduled__2020-07-20T03:12:00+00:00, externally triggered: False>
[2020-07-22 14:25:28,462] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:11:00+00:00: scheduled__2020-07-20T03:11:00+00:00, externally triggered: False>
[2020-07-22 14:25:28,470] {logging_mixin.py:112} INFO - [2020-07-22 14:25:28,470] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:11:00+00:00: scheduled__2020-07-20T03:11:00+00:00, externally triggered: False> failed
[2020-07-22 14:25:28,570] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:12:00+00:00: scheduled__2020-07-20T03:12:00+00:00, externally triggered: False>
[2020-07-22 14:25:28,589] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:25:28,593] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:12:00+00:00 [scheduled]> in ORM
[2020-07-22 14:25:28,752] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.750 seconds
[2020-07-22 14:25:58,265] {scheduler_job.py:153} INFO - Started process (PID=423064) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:25:58,269] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:25:58,270] {logging_mixin.py:112} INFO - [2020-07-22 14:25:58,270] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:25:58,289] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:25:58,535] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:25:58,839] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:13:00+00:00: scheduled__2020-07-20T03:13:00+00:00, externally triggered: False>
[2020-07-22 14:25:58,842] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:12:00+00:00: scheduled__2020-07-20T03:12:00+00:00, externally triggered: False>
[2020-07-22 14:25:58,849] {logging_mixin.py:112} INFO - [2020-07-22 14:25:58,849] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:12:00+00:00: scheduled__2020-07-20T03:12:00+00:00, externally triggered: False> failed
[2020-07-22 14:25:58,961] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:13:00+00:00: scheduled__2020-07-20T03:13:00+00:00, externally triggered: False>
[2020-07-22 14:25:58,975] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:25:58,980] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:13:00+00:00 [scheduled]> in ORM
[2020-07-22 14:25:59,155] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.890 seconds
[2020-07-22 14:26:22,484] {scheduler_job.py:153} INFO - Started process (PID=423582) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:26:22,487] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:26:22,487] {logging_mixin.py:112} INFO - [2020-07-22 14:26:22,487] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:26:22,496] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:26:22,671] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:26:23,108] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:14:00+00:00: scheduled__2020-07-20T03:14:00+00:00, externally triggered: False>
[2020-07-22 14:26:23,112] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:13:00+00:00: scheduled__2020-07-20T03:13:00+00:00, externally triggered: False>
[2020-07-22 14:26:23,119] {logging_mixin.py:112} INFO - [2020-07-22 14:26:23,119] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:13:00+00:00: scheduled__2020-07-20T03:13:00+00:00, externally triggered: False> failed
[2020-07-22 14:26:23,230] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:14:00+00:00: scheduled__2020-07-20T03:14:00+00:00, externally triggered: False>
[2020-07-22 14:26:23,249] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:26:23,252] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:14:00+00:00 [scheduled]> in ORM
[2020-07-22 14:26:23,445] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.961 seconds
[2020-07-22 14:26:52,571] {scheduler_job.py:153} INFO - Started process (PID=424287) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:26:52,574] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:26:52,574] {logging_mixin.py:112} INFO - [2020-07-22 14:26:52,574] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:26:52,585] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:26:52,707] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:26:53,094] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:15:00+00:00: scheduled__2020-07-20T03:15:00+00:00, externally triggered: False>
[2020-07-22 14:26:53,099] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:14:00+00:00: scheduled__2020-07-20T03:14:00+00:00, externally triggered: False>
[2020-07-22 14:26:53,112] {logging_mixin.py:112} INFO - [2020-07-22 14:26:53,112] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:14:00+00:00: scheduled__2020-07-20T03:14:00+00:00, externally triggered: False> failed
[2020-07-22 14:26:53,220] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:15:00+00:00: scheduled__2020-07-20T03:15:00+00:00, externally triggered: False>
[2020-07-22 14:26:53,237] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:26:53,242] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:15:00+00:00 [scheduled]> in ORM
[2020-07-22 14:26:53,402] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.832 seconds
[2020-07-22 14:27:16,549] {scheduler_job.py:153} INFO - Started process (PID=424867) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:27:16,554] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:27:16,555] {logging_mixin.py:112} INFO - [2020-07-22 14:27:16,555] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:27:16,570] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:27:16,744] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:27:17,187] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:16:00+00:00: scheduled__2020-07-20T03:16:00+00:00, externally triggered: False>
[2020-07-22 14:27:17,203] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:15:00+00:00: scheduled__2020-07-20T03:15:00+00:00, externally triggered: False>
[2020-07-22 14:27:17,217] {logging_mixin.py:112} INFO - [2020-07-22 14:27:17,217] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:15:00+00:00: scheduled__2020-07-20T03:15:00+00:00, externally triggered: False> failed
[2020-07-22 14:27:17,400] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:16:00+00:00: scheduled__2020-07-20T03:16:00+00:00, externally triggered: False>
[2020-07-22 14:27:17,421] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:27:17,428] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:16:00+00:00 [scheduled]> in ORM
[2020-07-22 14:27:17,592] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.043 seconds
[2020-07-22 14:27:46,316] {scheduler_job.py:153} INFO - Started process (PID=425508) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:27:46,319] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:27:46,320] {logging_mixin.py:112} INFO - [2020-07-22 14:27:46,320] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:27:46,330] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:27:46,465] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:27:46,770] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:17:00+00:00: scheduled__2020-07-20T03:17:00+00:00, externally triggered: False>
[2020-07-22 14:27:46,773] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:16:00+00:00: scheduled__2020-07-20T03:16:00+00:00, externally triggered: False>
[2020-07-22 14:27:46,781] {logging_mixin.py:112} INFO - [2020-07-22 14:27:46,781] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:16:00+00:00: scheduled__2020-07-20T03:16:00+00:00, externally triggered: False> failed
[2020-07-22 14:27:46,891] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:17:00+00:00: scheduled__2020-07-20T03:17:00+00:00, externally triggered: False>
[2020-07-22 14:27:46,910] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:27:46,915] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:17:00+00:00 [scheduled]> in ORM
[2020-07-22 14:27:47,074] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.758 seconds
[2020-07-22 14:28:22,360] {scheduler_job.py:153} INFO - Started process (PID=426278) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:28:22,364] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:28:22,364] {logging_mixin.py:112} INFO - [2020-07-22 14:28:22,364] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:28:22,374] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:28:22,490] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:28:22,906] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:18:00+00:00: scheduled__2020-07-20T03:18:00+00:00, externally triggered: False>
[2020-07-22 14:28:22,909] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:17:00+00:00: scheduled__2020-07-20T03:17:00+00:00, externally triggered: False>
[2020-07-22 14:28:22,918] {logging_mixin.py:112} INFO - [2020-07-22 14:28:22,917] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:17:00+00:00: scheduled__2020-07-20T03:17:00+00:00, externally triggered: False> failed
[2020-07-22 14:28:23,027] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:18:00+00:00: scheduled__2020-07-20T03:18:00+00:00, externally triggered: False>
[2020-07-22 14:28:23,099] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:28:23,119] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:18:00+00:00 [scheduled]> in ORM
[2020-07-22 14:28:23,343] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.983 seconds
[2020-07-22 14:28:51,935] {scheduler_job.py:153} INFO - Started process (PID=426999) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:28:51,939] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:28:51,939] {logging_mixin.py:112} INFO - [2020-07-22 14:28:51,939] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:28:51,949] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:28:52,138] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:28:52,500] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:19:00+00:00: scheduled__2020-07-20T03:19:00+00:00, externally triggered: False>
[2020-07-22 14:28:52,505] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:18:00+00:00: scheduled__2020-07-20T03:18:00+00:00, externally triggered: False>
[2020-07-22 14:28:52,521] {logging_mixin.py:112} INFO - [2020-07-22 14:28:52,521] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:18:00+00:00: scheduled__2020-07-20T03:18:00+00:00, externally triggered: False> failed
[2020-07-22 14:28:52,640] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:19:00+00:00: scheduled__2020-07-20T03:19:00+00:00, externally triggered: False>
[2020-07-22 14:28:52,665] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:28:52,673] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:19:00+00:00 [scheduled]> in ORM
[2020-07-22 14:28:52,877] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.941 seconds
[2020-07-22 14:29:21,331] {scheduler_job.py:153} INFO - Started process (PID=427613) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:29:21,334] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:29:21,335] {logging_mixin.py:112} INFO - [2020-07-22 14:29:21,335] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:29:21,344] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:29:21,451] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:29:21,759] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:20:00+00:00: scheduled__2020-07-20T03:20:00+00:00, externally triggered: False>
[2020-07-22 14:29:21,763] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:19:00+00:00: scheduled__2020-07-20T03:19:00+00:00, externally triggered: False>
[2020-07-22 14:29:21,772] {logging_mixin.py:112} INFO - [2020-07-22 14:29:21,771] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:19:00+00:00: scheduled__2020-07-20T03:19:00+00:00, externally triggered: False> failed
[2020-07-22 14:29:21,908] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:20:00+00:00: scheduled__2020-07-20T03:20:00+00:00, externally triggered: False>
[2020-07-22 14:29:21,918] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 08:59:10.410307+00:00: manual__2020-07-22T08:59:10.410307+00:00, externally triggered: True>
[2020-07-22 14:29:21,936] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:29:21,940] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:20:00+00:00 [scheduled]> in ORM
[2020-07-22 14:29:21,945] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 08:59:10.410307+00:00 [scheduled]> in ORM
[2020-07-22 14:29:22,111] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.779 seconds
[2020-07-22 14:30:04,203] {scheduler_job.py:153} INFO - Started process (PID=428561) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:30:04,207] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:30:04,208] {logging_mixin.py:112} INFO - [2020-07-22 14:30:04,208] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:30:04,225] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:30:04,379] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:30:04,708] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:21:00+00:00: scheduled__2020-07-20T03:21:00+00:00, externally triggered: False>
[2020-07-22 14:30:04,712] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:20:00+00:00: scheduled__2020-07-20T03:20:00+00:00, externally triggered: False>
[2020-07-22 14:30:04,721] {logging_mixin.py:112} INFO - [2020-07-22 14:30:04,721] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:20:00+00:00: scheduled__2020-07-20T03:20:00+00:00, externally triggered: False> failed
[2020-07-22 14:30:04,889] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:21:00+00:00: scheduled__2020-07-20T03:21:00+00:00, externally triggered: False>
[2020-07-22 14:30:04,899] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 08:59:10.410307+00:00: manual__2020-07-22T08:59:10.410307+00:00, externally triggered: True>
[2020-07-22 14:30:04,908] {logging_mixin.py:112} INFO - [2020-07-22 14:30:04,908] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-22 08:59:10.410307+00:00: manual__2020-07-22T08:59:10.410307+00:00, externally triggered: True> failed
[2020-07-22 14:30:05,027] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:30:05,033] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:21:00+00:00 [scheduled]> in ORM
[2020-07-22 14:30:05,225] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.023 seconds
[2020-07-22 14:30:34,334] {scheduler_job.py:153} INFO - Started process (PID=429204) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:30:34,337] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:30:34,338] {logging_mixin.py:112} INFO - [2020-07-22 14:30:34,338] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:30:34,348] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:30:34,486] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:30:34,821] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:22:00+00:00: scheduled__2020-07-20T03:22:00+00:00, externally triggered: False>
[2020-07-22 14:30:34,825] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:21:00+00:00: scheduled__2020-07-20T03:21:00+00:00, externally triggered: False>
[2020-07-22 14:30:34,836] {logging_mixin.py:112} INFO - [2020-07-22 14:30:34,836] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:21:00+00:00: scheduled__2020-07-20T03:21:00+00:00, externally triggered: False> failed
[2020-07-22 14:30:34,992] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:22:00+00:00: scheduled__2020-07-20T03:22:00+00:00, externally triggered: False>
[2020-07-22 14:30:35,010] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:30:35,015] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:22:00+00:00 [scheduled]> in ORM
[2020-07-22 14:30:35,186] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.852 seconds
[2020-07-22 14:31:03,877] {scheduler_job.py:153} INFO - Started process (PID=429891) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:31:03,879] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:31:03,880] {logging_mixin.py:112} INFO - [2020-07-22 14:31:03,880] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:31:03,888] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:31:04,097] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:31:04,469] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:23:00+00:00: scheduled__2020-07-20T03:23:00+00:00, externally triggered: False>
[2020-07-22 14:31:04,474] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:22:00+00:00: scheduled__2020-07-20T03:22:00+00:00, externally triggered: False>
[2020-07-22 14:31:04,482] {logging_mixin.py:112} INFO - [2020-07-22 14:31:04,482] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:22:00+00:00: scheduled__2020-07-20T03:22:00+00:00, externally triggered: False> failed
[2020-07-22 14:31:04,593] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:23:00+00:00: scheduled__2020-07-20T03:23:00+00:00, externally triggered: False>
[2020-07-22 14:31:04,614] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:31:04,618] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:23:00+00:00 [scheduled]> in ORM
[2020-07-22 14:31:04,774] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.898 seconds
[2020-07-22 14:31:28,119] {scheduler_job.py:153} INFO - Started process (PID=430470) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:31:28,123] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:31:28,124] {logging_mixin.py:112} INFO - [2020-07-22 14:31:28,123] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:31:28,132] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:31:28,405] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:31:28,799] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:24:00+00:00: scheduled__2020-07-20T03:24:00+00:00, externally triggered: False>
[2020-07-22 14:31:28,811] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:23:00+00:00: scheduled__2020-07-20T03:23:00+00:00, externally triggered: False>
[2020-07-22 14:31:28,827] {logging_mixin.py:112} INFO - [2020-07-22 14:31:28,826] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:23:00+00:00: scheduled__2020-07-20T03:23:00+00:00, externally triggered: False> failed
[2020-07-22 14:31:28,961] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:24:00+00:00: scheduled__2020-07-20T03:24:00+00:00, externally triggered: False>
[2020-07-22 14:31:28,982] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:31:28,988] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:24:00+00:00 [scheduled]> in ORM
[2020-07-22 14:31:29,157] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.037 seconds
[2020-07-22 14:31:58,772] {scheduler_job.py:153} INFO - Started process (PID=431139) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:31:58,778] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:31:58,779] {logging_mixin.py:112} INFO - [2020-07-22 14:31:58,778] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:31:58,789] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:31:58,938] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:31:59,273] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:25:00+00:00: scheduled__2020-07-20T03:25:00+00:00, externally triggered: False>
[2020-07-22 14:31:59,280] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:24:00+00:00: scheduled__2020-07-20T03:24:00+00:00, externally triggered: False>
[2020-07-22 14:31:59,303] {logging_mixin.py:112} INFO - [2020-07-22 14:31:59,303] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:24:00+00:00: scheduled__2020-07-20T03:24:00+00:00, externally triggered: False> failed
[2020-07-22 14:31:59,464] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:25:00+00:00: scheduled__2020-07-20T03:25:00+00:00, externally triggered: False>
[2020-07-22 14:31:59,483] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:31:59,487] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:25:00+00:00 [scheduled]> in ORM
[2020-07-22 14:31:59,647] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.875 seconds
[2020-07-22 14:32:34,540] {scheduler_job.py:153} INFO - Started process (PID=431926) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:32:34,543] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:32:34,543] {logging_mixin.py:112} INFO - [2020-07-22 14:32:34,543] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:32:34,551] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:32:35,265] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:32:35,910] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:26:00+00:00: scheduled__2020-07-20T03:26:00+00:00, externally triggered: False>
[2020-07-22 14:32:35,917] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:25:00+00:00: scheduled__2020-07-20T03:25:00+00:00, externally triggered: False>
[2020-07-22 14:32:35,935] {logging_mixin.py:112} INFO - [2020-07-22 14:32:35,935] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:25:00+00:00: scheduled__2020-07-20T03:25:00+00:00, externally triggered: False> failed
[2020-07-22 14:32:36,099] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:26:00+00:00: scheduled__2020-07-20T03:26:00+00:00, externally triggered: False>
[2020-07-22 14:32:36,113] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:02:09.135038+00:00: manual__2020-07-22T09:02:09.135038+00:00, externally triggered: True>
[2020-07-22 14:32:36,128] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:32:36,132] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:26:00+00:00 [scheduled]> in ORM
[2020-07-22 14:32:36,136] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 09:02:09.135038+00:00 [scheduled]> in ORM
[2020-07-22 14:32:36,293] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.753 seconds
[2020-07-22 14:33:22,393] {scheduler_job.py:153} INFO - Started process (PID=433005) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:33:22,397] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:33:22,398] {logging_mixin.py:112} INFO - [2020-07-22 14:33:22,397] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:33:22,405] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:33:22,533] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:33:22,841] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:27:00+00:00: scheduled__2020-07-20T03:27:00+00:00, externally triggered: False>
[2020-07-22 14:33:22,844] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:26:00+00:00: scheduled__2020-07-20T03:26:00+00:00, externally triggered: False>
[2020-07-22 14:33:22,854] {logging_mixin.py:112} INFO - [2020-07-22 14:33:22,854] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:26:00+00:00: scheduled__2020-07-20T03:26:00+00:00, externally triggered: False> failed
[2020-07-22 14:33:23,047] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:27:00+00:00: scheduled__2020-07-20T03:27:00+00:00, externally triggered: False>
[2020-07-22 14:33:23,057] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:02:09.135038+00:00: manual__2020-07-22T09:02:09.135038+00:00, externally triggered: True>
[2020-07-22 14:33:23,065] {logging_mixin.py:112} INFO - [2020-07-22 14:33:23,065] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-22 09:02:09.135038+00:00: manual__2020-07-22T09:02:09.135038+00:00, externally triggered: True> failed
[2020-07-22 14:33:23,284] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:33:23,291] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:27:00+00:00 [scheduled]> in ORM
[2020-07-22 14:33:23,454] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.061 seconds
[2020-07-22 14:33:51,897] {scheduler_job.py:153} INFO - Started process (PID=433678) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:33:51,901] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:33:51,901] {logging_mixin.py:112} INFO - [2020-07-22 14:33:51,901] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:33:51,910] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:33:52,054] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:33:52,357] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:28:00+00:00: scheduled__2020-07-20T03:28:00+00:00, externally triggered: False>
[2020-07-22 14:33:52,362] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:27:00+00:00: scheduled__2020-07-20T03:27:00+00:00, externally triggered: False>
[2020-07-22 14:33:52,373] {logging_mixin.py:112} INFO - [2020-07-22 14:33:52,373] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:27:00+00:00: scheduled__2020-07-20T03:27:00+00:00, externally triggered: False> failed
[2020-07-22 14:33:52,550] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:28:00+00:00: scheduled__2020-07-20T03:28:00+00:00, externally triggered: False>
[2020-07-22 14:33:52,571] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:33:52,575] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:28:00+00:00 [scheduled]> in ORM
[2020-07-22 14:33:52,741] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.844 seconds
[2020-07-22 14:34:22,334] {scheduler_job.py:153} INFO - Started process (PID=434294) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:34:22,338] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:34:22,339] {logging_mixin.py:112} INFO - [2020-07-22 14:34:22,338] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:34:22,353] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:34:22,502] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:34:22,864] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:29:00+00:00: scheduled__2020-07-20T03:29:00+00:00, externally triggered: False>
[2020-07-22 14:34:22,867] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:28:00+00:00: scheduled__2020-07-20T03:28:00+00:00, externally triggered: False>
[2020-07-22 14:34:22,876] {logging_mixin.py:112} INFO - [2020-07-22 14:34:22,876] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:28:00+00:00: scheduled__2020-07-20T03:28:00+00:00, externally triggered: False> failed
[2020-07-22 14:34:23,007] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:29:00+00:00: scheduled__2020-07-20T03:29:00+00:00, externally triggered: False>
[2020-07-22 14:34:23,039] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:34:23,047] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:29:00+00:00 [scheduled]> in ORM
[2020-07-22 14:34:23,232] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.898 seconds
[2020-07-22 14:34:59,596] {scheduler_job.py:153} INFO - Started process (PID=435097) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:34:59,599] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:34:59,600] {logging_mixin.py:112} INFO - [2020-07-22 14:34:59,600] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:34:59,609] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:34:59,766] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:35:00,132] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:30:00+00:00: scheduled__2020-07-20T03:30:00+00:00, externally triggered: False>
[2020-07-22 14:35:00,137] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:29:00+00:00: scheduled__2020-07-20T03:29:00+00:00, externally triggered: False>
[2020-07-22 14:35:00,144] {logging_mixin.py:112} INFO - [2020-07-22 14:35:00,144] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:29:00+00:00: scheduled__2020-07-20T03:29:00+00:00, externally triggered: False> failed
[2020-07-22 14:35:00,254] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:30:00+00:00: scheduled__2020-07-20T03:30:00+00:00, externally triggered: False>
[2020-07-22 14:35:00,271] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:04:32.760234+00:00: manual__2020-07-22T09:04:32.760234+00:00, externally triggered: True>
[2020-07-22 14:35:00,288] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:35:00,292] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:30:00+00:00 [scheduled]> in ORM
[2020-07-22 14:35:00,296] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 09:04:32.760234+00:00 [scheduled]> in ORM
[2020-07-22 14:35:00,476] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.880 seconds
[2020-07-22 14:35:48,563] {scheduler_job.py:153} INFO - Started process (PID=436117) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:35:48,566] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:35:48,566] {logging_mixin.py:112} INFO - [2020-07-22 14:35:48,566] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:35:48,574] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:35:48,800] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:35:49,156] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:31:00+00:00: scheduled__2020-07-20T03:31:00+00:00, externally triggered: False>
[2020-07-22 14:35:49,160] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:30:00+00:00: scheduled__2020-07-20T03:30:00+00:00, externally triggered: False>
[2020-07-22 14:35:49,169] {logging_mixin.py:112} INFO - [2020-07-22 14:35:49,168] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:30:00+00:00: scheduled__2020-07-20T03:30:00+00:00, externally triggered: False> failed
[2020-07-22 14:35:49,279] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:31:00+00:00: scheduled__2020-07-20T03:31:00+00:00, externally triggered: False>
[2020-07-22 14:35:49,297] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:04:32.760234+00:00: manual__2020-07-22T09:04:32.760234+00:00, externally triggered: True>
[2020-07-22 14:35:49,311] {logging_mixin.py:112} INFO - [2020-07-22 14:35:49,311] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-22 09:04:32.760234+00:00: manual__2020-07-22T09:04:32.760234+00:00, externally triggered: True> failed
[2020-07-22 14:35:49,420] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:35:49,427] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:31:00+00:00 [scheduled]> in ORM
[2020-07-22 14:35:49,618] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.055 seconds
[2020-07-22 14:36:18,327] {scheduler_job.py:153} INFO - Started process (PID=436806) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:36:18,330] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:36:18,331] {logging_mixin.py:112} INFO - [2020-07-22 14:36:18,330] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:36:18,340] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:36:18,451] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:36:19,171] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:32:00+00:00: scheduled__2020-07-20T03:32:00+00:00, externally triggered: False>
[2020-07-22 14:36:19,179] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:31:00+00:00: scheduled__2020-07-20T03:31:00+00:00, externally triggered: False>
[2020-07-22 14:36:19,197] {logging_mixin.py:112} INFO - [2020-07-22 14:36:19,196] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:31:00+00:00: scheduled__2020-07-20T03:31:00+00:00, externally triggered: False> failed
[2020-07-22 14:36:19,358] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:32:00+00:00: scheduled__2020-07-20T03:32:00+00:00, externally triggered: False>
[2020-07-22 14:36:19,390] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:36:19,399] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:32:00+00:00 [scheduled]> in ORM
[2020-07-22 14:36:19,608] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.281 seconds
[2020-07-22 14:36:43,464] {scheduler_job.py:153} INFO - Started process (PID=437370) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:36:43,468] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:36:43,469] {logging_mixin.py:112} INFO - [2020-07-22 14:36:43,469] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:36:43,479] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:36:43,670] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:36:44,061] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:33:00+00:00: scheduled__2020-07-20T03:33:00+00:00, externally triggered: False>
[2020-07-22 14:36:44,065] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:32:00+00:00: scheduled__2020-07-20T03:32:00+00:00, externally triggered: False>
[2020-07-22 14:36:44,072] {logging_mixin.py:112} INFO - [2020-07-22 14:36:44,072] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:32:00+00:00: scheduled__2020-07-20T03:32:00+00:00, externally triggered: False> failed
[2020-07-22 14:36:44,171] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:33:00+00:00: scheduled__2020-07-20T03:33:00+00:00, externally triggered: False>
[2020-07-22 14:36:44,189] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:36:44,193] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:33:00+00:00 [scheduled]> in ORM
[2020-07-22 14:36:44,343] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.879 seconds
[2020-07-22 14:37:13,626] {scheduler_job.py:153} INFO - Started process (PID=438034) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:37:13,629] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:37:13,630] {logging_mixin.py:112} INFO - [2020-07-22 14:37:13,630] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:37:13,639] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:37:13,759] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:37:14,084] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:34:00+00:00: scheduled__2020-07-20T03:34:00+00:00, externally triggered: False>
[2020-07-22 14:37:14,090] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:33:00+00:00: scheduled__2020-07-20T03:33:00+00:00, externally triggered: False>
[2020-07-22 14:37:14,097] {logging_mixin.py:112} INFO - [2020-07-22 14:37:14,097] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:33:00+00:00: scheduled__2020-07-20T03:33:00+00:00, externally triggered: False> failed
[2020-07-22 14:37:14,207] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:34:00+00:00: scheduled__2020-07-20T03:34:00+00:00, externally triggered: False>
[2020-07-22 14:37:14,236] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:37:14,245] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:34:00+00:00 [scheduled]> in ORM
[2020-07-22 14:37:14,501] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.874 seconds
[2020-07-22 14:37:43,911] {scheduler_job.py:153} INFO - Started process (PID=438761) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:37:43,915] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:37:43,916] {logging_mixin.py:112} INFO - [2020-07-22 14:37:43,916] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:37:43,928] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:37:44,047] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:37:44,388] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:35:00+00:00: scheduled__2020-07-20T03:35:00+00:00, externally triggered: False>
[2020-07-22 14:37:44,391] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:34:00+00:00: scheduled__2020-07-20T03:34:00+00:00, externally triggered: False>
[2020-07-22 14:37:44,399] {logging_mixin.py:112} INFO - [2020-07-22 14:37:44,399] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:34:00+00:00: scheduled__2020-07-20T03:34:00+00:00, externally triggered: False> failed
[2020-07-22 14:37:44,597] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:35:00+00:00: scheduled__2020-07-20T03:35:00+00:00, externally triggered: False>
[2020-07-22 14:37:44,616] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:37:44,620] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:35:00+00:00 [scheduled]> in ORM
[2020-07-22 14:37:44,791] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.880 seconds
[2020-07-22 14:38:14,599] {scheduler_job.py:153} INFO - Started process (PID=439547) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:38:14,606] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:38:14,606] {logging_mixin.py:112} INFO - [2020-07-22 14:38:14,606] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:38:14,624] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:38:14,774] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:38:15,123] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:36:00+00:00: scheduled__2020-07-20T03:36:00+00:00, externally triggered: False>
[2020-07-22 14:38:15,129] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:35:00+00:00: scheduled__2020-07-20T03:35:00+00:00, externally triggered: False>
[2020-07-22 14:38:15,140] {logging_mixin.py:112} INFO - [2020-07-22 14:38:15,139] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:35:00+00:00: scheduled__2020-07-20T03:35:00+00:00, externally triggered: False> failed
[2020-07-22 14:38:15,466] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:36:00+00:00: scheduled__2020-07-20T03:36:00+00:00, externally triggered: False>
[2020-07-22 14:38:15,480] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:38:15,487] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:36:00+00:00 [scheduled]> in ORM
[2020-07-22 14:38:15,673] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.074 seconds
[2020-07-22 14:38:50,015] {scheduler_job.py:153} INFO - Started process (PID=440268) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:38:50,019] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:38:50,019] {logging_mixin.py:112} INFO - [2020-07-22 14:38:50,019] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:38:50,031] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:38:50,237] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:38:50,582] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:37:00+00:00: scheduled__2020-07-20T03:37:00+00:00, externally triggered: False>
[2020-07-22 14:38:50,588] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:36:00+00:00: scheduled__2020-07-20T03:36:00+00:00, externally triggered: False>
[2020-07-22 14:38:50,604] {logging_mixin.py:112} INFO - [2020-07-22 14:38:50,604] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:36:00+00:00: scheduled__2020-07-20T03:36:00+00:00, externally triggered: False> successful
[2020-07-22 14:38:50,746] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:37:00+00:00: scheduled__2020-07-20T03:37:00+00:00, externally triggered: False>
[2020-07-22 14:38:50,762] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:38:50,768] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:37:00+00:00 [scheduled]> in ORM
[2020-07-22 14:38:50,926] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.911 seconds
[2020-07-22 14:39:26,035] {scheduler_job.py:153} INFO - Started process (PID=441017) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:39:26,040] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:39:26,040] {logging_mixin.py:112} INFO - [2020-07-22 14:39:26,040] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:39:26,051] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:39:26,156] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:39:26,489] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:38:00+00:00: scheduled__2020-07-20T03:38:00+00:00, externally triggered: False>
[2020-07-22 14:39:26,492] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:37:00+00:00: scheduled__2020-07-20T03:37:00+00:00, externally triggered: False>
[2020-07-22 14:39:26,500] {logging_mixin.py:112} INFO - [2020-07-22 14:39:26,500] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:37:00+00:00: scheduled__2020-07-20T03:37:00+00:00, externally triggered: False> successful
[2020-07-22 14:39:26,637] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:38:00+00:00: scheduled__2020-07-20T03:38:00+00:00, externally triggered: False>
[2020-07-22 14:39:26,656] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:08:51.340020+00:00: manual__2020-07-22T09:08:51.340020+00:00, externally triggered: True>
[2020-07-22 14:39:26,682] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:39:26,687] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:38:00+00:00 [scheduled]> in ORM
[2020-07-22 14:39:26,692] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 09:08:51.340020+00:00 [scheduled]> in ORM
[2020-07-22 14:39:26,898] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.863 seconds
[2020-07-22 14:40:20,543] {scheduler_job.py:153} INFO - Started process (PID=442199) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:40:20,546] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:40:20,546] {logging_mixin.py:112} INFO - [2020-07-22 14:40:20,546] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:40:20,556] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:40:20,702] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:40:21,101] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:39:00+00:00: scheduled__2020-07-20T03:39:00+00:00, externally triggered: False>
[2020-07-22 14:40:21,108] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:38:00+00:00: scheduled__2020-07-20T03:38:00+00:00, externally triggered: False>
[2020-07-22 14:40:21,127] {logging_mixin.py:112} INFO - [2020-07-22 14:40:21,127] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:38:00+00:00: scheduled__2020-07-20T03:38:00+00:00, externally triggered: False> successful
[2020-07-22 14:40:21,285] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:39:00+00:00: scheduled__2020-07-20T03:39:00+00:00, externally triggered: False>
[2020-07-22 14:40:21,311] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:08:51.340020+00:00: manual__2020-07-22T09:08:51.340020+00:00, externally triggered: True>
[2020-07-22 14:40:21,334] {logging_mixin.py:112} INFO - [2020-07-22 14:40:21,333] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-22 09:08:51.340020+00:00: manual__2020-07-22T09:08:51.340020+00:00, externally triggered: True> successful
[2020-07-22 14:40:21,452] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:40:21,467] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:39:00+00:00 [scheduled]> in ORM
[2020-07-22 14:40:21,651] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.108 seconds
[2020-07-22 14:40:52,364] {scheduler_job.py:153} INFO - Started process (PID=442888) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:40:52,369] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:40:52,370] {logging_mixin.py:112} INFO - [2020-07-22 14:40:52,370] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:40:52,379] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:40:52,579] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:40:52,944] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:40:00+00:00: scheduled__2020-07-20T03:40:00+00:00, externally triggered: False>
[2020-07-22 14:40:52,947] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:39:00+00:00: scheduled__2020-07-20T03:39:00+00:00, externally triggered: False>
[2020-07-22 14:40:52,954] {logging_mixin.py:112} INFO - [2020-07-22 14:40:52,954] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:39:00+00:00: scheduled__2020-07-20T03:39:00+00:00, externally triggered: False> successful
[2020-07-22 14:40:53,066] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:40:00+00:00: scheduled__2020-07-20T03:40:00+00:00, externally triggered: False>
[2020-07-22 14:40:53,085] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:40:53,088] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:40:00+00:00 [scheduled]> in ORM
[2020-07-22 14:40:53,249] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.884 seconds
[2020-07-22 14:41:26,689] {scheduler_job.py:153} INFO - Started process (PID=443669) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:41:26,696] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:41:26,696] {logging_mixin.py:112} INFO - [2020-07-22 14:41:26,696] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:41:26,706] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:41:26,856] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:41:27,206] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:41:00+00:00: scheduled__2020-07-20T03:41:00+00:00, externally triggered: False>
[2020-07-22 14:41:27,216] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:40:00+00:00: scheduled__2020-07-20T03:40:00+00:00, externally triggered: False>
[2020-07-22 14:41:27,226] {logging_mixin.py:112} INFO - [2020-07-22 14:41:27,225] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:40:00+00:00: scheduled__2020-07-20T03:40:00+00:00, externally triggered: False> successful
[2020-07-22 14:41:27,334] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:41:00+00:00: scheduled__2020-07-20T03:41:00+00:00, externally triggered: False>
[2020-07-22 14:41:27,350] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:41:27,354] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:41:00+00:00 [scheduled]> in ORM
[2020-07-22 14:41:27,517] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.829 seconds
[2020-07-22 14:41:56,317] {scheduler_job.py:153} INFO - Started process (PID=444382) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:41:56,321] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:41:56,321] {logging_mixin.py:112} INFO - [2020-07-22 14:41:56,321] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:41:56,331] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:41:56,489] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:41:56,850] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:42:00+00:00: scheduled__2020-07-20T03:42:00+00:00, externally triggered: False>
[2020-07-22 14:41:56,854] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:41:00+00:00: scheduled__2020-07-20T03:41:00+00:00, externally triggered: False>
[2020-07-22 14:41:56,861] {logging_mixin.py:112} INFO - [2020-07-22 14:41:56,861] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:41:00+00:00: scheduled__2020-07-20T03:41:00+00:00, externally triggered: False> successful
[2020-07-22 14:41:57,159] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:42:00+00:00: scheduled__2020-07-20T03:42:00+00:00, externally triggered: False>
[2020-07-22 14:41:57,177] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:41:57,181] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:42:00+00:00 [scheduled]> in ORM
[2020-07-22 14:41:57,342] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.025 seconds
[2020-07-22 14:42:25,892] {scheduler_job.py:153} INFO - Started process (PID=445186) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:42:25,896] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:42:25,897] {logging_mixin.py:112} INFO - [2020-07-22 14:42:25,897] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:42:25,910] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:42:26,087] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:42:26,440] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:43:00+00:00: scheduled__2020-07-20T03:43:00+00:00, externally triggered: False>
[2020-07-22 14:42:26,453] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:42:00+00:00: scheduled__2020-07-20T03:42:00+00:00, externally triggered: False>
[2020-07-22 14:42:26,479] {logging_mixin.py:112} INFO - [2020-07-22 14:42:26,479] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:42:00+00:00: scheduled__2020-07-20T03:42:00+00:00, externally triggered: False> successful
[2020-07-22 14:42:26,583] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:43:00+00:00: scheduled__2020-07-20T03:43:00+00:00, externally triggered: False>
[2020-07-22 14:42:26,617] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:42:26,626] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:43:00+00:00 [scheduled]> in ORM
[2020-07-22 14:42:26,876] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.984 seconds
[2020-07-22 14:43:01,936] {scheduler_job.py:153} INFO - Started process (PID=446001) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:43:01,941] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:43:01,941] {logging_mixin.py:112} INFO - [2020-07-22 14:43:01,941] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:43:01,954] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:43:02,105] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:43:02,442] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:44:00+00:00: scheduled__2020-07-20T03:44:00+00:00, externally triggered: False>
[2020-07-22 14:43:02,445] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:43:00+00:00: scheduled__2020-07-20T03:43:00+00:00, externally triggered: False>
[2020-07-22 14:43:02,452] {logging_mixin.py:112} INFO - [2020-07-22 14:43:02,452] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:43:00+00:00: scheduled__2020-07-20T03:43:00+00:00, externally triggered: False> successful
[2020-07-22 14:43:02,563] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:44:00+00:00: scheduled__2020-07-20T03:44:00+00:00, externally triggered: False>
[2020-07-22 14:43:02,581] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:43:02,585] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:44:00+00:00 [scheduled]> in ORM
[2020-07-22 14:43:02,744] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.808 seconds
[2020-07-22 14:43:36,276] {scheduler_job.py:153} INFO - Started process (PID=446765) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:43:36,280] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:43:36,281] {logging_mixin.py:112} INFO - [2020-07-22 14:43:36,280] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:43:36,289] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:43:36,457] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:43:36,813] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:45:00+00:00: scheduled__2020-07-20T03:45:00+00:00, externally triggered: False>
[2020-07-22 14:43:36,818] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:44:00+00:00: scheduled__2020-07-20T03:44:00+00:00, externally triggered: False>
[2020-07-22 14:43:36,831] {logging_mixin.py:112} INFO - [2020-07-22 14:43:36,831] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:44:00+00:00: scheduled__2020-07-20T03:44:00+00:00, externally triggered: False> successful
[2020-07-22 14:43:36,943] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:45:00+00:00: scheduled__2020-07-20T03:45:00+00:00, externally triggered: False>
[2020-07-22 14:43:36,961] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:43:36,965] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:45:00+00:00 [scheduled]> in ORM
[2020-07-22 14:43:37,126] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.850 seconds
[2020-07-22 14:44:05,601] {scheduler_job.py:153} INFO - Started process (PID=447493) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:44:05,607] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:44:05,608] {logging_mixin.py:112} INFO - [2020-07-22 14:44:05,608] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:44:05,617] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:44:05,767] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:44:06,277] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:46:00+00:00: scheduled__2020-07-20T03:46:00+00:00, externally triggered: False>
[2020-07-22 14:44:06,282] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:45:00+00:00: scheduled__2020-07-20T03:45:00+00:00, externally triggered: False>
[2020-07-22 14:44:06,291] {logging_mixin.py:112} INFO - [2020-07-22 14:44:06,291] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:45:00+00:00: scheduled__2020-07-20T03:45:00+00:00, externally triggered: False> successful
[2020-07-22 14:44:06,579] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:46:00+00:00: scheduled__2020-07-20T03:46:00+00:00, externally triggered: False>
[2020-07-22 14:44:06,597] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:44:06,601] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:46:00+00:00 [scheduled]> in ORM
[2020-07-22 14:44:06,762] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.161 seconds
[2020-07-22 14:44:41,345] {scheduler_job.py:153} INFO - Started process (PID=448474) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:44:41,378] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:44:41,380] {logging_mixin.py:112} INFO - [2020-07-22 14:44:41,379] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:44:41,426] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:44:41,726] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:44:42,269] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:47:00+00:00: scheduled__2020-07-20T03:47:00+00:00, externally triggered: False>
[2020-07-22 14:44:42,293] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:46:00+00:00: scheduled__2020-07-20T03:46:00+00:00, externally triggered: False>
[2020-07-22 14:44:42,344] {logging_mixin.py:112} INFO - [2020-07-22 14:44:42,343] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:46:00+00:00: scheduled__2020-07-20T03:46:00+00:00, externally triggered: False> successful
[2020-07-22 14:44:42,592] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:47:00+00:00: scheduled__2020-07-20T03:47:00+00:00, externally triggered: False>
[2020-07-22 14:44:42,632] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:44:42,666] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:47:00+00:00 [scheduled]> in ORM
[2020-07-22 14:44:42,908] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.563 seconds
[2020-07-22 14:45:37,483] {scheduler_job.py:153} INFO - Started process (PID=449718) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:45:37,490] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:45:37,492] {logging_mixin.py:112} INFO - [2020-07-22 14:45:37,492] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:45:37,511] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:45:37,674] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:45:38,028] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:48:00+00:00: scheduled__2020-07-20T03:48:00+00:00, externally triggered: False>
[2020-07-22 14:45:38,040] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:47:00+00:00: scheduled__2020-07-20T03:47:00+00:00, externally triggered: False>
[2020-07-22 14:45:38,076] {logging_mixin.py:112} INFO - [2020-07-22 14:45:38,076] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:47:00+00:00: scheduled__2020-07-20T03:47:00+00:00, externally triggered: False> successful
[2020-07-22 14:45:38,195] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:48:00+00:00: scheduled__2020-07-20T03:48:00+00:00, externally triggered: False>
[2020-07-22 14:45:38,243] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:45:38,251] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:48:00+00:00 [scheduled]> in ORM
[2020-07-22 14:45:38,435] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.952 seconds
[2020-07-22 14:46:23,472] {scheduler_job.py:153} INFO - Started process (PID=450653) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:46:23,477] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:46:23,478] {logging_mixin.py:112} INFO - [2020-07-22 14:46:23,477] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:46:23,494] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:46:23,740] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:46:24,205] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:49:00+00:00: scheduled__2020-07-20T03:49:00+00:00, externally triggered: False>
[2020-07-22 14:46:24,209] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:48:00+00:00: scheduled__2020-07-20T03:48:00+00:00, externally triggered: False>
[2020-07-22 14:46:24,219] {logging_mixin.py:112} INFO - [2020-07-22 14:46:24,219] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:48:00+00:00: scheduled__2020-07-20T03:48:00+00:00, externally triggered: False> successful
[2020-07-22 14:46:24,344] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:49:00+00:00: scheduled__2020-07-20T03:49:00+00:00, externally triggered: False>
[2020-07-22 14:46:24,362] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:46:24,365] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:49:00+00:00 [scheduled]> in ORM
[2020-07-22 14:46:24,529] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.057 seconds
[2020-07-22 14:47:10,732] {scheduler_job.py:153} INFO - Started process (PID=451604) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:47:10,735] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:47:10,736] {logging_mixin.py:112} INFO - [2020-07-22 14:47:10,735] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:47:10,750] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:47:10,990] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:47:11,364] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:50:00+00:00: scheduled__2020-07-20T03:50:00+00:00, externally triggered: False>
[2020-07-22 14:47:11,373] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:49:00+00:00: scheduled__2020-07-20T03:49:00+00:00, externally triggered: False>
[2020-07-22 14:47:11,394] {logging_mixin.py:112} INFO - [2020-07-22 14:47:11,394] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:49:00+00:00: scheduled__2020-07-20T03:49:00+00:00, externally triggered: False> successful
[2020-07-22 14:47:11,490] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:50:00+00:00: scheduled__2020-07-20T03:50:00+00:00, externally triggered: False>
[2020-07-22 14:47:11,516] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:47:11,521] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:50:00+00:00 [scheduled]> in ORM
[2020-07-22 14:47:11,685] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.954 seconds
[2020-07-22 14:47:51,837] {scheduler_job.py:153} INFO - Started process (PID=452528) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:47:51,842] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:47:51,842] {logging_mixin.py:112} INFO - [2020-07-22 14:47:51,842] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:47:51,854] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:47:52,732] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:47:53,329] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:51:00+00:00: scheduled__2020-07-20T03:51:00+00:00, externally triggered: False>
[2020-07-22 14:47:53,338] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:50:00+00:00: scheduled__2020-07-20T03:50:00+00:00, externally triggered: False>
[2020-07-22 14:47:53,357] {logging_mixin.py:112} INFO - [2020-07-22 14:47:53,357] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:50:00+00:00: scheduled__2020-07-20T03:50:00+00:00, externally triggered: False> successful
[2020-07-22 14:47:53,863] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:51:00+00:00: scheduled__2020-07-20T03:51:00+00:00, externally triggered: False>
[2020-07-22 14:47:54,025] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:47:54,031] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:51:00+00:00 [scheduled]> in ORM
[2020-07-22 14:47:54,233] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.396 seconds
[2020-07-22 14:48:38,955] {scheduler_job.py:153} INFO - Started process (PID=453545) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:48:39,015] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:48:39,022] {logging_mixin.py:112} INFO - [2020-07-22 14:48:39,022] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:48:39,105] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:48:39,466] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:48:40,154] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:52:00+00:00: scheduled__2020-07-20T03:52:00+00:00, externally triggered: False>
[2020-07-22 14:48:40,188] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:51:00+00:00: scheduled__2020-07-20T03:51:00+00:00, externally triggered: False>
[2020-07-22 14:48:40,264] {logging_mixin.py:112} INFO - [2020-07-22 14:48:40,264] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:51:00+00:00: scheduled__2020-07-20T03:51:00+00:00, externally triggered: False> successful
[2020-07-22 14:48:41,399] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:52:00+00:00: scheduled__2020-07-20T03:52:00+00:00, externally triggered: False>
[2020-07-22 14:48:41,431] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:48:41,438] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:52:00+00:00 [scheduled]> in ORM
[2020-07-22 14:48:41,650] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.695 seconds
[2020-07-22 14:49:15,640] {scheduler_job.py:153} INFO - Started process (PID=454329) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:49:15,644] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:49:15,645] {logging_mixin.py:112} INFO - [2020-07-22 14:49:15,645] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:49:15,665] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:49:15,874] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:49:16,445] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:53:00+00:00: scheduled__2020-07-20T03:53:00+00:00, externally triggered: False>
[2020-07-22 14:49:16,460] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:52:00+00:00: scheduled__2020-07-20T03:52:00+00:00, externally triggered: False>
[2020-07-22 14:49:16,476] {logging_mixin.py:112} INFO - [2020-07-22 14:49:16,475] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:52:00+00:00: scheduled__2020-07-20T03:52:00+00:00, externally triggered: False> successful
[2020-07-22 14:49:16,588] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:53:00+00:00: scheduled__2020-07-20T03:53:00+00:00, externally triggered: False>
[2020-07-22 14:49:16,627] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:49:16,636] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:53:00+00:00 [scheduled]> in ORM
[2020-07-22 14:49:16,794] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.154 seconds
[2020-07-22 14:50:05,037] {scheduler_job.py:153} INFO - Started process (PID=455500) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:50:05,042] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:50:05,043] {logging_mixin.py:112} INFO - [2020-07-22 14:50:05,043] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:50:05,055] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:50:05,189] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:50:05,758] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:54:00+00:00: scheduled__2020-07-20T03:54:00+00:00, externally triggered: False>
[2020-07-22 14:50:05,763] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:53:00+00:00: scheduled__2020-07-20T03:53:00+00:00, externally triggered: False>
[2020-07-22 14:50:05,772] {logging_mixin.py:112} INFO - [2020-07-22 14:50:05,772] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:53:00+00:00: scheduled__2020-07-20T03:53:00+00:00, externally triggered: False> successful
[2020-07-22 14:50:05,880] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:54:00+00:00: scheduled__2020-07-20T03:54:00+00:00, externally triggered: False>
[2020-07-22 14:50:05,899] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:50:05,903] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:54:00+00:00 [scheduled]> in ORM
[2020-07-22 14:50:06,084] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.047 seconds
[2020-07-22 14:50:44,958] {scheduler_job.py:153} INFO - Started process (PID=456370) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:50:44,962] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:50:44,963] {logging_mixin.py:112} INFO - [2020-07-22 14:50:44,963] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:50:44,974] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:50:45,269] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:50:45,750] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:55:00+00:00: scheduled__2020-07-20T03:55:00+00:00, externally triggered: False>
[2020-07-22 14:50:45,756] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:54:00+00:00: scheduled__2020-07-20T03:54:00+00:00, externally triggered: False>
[2020-07-22 14:50:45,770] {logging_mixin.py:112} INFO - [2020-07-22 14:50:45,770] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:54:00+00:00: scheduled__2020-07-20T03:54:00+00:00, externally triggered: False> successful
[2020-07-22 14:50:46,016] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:55:00+00:00: scheduled__2020-07-20T03:55:00+00:00, externally triggered: False>
[2020-07-22 14:50:46,046] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:50:46,055] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:55:00+00:00 [scheduled]> in ORM
[2020-07-22 14:50:46,232] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.274 seconds
[2020-07-22 14:51:25,453] {scheduler_job.py:153} INFO - Started process (PID=457211) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:51:25,456] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:51:25,456] {logging_mixin.py:112} INFO - [2020-07-22 14:51:25,456] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:51:25,467] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:51:25,679] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:51:26,041] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:56:00+00:00: scheduled__2020-07-20T03:56:00+00:00, externally triggered: False>
[2020-07-22 14:51:26,045] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:55:00+00:00: scheduled__2020-07-20T03:55:00+00:00, externally triggered: False>
[2020-07-22 14:51:26,053] {logging_mixin.py:112} INFO - [2020-07-22 14:51:26,053] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:55:00+00:00: scheduled__2020-07-20T03:55:00+00:00, externally triggered: False> successful
[2020-07-22 14:51:26,163] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:56:00+00:00: scheduled__2020-07-20T03:56:00+00:00, externally triggered: False>
[2020-07-22 14:51:26,196] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:51:26,210] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:56:00+00:00 [scheduled]> in ORM
[2020-07-22 14:51:26,361] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.908 seconds
[2020-07-22 14:51:53,353] {scheduler_job.py:153} INFO - Started process (PID=457796) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:51:53,356] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:51:53,357] {logging_mixin.py:112} INFO - [2020-07-22 14:51:53,357] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:51:53,368] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:51:53,504] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:51:53,869] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:57:00+00:00: scheduled__2020-07-20T03:57:00+00:00, externally triggered: False>
[2020-07-22 14:51:53,874] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:56:00+00:00: scheduled__2020-07-20T03:56:00+00:00, externally triggered: False>
[2020-07-22 14:51:53,890] {logging_mixin.py:112} INFO - [2020-07-22 14:51:53,890] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:56:00+00:00: scheduled__2020-07-20T03:56:00+00:00, externally triggered: False> failed
[2020-07-22 14:51:54,009] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:57:00+00:00: scheduled__2020-07-20T03:57:00+00:00, externally triggered: False>
[2020-07-22 14:51:54,028] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:51:54,035] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:57:00+00:00 [scheduled]> in ORM
[2020-07-22 14:51:54,175] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.822 seconds
[2020-07-22 14:52:26,893] {scheduler_job.py:153} INFO - Started process (PID=458517) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:52:26,896] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:52:26,896] {logging_mixin.py:112} INFO - [2020-07-22 14:52:26,896] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:52:26,905] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:52:27,053] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:52:27,383] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:58:00+00:00: scheduled__2020-07-20T03:58:00+00:00, externally triggered: False>
[2020-07-22 14:52:27,387] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:57:00+00:00: scheduled__2020-07-20T03:57:00+00:00, externally triggered: False>
[2020-07-22 14:52:27,395] {logging_mixin.py:112} INFO - [2020-07-22 14:52:27,395] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:57:00+00:00: scheduled__2020-07-20T03:57:00+00:00, externally triggered: False> failed
[2020-07-22 14:52:27,511] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:58:00+00:00: scheduled__2020-07-20T03:58:00+00:00, externally triggered: False>
[2020-07-22 14:52:27,529] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:22:15.633481+00:00: manual__2020-07-22T09:22:15.633481+00:00, externally triggered: True>
[2020-07-22 14:52:27,555] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:52:27,562] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:58:00+00:00 [scheduled]> in ORM
[2020-07-22 14:52:27,569] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 09:22:15.633481+00:00 [scheduled]> in ORM
[2020-07-22 14:52:27,756] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.863 seconds
[2020-07-22 14:53:21,002] {scheduler_job.py:153} INFO - Started process (PID=459693) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:53:21,010] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:53:21,011] {logging_mixin.py:112} INFO - [2020-07-22 14:53:21,011] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:53:21,031] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:53:21,188] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:53:21,574] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T03:59:00+00:00: scheduled__2020-07-20T03:59:00+00:00, externally triggered: False>
[2020-07-22 14:53:21,579] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:58:00+00:00: scheduled__2020-07-20T03:58:00+00:00, externally triggered: False>
[2020-07-22 14:53:21,590] {logging_mixin.py:112} INFO - [2020-07-22 14:53:21,590] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:58:00+00:00: scheduled__2020-07-20T03:58:00+00:00, externally triggered: False> failed
[2020-07-22 14:53:21,704] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:59:00+00:00: scheduled__2020-07-20T03:59:00+00:00, externally triggered: False>
[2020-07-22 14:53:21,719] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:22:15.633481+00:00: manual__2020-07-22T09:22:15.633481+00:00, externally triggered: True>
[2020-07-22 14:53:21,733] {logging_mixin.py:112} INFO - [2020-07-22 14:53:21,732] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-22 09:22:15.633481+00:00: manual__2020-07-22T09:22:15.633481+00:00, externally triggered: True> failed
[2020-07-22 14:53:21,844] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:53:21,855] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 03:59:00+00:00 [scheduled]> in ORM
[2020-07-22 14:53:22,098] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.096 seconds
[2020-07-22 14:53:56,716] {scheduler_job.py:153} INFO - Started process (PID=460439) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:53:56,720] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:53:56,721] {logging_mixin.py:112} INFO - [2020-07-22 14:53:56,721] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:53:56,734] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:53:56,880] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:53:57,251] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:00:00+00:00: scheduled__2020-07-20T04:00:00+00:00, externally triggered: False>
[2020-07-22 14:53:57,256] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 03:59:00+00:00: scheduled__2020-07-20T03:59:00+00:00, externally triggered: False>
[2020-07-22 14:53:57,264] {logging_mixin.py:112} INFO - [2020-07-22 14:53:57,264] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 03:59:00+00:00: scheduled__2020-07-20T03:59:00+00:00, externally triggered: False> failed
[2020-07-22 14:53:57,373] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:00:00+00:00: scheduled__2020-07-20T04:00:00+00:00, externally triggered: False>
[2020-07-22 14:53:57,392] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:53:57,396] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:00:00+00:00 [scheduled]> in ORM
[2020-07-22 14:53:57,540] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.824 seconds
[2020-07-22 14:54:32,076] {scheduler_job.py:153} INFO - Started process (PID=461214) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:54:32,078] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:54:32,079] {logging_mixin.py:112} INFO - [2020-07-22 14:54:32,079] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:54:32,088] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:54:32,196] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:54:32,578] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:01:00+00:00: scheduled__2020-07-20T04:01:00+00:00, externally triggered: False>
[2020-07-22 14:54:32,582] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:00:00+00:00: scheduled__2020-07-20T04:00:00+00:00, externally triggered: False>
[2020-07-22 14:54:32,589] {logging_mixin.py:112} INFO - [2020-07-22 14:54:32,589] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:00:00+00:00: scheduled__2020-07-20T04:00:00+00:00, externally triggered: False> failed
[2020-07-22 14:54:32,698] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:01:00+00:00: scheduled__2020-07-20T04:01:00+00:00, externally triggered: False>
[2020-07-22 14:54:32,720] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:54:32,724] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:01:00+00:00 [scheduled]> in ORM
[2020-07-22 14:54:32,865] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.789 seconds
[2020-07-22 14:55:07,375] {scheduler_job.py:153} INFO - Started process (PID=462006) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:55:07,378] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:55:07,379] {logging_mixin.py:112} INFO - [2020-07-22 14:55:07,379] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:55:07,390] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:55:07,506] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:55:07,835] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:02:00+00:00: scheduled__2020-07-20T04:02:00+00:00, externally triggered: False>
[2020-07-22 14:55:07,838] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:01:00+00:00: scheduled__2020-07-20T04:01:00+00:00, externally triggered: False>
[2020-07-22 14:55:07,845] {logging_mixin.py:112} INFO - [2020-07-22 14:55:07,845] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:01:00+00:00: scheduled__2020-07-20T04:01:00+00:00, externally triggered: False> successful
[2020-07-22 14:55:07,956] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:02:00+00:00: scheduled__2020-07-20T04:02:00+00:00, externally triggered: False>
[2020-07-22 14:55:07,975] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:24:53.790602+00:00: manual__2020-07-22T09:24:53.790602+00:00, externally triggered: True>
[2020-07-22 14:55:08,004] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:55:08,011] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:02:00+00:00 [scheduled]> in ORM
[2020-07-22 14:55:08,019] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 09:24:53.790602+00:00 [scheduled]> in ORM
[2020-07-22 14:55:08,243] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.869 seconds
[2020-07-22 14:55:54,128] {scheduler_job.py:153} INFO - Started process (PID=463074) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:55:54,131] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:55:54,131] {logging_mixin.py:112} INFO - [2020-07-22 14:55:54,131] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:55:54,141] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:55:54,371] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:55:54,721] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:03:00+00:00: scheduled__2020-07-20T04:03:00+00:00, externally triggered: False>
[2020-07-22 14:55:54,725] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:02:00+00:00: scheduled__2020-07-20T04:02:00+00:00, externally triggered: False>
[2020-07-22 14:55:54,733] {logging_mixin.py:112} INFO - [2020-07-22 14:55:54,733] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:02:00+00:00: scheduled__2020-07-20T04:02:00+00:00, externally triggered: False> successful
[2020-07-22 14:55:54,870] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:03:00+00:00: scheduled__2020-07-20T04:03:00+00:00, externally triggered: False>
[2020-07-22 14:55:54,888] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:24:53.790602+00:00: manual__2020-07-22T09:24:53.790602+00:00, externally triggered: True>
[2020-07-22 14:55:54,908] {logging_mixin.py:112} INFO - [2020-07-22 14:55:54,907] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-22 09:24:53.790602+00:00: manual__2020-07-22T09:24:53.790602+00:00, externally triggered: True> successful
[2020-07-22 14:55:55,043] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:55:55,050] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:03:00+00:00 [scheduled]> in ORM
[2020-07-22 14:55:55,213] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.085 seconds
[2020-07-22 14:56:23,538] {scheduler_job.py:153} INFO - Started process (PID=463765) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:56:23,543] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:56:23,544] {logging_mixin.py:112} INFO - [2020-07-22 14:56:23,544] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:56:23,561] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:56:23,710] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:56:24,118] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:04:00+00:00: scheduled__2020-07-20T04:04:00+00:00, externally triggered: False>
[2020-07-22 14:56:24,121] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:03:00+00:00: scheduled__2020-07-20T04:03:00+00:00, externally triggered: False>
[2020-07-22 14:56:24,130] {logging_mixin.py:112} INFO - [2020-07-22 14:56:24,130] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:03:00+00:00: scheduled__2020-07-20T04:03:00+00:00, externally triggered: False> successful
[2020-07-22 14:56:24,249] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:04:00+00:00: scheduled__2020-07-20T04:04:00+00:00, externally triggered: False>
[2020-07-22 14:56:24,262] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:56:24,266] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:04:00+00:00 [scheduled]> in ORM
[2020-07-22 14:56:24,414] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.876 seconds
[2020-07-22 14:56:59,357] {scheduler_job.py:153} INFO - Started process (PID=464517) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:56:59,362] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:56:59,362] {logging_mixin.py:112} INFO - [2020-07-22 14:56:59,362] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:56:59,378] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:56:59,615] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:57:00,013] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:05:00+00:00: scheduled__2020-07-20T04:05:00+00:00, externally triggered: False>
[2020-07-22 14:57:00,028] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:04:00+00:00: scheduled__2020-07-20T04:04:00+00:00, externally triggered: False>
[2020-07-22 14:57:00,121] {logging_mixin.py:112} INFO - [2020-07-22 14:57:00,121] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:04:00+00:00: scheduled__2020-07-20T04:04:00+00:00, externally triggered: False> successful
[2020-07-22 14:57:00,274] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:05:00+00:00: scheduled__2020-07-20T04:05:00+00:00, externally triggered: False>
[2020-07-22 14:57:00,380] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:57:00,425] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:05:00+00:00 [scheduled]> in ORM
[2020-07-22 14:57:00,586] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.230 seconds
[2020-07-22 14:57:38,220] {scheduler_job.py:153} INFO - Started process (PID=465412) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:57:38,224] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:57:38,225] {logging_mixin.py:112} INFO - [2020-07-22 14:57:38,225] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:57:38,239] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:57:38,541] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:57:38,876] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:06:00+00:00: scheduled__2020-07-20T04:06:00+00:00, externally triggered: False>
[2020-07-22 14:57:38,880] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:05:00+00:00: scheduled__2020-07-20T04:05:00+00:00, externally triggered: False>
[2020-07-22 14:57:38,893] {logging_mixin.py:112} INFO - [2020-07-22 14:57:38,893] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:05:00+00:00: scheduled__2020-07-20T04:05:00+00:00, externally triggered: False> successful
[2020-07-22 14:57:39,043] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:06:00+00:00: scheduled__2020-07-20T04:06:00+00:00, externally triggered: False>
[2020-07-22 14:57:39,071] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:57:39,079] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:06:00+00:00 [scheduled]> in ORM
[2020-07-22 14:57:39,334] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.114 seconds
[2020-07-22 14:58:29,588] {scheduler_job.py:153} INFO - Started process (PID=466421) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:58:29,605] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:58:29,606] {logging_mixin.py:112} INFO - [2020-07-22 14:58:29,605] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:58:29,618] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:58:29,744] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:58:30,218] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:07:00+00:00: scheduled__2020-07-20T04:07:00+00:00, externally triggered: False>
[2020-07-22 14:58:30,257] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:06:00+00:00: scheduled__2020-07-20T04:06:00+00:00, externally triggered: False>
[2020-07-22 14:58:30,285] {logging_mixin.py:112} INFO - [2020-07-22 14:58:30,285] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:06:00+00:00: scheduled__2020-07-20T04:06:00+00:00, externally triggered: False> successful
[2020-07-22 14:58:30,402] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:07:00+00:00: scheduled__2020-07-20T04:07:00+00:00, externally triggered: False>
[2020-07-22 14:58:30,441] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:58:30,449] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:07:00+00:00 [scheduled]> in ORM
[2020-07-22 14:58:30,659] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.071 seconds
[2020-07-22 14:59:46,653] {scheduler_job.py:153} INFO - Started process (PID=467800) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:59:46,656] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 14:59:46,656] {logging_mixin.py:112} INFO - [2020-07-22 14:59:46,656] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:59:46,671] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 14:59:46,812] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 14:59:47,141] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:08:00+00:00: scheduled__2020-07-20T04:08:00+00:00, externally triggered: False>
[2020-07-22 14:59:47,147] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:07:00+00:00: scheduled__2020-07-20T04:07:00+00:00, externally triggered: False>
[2020-07-22 14:59:47,161] {logging_mixin.py:112} INFO - [2020-07-22 14:59:47,161] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:07:00+00:00: scheduled__2020-07-20T04:07:00+00:00, externally triggered: False> successful
[2020-07-22 14:59:47,274] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:08:00+00:00: scheduled__2020-07-20T04:08:00+00:00, externally triggered: False>
[2020-07-22 14:59:47,294] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 14:59:47,298] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:08:00+00:00 [scheduled]> in ORM
[2020-07-22 14:59:47,452] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.799 seconds
[2020-07-22 15:00:47,035] {scheduler_job.py:153} INFO - Started process (PID=468979) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:00:47,046] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:00:47,046] {logging_mixin.py:112} INFO - [2020-07-22 15:00:47,046] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:00:47,056] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:00:47,169] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:00:47,566] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:09:00+00:00: scheduled__2020-07-20T04:09:00+00:00, externally triggered: False>
[2020-07-22 15:00:47,571] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:08:00+00:00: scheduled__2020-07-20T04:08:00+00:00, externally triggered: False>
[2020-07-22 15:00:47,579] {logging_mixin.py:112} INFO - [2020-07-22 15:00:47,579] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:08:00+00:00: scheduled__2020-07-20T04:08:00+00:00, externally triggered: False> successful
[2020-07-22 15:00:47,689] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:09:00+00:00: scheduled__2020-07-20T04:09:00+00:00, externally triggered: False>
[2020-07-22 15:00:47,706] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:00:47,710] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:09:00+00:00 [scheduled]> in ORM
[2020-07-22 15:00:47,853] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.818 seconds
[2020-07-22 15:01:23,469] {scheduler_job.py:153} INFO - Started process (PID=469774) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:01:23,475] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:01:23,476] {logging_mixin.py:112} INFO - [2020-07-22 15:01:23,475] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:01:23,485] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:01:23,604] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:01:24,005] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:10:00+00:00: scheduled__2020-07-20T04:10:00+00:00, externally triggered: False>
[2020-07-22 15:01:24,008] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:09:00+00:00: scheduled__2020-07-20T04:09:00+00:00, externally triggered: False>
[2020-07-22 15:01:24,020] {logging_mixin.py:112} INFO - [2020-07-22 15:01:24,020] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:09:00+00:00: scheduled__2020-07-20T04:09:00+00:00, externally triggered: False> successful
[2020-07-22 15:01:24,126] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:10:00+00:00: scheduled__2020-07-20T04:10:00+00:00, externally triggered: False>
[2020-07-22 15:01:24,140] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:01:24,144] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:10:00+00:00 [scheduled]> in ORM
[2020-07-22 15:01:24,293] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.824 seconds
[2020-07-22 15:01:58,207] {scheduler_job.py:153} INFO - Started process (PID=470543) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:01:58,210] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:01:58,211] {logging_mixin.py:112} INFO - [2020-07-22 15:01:58,211] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:01:58,224] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:01:58,403] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:01:58,857] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:11:00+00:00: scheduled__2020-07-20T04:11:00+00:00, externally triggered: False>
[2020-07-22 15:01:58,863] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:10:00+00:00: scheduled__2020-07-20T04:10:00+00:00, externally triggered: False>
[2020-07-22 15:01:58,870] {logging_mixin.py:112} INFO - [2020-07-22 15:01:58,870] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:10:00+00:00: scheduled__2020-07-20T04:10:00+00:00, externally triggered: False> successful
[2020-07-22 15:01:58,960] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:11:00+00:00: scheduled__2020-07-20T04:11:00+00:00, externally triggered: False>
[2020-07-22 15:01:58,977] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:01:58,981] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:11:00+00:00 [scheduled]> in ORM
[2020-07-22 15:01:59,118] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.910 seconds
[2020-07-22 15:02:34,849] {scheduler_job.py:153} INFO - Started process (PID=471318) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:02:34,854] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:02:34,855] {logging_mixin.py:112} INFO - [2020-07-22 15:02:34,855] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:02:34,868] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:02:35,052] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:02:35,375] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:12:00+00:00: scheduled__2020-07-20T04:12:00+00:00, externally triggered: False>
[2020-07-22 15:02:35,382] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:11:00+00:00: scheduled__2020-07-20T04:11:00+00:00, externally triggered: False>
[2020-07-22 15:02:35,398] {logging_mixin.py:112} INFO - [2020-07-22 15:02:35,398] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:11:00+00:00: scheduled__2020-07-20T04:11:00+00:00, externally triggered: False> successful
[2020-07-22 15:02:35,552] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:12:00+00:00: scheduled__2020-07-20T04:12:00+00:00, externally triggered: False>
[2020-07-22 15:02:35,575] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:02:35,582] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:12:00+00:00 [scheduled]> in ORM
[2020-07-22 15:02:35,740] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.891 seconds
[2020-07-22 15:03:10,232] {scheduler_job.py:153} INFO - Started process (PID=472077) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:03:10,235] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:03:10,236] {logging_mixin.py:112} INFO - [2020-07-22 15:03:10,236] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:03:10,244] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:03:10,390] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:03:10,816] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:13:00+00:00: scheduled__2020-07-20T04:13:00+00:00, externally triggered: False>
[2020-07-22 15:03:10,820] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:12:00+00:00: scheduled__2020-07-20T04:12:00+00:00, externally triggered: False>
[2020-07-22 15:03:10,827] {logging_mixin.py:112} INFO - [2020-07-22 15:03:10,827] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:12:00+00:00: scheduled__2020-07-20T04:12:00+00:00, externally triggered: False> successful
[2020-07-22 15:03:11,202] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:13:00+00:00: scheduled__2020-07-20T04:13:00+00:00, externally triggered: False>
[2020-07-22 15:03:11,221] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:03:11,225] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:13:00+00:00 [scheduled]> in ORM
[2020-07-22 15:03:11,532] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.300 seconds
[2020-07-22 15:03:52,320] {scheduler_job.py:153} INFO - Started process (PID=472969) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:03:52,324] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:03:52,324] {logging_mixin.py:112} INFO - [2020-07-22 15:03:52,324] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:03:52,336] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:03:52,456] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:03:52,858] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:14:00+00:00: scheduled__2020-07-20T04:14:00+00:00, externally triggered: False>
[2020-07-22 15:03:52,862] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:13:00+00:00: scheduled__2020-07-20T04:13:00+00:00, externally triggered: False>
[2020-07-22 15:03:52,869] {logging_mixin.py:112} INFO - [2020-07-22 15:03:52,869] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:13:00+00:00: scheduled__2020-07-20T04:13:00+00:00, externally triggered: False> successful
[2020-07-22 15:03:52,979] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:14:00+00:00: scheduled__2020-07-20T04:14:00+00:00, externally triggered: False>
[2020-07-22 15:03:52,998] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:03:53,002] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:14:00+00:00 [scheduled]> in ORM
[2020-07-22 15:03:53,147] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.827 seconds
[2020-07-22 15:04:34,750] {scheduler_job.py:153} INFO - Started process (PID=473853) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:04:34,755] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:04:34,756] {logging_mixin.py:112} INFO - [2020-07-22 15:04:34,756] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:04:34,773] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:04:34,955] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:04:35,272] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:15:00+00:00: scheduled__2020-07-20T04:15:00+00:00, externally triggered: False>
[2020-07-22 15:04:35,275] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:14:00+00:00: scheduled__2020-07-20T04:14:00+00:00, externally triggered: False>
[2020-07-22 15:04:35,282] {logging_mixin.py:112} INFO - [2020-07-22 15:04:35,282] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:14:00+00:00: scheduled__2020-07-20T04:14:00+00:00, externally triggered: False> successful
[2020-07-22 15:04:35,437] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:15:00+00:00: scheduled__2020-07-20T04:15:00+00:00, externally triggered: False>
[2020-07-22 15:04:35,451] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:04:35,455] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:15:00+00:00 [scheduled]> in ORM
[2020-07-22 15:04:35,727] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.978 seconds
[2020-07-22 15:05:04,605] {scheduler_job.py:153} INFO - Started process (PID=474573) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:05:04,609] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:05:04,609] {logging_mixin.py:112} INFO - [2020-07-22 15:05:04,609] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:05:04,620] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:05:04,753] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:05:05,159] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:16:00+00:00: scheduled__2020-07-20T04:16:00+00:00, externally triggered: False>
[2020-07-22 15:05:05,164] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:15:00+00:00: scheduled__2020-07-20T04:15:00+00:00, externally triggered: False>
[2020-07-22 15:05:05,176] {logging_mixin.py:112} INFO - [2020-07-22 15:05:05,176] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:15:00+00:00: scheduled__2020-07-20T04:15:00+00:00, externally triggered: False> successful
[2020-07-22 15:05:05,350] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:16:00+00:00: scheduled__2020-07-20T04:16:00+00:00, externally triggered: False>
[2020-07-22 15:05:05,374] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:05:05,381] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:16:00+00:00 [scheduled]> in ORM
[2020-07-22 15:05:05,585] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.980 seconds
[2020-07-22 15:05:34,327] {scheduler_job.py:153} INFO - Started process (PID=475220) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:05:34,332] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:05:34,333] {logging_mixin.py:112} INFO - [2020-07-22 15:05:34,333] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:05:34,365] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:05:34,611] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:05:34,979] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:17:00+00:00: scheduled__2020-07-20T04:17:00+00:00, externally triggered: False>
[2020-07-22 15:05:35,026] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:16:00+00:00: scheduled__2020-07-20T04:16:00+00:00, externally triggered: False>
[2020-07-22 15:05:35,082] {logging_mixin.py:112} INFO - [2020-07-22 15:05:35,082] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:16:00+00:00: scheduled__2020-07-20T04:16:00+00:00, externally triggered: False> successful
[2020-07-22 15:05:35,230] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:17:00+00:00: scheduled__2020-07-20T04:17:00+00:00, externally triggered: False>
[2020-07-22 15:05:35,253] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:05:35,261] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:17:00+00:00 [scheduled]> in ORM
[2020-07-22 15:05:36,130] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.812 seconds
[2020-07-22 15:06:06,385] {scheduler_job.py:153} INFO - Started process (PID=475910) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:06:06,389] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:06:06,389] {logging_mixin.py:112} INFO - [2020-07-22 15:06:06,389] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:06:06,399] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:06:06,553] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:06:06,942] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:18:00+00:00: scheduled__2020-07-20T04:18:00+00:00, externally triggered: False>
[2020-07-22 15:06:06,947] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:17:00+00:00: scheduled__2020-07-20T04:17:00+00:00, externally triggered: False>
[2020-07-22 15:06:06,957] {logging_mixin.py:112} INFO - [2020-07-22 15:06:06,957] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:17:00+00:00: scheduled__2020-07-20T04:17:00+00:00, externally triggered: False> failed
[2020-07-22 15:06:07,133] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:18:00+00:00: scheduled__2020-07-20T04:18:00+00:00, externally triggered: False>
[2020-07-22 15:06:07,158] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:06:07,166] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:18:00+00:00 [scheduled]> in ORM
[2020-07-22 15:06:07,302] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.917 seconds
[2020-07-22 15:06:48,143] {scheduler_job.py:153} INFO - Started process (PID=476798) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:06:48,146] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:06:48,146] {logging_mixin.py:112} INFO - [2020-07-22 15:06:48,146] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:06:48,155] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:06:48,275] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:06:48,874] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:19:00+00:00: scheduled__2020-07-20T04:19:00+00:00, externally triggered: False>
[2020-07-22 15:06:48,881] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:18:00+00:00: scheduled__2020-07-20T04:18:00+00:00, externally triggered: False>
[2020-07-22 15:06:48,892] {logging_mixin.py:112} INFO - [2020-07-22 15:06:48,892] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:18:00+00:00: scheduled__2020-07-20T04:18:00+00:00, externally triggered: False> successful
[2020-07-22 15:06:49,059] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:19:00+00:00: scheduled__2020-07-20T04:19:00+00:00, externally triggered: False>
[2020-07-22 15:06:49,084] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:36:15.319988+00:00: manual__2020-07-22T09:36:15.319988+00:00, externally triggered: True>
[2020-07-22 15:06:49,118] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:06:49,127] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:19:00+00:00 [scheduled]> in ORM
[2020-07-22 15:06:49,139] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 09:36:15.319988+00:00 [scheduled]> in ORM
[2020-07-22 15:06:49,314] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.170 seconds
[2020-07-22 15:07:41,389] {scheduler_job.py:153} INFO - Started process (PID=477904) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:07:41,392] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:07:41,393] {logging_mixin.py:112} INFO - [2020-07-22 15:07:41,393] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:07:41,402] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:07:41,526] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:07:41,840] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:20:00+00:00: scheduled__2020-07-20T04:20:00+00:00, externally triggered: False>
[2020-07-22 15:07:41,844] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:19:00+00:00: scheduled__2020-07-20T04:19:00+00:00, externally triggered: False>
[2020-07-22 15:07:41,853] {logging_mixin.py:112} INFO - [2020-07-22 15:07:41,853] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:19:00+00:00: scheduled__2020-07-20T04:19:00+00:00, externally triggered: False> successful
[2020-07-22 15:07:41,950] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:20:00+00:00: scheduled__2020-07-20T04:20:00+00:00, externally triggered: False>
[2020-07-22 15:07:41,966] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:36:15.319988+00:00: manual__2020-07-22T09:36:15.319988+00:00, externally triggered: True>
[2020-07-22 15:07:41,974] {logging_mixin.py:112} INFO - [2020-07-22 15:07:41,974] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-22 09:36:15.319988+00:00: manual__2020-07-22T09:36:15.319988+00:00, externally triggered: True> successful
[2020-07-22 15:07:42,091] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:07:42,095] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:20:00+00:00 [scheduled]> in ORM
[2020-07-22 15:07:42,239] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.851 seconds
[2020-07-22 15:08:18,083] {scheduler_job.py:153} INFO - Started process (PID=478779) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:08:18,086] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:08:18,087] {logging_mixin.py:112} INFO - [2020-07-22 15:08:18,087] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:08:18,097] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:08:18,215] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:08:18,581] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:21:00+00:00: scheduled__2020-07-20T04:21:00+00:00, externally triggered: False>
[2020-07-22 15:08:18,584] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:20:00+00:00: scheduled__2020-07-20T04:20:00+00:00, externally triggered: False>
[2020-07-22 15:08:18,593] {logging_mixin.py:112} INFO - [2020-07-22 15:08:18,592] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:20:00+00:00: scheduled__2020-07-20T04:20:00+00:00, externally triggered: False> successful
[2020-07-22 15:08:18,697] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:21:00+00:00: scheduled__2020-07-20T04:21:00+00:00, externally triggered: False>
[2020-07-22 15:08:18,717] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:08:18,721] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:21:00+00:00 [scheduled]> in ORM
[2020-07-22 15:08:18,872] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.789 seconds
[2020-07-22 15:08:58,729] {scheduler_job.py:153} INFO - Started process (PID=479625) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:08:58,732] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:08:58,733] {logging_mixin.py:112} INFO - [2020-07-22 15:08:58,732] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:08:58,741] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:08:59,106] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:08:59,496] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:22:00+00:00: scheduled__2020-07-20T04:22:00+00:00, externally triggered: False>
[2020-07-22 15:08:59,502] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:21:00+00:00: scheduled__2020-07-20T04:21:00+00:00, externally triggered: False>
[2020-07-22 15:08:59,515] {logging_mixin.py:112} INFO - [2020-07-22 15:08:59,515] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:21:00+00:00: scheduled__2020-07-20T04:21:00+00:00, externally triggered: False> successful
[2020-07-22 15:08:59,622] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:22:00+00:00: scheduled__2020-07-20T04:22:00+00:00, externally triggered: False>
[2020-07-22 15:08:59,641] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:08:59,645] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:22:00+00:00 [scheduled]> in ORM
[2020-07-22 15:08:59,786] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.057 seconds
[2020-07-22 15:09:33,407] {scheduler_job.py:153} INFO - Started process (PID=480412) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:09:33,411] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:09:33,411] {logging_mixin.py:112} INFO - [2020-07-22 15:09:33,411] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:09:33,420] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:09:33,543] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:09:33,861] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:23:00+00:00: scheduled__2020-07-20T04:23:00+00:00, externally triggered: False>
[2020-07-22 15:09:33,866] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:22:00+00:00: scheduled__2020-07-20T04:22:00+00:00, externally triggered: False>
[2020-07-22 15:09:33,878] {logging_mixin.py:112} INFO - [2020-07-22 15:09:33,878] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:22:00+00:00: scheduled__2020-07-20T04:22:00+00:00, externally triggered: False> successful
[2020-07-22 15:09:34,024] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:23:00+00:00: scheduled__2020-07-20T04:23:00+00:00, externally triggered: False>
[2020-07-22 15:09:34,037] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:09:34,042] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:23:00+00:00 [scheduled]> in ORM
[2020-07-22 15:09:34,226] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.819 seconds
[2020-07-22 15:10:13,360] {scheduler_job.py:153} INFO - Started process (PID=481207) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:10:13,367] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:10:13,369] {logging_mixin.py:112} INFO - [2020-07-22 15:10:13,368] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:10:13,384] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:10:13,500] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:10:13,871] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:24:00+00:00: scheduled__2020-07-20T04:24:00+00:00, externally triggered: False>
[2020-07-22 15:10:13,875] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:23:00+00:00: scheduled__2020-07-20T04:23:00+00:00, externally triggered: False>
[2020-07-22 15:10:13,893] {logging_mixin.py:112} INFO - [2020-07-22 15:10:13,893] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:23:00+00:00: scheduled__2020-07-20T04:23:00+00:00, externally triggered: False> successful
[2020-07-22 15:10:14,004] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:24:00+00:00: scheduled__2020-07-20T04:24:00+00:00, externally triggered: False>
[2020-07-22 15:10:14,013] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:40:01.412185+00:00: manual__2020-07-22T09:40:01.412185+00:00, externally triggered: True>
[2020-07-22 15:10:14,031] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:10:14,036] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:24:00+00:00 [scheduled]> in ORM
[2020-07-22 15:10:14,040] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 09:40:01.412185+00:00 [scheduled]> in ORM
[2020-07-22 15:10:14,182] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.821 seconds
[2020-07-22 15:11:11,728] {scheduler_job.py:153} INFO - Started process (PID=482459) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:11:11,730] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:11:11,731] {logging_mixin.py:112} INFO - [2020-07-22 15:11:11,731] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:11:11,742] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:11:12,077] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:11:12,843] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:25:00+00:00: scheduled__2020-07-20T04:25:00+00:00, externally triggered: False>
[2020-07-22 15:11:12,850] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:24:00+00:00: scheduled__2020-07-20T04:24:00+00:00, externally triggered: False>
[2020-07-22 15:11:12,868] {logging_mixin.py:112} INFO - [2020-07-22 15:11:12,867] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:24:00+00:00: scheduled__2020-07-20T04:24:00+00:00, externally triggered: False> successful
[2020-07-22 15:11:13,241] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:25:00+00:00: scheduled__2020-07-20T04:25:00+00:00, externally triggered: False>
[2020-07-22 15:11:13,253] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 09:40:01.412185+00:00: manual__2020-07-22T09:40:01.412185+00:00, externally triggered: True>
[2020-07-22 15:11:13,262] {logging_mixin.py:112} INFO - [2020-07-22 15:11:13,262] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-22 09:40:01.412185+00:00: manual__2020-07-22T09:40:01.412185+00:00, externally triggered: True> successful
[2020-07-22 15:11:13,601] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:11:13,619] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:25:00+00:00 [scheduled]> in ORM
[2020-07-22 15:11:13,851] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.123 seconds
[2020-07-22 15:12:02,598] {scheduler_job.py:153} INFO - Started process (PID=483245) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:12:02,668] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:12:02,669] {logging_mixin.py:112} INFO - [2020-07-22 15:12:02,669] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:12:02,680] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:12:02,821] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:12:03,273] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:26:00+00:00: scheduled__2020-07-20T04:26:00+00:00, externally triggered: False>
[2020-07-22 15:12:03,280] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:25:00+00:00: scheduled__2020-07-20T04:25:00+00:00, externally triggered: False>
[2020-07-22 15:12:03,301] {logging_mixin.py:112} INFO - [2020-07-22 15:12:03,301] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:25:00+00:00: scheduled__2020-07-20T04:25:00+00:00, externally triggered: False> successful
[2020-07-22 15:12:03,411] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:26:00+00:00: scheduled__2020-07-20T04:26:00+00:00, externally triggered: False>
[2020-07-22 15:12:03,429] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:12:03,434] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:26:00+00:00 [scheduled]> in ORM
[2020-07-22 15:12:03,632] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.034 seconds
[2020-07-22 15:12:58,189] {scheduler_job.py:153} INFO - Started process (PID=484339) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:12:58,193] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:12:58,194] {logging_mixin.py:112} INFO - [2020-07-22 15:12:58,194] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:12:58,202] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:12:58,324] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:12:58,633] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:27:00+00:00: scheduled__2020-07-20T04:27:00+00:00, externally triggered: False>
[2020-07-22 15:12:58,639] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:26:00+00:00: scheduled__2020-07-20T04:26:00+00:00, externally triggered: False>
[2020-07-22 15:12:58,654] {logging_mixin.py:112} INFO - [2020-07-22 15:12:58,654] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:26:00+00:00: scheduled__2020-07-20T04:26:00+00:00, externally triggered: False> successful
[2020-07-22 15:12:58,804] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:27:00+00:00: scheduled__2020-07-20T04:27:00+00:00, externally triggered: False>
[2020-07-22 15:12:58,828] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:12:58,835] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:27:00+00:00 [scheduled]> in ORM
[2020-07-22 15:12:59,161] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.972 seconds
[2020-07-22 15:13:34,288] {scheduler_job.py:153} INFO - Started process (PID=485167) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:13:34,293] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:13:34,293] {logging_mixin.py:112} INFO - [2020-07-22 15:13:34,293] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:13:34,306] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:13:34,544] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:13:34,872] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:28:00+00:00: scheduled__2020-07-20T04:28:00+00:00, externally triggered: False>
[2020-07-22 15:13:34,879] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:27:00+00:00: scheduled__2020-07-20T04:27:00+00:00, externally triggered: False>
[2020-07-22 15:13:34,893] {logging_mixin.py:112} INFO - [2020-07-22 15:13:34,893] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:27:00+00:00: scheduled__2020-07-20T04:27:00+00:00, externally triggered: False> successful
[2020-07-22 15:13:34,995] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:28:00+00:00: scheduled__2020-07-20T04:28:00+00:00, externally triggered: False>
[2020-07-22 15:13:35,015] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:13:35,020] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:28:00+00:00 [scheduled]> in ORM
[2020-07-22 15:13:35,163] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.875 seconds
[2020-07-22 15:14:15,805] {scheduler_job.py:153} INFO - Started process (PID=486040) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:14:15,808] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:14:15,809] {logging_mixin.py:112} INFO - [2020-07-22 15:14:15,809] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:14:15,818] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:14:16,071] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:14:16,526] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:29:00+00:00: scheduled__2020-07-20T04:29:00+00:00, externally triggered: False>
[2020-07-22 15:14:16,533] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:28:00+00:00: scheduled__2020-07-20T04:28:00+00:00, externally triggered: False>
[2020-07-22 15:14:16,543] {logging_mixin.py:112} INFO - [2020-07-22 15:14:16,543] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:28:00+00:00: scheduled__2020-07-20T04:28:00+00:00, externally triggered: False> successful
[2020-07-22 15:14:16,687] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:29:00+00:00: scheduled__2020-07-20T04:29:00+00:00, externally triggered: False>
[2020-07-22 15:14:16,705] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:14:16,709] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:29:00+00:00 [scheduled]> in ORM
[2020-07-22 15:14:16,844] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.039 seconds
[2020-07-22 15:14:46,959] {scheduler_job.py:153} INFO - Started process (PID=486721) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:14:46,964] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:14:46,965] {logging_mixin.py:112} INFO - [2020-07-22 15:14:46,965] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:14:46,994] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:14:47,158] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:14:47,851] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:30:00+00:00: scheduled__2020-07-20T04:30:00+00:00, externally triggered: False>
[2020-07-22 15:14:47,869] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:29:00+00:00: scheduled__2020-07-20T04:29:00+00:00, externally triggered: False>
[2020-07-22 15:14:47,887] {logging_mixin.py:112} INFO - [2020-07-22 15:14:47,887] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:29:00+00:00: scheduled__2020-07-20T04:29:00+00:00, externally triggered: False> successful
[2020-07-22 15:14:48,222] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:30:00+00:00: scheduled__2020-07-20T04:30:00+00:00, externally triggered: False>
[2020-07-22 15:14:48,290] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:14:48,308] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:30:00+00:00 [scheduled]> in ORM
[2020-07-22 15:14:48,545] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.585 seconds
[2020-07-22 15:15:23,533] {scheduler_job.py:153} INFO - Started process (PID=487481) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:15:23,541] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:15:23,543] {logging_mixin.py:112} INFO - [2020-07-22 15:15:23,542] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:15:23,562] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:15:23,782] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:15:24,173] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:31:00+00:00: scheduled__2020-07-20T04:31:00+00:00, externally triggered: False>
[2020-07-22 15:15:24,178] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:30:00+00:00: scheduled__2020-07-20T04:30:00+00:00, externally triggered: False>
[2020-07-22 15:15:24,190] {logging_mixin.py:112} INFO - [2020-07-22 15:15:24,190] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:30:00+00:00: scheduled__2020-07-20T04:30:00+00:00, externally triggered: False> successful
[2020-07-22 15:15:24,325] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:31:00+00:00: scheduled__2020-07-20T04:31:00+00:00, externally triggered: False>
[2020-07-22 15:15:24,354] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:15:24,367] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:31:00+00:00 [scheduled]> in ORM
[2020-07-22 15:15:24,622] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.089 seconds
[2020-07-22 15:16:00,045] {scheduler_job.py:153} INFO - Started process (PID=488293) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:16:00,050] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:16:00,051] {logging_mixin.py:112} INFO - [2020-07-22 15:16:00,051] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:16:00,071] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:16:00,515] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:16:00,990] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:32:00+00:00: scheduled__2020-07-20T04:32:00+00:00, externally triggered: False>
[2020-07-22 15:16:00,998] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:31:00+00:00: scheduled__2020-07-20T04:31:00+00:00, externally triggered: False>
[2020-07-22 15:16:01,014] {logging_mixin.py:112} INFO - [2020-07-22 15:16:01,014] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:31:00+00:00: scheduled__2020-07-20T04:31:00+00:00, externally triggered: False> successful
[2020-07-22 15:16:01,160] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:32:00+00:00: scheduled__2020-07-20T04:32:00+00:00, externally triggered: False>
[2020-07-22 15:16:01,174] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:16:01,178] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:32:00+00:00 [scheduled]> in ORM
[2020-07-22 15:16:01,337] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.292 seconds
[2020-07-22 15:16:34,715] {scheduler_job.py:153} INFO - Started process (PID=489097) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:16:34,719] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:16:34,720] {logging_mixin.py:112} INFO - [2020-07-22 15:16:34,720] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:16:34,735] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:16:35,010] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:16:35,293] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:33:00+00:00: scheduled__2020-07-20T04:33:00+00:00, externally triggered: False>
[2020-07-22 15:16:35,302] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:32:00+00:00: scheduled__2020-07-20T04:32:00+00:00, externally triggered: False>
[2020-07-22 15:16:35,318] {logging_mixin.py:112} INFO - [2020-07-22 15:16:35,317] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:32:00+00:00: scheduled__2020-07-20T04:32:00+00:00, externally triggered: False> successful
[2020-07-22 15:16:35,418] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:33:00+00:00: scheduled__2020-07-20T04:33:00+00:00, externally triggered: False>
[2020-07-22 15:16:35,442] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:16:35,448] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:33:00+00:00 [scheduled]> in ORM
[2020-07-22 15:16:35,585] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.870 seconds
[2020-07-22 15:17:09,926] {scheduler_job.py:153} INFO - Started process (PID=489864) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:17:09,929] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:17:09,929] {logging_mixin.py:112} INFO - [2020-07-22 15:17:09,929] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:17:09,938] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:17:10,125] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:17:10,543] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:34:00+00:00: scheduled__2020-07-20T04:34:00+00:00, externally triggered: False>
[2020-07-22 15:17:10,547] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:33:00+00:00: scheduled__2020-07-20T04:33:00+00:00, externally triggered: False>
[2020-07-22 15:17:10,555] {logging_mixin.py:112} INFO - [2020-07-22 15:17:10,555] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:33:00+00:00: scheduled__2020-07-20T04:33:00+00:00, externally triggered: False> successful
[2020-07-22 15:17:10,666] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:34:00+00:00: scheduled__2020-07-20T04:34:00+00:00, externally triggered: False>
[2020-07-22 15:17:10,685] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:17:10,689] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:34:00+00:00 [scheduled]> in ORM
[2020-07-22 15:17:10,833] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.907 seconds
[2020-07-22 15:17:48,171] {scheduler_job.py:153} INFO - Started process (PID=490730) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:17:48,174] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:17:48,175] {logging_mixin.py:112} INFO - [2020-07-22 15:17:48,174] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:17:48,184] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:17:48,357] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:17:48,651] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:35:00+00:00: scheduled__2020-07-20T04:35:00+00:00, externally triggered: False>
[2020-07-22 15:17:48,656] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:34:00+00:00: scheduled__2020-07-20T04:34:00+00:00, externally triggered: False>
[2020-07-22 15:17:48,665] {logging_mixin.py:112} INFO - [2020-07-22 15:17:48,665] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:34:00+00:00: scheduled__2020-07-20T04:34:00+00:00, externally triggered: False> successful
[2020-07-22 15:17:48,767] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:35:00+00:00: scheduled__2020-07-20T04:35:00+00:00, externally triggered: False>
[2020-07-22 15:17:48,784] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:17:48,789] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:35:00+00:00 [scheduled]> in ORM
[2020-07-22 15:17:48,945] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.774 seconds
[2020-07-22 15:18:22,782] {scheduler_job.py:153} INFO - Started process (PID=491486) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:18:22,786] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:18:22,787] {logging_mixin.py:112} INFO - [2020-07-22 15:18:22,786] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:18:22,799] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:18:22,957] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:18:23,233] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:36:00+00:00: scheduled__2020-07-20T04:36:00+00:00, externally triggered: False>
[2020-07-22 15:18:23,237] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:35:00+00:00: scheduled__2020-07-20T04:35:00+00:00, externally triggered: False>
[2020-07-22 15:18:23,244] {logging_mixin.py:112} INFO - [2020-07-22 15:18:23,244] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:35:00+00:00: scheduled__2020-07-20T04:35:00+00:00, externally triggered: False> successful
[2020-07-22 15:18:23,337] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:36:00+00:00: scheduled__2020-07-20T04:36:00+00:00, externally triggered: False>
[2020-07-22 15:18:23,355] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:18:23,359] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:36:00+00:00 [scheduled]> in ORM
[2020-07-22 15:18:23,491] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.709 seconds
[2020-07-22 15:18:58,573] {scheduler_job.py:153} INFO - Started process (PID=492282) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:18:58,578] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:18:58,578] {logging_mixin.py:112} INFO - [2020-07-22 15:18:58,578] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:18:58,615] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:18:58,803] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:18:59,174] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:37:00+00:00: scheduled__2020-07-20T04:37:00+00:00, externally triggered: False>
[2020-07-22 15:18:59,182] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:36:00+00:00: scheduled__2020-07-20T04:36:00+00:00, externally triggered: False>
[2020-07-22 15:18:59,207] {logging_mixin.py:112} INFO - [2020-07-22 15:18:59,207] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:36:00+00:00: scheduled__2020-07-20T04:36:00+00:00, externally triggered: False> successful
[2020-07-22 15:18:59,361] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:37:00+00:00: scheduled__2020-07-20T04:37:00+00:00, externally triggered: False>
[2020-07-22 15:18:59,385] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:18:59,393] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:37:00+00:00 [scheduled]> in ORM
[2020-07-22 15:18:59,537] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.964 seconds
[2020-07-22 15:19:30,239] {scheduler_job.py:153} INFO - Started process (PID=492982) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:19:30,243] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:19:30,243] {logging_mixin.py:112} INFO - [2020-07-22 15:19:30,243] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:19:30,258] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:19:30,448] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:19:30,983] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:38:00+00:00: scheduled__2020-07-20T04:38:00+00:00, externally triggered: False>
[2020-07-22 15:19:30,986] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:37:00+00:00: scheduled__2020-07-20T04:37:00+00:00, externally triggered: False>
[2020-07-22 15:19:30,993] {logging_mixin.py:112} INFO - [2020-07-22 15:19:30,993] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:37:00+00:00: scheduled__2020-07-20T04:37:00+00:00, externally triggered: False> successful
[2020-07-22 15:19:31,108] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:38:00+00:00: scheduled__2020-07-20T04:38:00+00:00, externally triggered: False>
[2020-07-22 15:19:31,127] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:19:31,131] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:38:00+00:00 [scheduled]> in ORM
[2020-07-22 15:19:31,286] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.048 seconds
[2020-07-22 15:20:10,422] {scheduler_job.py:153} INFO - Started process (PID=493823) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:20:10,426] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:20:10,426] {logging_mixin.py:112} INFO - [2020-07-22 15:20:10,426] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:20:10,435] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:20:10,551] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:20:10,837] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:39:00+00:00: scheduled__2020-07-20T04:39:00+00:00, externally triggered: False>
[2020-07-22 15:20:10,842] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:38:00+00:00: scheduled__2020-07-20T04:38:00+00:00, externally triggered: False>
[2020-07-22 15:20:10,850] {logging_mixin.py:112} INFO - [2020-07-22 15:20:10,850] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:38:00+00:00: scheduled__2020-07-20T04:38:00+00:00, externally triggered: False> successful
[2020-07-22 15:20:10,944] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:39:00+00:00: scheduled__2020-07-20T04:39:00+00:00, externally triggered: False>
[2020-07-22 15:20:10,963] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:20:10,967] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:39:00+00:00 [scheduled]> in ORM
[2020-07-22 15:20:11,100] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.678 seconds
[2020-07-22 15:20:45,448] {scheduler_job.py:153} INFO - Started process (PID=494596) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:20:45,454] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:20:45,454] {logging_mixin.py:112} INFO - [2020-07-22 15:20:45,454] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:20:45,465] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:20:45,640] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:20:45,932] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:40:00+00:00: scheduled__2020-07-20T04:40:00+00:00, externally triggered: False>
[2020-07-22 15:20:45,943] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:39:00+00:00: scheduled__2020-07-20T04:39:00+00:00, externally triggered: False>
[2020-07-22 15:20:45,962] {logging_mixin.py:112} INFO - [2020-07-22 15:20:45,962] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:39:00+00:00: scheduled__2020-07-20T04:39:00+00:00, externally triggered: False> successful
[2020-07-22 15:20:46,113] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:40:00+00:00: scheduled__2020-07-20T04:40:00+00:00, externally triggered: False>
[2020-07-22 15:20:46,127] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:20:46,131] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:40:00+00:00 [scheduled]> in ORM
[2020-07-22 15:20:46,256] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.808 seconds
[2020-07-22 15:21:20,119] {scheduler_job.py:153} INFO - Started process (PID=495383) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:21:20,122] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:21:20,122] {logging_mixin.py:112} INFO - [2020-07-22 15:21:20,122] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:21:20,131] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:21:20,266] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:21:20,555] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:41:00+00:00: scheduled__2020-07-20T04:41:00+00:00, externally triggered: False>
[2020-07-22 15:21:20,560] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:40:00+00:00: scheduled__2020-07-20T04:40:00+00:00, externally triggered: False>
[2020-07-22 15:21:20,573] {logging_mixin.py:112} INFO - [2020-07-22 15:21:20,573] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:40:00+00:00: scheduled__2020-07-20T04:40:00+00:00, externally triggered: False> successful
[2020-07-22 15:21:20,771] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:41:00+00:00: scheduled__2020-07-20T04:41:00+00:00, externally triggered: False>
[2020-07-22 15:21:20,798] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:21:20,809] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:41:00+00:00 [scheduled]> in ORM
[2020-07-22 15:21:21,004] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.886 seconds
[2020-07-22 15:21:55,677] {scheduler_job.py:153} INFO - Started process (PID=496156) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:21:55,692] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:21:55,693] {logging_mixin.py:112} INFO - [2020-07-22 15:21:55,693] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:21:55,720] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:21:56,254] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:21:56,645] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:42:00+00:00: scheduled__2020-07-20T04:42:00+00:00, externally triggered: False>
[2020-07-22 15:21:56,652] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:41:00+00:00: scheduled__2020-07-20T04:41:00+00:00, externally triggered: False>
[2020-07-22 15:21:56,665] {logging_mixin.py:112} INFO - [2020-07-22 15:21:56,664] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:41:00+00:00: scheduled__2020-07-20T04:41:00+00:00, externally triggered: False> successful
[2020-07-22 15:21:56,817] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:42:00+00:00: scheduled__2020-07-20T04:42:00+00:00, externally triggered: False>
[2020-07-22 15:21:56,837] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:21:56,848] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:42:00+00:00 [scheduled]> in ORM
[2020-07-22 15:21:57,004] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.327 seconds
[2020-07-22 15:22:30,669] {scheduler_job.py:153} INFO - Started process (PID=496894) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:22:30,672] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:22:30,672] {logging_mixin.py:112} INFO - [2020-07-22 15:22:30,672] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:22:30,684] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:22:30,929] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:22:31,264] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:43:00+00:00: scheduled__2020-07-20T04:43:00+00:00, externally triggered: False>
[2020-07-22 15:22:31,270] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:42:00+00:00: scheduled__2020-07-20T04:42:00+00:00, externally triggered: False>
[2020-07-22 15:22:31,277] {logging_mixin.py:112} INFO - [2020-07-22 15:22:31,277] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:42:00+00:00: scheduled__2020-07-20T04:42:00+00:00, externally triggered: False> successful
[2020-07-22 15:22:31,387] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:43:00+00:00: scheduled__2020-07-20T04:43:00+00:00, externally triggered: False>
[2020-07-22 15:22:31,407] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:22:31,413] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:43:00+00:00 [scheduled]> in ORM
[2020-07-22 15:22:31,541] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.872 seconds
[2020-07-22 15:23:05,897] {scheduler_job.py:153} INFO - Started process (PID=497641) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:23:05,901] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:23:05,901] {logging_mixin.py:112} INFO - [2020-07-22 15:23:05,901] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:23:05,909] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:23:06,043] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:23:06,338] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:44:00+00:00: scheduled__2020-07-20T04:44:00+00:00, externally triggered: False>
[2020-07-22 15:23:06,343] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:43:00+00:00: scheduled__2020-07-20T04:43:00+00:00, externally triggered: False>
[2020-07-22 15:23:06,352] {logging_mixin.py:112} INFO - [2020-07-22 15:23:06,351] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:43:00+00:00: scheduled__2020-07-20T04:43:00+00:00, externally triggered: False> successful
[2020-07-22 15:23:06,467] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:44:00+00:00: scheduled__2020-07-20T04:44:00+00:00, externally triggered: False>
[2020-07-22 15:23:06,485] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:23:06,490] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:44:00+00:00 [scheduled]> in ORM
[2020-07-22 15:23:06,691] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.793 seconds
[2020-07-22 15:23:46,258] {scheduler_job.py:153} INFO - Started process (PID=498499) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:23:46,260] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:23:46,261] {logging_mixin.py:112} INFO - [2020-07-22 15:23:46,261] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:23:46,273] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:23:46,421] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:23:46,755] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:45:00+00:00: scheduled__2020-07-20T04:45:00+00:00, externally triggered: False>
[2020-07-22 15:23:46,759] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:44:00+00:00: scheduled__2020-07-20T04:44:00+00:00, externally triggered: False>
[2020-07-22 15:23:46,769] {logging_mixin.py:112} INFO - [2020-07-22 15:23:46,769] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:44:00+00:00: scheduled__2020-07-20T04:44:00+00:00, externally triggered: False> successful
[2020-07-22 15:23:46,870] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:45:00+00:00: scheduled__2020-07-20T04:45:00+00:00, externally triggered: False>
[2020-07-22 15:23:46,887] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:23:46,891] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:45:00+00:00 [scheduled]> in ORM
[2020-07-22 15:23:47,093] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.835 seconds
[2020-07-22 15:24:27,452] {scheduler_job.py:153} INFO - Started process (PID=499347) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:24:27,456] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:24:27,456] {logging_mixin.py:112} INFO - [2020-07-22 15:24:27,456] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:24:27,466] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:24:27,723] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:24:28,093] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:46:00+00:00: scheduled__2020-07-20T04:46:00+00:00, externally triggered: False>
[2020-07-22 15:24:28,096] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:45:00+00:00: scheduled__2020-07-20T04:45:00+00:00, externally triggered: False>
[2020-07-22 15:24:28,104] {logging_mixin.py:112} INFO - [2020-07-22 15:24:28,104] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:45:00+00:00: scheduled__2020-07-20T04:45:00+00:00, externally triggered: False> successful
[2020-07-22 15:24:28,205] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:46:00+00:00: scheduled__2020-07-20T04:46:00+00:00, externally triggered: False>
[2020-07-22 15:24:28,223] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:24:28,227] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:46:00+00:00 [scheduled]> in ORM
[2020-07-22 15:24:28,351] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.899 seconds
[2020-07-22 15:25:03,293] {scheduler_job.py:153} INFO - Started process (PID=500151) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:25:03,297] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:25:03,297] {logging_mixin.py:112} INFO - [2020-07-22 15:25:03,297] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:25:03,306] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:25:03,802] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:25:04,399] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:47:00+00:00: scheduled__2020-07-20T04:47:00+00:00, externally triggered: False>
[2020-07-22 15:25:04,406] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:46:00+00:00: scheduled__2020-07-20T04:46:00+00:00, externally triggered: False>
[2020-07-22 15:25:04,414] {logging_mixin.py:112} INFO - [2020-07-22 15:25:04,414] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:46:00+00:00: scheduled__2020-07-20T04:46:00+00:00, externally triggered: False> successful
[2020-07-22 15:25:04,541] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:47:00+00:00: scheduled__2020-07-20T04:47:00+00:00, externally triggered: False>
[2020-07-22 15:25:04,556] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:25:04,563] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:47:00+00:00 [scheduled]> in ORM
[2020-07-22 15:25:04,731] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.438 seconds
[2020-07-22 15:25:32,869] {scheduler_job.py:153} INFO - Started process (PID=500780) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:25:32,881] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:25:32,882] {logging_mixin.py:112} INFO - [2020-07-22 15:25:32,881] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:25:32,896] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:25:33,750] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:25:34,138] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:48:00+00:00: scheduled__2020-07-20T04:48:00+00:00, externally triggered: False>
[2020-07-22 15:25:34,154] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:47:00+00:00: scheduled__2020-07-20T04:47:00+00:00, externally triggered: False>
[2020-07-22 15:25:34,206] {logging_mixin.py:112} INFO - [2020-07-22 15:25:34,199] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:47:00+00:00: scheduled__2020-07-20T04:47:00+00:00, externally triggered: False> successful
[2020-07-22 15:25:34,365] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:48:00+00:00: scheduled__2020-07-20T04:48:00+00:00, externally triggered: False>
[2020-07-22 15:25:34,402] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:25:34,420] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:48:00+00:00 [scheduled]> in ORM
[2020-07-22 15:25:34,608] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.739 seconds
[2020-07-22 15:26:11,163] {scheduler_job.py:153} INFO - Started process (PID=501664) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:26:11,166] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:26:11,166] {logging_mixin.py:112} INFO - [2020-07-22 15:26:11,166] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:26:11,175] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:26:11,299] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:26:11,745] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:49:00+00:00: scheduled__2020-07-20T04:49:00+00:00, externally triggered: False>
[2020-07-22 15:26:11,751] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:48:00+00:00: scheduled__2020-07-20T04:48:00+00:00, externally triggered: False>
[2020-07-22 15:26:11,769] {logging_mixin.py:112} INFO - [2020-07-22 15:26:11,768] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:48:00+00:00: scheduled__2020-07-20T04:48:00+00:00, externally triggered: False> successful
[2020-07-22 15:26:11,879] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:49:00+00:00: scheduled__2020-07-20T04:49:00+00:00, externally triggered: False>
[2020-07-22 15:26:11,899] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:26:11,904] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:49:00+00:00 [scheduled]> in ORM
[2020-07-22 15:26:12,652] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.489 seconds
[2020-07-22 15:27:04,251] {scheduler_job.py:153} INFO - Started process (PID=502631) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:27:04,310] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:27:04,310] {logging_mixin.py:112} INFO - [2020-07-22 15:27:04,310] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:27:04,320] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:27:04,419] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:27:04,999] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:50:00+00:00: scheduled__2020-07-20T04:50:00+00:00, externally triggered: False>
[2020-07-22 15:27:05,007] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:49:00+00:00: scheduled__2020-07-20T04:49:00+00:00, externally triggered: False>
[2020-07-22 15:27:05,021] {logging_mixin.py:112} INFO - [2020-07-22 15:27:05,021] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:49:00+00:00: scheduled__2020-07-20T04:49:00+00:00, externally triggered: False> successful
[2020-07-22 15:27:05,140] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:50:00+00:00: scheduled__2020-07-20T04:50:00+00:00, externally triggered: False>
[2020-07-22 15:27:05,160] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:27:05,164] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:50:00+00:00 [scheduled]> in ORM
[2020-07-22 15:27:05,305] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.054 seconds
[2020-07-22 15:28:03,713] {scheduler_job.py:153} INFO - Started process (PID=503695) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:28:03,717] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:28:03,717] {logging_mixin.py:112} INFO - [2020-07-22 15:28:03,717] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:28:03,726] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:28:03,885] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:28:04,248] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:51:00+00:00: scheduled__2020-07-20T04:51:00+00:00, externally triggered: False>
[2020-07-22 15:28:04,251] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:50:00+00:00: scheduled__2020-07-20T04:50:00+00:00, externally triggered: False>
[2020-07-22 15:28:04,259] {logging_mixin.py:112} INFO - [2020-07-22 15:28:04,259] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:50:00+00:00: scheduled__2020-07-20T04:50:00+00:00, externally triggered: False> successful
[2020-07-22 15:28:04,498] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:51:00+00:00: scheduled__2020-07-20T04:51:00+00:00, externally triggered: False>
[2020-07-22 15:28:04,519] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:28:04,523] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:51:00+00:00 [scheduled]> in ORM
[2020-07-22 15:28:04,653] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.940 seconds
[2020-07-22 15:28:39,138] {scheduler_job.py:153} INFO - Started process (PID=504456) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:28:39,141] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:28:39,141] {logging_mixin.py:112} INFO - [2020-07-22 15:28:39,141] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:28:39,152] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:28:39,331] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:28:39,639] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:52:00+00:00: scheduled__2020-07-20T04:52:00+00:00, externally triggered: False>
[2020-07-22 15:28:39,642] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:51:00+00:00: scheduled__2020-07-20T04:51:00+00:00, externally triggered: False>
[2020-07-22 15:28:39,649] {logging_mixin.py:112} INFO - [2020-07-22 15:28:39,649] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:51:00+00:00: scheduled__2020-07-20T04:51:00+00:00, externally triggered: False> successful
[2020-07-22 15:28:39,744] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:52:00+00:00: scheduled__2020-07-20T04:52:00+00:00, externally triggered: False>
[2020-07-22 15:28:39,764] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:28:39,768] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:52:00+00:00 [scheduled]> in ORM
[2020-07-22 15:28:39,900] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.763 seconds
[2020-07-22 15:29:09,046] {scheduler_job.py:153} INFO - Started process (PID=505180) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:29:09,050] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:29:09,051] {logging_mixin.py:112} INFO - [2020-07-22 15:29:09,051] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:29:09,061] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:29:09,206] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:29:09,496] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:53:00+00:00: scheduled__2020-07-20T04:53:00+00:00, externally triggered: False>
[2020-07-22 15:29:09,500] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:52:00+00:00: scheduled__2020-07-20T04:52:00+00:00, externally triggered: False>
[2020-07-22 15:29:09,508] {logging_mixin.py:112} INFO - [2020-07-22 15:29:09,508] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:52:00+00:00: scheduled__2020-07-20T04:52:00+00:00, externally triggered: False> successful
[2020-07-22 15:29:09,613] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:53:00+00:00: scheduled__2020-07-20T04:53:00+00:00, externally triggered: False>
[2020-07-22 15:29:09,632] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:29:09,636] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:53:00+00:00 [scheduled]> in ORM
[2020-07-22 15:29:09,804] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.758 seconds
[2020-07-22 15:29:38,810] {scheduler_job.py:153} INFO - Started process (PID=505830) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:29:38,815] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:29:38,815] {logging_mixin.py:112} INFO - [2020-07-22 15:29:38,815] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:29:38,827] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:29:39,256] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:29:39,563] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:54:00+00:00: scheduled__2020-07-20T04:54:00+00:00, externally triggered: False>
[2020-07-22 15:29:39,579] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:53:00+00:00: scheduled__2020-07-20T04:53:00+00:00, externally triggered: False>
[2020-07-22 15:29:39,609] {logging_mixin.py:112} INFO - [2020-07-22 15:29:39,608] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:53:00+00:00: scheduled__2020-07-20T04:53:00+00:00, externally triggered: False> successful
[2020-07-22 15:29:39,726] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:54:00+00:00: scheduled__2020-07-20T04:54:00+00:00, externally triggered: False>
[2020-07-22 15:29:39,749] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:29:39,769] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:54:00+00:00 [scheduled]> in ORM
[2020-07-22 15:29:39,913] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.103 seconds
[2020-07-22 15:30:14,422] {scheduler_job.py:153} INFO - Started process (PID=506580) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:30:14,425] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:30:14,425] {logging_mixin.py:112} INFO - [2020-07-22 15:30:14,425] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:30:14,437] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:30:14,569] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:30:14,855] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:55:00+00:00: scheduled__2020-07-20T04:55:00+00:00, externally triggered: False>
[2020-07-22 15:30:14,863] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:54:00+00:00: scheduled__2020-07-20T04:54:00+00:00, externally triggered: False>
[2020-07-22 15:30:14,874] {logging_mixin.py:112} INFO - [2020-07-22 15:30:14,874] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:54:00+00:00: scheduled__2020-07-20T04:54:00+00:00, externally triggered: False> successful
[2020-07-22 15:30:15,028] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:55:00+00:00: scheduled__2020-07-20T04:55:00+00:00, externally triggered: False>
[2020-07-22 15:30:15,046] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:30:15,050] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:55:00+00:00 [scheduled]> in ORM
[2020-07-22 15:30:15,173] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.751 seconds
[2020-07-22 15:30:54,019] {scheduler_job.py:153} INFO - Started process (PID=507434) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:30:54,022] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:30:54,022] {logging_mixin.py:112} INFO - [2020-07-22 15:30:54,022] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:30:54,031] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:30:55,031] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:30:55,471] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:56:00+00:00: scheduled__2020-07-20T04:56:00+00:00, externally triggered: False>
[2020-07-22 15:30:55,475] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:55:00+00:00: scheduled__2020-07-20T04:55:00+00:00, externally triggered: False>
[2020-07-22 15:30:55,484] {logging_mixin.py:112} INFO - [2020-07-22 15:30:55,484] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:55:00+00:00: scheduled__2020-07-20T04:55:00+00:00, externally triggered: False> successful
[2020-07-22 15:30:55,642] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:56:00+00:00: scheduled__2020-07-20T04:56:00+00:00, externally triggered: False>
[2020-07-22 15:30:55,661] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:30:55,665] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:56:00+00:00 [scheduled]> in ORM
[2020-07-22 15:30:55,931] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.912 seconds
[2020-07-22 15:31:29,623] {scheduler_job.py:153} INFO - Started process (PID=508234) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:31:29,627] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:31:29,628] {logging_mixin.py:112} INFO - [2020-07-22 15:31:29,628] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:31:29,638] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:31:29,769] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:31:30,294] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:57:00+00:00: scheduled__2020-07-20T04:57:00+00:00, externally triggered: False>
[2020-07-22 15:31:30,298] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:56:00+00:00: scheduled__2020-07-20T04:56:00+00:00, externally triggered: False>
[2020-07-22 15:31:30,307] {logging_mixin.py:112} INFO - [2020-07-22 15:31:30,307] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:56:00+00:00: scheduled__2020-07-20T04:56:00+00:00, externally triggered: False> successful
[2020-07-22 15:31:30,433] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:57:00+00:00: scheduled__2020-07-20T04:57:00+00:00, externally triggered: False>
[2020-07-22 15:31:30,456] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:31:30,461] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:57:00+00:00 [scheduled]> in ORM
[2020-07-22 15:31:30,667] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.044 seconds
[2020-07-22 15:31:59,710] {scheduler_job.py:153} INFO - Started process (PID=508963) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:31:59,713] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:31:59,713] {logging_mixin.py:112} INFO - [2020-07-22 15:31:59,713] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:31:59,724] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:31:59,861] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:32:00,329] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:58:00+00:00: scheduled__2020-07-20T04:58:00+00:00, externally triggered: False>
[2020-07-22 15:32:00,332] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:57:00+00:00: scheduled__2020-07-20T04:57:00+00:00, externally triggered: False>
[2020-07-22 15:32:00,341] {logging_mixin.py:112} INFO - [2020-07-22 15:32:00,340] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:57:00+00:00: scheduled__2020-07-20T04:57:00+00:00, externally triggered: False> successful
[2020-07-22 15:32:00,480] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:58:00+00:00: scheduled__2020-07-20T04:58:00+00:00, externally triggered: False>
[2020-07-22 15:32:00,498] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:32:00,502] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:58:00+00:00 [scheduled]> in ORM
[2020-07-22 15:32:00,672] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.962 seconds
[2020-07-22 15:32:29,009] {scheduler_job.py:153} INFO - Started process (PID=509577) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:32:29,028] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:32:29,029] {logging_mixin.py:112} INFO - [2020-07-22 15:32:29,028] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:32:29,054] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:32:29,243] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:32:30,214] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T04:59:00+00:00: scheduled__2020-07-20T04:59:00+00:00, externally triggered: False>
[2020-07-22 15:32:30,221] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:58:00+00:00: scheduled__2020-07-20T04:58:00+00:00, externally triggered: False>
[2020-07-22 15:32:30,229] {logging_mixin.py:112} INFO - [2020-07-22 15:32:30,229] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:58:00+00:00: scheduled__2020-07-20T04:58:00+00:00, externally triggered: False> successful
[2020-07-22 15:32:30,549] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:59:00+00:00: scheduled__2020-07-20T04:59:00+00:00, externally triggered: False>
[2020-07-22 15:32:30,574] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:32:30,580] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 04:59:00+00:00 [scheduled]> in ORM
[2020-07-22 15:32:30,716] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.707 seconds
[2020-07-22 15:33:05,880] {scheduler_job.py:153} INFO - Started process (PID=510376) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:33:05,883] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:33:05,883] {logging_mixin.py:112} INFO - [2020-07-22 15:33:05,883] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:33:05,893] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:33:06,104] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:33:06,400] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:00:00+00:00: scheduled__2020-07-20T05:00:00+00:00, externally triggered: False>
[2020-07-22 15:33:06,404] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 04:59:00+00:00: scheduled__2020-07-20T04:59:00+00:00, externally triggered: False>
[2020-07-22 15:33:06,411] {logging_mixin.py:112} INFO - [2020-07-22 15:33:06,411] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 04:59:00+00:00: scheduled__2020-07-20T04:59:00+00:00, externally triggered: False> successful
[2020-07-22 15:33:06,529] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:00:00+00:00: scheduled__2020-07-20T05:00:00+00:00, externally triggered: False>
[2020-07-22 15:33:06,548] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:33:06,552] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:00:00+00:00 [scheduled]> in ORM
[2020-07-22 15:33:06,683] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.803 seconds
[2020-07-22 15:33:41,503] {scheduler_job.py:153} INFO - Started process (PID=511166) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:33:41,511] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:33:41,511] {logging_mixin.py:112} INFO - [2020-07-22 15:33:41,511] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:33:41,524] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:33:41,704] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:33:42,144] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:01:00+00:00: scheduled__2020-07-20T05:01:00+00:00, externally triggered: False>
[2020-07-22 15:33:42,148] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:00:00+00:00: scheduled__2020-07-20T05:00:00+00:00, externally triggered: False>
[2020-07-22 15:33:42,157] {logging_mixin.py:112} INFO - [2020-07-22 15:33:42,156] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:00:00+00:00: scheduled__2020-07-20T05:00:00+00:00, externally triggered: False> successful
[2020-07-22 15:33:42,277] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:01:00+00:00: scheduled__2020-07-20T05:01:00+00:00, externally triggered: False>
[2020-07-22 15:33:42,328] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:33:42,341] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:01:00+00:00 [scheduled]> in ORM
[2020-07-22 15:33:42,508] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.005 seconds
[2020-07-22 15:34:11,344] {scheduler_job.py:153} INFO - Started process (PID=511867) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:34:11,348] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:34:11,348] {logging_mixin.py:112} INFO - [2020-07-22 15:34:11,348] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:34:11,362] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:34:11,521] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:34:11,883] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:02:00+00:00: scheduled__2020-07-20T05:02:00+00:00, externally triggered: False>
[2020-07-22 15:34:11,888] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:01:00+00:00: scheduled__2020-07-20T05:01:00+00:00, externally triggered: False>
[2020-07-22 15:34:11,900] {logging_mixin.py:112} INFO - [2020-07-22 15:34:11,900] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:01:00+00:00: scheduled__2020-07-20T05:01:00+00:00, externally triggered: False> successful
[2020-07-22 15:34:12,088] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:02:00+00:00: scheduled__2020-07-20T05:02:00+00:00, externally triggered: False>
[2020-07-22 15:34:12,108] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:34:12,115] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:02:00+00:00 [scheduled]> in ORM
[2020-07-22 15:34:12,278] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.934 seconds
[2020-07-22 15:34:40,562] {scheduler_job.py:153} INFO - Started process (PID=512512) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:34:40,566] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:34:40,566] {logging_mixin.py:112} INFO - [2020-07-22 15:34:40,566] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:34:40,576] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:34:40,725] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:34:41,070] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:03:00+00:00: scheduled__2020-07-20T05:03:00+00:00, externally triggered: False>
[2020-07-22 15:34:41,073] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:02:00+00:00: scheduled__2020-07-20T05:02:00+00:00, externally triggered: False>
[2020-07-22 15:34:41,080] {logging_mixin.py:112} INFO - [2020-07-22 15:34:41,080] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:02:00+00:00: scheduled__2020-07-20T05:02:00+00:00, externally triggered: False> successful
[2020-07-22 15:34:41,191] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:03:00+00:00: scheduled__2020-07-20T05:03:00+00:00, externally triggered: False>
[2020-07-22 15:34:41,209] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:34:41,215] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:03:00+00:00 [scheduled]> in ORM
[2020-07-22 15:34:41,369] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.807 seconds
[2020-07-22 15:35:16,357] {scheduler_job.py:153} INFO - Started process (PID=513308) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:35:16,360] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:35:16,361] {logging_mixin.py:112} INFO - [2020-07-22 15:35:16,361] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:35:16,370] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:35:16,478] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:35:16,767] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:04:00+00:00: scheduled__2020-07-20T05:04:00+00:00, externally triggered: False>
[2020-07-22 15:35:16,770] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:03:00+00:00: scheduled__2020-07-20T05:03:00+00:00, externally triggered: False>
[2020-07-22 15:35:16,777] {logging_mixin.py:112} INFO - [2020-07-22 15:35:16,777] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:03:00+00:00: scheduled__2020-07-20T05:03:00+00:00, externally triggered: False> successful
[2020-07-22 15:35:16,893] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:04:00+00:00: scheduled__2020-07-20T05:04:00+00:00, externally triggered: False>
[2020-07-22 15:35:16,916] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:35:16,921] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:04:00+00:00 [scheduled]> in ORM
[2020-07-22 15:35:17,160] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.803 seconds
[2020-07-22 15:35:51,022] {scheduler_job.py:153} INFO - Started process (PID=514092) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:35:51,027] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:35:51,027] {logging_mixin.py:112} INFO - [2020-07-22 15:35:51,027] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:35:51,036] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:35:51,179] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:35:51,522] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:05:00+00:00: scheduled__2020-07-20T05:05:00+00:00, externally triggered: False>
[2020-07-22 15:35:51,529] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:04:00+00:00: scheduled__2020-07-20T05:04:00+00:00, externally triggered: False>
[2020-07-22 15:35:51,545] {logging_mixin.py:112} INFO - [2020-07-22 15:35:51,545] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:04:00+00:00: scheduled__2020-07-20T05:04:00+00:00, externally triggered: False> successful
[2020-07-22 15:35:51,673] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:05:00+00:00: scheduled__2020-07-20T05:05:00+00:00, externally triggered: False>
[2020-07-22 15:35:51,688] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:35:51,692] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:05:00+00:00 [scheduled]> in ORM
[2020-07-22 15:35:51,826] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.804 seconds
[2020-07-22 15:36:20,874] {scheduler_job.py:153} INFO - Started process (PID=514786) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:36:20,879] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:36:20,880] {logging_mixin.py:112} INFO - [2020-07-22 15:36:20,880] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:36:20,896] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:36:21,610] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:36:22,695] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:06:00+00:00: scheduled__2020-07-20T05:06:00+00:00, externally triggered: False>
[2020-07-22 15:36:22,703] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:05:00+00:00: scheduled__2020-07-20T05:05:00+00:00, externally triggered: False>
[2020-07-22 15:36:22,720] {logging_mixin.py:112} INFO - [2020-07-22 15:36:22,720] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:05:00+00:00: scheduled__2020-07-20T05:05:00+00:00, externally triggered: False> successful
[2020-07-22 15:36:23,287] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:06:00+00:00: scheduled__2020-07-20T05:06:00+00:00, externally triggered: False>
[2020-07-22 15:36:24,062] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:36:24,072] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:06:00+00:00 [scheduled]> in ORM
[2020-07-22 15:36:24,616] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 3.742 seconds
[2020-07-22 15:36:57,257] {scheduler_job.py:153} INFO - Started process (PID=515565) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:36:57,260] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:36:57,260] {logging_mixin.py:112} INFO - [2020-07-22 15:36:57,260] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:36:57,270] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:36:57,430] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:36:57,761] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:07:00+00:00: scheduled__2020-07-20T05:07:00+00:00, externally triggered: False>
[2020-07-22 15:36:57,765] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:06:00+00:00: scheduled__2020-07-20T05:06:00+00:00, externally triggered: False>
[2020-07-22 15:36:57,773] {logging_mixin.py:112} INFO - [2020-07-22 15:36:57,773] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:06:00+00:00: scheduled__2020-07-20T05:06:00+00:00, externally triggered: False> successful
[2020-07-22 15:36:57,921] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:07:00+00:00: scheduled__2020-07-20T05:07:00+00:00, externally triggered: False>
[2020-07-22 15:36:57,943] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:36:57,949] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:07:00+00:00 [scheduled]> in ORM
[2020-07-22 15:36:58,077] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.820 seconds
[2020-07-22 15:37:35,481] {scheduler_job.py:153} INFO - Started process (PID=516359) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:37:35,485] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:37:35,486] {logging_mixin.py:112} INFO - [2020-07-22 15:37:35,486] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:37:35,494] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:37:35,638] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:37:36,408] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:08:00+00:00: scheduled__2020-07-20T05:08:00+00:00, externally triggered: False>
[2020-07-22 15:37:36,414] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:07:00+00:00: scheduled__2020-07-20T05:07:00+00:00, externally triggered: False>
[2020-07-22 15:37:36,427] {logging_mixin.py:112} INFO - [2020-07-22 15:37:36,427] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:07:00+00:00: scheduled__2020-07-20T05:07:00+00:00, externally triggered: False> successful
[2020-07-22 15:37:36,558] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:08:00+00:00: scheduled__2020-07-20T05:08:00+00:00, externally triggered: False>
[2020-07-22 15:37:36,577] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:37:36,583] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:08:00+00:00 [scheduled]> in ORM
[2020-07-22 15:37:36,725] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.243 seconds
[2020-07-22 15:38:10,840] {scheduler_job.py:153} INFO - Started process (PID=517138) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:38:10,844] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:38:10,845] {logging_mixin.py:112} INFO - [2020-07-22 15:38:10,845] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:38:10,855] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:38:11,716] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:38:12,676] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:09:00+00:00: scheduled__2020-07-20T05:09:00+00:00, externally triggered: False>
[2020-07-22 15:38:12,679] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:08:00+00:00: scheduled__2020-07-20T05:08:00+00:00, externally triggered: False>
[2020-07-22 15:38:12,687] {logging_mixin.py:112} INFO - [2020-07-22 15:38:12,687] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:08:00+00:00: scheduled__2020-07-20T05:08:00+00:00, externally triggered: False> successful
[2020-07-22 15:38:12,906] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:09:00+00:00: scheduled__2020-07-20T05:09:00+00:00, externally triggered: False>
[2020-07-22 15:38:13,561] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:38:13,565] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:09:00+00:00 [scheduled]> in ORM
[2020-07-22 15:38:13,695] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.855 seconds
[2020-07-22 15:38:46,266] {scheduler_job.py:153} INFO - Started process (PID=517964) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:38:46,270] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:38:46,270] {logging_mixin.py:112} INFO - [2020-07-22 15:38:46,270] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:38:46,278] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:38:46,438] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:38:46,781] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:10:00+00:00: scheduled__2020-07-20T05:10:00+00:00, externally triggered: False>
[2020-07-22 15:38:46,785] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:09:00+00:00: scheduled__2020-07-20T05:09:00+00:00, externally triggered: False>
[2020-07-22 15:38:46,793] {logging_mixin.py:112} INFO - [2020-07-22 15:38:46,793] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:09:00+00:00: scheduled__2020-07-20T05:09:00+00:00, externally triggered: False> successful
[2020-07-22 15:38:46,907] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:10:00+00:00: scheduled__2020-07-20T05:10:00+00:00, externally triggered: False>
[2020-07-22 15:38:46,924] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:38:46,928] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:10:00+00:00 [scheduled]> in ORM
[2020-07-22 15:38:47,051] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.785 seconds
[2020-07-22 15:39:15,656] {scheduler_job.py:153} INFO - Started process (PID=518627) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:39:15,659] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:39:15,660] {logging_mixin.py:112} INFO - [2020-07-22 15:39:15,659] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:39:15,675] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:39:15,812] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:39:16,212] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:11:00+00:00: scheduled__2020-07-20T05:11:00+00:00, externally triggered: False>
[2020-07-22 15:39:16,218] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:10:00+00:00: scheduled__2020-07-20T05:10:00+00:00, externally triggered: False>
[2020-07-22 15:39:16,228] {logging_mixin.py:112} INFO - [2020-07-22 15:39:16,228] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:10:00+00:00: scheduled__2020-07-20T05:10:00+00:00, externally triggered: False> successful
[2020-07-22 15:39:16,342] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:11:00+00:00: scheduled__2020-07-20T05:11:00+00:00, externally triggered: False>
[2020-07-22 15:39:16,368] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:39:16,375] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:11:00+00:00 [scheduled]> in ORM
[2020-07-22 15:39:16,497] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.841 seconds
[2020-07-22 15:39:50,743] {scheduler_job.py:153} INFO - Started process (PID=519370) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:39:50,749] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:39:50,749] {logging_mixin.py:112} INFO - [2020-07-22 15:39:50,749] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:39:50,766] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:39:50,903] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:39:51,282] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:12:00+00:00: scheduled__2020-07-20T05:12:00+00:00, externally triggered: False>
[2020-07-22 15:39:51,287] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:11:00+00:00: scheduled__2020-07-20T05:11:00+00:00, externally triggered: False>
[2020-07-22 15:39:51,300] {logging_mixin.py:112} INFO - [2020-07-22 15:39:51,300] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:11:00+00:00: scheduled__2020-07-20T05:11:00+00:00, externally triggered: False> successful
[2020-07-22 15:39:51,411] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:12:00+00:00: scheduled__2020-07-20T05:12:00+00:00, externally triggered: False>
[2020-07-22 15:39:51,433] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:39:51,438] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:12:00+00:00 [scheduled]> in ORM
[2020-07-22 15:39:51,577] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.834 seconds
[2020-07-22 15:40:27,294] {scheduler_job.py:153} INFO - Started process (PID=520218) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:40:27,299] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:40:27,300] {logging_mixin.py:112} INFO - [2020-07-22 15:40:27,300] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:40:27,312] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:40:27,445] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:40:27,729] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:13:00+00:00: scheduled__2020-07-20T05:13:00+00:00, externally triggered: False>
[2020-07-22 15:40:27,733] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:12:00+00:00: scheduled__2020-07-20T05:12:00+00:00, externally triggered: False>
[2020-07-22 15:40:27,740] {logging_mixin.py:112} INFO - [2020-07-22 15:40:27,740] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:12:00+00:00: scheduled__2020-07-20T05:12:00+00:00, externally triggered: False> successful
[2020-07-22 15:40:27,847] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:13:00+00:00: scheduled__2020-07-20T05:13:00+00:00, externally triggered: False>
[2020-07-22 15:40:27,865] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:40:27,869] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:13:00+00:00 [scheduled]> in ORM
[2020-07-22 15:40:28,001] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.707 seconds
[2020-07-22 15:41:06,992] {scheduler_job.py:153} INFO - Started process (PID=521076) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:41:06,997] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:41:06,997] {logging_mixin.py:112} INFO - [2020-07-22 15:41:06,997] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:41:07,010] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:41:07,173] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:41:07,468] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:14:00+00:00: scheduled__2020-07-20T05:14:00+00:00, externally triggered: False>
[2020-07-22 15:41:07,472] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:13:00+00:00: scheduled__2020-07-20T05:13:00+00:00, externally triggered: False>
[2020-07-22 15:41:07,481] {logging_mixin.py:112} INFO - [2020-07-22 15:41:07,481] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:13:00+00:00: scheduled__2020-07-20T05:13:00+00:00, externally triggered: False> successful
[2020-07-22 15:41:07,583] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:14:00+00:00: scheduled__2020-07-20T05:14:00+00:00, externally triggered: False>
[2020-07-22 15:41:07,600] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:41:07,604] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:14:00+00:00 [scheduled]> in ORM
[2020-07-22 15:41:07,728] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.736 seconds
[2020-07-22 15:41:43,088] {scheduler_job.py:153} INFO - Started process (PID=521897) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:41:43,091] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:41:43,092] {logging_mixin.py:112} INFO - [2020-07-22 15:41:43,092] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:41:43,104] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:41:43,215] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:41:43,479] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:15:00+00:00: scheduled__2020-07-20T05:15:00+00:00, externally triggered: False>
[2020-07-22 15:41:43,484] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:14:00+00:00: scheduled__2020-07-20T05:14:00+00:00, externally triggered: False>
[2020-07-22 15:41:43,493] {logging_mixin.py:112} INFO - [2020-07-22 15:41:43,492] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:14:00+00:00: scheduled__2020-07-20T05:14:00+00:00, externally triggered: False> successful
[2020-07-22 15:41:43,585] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:15:00+00:00: scheduled__2020-07-20T05:15:00+00:00, externally triggered: False>
[2020-07-22 15:41:43,601] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:41:43,606] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:15:00+00:00 [scheduled]> in ORM
[2020-07-22 15:41:43,796] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.708 seconds
[2020-07-22 15:42:18,121] {scheduler_job.py:153} INFO - Started process (PID=522665) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:42:18,129] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:42:18,131] {logging_mixin.py:112} INFO - [2020-07-22 15:42:18,130] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:42:18,146] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:42:18,332] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:42:19,092] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:16:00+00:00: scheduled__2020-07-20T05:16:00+00:00, externally triggered: False>
[2020-07-22 15:42:19,102] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:15:00+00:00: scheduled__2020-07-20T05:15:00+00:00, externally triggered: False>
[2020-07-22 15:42:19,120] {logging_mixin.py:112} INFO - [2020-07-22 15:42:19,119] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:15:00+00:00: scheduled__2020-07-20T05:15:00+00:00, externally triggered: False> successful
[2020-07-22 15:42:19,265] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:16:00+00:00: scheduled__2020-07-20T05:16:00+00:00, externally triggered: False>
[2020-07-22 15:42:19,314] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:42:19,323] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:16:00+00:00 [scheduled]> in ORM
[2020-07-22 15:42:19,482] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.361 seconds
[2020-07-22 15:42:53,610] {scheduler_job.py:153} INFO - Started process (PID=523436) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:42:53,617] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:42:53,618] {logging_mixin.py:112} INFO - [2020-07-22 15:42:53,617] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:42:53,631] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:42:53,772] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:42:54,134] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:17:00+00:00: scheduled__2020-07-20T05:17:00+00:00, externally triggered: False>
[2020-07-22 15:42:54,140] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:16:00+00:00: scheduled__2020-07-20T05:16:00+00:00, externally triggered: False>
[2020-07-22 15:42:54,156] {logging_mixin.py:112} INFO - [2020-07-22 15:42:54,156] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:16:00+00:00: scheduled__2020-07-20T05:16:00+00:00, externally triggered: False> successful
[2020-07-22 15:42:54,245] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:17:00+00:00: scheduled__2020-07-20T05:17:00+00:00, externally triggered: False>
[2020-07-22 15:42:54,262] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:42:54,268] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:17:00+00:00 [scheduled]> in ORM
[2020-07-22 15:42:54,711] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.101 seconds
[2020-07-22 15:43:30,644] {scheduler_job.py:153} INFO - Started process (PID=524250) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:43:30,649] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:43:30,650] {logging_mixin.py:112} INFO - [2020-07-22 15:43:30,649] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:43:30,659] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:43:30,766] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:43:31,123] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:18:00+00:00: scheduled__2020-07-20T05:18:00+00:00, externally triggered: False>
[2020-07-22 15:43:31,128] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:17:00+00:00: scheduled__2020-07-20T05:17:00+00:00, externally triggered: False>
[2020-07-22 15:43:31,136] {logging_mixin.py:112} INFO - [2020-07-22 15:43:31,135] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:17:00+00:00: scheduled__2020-07-20T05:17:00+00:00, externally triggered: False> successful
[2020-07-22 15:43:31,281] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:18:00+00:00: scheduled__2020-07-20T05:18:00+00:00, externally triggered: False>
[2020-07-22 15:43:31,300] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:43:31,304] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:18:00+00:00 [scheduled]> in ORM
[2020-07-22 15:43:31,470] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.826 seconds
[2020-07-22 15:44:24,935] {scheduler_job.py:153} INFO - Started process (PID=525255) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:44:24,954] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:44:24,955] {logging_mixin.py:112} INFO - [2020-07-22 15:44:24,955] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:44:24,970] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:44:25,090] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:44:25,696] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:19:00+00:00: scheduled__2020-07-20T05:19:00+00:00, externally triggered: False>
[2020-07-22 15:44:25,701] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:18:00+00:00: scheduled__2020-07-20T05:18:00+00:00, externally triggered: False>
[2020-07-22 15:44:25,718] {logging_mixin.py:112} INFO - [2020-07-22 15:44:25,718] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:18:00+00:00: scheduled__2020-07-20T05:18:00+00:00, externally triggered: False> successful
[2020-07-22 15:44:25,874] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:19:00+00:00: scheduled__2020-07-20T05:19:00+00:00, externally triggered: False>
[2020-07-22 15:44:25,894] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:44:25,898] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:19:00+00:00 [scheduled]> in ORM
[2020-07-22 15:44:26,041] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.106 seconds
[2020-07-22 15:45:04,209] {scheduler_job.py:153} INFO - Started process (PID=526188) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:45:04,212] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:45:04,212] {logging_mixin.py:112} INFO - [2020-07-22 15:45:04,212] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:45:04,233] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:45:04,363] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:45:04,713] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:20:00+00:00: scheduled__2020-07-20T05:20:00+00:00, externally triggered: False>
[2020-07-22 15:45:04,718] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:19:00+00:00: scheduled__2020-07-20T05:19:00+00:00, externally triggered: False>
[2020-07-22 15:45:04,733] {logging_mixin.py:112} INFO - [2020-07-22 15:45:04,732] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:19:00+00:00: scheduled__2020-07-20T05:19:00+00:00, externally triggered: False> successful
[2020-07-22 15:45:04,842] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:20:00+00:00: scheduled__2020-07-20T05:20:00+00:00, externally triggered: False>
[2020-07-22 15:45:04,864] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:45:04,869] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:20:00+00:00 [scheduled]> in ORM
[2020-07-22 15:45:05,010] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.801 seconds
[2020-07-22 15:45:53,153] {scheduler_job.py:153} INFO - Started process (PID=527095) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:45:53,156] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:45:53,157] {logging_mixin.py:112} INFO - [2020-07-22 15:45:53,157] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:45:53,170] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:45:53,350] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:45:53,641] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:21:00+00:00: scheduled__2020-07-20T05:21:00+00:00, externally triggered: False>
[2020-07-22 15:45:53,647] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:20:00+00:00: scheduled__2020-07-20T05:20:00+00:00, externally triggered: False>
[2020-07-22 15:45:53,656] {logging_mixin.py:112} INFO - [2020-07-22 15:45:53,656] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:20:00+00:00: scheduled__2020-07-20T05:20:00+00:00, externally triggered: False> successful
[2020-07-22 15:45:53,758] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:21:00+00:00: scheduled__2020-07-20T05:21:00+00:00, externally triggered: False>
[2020-07-22 15:45:53,782] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:45:53,786] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:21:00+00:00 [scheduled]> in ORM
[2020-07-22 15:45:53,925] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.772 seconds
[2020-07-22 15:46:29,124] {scheduler_job.py:153} INFO - Started process (PID=527869) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:46:29,127] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:46:29,127] {logging_mixin.py:112} INFO - [2020-07-22 15:46:29,127] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:46:29,137] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:46:29,279] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:46:29,577] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:22:00+00:00: scheduled__2020-07-20T05:22:00+00:00, externally triggered: False>
[2020-07-22 15:46:29,582] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:21:00+00:00: scheduled__2020-07-20T05:21:00+00:00, externally triggered: False>
[2020-07-22 15:46:29,596] {logging_mixin.py:112} INFO - [2020-07-22 15:46:29,596] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:21:00+00:00: scheduled__2020-07-20T05:21:00+00:00, externally triggered: False> successful
[2020-07-22 15:46:29,749] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:22:00+00:00: scheduled__2020-07-20T05:22:00+00:00, externally triggered: False>
[2020-07-22 15:46:29,767] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:46:29,770] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:22:00+00:00 [scheduled]> in ORM
[2020-07-22 15:46:29,905] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.781 seconds
[2020-07-22 15:47:04,826] {scheduler_job.py:153} INFO - Started process (PID=528628) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:47:04,830] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:47:04,831] {logging_mixin.py:112} INFO - [2020-07-22 15:47:04,831] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:47:04,843] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:47:05,005] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:47:05,420] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:23:00+00:00: scheduled__2020-07-20T05:23:00+00:00, externally triggered: False>
[2020-07-22 15:47:05,423] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:22:00+00:00: scheduled__2020-07-20T05:22:00+00:00, externally triggered: False>
[2020-07-22 15:47:05,430] {logging_mixin.py:112} INFO - [2020-07-22 15:47:05,430] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:22:00+00:00: scheduled__2020-07-20T05:22:00+00:00, externally triggered: False> successful
[2020-07-22 15:47:05,525] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:23:00+00:00: scheduled__2020-07-20T05:23:00+00:00, externally triggered: False>
[2020-07-22 15:47:05,545] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:47:05,548] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:23:00+00:00 [scheduled]> in ORM
[2020-07-22 15:47:05,681] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.855 seconds
[2020-07-22 15:47:40,033] {scheduler_job.py:153} INFO - Started process (PID=529367) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:47:40,037] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:47:40,038] {logging_mixin.py:112} INFO - [2020-07-22 15:47:40,038] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:47:40,051] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:47:40,430] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:47:40,777] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:24:00+00:00: scheduled__2020-07-20T05:24:00+00:00, externally triggered: False>
[2020-07-22 15:47:40,798] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:23:00+00:00: scheduled__2020-07-20T05:23:00+00:00, externally triggered: False>
[2020-07-22 15:47:40,816] {logging_mixin.py:112} INFO - [2020-07-22 15:47:40,816] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:23:00+00:00: scheduled__2020-07-20T05:23:00+00:00, externally triggered: False> successful
[2020-07-22 15:47:40,946] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:24:00+00:00: scheduled__2020-07-20T05:24:00+00:00, externally triggered: False>
[2020-07-22 15:47:40,967] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:47:40,975] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:24:00+00:00 [scheduled]> in ORM
[2020-07-22 15:47:41,101] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.068 seconds
[2020-07-22 15:48:17,299] {scheduler_job.py:153} INFO - Started process (PID=530160) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:48:17,303] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:48:17,303] {logging_mixin.py:112} INFO - [2020-07-22 15:48:17,303] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:48:17,312] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:48:17,476] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:48:17,793] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:25:00+00:00: scheduled__2020-07-20T05:25:00+00:00, externally triggered: False>
[2020-07-22 15:48:17,798] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:24:00+00:00: scheduled__2020-07-20T05:24:00+00:00, externally triggered: False>
[2020-07-22 15:48:17,815] {logging_mixin.py:112} INFO - [2020-07-22 15:48:17,815] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:24:00+00:00: scheduled__2020-07-20T05:24:00+00:00, externally triggered: False> successful
[2020-07-22 15:48:17,945] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:25:00+00:00: scheduled__2020-07-20T05:25:00+00:00, externally triggered: False>
[2020-07-22 15:48:17,963] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:48:17,970] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:25:00+00:00 [scheduled]> in ORM
[2020-07-22 15:48:18,123] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.825 seconds
[2020-07-22 15:48:52,355] {scheduler_job.py:153} INFO - Started process (PID=530952) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:48:52,360] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:48:52,360] {logging_mixin.py:112} INFO - [2020-07-22 15:48:52,360] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:48:52,377] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:48:52,574] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:48:52,905] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:26:00+00:00: scheduled__2020-07-20T05:26:00+00:00, externally triggered: False>
[2020-07-22 15:48:52,909] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:25:00+00:00: scheduled__2020-07-20T05:25:00+00:00, externally triggered: False>
[2020-07-22 15:48:52,917] {logging_mixin.py:112} INFO - [2020-07-22 15:48:52,917] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:25:00+00:00: scheduled__2020-07-20T05:25:00+00:00, externally triggered: False> successful
[2020-07-22 15:48:53,011] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:26:00+00:00: scheduled__2020-07-20T05:26:00+00:00, externally triggered: False>
[2020-07-22 15:48:53,029] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:48:53,033] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:26:00+00:00 [scheduled]> in ORM
[2020-07-22 15:48:53,165] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.810 seconds
[2020-07-22 15:49:32,843] {scheduler_job.py:153} INFO - Started process (PID=531787) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:49:32,847] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:49:32,847] {logging_mixin.py:112} INFO - [2020-07-22 15:49:32,847] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:49:32,856] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:49:33,069] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:49:33,349] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:27:00+00:00: scheduled__2020-07-20T05:27:00+00:00, externally triggered: False>
[2020-07-22 15:49:33,354] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:26:00+00:00: scheduled__2020-07-20T05:26:00+00:00, externally triggered: False>
[2020-07-22 15:49:33,362] {logging_mixin.py:112} INFO - [2020-07-22 15:49:33,362] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:26:00+00:00: scheduled__2020-07-20T05:26:00+00:00, externally triggered: False> successful
[2020-07-22 15:49:33,465] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:27:00+00:00: scheduled__2020-07-20T05:27:00+00:00, externally triggered: False>
[2020-07-22 15:49:33,483] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:49:33,488] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:27:00+00:00 [scheduled]> in ORM
[2020-07-22 15:49:33,622] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.779 seconds
[2020-07-22 15:50:07,808] {scheduler_job.py:153} INFO - Started process (PID=532580) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:50:07,811] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:50:07,811] {logging_mixin.py:112} INFO - [2020-07-22 15:50:07,811] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:50:07,820] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:50:07,939] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:50:08,261] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:28:00+00:00: scheduled__2020-07-20T05:28:00+00:00, externally triggered: False>
[2020-07-22 15:50:08,265] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:27:00+00:00: scheduled__2020-07-20T05:27:00+00:00, externally triggered: False>
[2020-07-22 15:50:08,272] {logging_mixin.py:112} INFO - [2020-07-22 15:50:08,272] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:27:00+00:00: scheduled__2020-07-20T05:27:00+00:00, externally triggered: False> successful
[2020-07-22 15:50:08,376] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:28:00+00:00: scheduled__2020-07-20T05:28:00+00:00, externally triggered: False>
[2020-07-22 15:50:08,397] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:50:08,401] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:28:00+00:00 [scheduled]> in ORM
[2020-07-22 15:50:08,544] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.736 seconds
[2020-07-22 15:50:48,100] {scheduler_job.py:153} INFO - Started process (PID=533402) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:50:48,103] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:50:48,104] {logging_mixin.py:112} INFO - [2020-07-22 15:50:48,104] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:50:48,113] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:50:48,257] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:50:48,575] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:29:00+00:00: scheduled__2020-07-20T05:29:00+00:00, externally triggered: False>
[2020-07-22 15:50:48,581] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:28:00+00:00: scheduled__2020-07-20T05:28:00+00:00, externally triggered: False>
[2020-07-22 15:50:48,594] {logging_mixin.py:112} INFO - [2020-07-22 15:50:48,594] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:28:00+00:00: scheduled__2020-07-20T05:28:00+00:00, externally triggered: False> successful
[2020-07-22 15:50:48,764] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:29:00+00:00: scheduled__2020-07-20T05:29:00+00:00, externally triggered: False>
[2020-07-22 15:50:48,783] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:50:48,792] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:29:00+00:00 [scheduled]> in ORM
[2020-07-22 15:50:48,978] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.878 seconds
[2020-07-22 15:51:22,493] {scheduler_job.py:153} INFO - Started process (PID=534158) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:51:22,497] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:51:22,497] {logging_mixin.py:112} INFO - [2020-07-22 15:51:22,497] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:51:22,509] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:51:22,672] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:51:22,962] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:30:00+00:00: scheduled__2020-07-20T05:30:00+00:00, externally triggered: False>
[2020-07-22 15:51:22,965] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:29:00+00:00: scheduled__2020-07-20T05:29:00+00:00, externally triggered: False>
[2020-07-22 15:51:22,980] {logging_mixin.py:112} INFO - [2020-07-22 15:51:22,980] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:29:00+00:00: scheduled__2020-07-20T05:29:00+00:00, externally triggered: False> successful
[2020-07-22 15:51:23,098] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:30:00+00:00: scheduled__2020-07-20T05:30:00+00:00, externally triggered: False>
[2020-07-22 15:51:23,123] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:51:23,133] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:30:00+00:00 [scheduled]> in ORM
[2020-07-22 15:51:23,252] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.759 seconds
[2020-07-22 15:51:58,604] {scheduler_job.py:153} INFO - Started process (PID=534914) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:51:58,608] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:51:58,609] {logging_mixin.py:112} INFO - [2020-07-22 15:51:58,609] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:51:58,617] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:51:58,842] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:51:59,159] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:31:00+00:00: scheduled__2020-07-20T05:31:00+00:00, externally triggered: False>
[2020-07-22 15:51:59,166] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:30:00+00:00: scheduled__2020-07-20T05:30:00+00:00, externally triggered: False>
[2020-07-22 15:51:59,177] {logging_mixin.py:112} INFO - [2020-07-22 15:51:59,177] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:30:00+00:00: scheduled__2020-07-20T05:30:00+00:00, externally triggered: False> successful
[2020-07-22 15:51:59,265] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:31:00+00:00: scheduled__2020-07-20T05:31:00+00:00, externally triggered: False>
[2020-07-22 15:51:59,284] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:51:59,289] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:31:00+00:00 [scheduled]> in ORM
[2020-07-22 15:51:59,409] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.805 seconds
[2020-07-22 15:52:38,675] {scheduler_job.py:153} INFO - Started process (PID=535757) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:52:38,678] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:52:38,679] {logging_mixin.py:112} INFO - [2020-07-22 15:52:38,679] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:52:38,688] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:52:38,824] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:52:39,223] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:32:00+00:00: scheduled__2020-07-20T05:32:00+00:00, externally triggered: False>
[2020-07-22 15:52:39,228] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:31:00+00:00: scheduled__2020-07-20T05:31:00+00:00, externally triggered: False>
[2020-07-22 15:52:39,239] {logging_mixin.py:112} INFO - [2020-07-22 15:52:39,239] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:31:00+00:00: scheduled__2020-07-20T05:31:00+00:00, externally triggered: False> successful
[2020-07-22 15:52:39,353] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:32:00+00:00: scheduled__2020-07-20T05:32:00+00:00, externally triggered: False>
[2020-07-22 15:52:39,379] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:52:39,387] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:32:00+00:00 [scheduled]> in ORM
[2020-07-22 15:52:39,538] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.863 seconds
[2020-07-22 15:53:19,759] {scheduler_job.py:153} INFO - Started process (PID=536683) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:53:19,764] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:53:19,764] {logging_mixin.py:112} INFO - [2020-07-22 15:53:19,764] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:53:19,774] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:53:19,884] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:53:20,586] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:33:00+00:00: scheduled__2020-07-20T05:33:00+00:00, externally triggered: False>
[2020-07-22 15:53:20,590] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:32:00+00:00: scheduled__2020-07-20T05:32:00+00:00, externally triggered: False>
[2020-07-22 15:53:20,600] {logging_mixin.py:112} INFO - [2020-07-22 15:53:20,599] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:32:00+00:00: scheduled__2020-07-20T05:32:00+00:00, externally triggered: False> successful
[2020-07-22 15:53:20,709] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:33:00+00:00: scheduled__2020-07-20T05:33:00+00:00, externally triggered: False>
[2020-07-22 15:53:20,729] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:53:20,733] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:33:00+00:00 [scheduled]> in ORM
[2020-07-22 15:53:20,862] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.103 seconds
[2020-07-22 15:54:01,223] {scheduler_job.py:153} INFO - Started process (PID=537579) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:54:01,230] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:54:01,230] {logging_mixin.py:112} INFO - [2020-07-22 15:54:01,230] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:54:01,241] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:54:01,362] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:54:01,643] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:34:00+00:00: scheduled__2020-07-20T05:34:00+00:00, externally triggered: False>
[2020-07-22 15:54:01,646] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:33:00+00:00: scheduled__2020-07-20T05:33:00+00:00, externally triggered: False>
[2020-07-22 15:54:01,655] {logging_mixin.py:112} INFO - [2020-07-22 15:54:01,655] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:33:00+00:00: scheduled__2020-07-20T05:33:00+00:00, externally triggered: False> successful
[2020-07-22 15:54:01,798] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:34:00+00:00: scheduled__2020-07-20T05:34:00+00:00, externally triggered: False>
[2020-07-22 15:54:01,822] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:54:01,827] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:34:00+00:00 [scheduled]> in ORM
[2020-07-22 15:54:01,977] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.754 seconds
[2020-07-22 15:54:38,296] {scheduler_job.py:153} INFO - Started process (PID=538350) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:54:38,299] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:54:38,299] {logging_mixin.py:112} INFO - [2020-07-22 15:54:38,299] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:54:38,308] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:54:38,439] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:54:38,741] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:35:00+00:00: scheduled__2020-07-20T05:35:00+00:00, externally triggered: False>
[2020-07-22 15:54:38,747] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:34:00+00:00: scheduled__2020-07-20T05:34:00+00:00, externally triggered: False>
[2020-07-22 15:54:38,760] {logging_mixin.py:112} INFO - [2020-07-22 15:54:38,759] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:34:00+00:00: scheduled__2020-07-20T05:34:00+00:00, externally triggered: False> successful
[2020-07-22 15:54:39,683] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:35:00+00:00: scheduled__2020-07-20T05:35:00+00:00, externally triggered: False>
[2020-07-22 15:54:39,703] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:54:39,707] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:35:00+00:00 [scheduled]> in ORM
[2020-07-22 15:54:40,009] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.713 seconds
[2020-07-22 15:55:14,331] {scheduler_job.py:153} INFO - Started process (PID=539103) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:55:14,334] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:55:14,335] {logging_mixin.py:112} INFO - [2020-07-22 15:55:14,335] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:55:14,344] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:55:14,530] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:55:14,988] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:36:00+00:00: scheduled__2020-07-20T05:36:00+00:00, externally triggered: False>
[2020-07-22 15:55:15,008] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:35:00+00:00: scheduled__2020-07-20T05:35:00+00:00, externally triggered: False>
[2020-07-22 15:55:15,039] {logging_mixin.py:112} INFO - [2020-07-22 15:55:15,039] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:35:00+00:00: scheduled__2020-07-20T05:35:00+00:00, externally triggered: False> successful
[2020-07-22 15:55:15,132] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:36:00+00:00: scheduled__2020-07-20T05:36:00+00:00, externally triggered: False>
[2020-07-22 15:55:15,167] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:55:15,173] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:36:00+00:00 [scheduled]> in ORM
[2020-07-22 15:55:15,298] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.967 seconds
[2020-07-22 15:55:52,936] {scheduler_job.py:153} INFO - Started process (PID=539892) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:55:52,940] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:55:52,940] {logging_mixin.py:112} INFO - [2020-07-22 15:55:52,940] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:55:52,952] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:55:53,075] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:55:53,407] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:37:00+00:00: scheduled__2020-07-20T05:37:00+00:00, externally triggered: False>
[2020-07-22 15:55:53,413] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:36:00+00:00: scheduled__2020-07-20T05:36:00+00:00, externally triggered: False>
[2020-07-22 15:55:53,421] {logging_mixin.py:112} INFO - [2020-07-22 15:55:53,421] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:36:00+00:00: scheduled__2020-07-20T05:36:00+00:00, externally triggered: False> successful
[2020-07-22 15:55:53,533] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:37:00+00:00: scheduled__2020-07-20T05:37:00+00:00, externally triggered: False>
[2020-07-22 15:55:53,553] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:55:53,557] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:37:00+00:00 [scheduled]> in ORM
[2020-07-22 15:55:53,701] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.764 seconds
[2020-07-22 15:56:53,407] {scheduler_job.py:153} INFO - Started process (PID=541136) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:56:53,411] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:56:53,412] {logging_mixin.py:112} INFO - [2020-07-22 15:56:53,412] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:56:53,457] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:56:53,848] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:56:55,183] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:38:00+00:00: scheduled__2020-07-20T05:38:00+00:00, externally triggered: False>
[2020-07-22 15:56:55,202] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:37:00+00:00: scheduled__2020-07-20T05:37:00+00:00, externally triggered: False>
[2020-07-22 15:56:55,218] {logging_mixin.py:112} INFO - [2020-07-22 15:56:55,218] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:37:00+00:00: scheduled__2020-07-20T05:37:00+00:00, externally triggered: False> successful
[2020-07-22 15:56:55,681] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:38:00+00:00: scheduled__2020-07-20T05:38:00+00:00, externally triggered: False>
[2020-07-22 15:56:55,701] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:56:55,707] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:38:00+00:00 [scheduled]> in ORM
[2020-07-22 15:56:56,194] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.787 seconds
[2020-07-22 15:57:10,123] {scheduler_job.py:153} INFO - Started process (PID=541482) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:57:10,126] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:57:10,127] {logging_mixin.py:112} INFO - [2020-07-22 15:57:10,127] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:57:10,138] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:57:10,820] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:57:12,791] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:39:00+00:00: scheduled__2020-07-20T05:39:00+00:00, externally triggered: False>
[2020-07-22 15:57:12,796] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:38:00+00:00: scheduled__2020-07-20T05:38:00+00:00, externally triggered: False>
[2020-07-22 15:57:12,807] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:39:00+00:00: scheduled__2020-07-20T05:39:00+00:00, externally triggered: False>
[2020-07-22 15:57:12,823] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:57:12,827] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:39:00+00:00 [scheduled]> in ORM
[2020-07-22 15:57:13,738] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 3.615 seconds
[2020-07-22 15:57:31,980] {scheduler_job.py:153} INFO - Started process (PID=541989) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:57:31,996] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:57:31,997] {logging_mixin.py:112} INFO - [2020-07-22 15:57:31,996] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:57:32,035] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:57:32,228] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:57:32,648] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:40:00+00:00: scheduled__2020-07-20T05:40:00+00:00, externally triggered: False>
[2020-07-22 15:57:32,655] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:38:00+00:00: scheduled__2020-07-20T05:38:00+00:00, externally triggered: False>
[2020-07-22 15:57:32,671] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:39:00+00:00: scheduled__2020-07-20T05:39:00+00:00, externally triggered: False>
[2020-07-22 15:57:32,687] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:40:00+00:00: scheduled__2020-07-20T05:40:00+00:00, externally triggered: False>
[2020-07-22 15:57:32,730] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:57:32,737] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:40:00+00:00 [scheduled]> in ORM
[2020-07-22 15:57:32,943] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.962 seconds
[2020-07-22 15:58:55,410] {scheduler_job.py:153} INFO - Started process (PID=543597) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:58:55,430] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:58:55,431] {logging_mixin.py:112} INFO - [2020-07-22 15:58:55,431] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:58:55,456] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:58:55,675] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:58:56,105] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:41:00+00:00: scheduled__2020-07-20T05:41:00+00:00, externally triggered: False>
[2020-07-22 15:58:56,108] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:38:00+00:00: scheduled__2020-07-20T05:38:00+00:00, externally triggered: False>
[2020-07-22 15:58:56,116] {logging_mixin.py:112} INFO - [2020-07-22 15:58:56,116] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:38:00+00:00: scheduled__2020-07-20T05:38:00+00:00, externally triggered: False> successful
[2020-07-22 15:58:56,216] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:39:00+00:00: scheduled__2020-07-20T05:39:00+00:00, externally triggered: False>
[2020-07-22 15:58:56,230] {logging_mixin.py:112} INFO - [2020-07-22 15:58:56,230] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:39:00+00:00: scheduled__2020-07-20T05:39:00+00:00, externally triggered: False> successful
[2020-07-22 15:58:56,338] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:40:00+00:00: scheduled__2020-07-20T05:40:00+00:00, externally triggered: False>
[2020-07-22 15:58:56,354] {logging_mixin.py:112} INFO - [2020-07-22 15:58:56,354] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:40:00+00:00: scheduled__2020-07-20T05:40:00+00:00, externally triggered: False> successful
[2020-07-22 15:58:56,482] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:41:00+00:00: scheduled__2020-07-20T05:41:00+00:00, externally triggered: False>
[2020-07-22 15:58:56,509] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:58:56,518] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:41:00+00:00 [scheduled]> in ORM
[2020-07-22 15:58:56,649] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.239 seconds
[2020-07-22 15:59:32,384] {scheduler_job.py:153} INFO - Started process (PID=544407) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:59:32,390] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 15:59:32,390] {logging_mixin.py:112} INFO - [2020-07-22 15:59:32,390] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:59:32,411] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 15:59:32,623] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 15:59:32,924] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:42:00+00:00: scheduled__2020-07-20T05:42:00+00:00, externally triggered: False>
[2020-07-22 15:59:32,932] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:41:00+00:00: scheduled__2020-07-20T05:41:00+00:00, externally triggered: False>
[2020-07-22 15:59:32,950] {logging_mixin.py:112} INFO - [2020-07-22 15:59:32,949] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:41:00+00:00: scheduled__2020-07-20T05:41:00+00:00, externally triggered: False> successful
[2020-07-22 15:59:33,117] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:42:00+00:00: scheduled__2020-07-20T05:42:00+00:00, externally triggered: False>
[2020-07-22 15:59:33,138] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 15:59:33,146] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:42:00+00:00 [scheduled]> in ORM
[2020-07-22 15:59:33,318] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.935 seconds
[2020-07-22 16:00:13,450] {scheduler_job.py:153} INFO - Started process (PID=545334) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:00:13,456] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:00:13,457] {logging_mixin.py:112} INFO - [2020-07-22 16:00:13,457] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:00:13,471] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:00:13,592] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:00:13,915] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:43:00+00:00: scheduled__2020-07-20T05:43:00+00:00, externally triggered: False>
[2020-07-22 16:00:13,932] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:42:00+00:00: scheduled__2020-07-20T05:42:00+00:00, externally triggered: False>
[2020-07-22 16:00:13,955] {logging_mixin.py:112} INFO - [2020-07-22 16:00:13,955] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:42:00+00:00: scheduled__2020-07-20T05:42:00+00:00, externally triggered: False> successful
[2020-07-22 16:00:14,096] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:43:00+00:00: scheduled__2020-07-20T05:43:00+00:00, externally triggered: False>
[2020-07-22 16:00:14,144] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:00:14,160] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:43:00+00:00 [scheduled]> in ORM
[2020-07-22 16:00:14,283] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.833 seconds
[2020-07-22 16:01:01,965] {scheduler_job.py:153} INFO - Started process (PID=546677) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:01:01,968] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:01:01,969] {logging_mixin.py:112} INFO - [2020-07-22 16:01:01,969] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:01:01,979] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:01:02,088] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:01:02,410] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:44:00+00:00: scheduled__2020-07-20T05:44:00+00:00, externally triggered: False>
[2020-07-22 16:01:02,415] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:43:00+00:00: scheduled__2020-07-20T05:43:00+00:00, externally triggered: False>
[2020-07-22 16:01:02,423] {logging_mixin.py:112} INFO - [2020-07-22 16:01:02,423] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:43:00+00:00: scheduled__2020-07-20T05:43:00+00:00, externally triggered: False> successful
[2020-07-22 16:01:02,519] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:44:00+00:00: scheduled__2020-07-20T05:44:00+00:00, externally triggered: False>
[2020-07-22 16:01:02,534] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:01:02,539] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:44:00+00:00 [scheduled]> in ORM
[2020-07-22 16:01:02,687] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.722 seconds
[2020-07-22 16:01:37,272] {scheduler_job.py:153} INFO - Started process (PID=547421) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:01:37,277] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:01:37,277] {logging_mixin.py:112} INFO - [2020-07-22 16:01:37,277] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:01:37,293] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:01:37,436] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:01:37,767] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:45:00+00:00: scheduled__2020-07-20T05:45:00+00:00, externally triggered: False>
[2020-07-22 16:01:37,771] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:44:00+00:00: scheduled__2020-07-20T05:44:00+00:00, externally triggered: False>
[2020-07-22 16:01:37,780] {logging_mixin.py:112} INFO - [2020-07-22 16:01:37,780] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:44:00+00:00: scheduled__2020-07-20T05:44:00+00:00, externally triggered: False> successful
[2020-07-22 16:01:37,909] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:45:00+00:00: scheduled__2020-07-20T05:45:00+00:00, externally triggered: False>
[2020-07-22 16:01:37,925] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:01:37,929] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:45:00+00:00 [scheduled]> in ORM
[2020-07-22 16:01:38,074] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.801 seconds
[2020-07-22 16:02:24,786] {scheduler_job.py:153} INFO - Started process (PID=548353) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:02:24,790] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:02:24,791] {logging_mixin.py:112} INFO - [2020-07-22 16:02:24,790] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:02:24,808] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:02:24,983] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:02:25,373] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:46:00+00:00: scheduled__2020-07-20T05:46:00+00:00, externally triggered: False>
[2020-07-22 16:02:25,378] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:45:00+00:00: scheduled__2020-07-20T05:45:00+00:00, externally triggered: False>
[2020-07-22 16:02:25,403] {logging_mixin.py:112} INFO - [2020-07-22 16:02:25,403] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:45:00+00:00: scheduled__2020-07-20T05:45:00+00:00, externally triggered: False> successful
[2020-07-22 16:02:25,725] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:46:00+00:00: scheduled__2020-07-20T05:46:00+00:00, externally triggered: False>
[2020-07-22 16:02:25,743] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:02:25,750] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:46:00+00:00 [scheduled]> in ORM
[2020-07-22 16:02:25,943] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.158 seconds
[2020-07-22 16:03:08,653] {scheduler_job.py:153} INFO - Started process (PID=549256) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:03:08,663] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:03:08,663] {logging_mixin.py:112} INFO - [2020-07-22 16:03:08,663] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:03:08,691] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:03:08,913] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:03:09,291] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:47:00+00:00: scheduled__2020-07-20T05:47:00+00:00, externally triggered: False>
[2020-07-22 16:03:09,298] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:46:00+00:00: scheduled__2020-07-20T05:46:00+00:00, externally triggered: False>
[2020-07-22 16:03:09,323] {logging_mixin.py:112} INFO - [2020-07-22 16:03:09,323] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:46:00+00:00: scheduled__2020-07-20T05:46:00+00:00, externally triggered: False> successful
[2020-07-22 16:03:09,524] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:47:00+00:00: scheduled__2020-07-20T05:47:00+00:00, externally triggered: False>
[2020-07-22 16:03:09,549] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:03:09,559] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:47:00+00:00 [scheduled]> in ORM
[2020-07-22 16:03:09,719] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.066 seconds
[2020-07-22 16:04:04,296] {scheduler_job.py:153} INFO - Started process (PID=550313) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:04:04,300] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:04:04,301] {logging_mixin.py:112} INFO - [2020-07-22 16:04:04,301] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:04:04,328] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:04:04,550] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:04:04,874] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:48:00+00:00: scheduled__2020-07-20T05:48:00+00:00, externally triggered: False>
[2020-07-22 16:04:04,881] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:47:00+00:00: scheduled__2020-07-20T05:47:00+00:00, externally triggered: False>
[2020-07-22 16:04:04,896] {logging_mixin.py:112} INFO - [2020-07-22 16:04:04,896] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:47:00+00:00: scheduled__2020-07-20T05:47:00+00:00, externally triggered: False> successful
[2020-07-22 16:04:05,004] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:48:00+00:00: scheduled__2020-07-20T05:48:00+00:00, externally triggered: False>
[2020-07-22 16:04:05,079] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:04:05,086] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:48:00+00:00 [scheduled]> in ORM
[2020-07-22 16:04:05,317] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.021 seconds
[2020-07-22 16:04:41,987] {scheduler_job.py:153} INFO - Started process (PID=551034) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:04:42,000] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:04:42,001] {logging_mixin.py:112} INFO - [2020-07-22 16:04:42,001] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:04:42,029] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:04:42,280] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:04:43,025] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:49:00+00:00: scheduled__2020-07-20T05:49:00+00:00, externally triggered: False>
[2020-07-22 16:04:43,032] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:48:00+00:00: scheduled__2020-07-20T05:48:00+00:00, externally triggered: False>
[2020-07-22 16:04:43,053] {logging_mixin.py:112} INFO - [2020-07-22 16:04:43,053] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:48:00+00:00: scheduled__2020-07-20T05:48:00+00:00, externally triggered: False> failed
[2020-07-22 16:04:43,194] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:49:00+00:00: scheduled__2020-07-20T05:49:00+00:00, externally triggered: False>
[2020-07-22 16:04:43,213] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:04:43,219] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:49:00+00:00 [scheduled]> in ORM
[2020-07-22 16:04:43,383] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.395 seconds
[2020-07-22 16:05:15,914] {scheduler_job.py:153} INFO - Started process (PID=551712) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:05:15,921] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:05:15,922] {logging_mixin.py:112} INFO - [2020-07-22 16:05:15,922] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:05:15,937] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:05:16,581] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:05:16,966] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:50:00+00:00: scheduled__2020-07-20T05:50:00+00:00, externally triggered: False>
[2020-07-22 16:05:16,972] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:49:00+00:00: scheduled__2020-07-20T05:49:00+00:00, externally triggered: False>
[2020-07-22 16:05:16,981] {logging_mixin.py:112} INFO - [2020-07-22 16:05:16,981] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:49:00+00:00: scheduled__2020-07-20T05:49:00+00:00, externally triggered: False> failed
[2020-07-22 16:05:17,107] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:50:00+00:00: scheduled__2020-07-20T05:50:00+00:00, externally triggered: False>
[2020-07-22 16:05:17,123] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:05:17,129] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:50:00+00:00 [scheduled]> in ORM
[2020-07-22 16:05:17,294] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.380 seconds
[2020-07-22 16:05:52,924] {scheduler_job.py:153} INFO - Started process (PID=552408) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:05:52,929] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:05:52,930] {logging_mixin.py:112} INFO - [2020-07-22 16:05:52,930] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:05:52,950] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:05:53,111] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:05:53,830] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:51:00+00:00: scheduled__2020-07-20T05:51:00+00:00, externally triggered: False>
[2020-07-22 16:05:53,854] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:50:00+00:00: scheduled__2020-07-20T05:50:00+00:00, externally triggered: False>
[2020-07-22 16:05:53,895] {logging_mixin.py:112} INFO - [2020-07-22 16:05:53,894] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:50:00+00:00: scheduled__2020-07-20T05:50:00+00:00, externally triggered: False> failed
[2020-07-22 16:05:54,020] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:51:00+00:00: scheduled__2020-07-20T05:51:00+00:00, externally triggered: False>
[2020-07-22 16:05:54,084] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:05:54,096] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:51:00+00:00 [scheduled]> in ORM
[2020-07-22 16:05:54,265] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.341 seconds
[2020-07-22 16:06:26,312] {scheduler_job.py:153} INFO - Started process (PID=553050) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:06:26,316] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:06:26,317] {logging_mixin.py:112} INFO - [2020-07-22 16:06:26,317] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:06:26,331] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:06:26,473] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:06:26,860] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:52:00+00:00: scheduled__2020-07-20T05:52:00+00:00, externally triggered: False>
[2020-07-22 16:06:26,865] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:51:00+00:00: scheduled__2020-07-20T05:51:00+00:00, externally triggered: False>
[2020-07-22 16:06:26,878] {logging_mixin.py:112} INFO - [2020-07-22 16:06:26,878] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:51:00+00:00: scheduled__2020-07-20T05:51:00+00:00, externally triggered: False> failed
[2020-07-22 16:06:27,010] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:52:00+00:00: scheduled__2020-07-20T05:52:00+00:00, externally triggered: False>
[2020-07-22 16:06:27,024] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:06:27,029] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:52:00+00:00 [scheduled]> in ORM
[2020-07-22 16:06:27,174] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.862 seconds
[2020-07-22 16:06:57,716] {scheduler_job.py:153} INFO - Started process (PID=553697) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:06:57,725] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:06:57,726] {logging_mixin.py:112} INFO - [2020-07-22 16:06:57,726] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:06:57,750] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:06:58,051] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:06:58,487] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:53:00+00:00: scheduled__2020-07-20T05:53:00+00:00, externally triggered: False>
[2020-07-22 16:06:58,533] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:52:00+00:00: scheduled__2020-07-20T05:52:00+00:00, externally triggered: False>
[2020-07-22 16:06:58,564] {logging_mixin.py:112} INFO - [2020-07-22 16:06:58,564] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:52:00+00:00: scheduled__2020-07-20T05:52:00+00:00, externally triggered: False> failed
[2020-07-22 16:06:58,771] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:53:00+00:00: scheduled__2020-07-20T05:53:00+00:00, externally triggered: False>
[2020-07-22 16:06:58,838] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:06:58,863] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:53:00+00:00 [scheduled]> in ORM
[2020-07-22 16:06:59,077] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.362 seconds
[2020-07-22 16:07:25,269] {scheduler_job.py:153} INFO - Started process (PID=554262) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:07:25,278] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:07:25,279] {logging_mixin.py:112} INFO - [2020-07-22 16:07:25,279] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:07:25,299] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:07:25,546] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:07:26,060] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:54:00+00:00: scheduled__2020-07-20T05:54:00+00:00, externally triggered: False>
[2020-07-22 16:07:26,072] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:53:00+00:00: scheduled__2020-07-20T05:53:00+00:00, externally triggered: False>
[2020-07-22 16:07:26,120] {logging_mixin.py:112} INFO - [2020-07-22 16:07:26,119] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:53:00+00:00: scheduled__2020-07-20T05:53:00+00:00, externally triggered: False> failed
[2020-07-22 16:07:26,313] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:54:00+00:00: scheduled__2020-07-20T05:54:00+00:00, externally triggered: False>
[2020-07-22 16:07:26,385] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:07:26,405] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:54:00+00:00 [scheduled]> in ORM
[2020-07-22 16:07:26,596] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.326 seconds
[2020-07-22 16:08:02,065] {scheduler_job.py:153} INFO - Started process (PID=555006) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:08:02,068] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:08:02,069] {logging_mixin.py:112} INFO - [2020-07-22 16:08:02,068] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:08:02,081] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:08:02,269] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:08:02,619] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:55:00+00:00: scheduled__2020-07-20T05:55:00+00:00, externally triggered: False>
[2020-07-22 16:08:02,625] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:54:00+00:00: scheduled__2020-07-20T05:54:00+00:00, externally triggered: False>
[2020-07-22 16:08:02,638] {logging_mixin.py:112} INFO - [2020-07-22 16:08:02,638] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:54:00+00:00: scheduled__2020-07-20T05:54:00+00:00, externally triggered: False> failed
[2020-07-22 16:08:02,781] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:55:00+00:00: scheduled__2020-07-20T05:55:00+00:00, externally triggered: False>
[2020-07-22 16:08:02,803] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:08:02,811] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:55:00+00:00 [scheduled]> in ORM
[2020-07-22 16:08:02,990] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.925 seconds
[2020-07-22 16:08:48,927] {scheduler_job.py:153} INFO - Started process (PID=555962) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:08:48,932] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:08:48,933] {logging_mixin.py:112} INFO - [2020-07-22 16:08:48,933] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:08:48,948] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:08:49,114] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:08:49,476] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:56:00+00:00: scheduled__2020-07-20T05:56:00+00:00, externally triggered: False>
[2020-07-22 16:08:49,487] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:55:00+00:00: scheduled__2020-07-20T05:55:00+00:00, externally triggered: False>
[2020-07-22 16:08:49,514] {logging_mixin.py:112} INFO - [2020-07-22 16:08:49,514] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:55:00+00:00: scheduled__2020-07-20T05:55:00+00:00, externally triggered: False> successful
[2020-07-22 16:08:49,675] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:56:00+00:00: scheduled__2020-07-20T05:56:00+00:00, externally triggered: False>
[2020-07-22 16:08:49,702] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:08:49,713] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:56:00+00:00 [scheduled]> in ORM
[2020-07-22 16:08:49,904] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.978 seconds
[2020-07-22 16:09:31,521] {scheduler_job.py:153} INFO - Started process (PID=556825) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:09:31,527] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:09:31,528] {logging_mixin.py:112} INFO - [2020-07-22 16:09:31,528] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:09:31,540] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:09:31,739] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:09:32,076] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:57:00+00:00: scheduled__2020-07-20T05:57:00+00:00, externally triggered: False>
[2020-07-22 16:09:32,079] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:56:00+00:00: scheduled__2020-07-20T05:56:00+00:00, externally triggered: False>
[2020-07-22 16:09:32,088] {logging_mixin.py:112} INFO - [2020-07-22 16:09:32,087] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:56:00+00:00: scheduled__2020-07-20T05:56:00+00:00, externally triggered: False> successful
[2020-07-22 16:09:32,218] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:57:00+00:00: scheduled__2020-07-20T05:57:00+00:00, externally triggered: False>
[2020-07-22 16:09:32,245] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:09:32,265] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:57:00+00:00 [scheduled]> in ORM
[2020-07-22 16:09:32,462] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.941 seconds
[2020-07-22 16:10:04,315] {scheduler_job.py:153} INFO - Started process (PID=557442) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:10:04,320] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:10:04,320] {logging_mixin.py:112} INFO - [2020-07-22 16:10:04,320] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:10:04,343] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:10:04,865] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:10:05,280] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:58:00+00:00: scheduled__2020-07-20T05:58:00+00:00, externally triggered: False>
[2020-07-22 16:10:05,285] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:57:00+00:00: scheduled__2020-07-20T05:57:00+00:00, externally triggered: False>
[2020-07-22 16:10:05,297] {logging_mixin.py:112} INFO - [2020-07-22 16:10:05,297] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:57:00+00:00: scheduled__2020-07-20T05:57:00+00:00, externally triggered: False> failed
[2020-07-22 16:10:05,397] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:58:00+00:00: scheduled__2020-07-20T05:58:00+00:00, externally triggered: False>
[2020-07-22 16:10:05,413] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:10:05,420] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:58:00+00:00 [scheduled]> in ORM
[2020-07-22 16:10:05,596] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.282 seconds
[2020-07-22 16:10:38,247] {scheduler_job.py:153} INFO - Started process (PID=558097) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:10:38,251] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:10:38,251] {logging_mixin.py:112} INFO - [2020-07-22 16:10:38,251] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:10:38,262] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:10:38,428] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:10:38,834] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T05:59:00+00:00: scheduled__2020-07-20T05:59:00+00:00, externally triggered: False>
[2020-07-22 16:10:38,840] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:58:00+00:00: scheduled__2020-07-20T05:58:00+00:00, externally triggered: False>
[2020-07-22 16:10:38,851] {logging_mixin.py:112} INFO - [2020-07-22 16:10:38,851] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:58:00+00:00: scheduled__2020-07-20T05:58:00+00:00, externally triggered: False> failed
[2020-07-22 16:10:38,966] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:59:00+00:00: scheduled__2020-07-20T05:59:00+00:00, externally triggered: False>
[2020-07-22 16:10:38,986] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:10:38,991] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 05:59:00+00:00 [scheduled]> in ORM
[2020-07-22 16:10:39,179] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.932 seconds
[2020-07-22 16:11:09,292] {scheduler_job.py:153} INFO - Started process (PID=558739) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:11:09,320] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:11:09,320] {logging_mixin.py:112} INFO - [2020-07-22 16:11:09,320] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:11:09,393] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:11:09,547] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:11:09,893] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:00:00+00:00: scheduled__2020-07-20T06:00:00+00:00, externally triggered: False>
[2020-07-22 16:11:09,906] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 05:59:00+00:00: scheduled__2020-07-20T05:59:00+00:00, externally triggered: False>
[2020-07-22 16:11:09,966] {logging_mixin.py:112} INFO - [2020-07-22 16:11:09,965] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 05:59:00+00:00: scheduled__2020-07-20T05:59:00+00:00, externally triggered: False> failed
[2020-07-22 16:11:10,089] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:00:00+00:00: scheduled__2020-07-20T06:00:00+00:00, externally triggered: False>
[2020-07-22 16:11:10,165] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:11:10,212] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:00:00+00:00 [scheduled]> in ORM
[2020-07-22 16:11:10,533] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.241 seconds
[2020-07-22 16:11:43,226] {scheduler_job.py:153} INFO - Started process (PID=559375) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:11:43,230] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:11:43,231] {logging_mixin.py:112} INFO - [2020-07-22 16:11:43,231] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:11:43,246] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:11:43,428] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:11:43,824] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:01:00+00:00: scheduled__2020-07-20T06:01:00+00:00, externally triggered: False>
[2020-07-22 16:11:43,832] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:00:00+00:00: scheduled__2020-07-20T06:00:00+00:00, externally triggered: False>
[2020-07-22 16:11:43,860] {logging_mixin.py:112} INFO - [2020-07-22 16:11:43,860] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:00:00+00:00: scheduled__2020-07-20T06:00:00+00:00, externally triggered: False> failed
[2020-07-22 16:11:43,991] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:01:00+00:00: scheduled__2020-07-20T06:01:00+00:00, externally triggered: False>
[2020-07-22 16:11:44,029] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:11:44,066] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:01:00+00:00 [scheduled]> in ORM
[2020-07-22 16:11:44,246] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.020 seconds
[2020-07-22 16:13:07,205] {scheduler_job.py:153} INFO - Started process (PID=560880) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:13:07,210] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:13:07,211] {logging_mixin.py:112} INFO - [2020-07-22 16:13:07,211] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:13:07,234] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:13:07,492] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:13:07,845] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:02:00+00:00: scheduled__2020-07-20T06:02:00+00:00, externally triggered: False>
[2020-07-22 16:13:07,849] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:01:00+00:00: scheduled__2020-07-20T06:01:00+00:00, externally triggered: False>
[2020-07-22 16:13:07,858] {logging_mixin.py:112} INFO - [2020-07-22 16:13:07,858] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:01:00+00:00: scheduled__2020-07-20T06:01:00+00:00, externally triggered: False> successful
[2020-07-22 16:13:07,995] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:02:00+00:00: scheduled__2020-07-20T06:02:00+00:00, externally triggered: False>
[2020-07-22 16:13:08,014] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:13:08,018] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:02:00+00:00 [scheduled]> in ORM
[2020-07-22 16:13:08,173] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.968 seconds
[2020-07-22 16:14:13,161] {scheduler_job.py:153} INFO - Started process (PID=562104) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:14:13,164] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:14:13,165] {logging_mixin.py:112} INFO - [2020-07-22 16:14:13,165] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:14:13,175] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:14:13,576] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:14:13,944] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:03:00+00:00: scheduled__2020-07-20T06:03:00+00:00, externally triggered: False>
[2020-07-22 16:14:13,948] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:02:00+00:00: scheduled__2020-07-20T06:02:00+00:00, externally triggered: False>
[2020-07-22 16:14:13,957] {logging_mixin.py:112} INFO - [2020-07-22 16:14:13,956] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:02:00+00:00: scheduled__2020-07-20T06:02:00+00:00, externally triggered: False> successful
[2020-07-22 16:14:14,120] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:03:00+00:00: scheduled__2020-07-20T06:03:00+00:00, externally triggered: False>
[2020-07-22 16:14:14,135] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 10:43:43.512840+00:00: manual__2020-07-22T10:43:43.512840+00:00, externally triggered: True>
[2020-07-22 16:14:14,152] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:14:14,156] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:03:00+00:00 [scheduled]> in ORM
[2020-07-22 16:14:14,161] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 10:43:43.512840+00:00 [scheduled]> in ORM
[2020-07-22 16:14:14,390] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.229 seconds
[2020-07-22 16:15:32,667] {scheduler_job.py:153} INFO - Started process (PID=563729) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:15:32,671] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:15:32,671] {logging_mixin.py:112} INFO - [2020-07-22 16:15:32,671] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:15:32,693] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:15:32,905] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:15:33,349] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:04:00+00:00: scheduled__2020-07-20T06:04:00+00:00, externally triggered: False>
[2020-07-22 16:15:33,354] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:03:00+00:00: scheduled__2020-07-20T06:03:00+00:00, externally triggered: False>
[2020-07-22 16:15:33,369] {logging_mixin.py:112} INFO - [2020-07-22 16:15:33,369] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:03:00+00:00: scheduled__2020-07-20T06:03:00+00:00, externally triggered: False> successful
[2020-07-22 16:15:33,546] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:04:00+00:00: scheduled__2020-07-20T06:04:00+00:00, externally triggered: False>
[2020-07-22 16:15:33,567] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 10:43:43.512840+00:00: manual__2020-07-22T10:43:43.512840+00:00, externally triggered: True>
[2020-07-22 16:15:33,580] {logging_mixin.py:112} INFO - [2020-07-22 16:15:33,580] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-22 10:43:43.512840+00:00: manual__2020-07-22T10:43:43.512840+00:00, externally triggered: True> successful
[2020-07-22 16:15:33,708] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:15:33,714] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:04:00+00:00 [scheduled]> in ORM
[2020-07-22 16:15:33,911] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.244 seconds
[2020-07-22 16:16:19,408] {scheduler_job.py:153} INFO - Started process (PID=564675) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:16:19,412] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:16:19,412] {logging_mixin.py:112} INFO - [2020-07-22 16:16:19,412] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:16:19,422] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:16:19,624] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:16:19,971] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:05:00+00:00: scheduled__2020-07-20T06:05:00+00:00, externally triggered: False>
[2020-07-22 16:16:19,974] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:04:00+00:00: scheduled__2020-07-20T06:04:00+00:00, externally triggered: False>
[2020-07-22 16:16:19,982] {logging_mixin.py:112} INFO - [2020-07-22 16:16:19,982] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:04:00+00:00: scheduled__2020-07-20T06:04:00+00:00, externally triggered: False> successful
[2020-07-22 16:16:20,093] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:05:00+00:00: scheduled__2020-07-20T06:05:00+00:00, externally triggered: False>
[2020-07-22 16:16:20,111] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:16:20,116] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:05:00+00:00 [scheduled]> in ORM
[2020-07-22 16:16:20,260] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.852 seconds
[2020-07-22 16:17:16,281] {scheduler_job.py:153} INFO - Started process (PID=565786) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:17:16,285] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:17:16,286] {logging_mixin.py:112} INFO - [2020-07-22 16:17:16,285] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:17:16,300] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:17:16,525] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:17:16,868] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:06:00+00:00: scheduled__2020-07-20T06:06:00+00:00, externally triggered: False>
[2020-07-22 16:17:16,874] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:05:00+00:00: scheduled__2020-07-20T06:05:00+00:00, externally triggered: False>
[2020-07-22 16:17:16,889] {logging_mixin.py:112} INFO - [2020-07-22 16:17:16,889] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:05:00+00:00: scheduled__2020-07-20T06:05:00+00:00, externally triggered: False> successful
[2020-07-22 16:17:17,088] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:06:00+00:00: scheduled__2020-07-20T06:06:00+00:00, externally triggered: False>
[2020-07-22 16:17:17,112] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:17:17,119] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:06:00+00:00 [scheduled]> in ORM
[2020-07-22 16:17:17,283] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.002 seconds
[2020-07-22 16:18:23,280] {scheduler_job.py:153} INFO - Started process (PID=566994) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:18:23,285] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:18:23,288] {logging_mixin.py:112} INFO - [2020-07-22 16:18:23,287] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:18:23,305] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:18:23,446] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:18:23,829] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:07:00+00:00: scheduled__2020-07-20T06:07:00+00:00, externally triggered: False>
[2020-07-22 16:18:23,833] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:06:00+00:00: scheduled__2020-07-20T06:06:00+00:00, externally triggered: False>
[2020-07-22 16:18:23,842] {logging_mixin.py:112} INFO - [2020-07-22 16:18:23,842] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:06:00+00:00: scheduled__2020-07-20T06:06:00+00:00, externally triggered: False> successful
[2020-07-22 16:18:24,033] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:07:00+00:00: scheduled__2020-07-20T06:07:00+00:00, externally triggered: False>
[2020-07-22 16:18:24,053] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:18:24,057] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:07:00+00:00 [scheduled]> in ORM
[2020-07-22 16:18:24,366] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.086 seconds
[2020-07-22 16:19:08,330] {scheduler_job.py:153} INFO - Started process (PID=567928) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:19:08,334] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:19:08,334] {logging_mixin.py:112} INFO - [2020-07-22 16:19:08,334] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:19:08,347] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:19:08,522] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:19:08,844] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:08:00+00:00: scheduled__2020-07-20T06:08:00+00:00, externally triggered: False>
[2020-07-22 16:19:08,851] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:07:00+00:00: scheduled__2020-07-20T06:07:00+00:00, externally triggered: False>
[2020-07-22 16:19:08,867] {logging_mixin.py:112} INFO - [2020-07-22 16:19:08,867] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:07:00+00:00: scheduled__2020-07-20T06:07:00+00:00, externally triggered: False> successful
[2020-07-22 16:19:09,034] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:08:00+00:00: scheduled__2020-07-20T06:08:00+00:00, externally triggered: False>
[2020-07-22 16:19:09,065] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:19:09,075] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:08:00+00:00 [scheduled]> in ORM
[2020-07-22 16:19:09,246] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.917 seconds
[2020-07-22 16:19:54,010] {scheduler_job.py:153} INFO - Started process (PID=568857) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:19:54,015] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:19:54,016] {logging_mixin.py:112} INFO - [2020-07-22 16:19:54,015] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:19:54,073] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:19:54,295] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:19:54,593] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:09:00+00:00: scheduled__2020-07-20T06:09:00+00:00, externally triggered: False>
[2020-07-22 16:19:54,598] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:08:00+00:00: scheduled__2020-07-20T06:08:00+00:00, externally triggered: False>
[2020-07-22 16:19:54,613] {logging_mixin.py:112} INFO - [2020-07-22 16:19:54,612] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:08:00+00:00: scheduled__2020-07-20T06:08:00+00:00, externally triggered: False> successful
[2020-07-22 16:19:54,728] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:09:00+00:00: scheduled__2020-07-20T06:09:00+00:00, externally triggered: False>
[2020-07-22 16:19:54,821] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:19:54,834] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:09:00+00:00 [scheduled]> in ORM
[2020-07-22 16:19:55,025] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.015 seconds
[2020-07-22 16:20:50,303] {scheduler_job.py:153} INFO - Started process (PID=569933) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:20:50,307] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:20:50,308] {logging_mixin.py:112} INFO - [2020-07-22 16:20:50,308] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:20:50,325] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:20:50,504] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:20:50,879] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:10:00+00:00: scheduled__2020-07-20T06:10:00+00:00, externally triggered: False>
[2020-07-22 16:20:50,882] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:09:00+00:00: scheduled__2020-07-20T06:09:00+00:00, externally triggered: False>
[2020-07-22 16:20:50,890] {logging_mixin.py:112} INFO - [2020-07-22 16:20:50,890] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:09:00+00:00: scheduled__2020-07-20T06:09:00+00:00, externally triggered: False> successful
[2020-07-22 16:20:51,006] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:10:00+00:00: scheduled__2020-07-20T06:10:00+00:00, externally triggered: False>
[2020-07-22 16:20:51,029] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:20:51,033] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:10:00+00:00 [scheduled]> in ORM
[2020-07-22 16:20:51,184] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.882 seconds
[2020-07-22 16:21:51,469] {scheduler_job.py:153} INFO - Started process (PID=571071) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:21:51,472] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:21:51,473] {logging_mixin.py:112} INFO - [2020-07-22 16:21:51,472] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:21:51,485] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:21:51,607] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:21:51,988] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:11:00+00:00: scheduled__2020-07-20T06:11:00+00:00, externally triggered: False>
[2020-07-22 16:21:51,991] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:10:00+00:00: scheduled__2020-07-20T06:10:00+00:00, externally triggered: False>
[2020-07-22 16:21:52,000] {logging_mixin.py:112} INFO - [2020-07-22 16:21:52,000] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:10:00+00:00: scheduled__2020-07-20T06:10:00+00:00, externally triggered: False> successful
[2020-07-22 16:21:52,132] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:11:00+00:00: scheduled__2020-07-20T06:11:00+00:00, externally triggered: False>
[2020-07-22 16:21:52,152] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:21:52,156] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:11:00+00:00 [scheduled]> in ORM
[2020-07-22 16:21:52,300] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.831 seconds
[2020-07-22 16:22:21,857] {scheduler_job.py:153} INFO - Started process (PID=571736) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:22:21,861] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:22:21,861] {logging_mixin.py:112} INFO - [2020-07-22 16:22:21,861] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:22:21,872] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:22:22,151] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:22:22,521] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:12:00+00:00: scheduled__2020-07-20T06:12:00+00:00, externally triggered: False>
[2020-07-22 16:22:22,527] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:11:00+00:00: scheduled__2020-07-20T06:11:00+00:00, externally triggered: False>
[2020-07-22 16:22:22,537] {logging_mixin.py:112} INFO - [2020-07-22 16:22:22,536] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:11:00+00:00: scheduled__2020-07-20T06:11:00+00:00, externally triggered: False> successful
[2020-07-22 16:22:22,644] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:12:00+00:00: scheduled__2020-07-20T06:12:00+00:00, externally triggered: False>
[2020-07-22 16:22:22,655] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 10:51:53.025506+00:00: manual__2020-07-22T10:51:53.025506+00:00, externally triggered: True>
[2020-07-22 16:22:22,674] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:22:22,678] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:12:00+00:00 [scheduled]> in ORM
[2020-07-22 16:22:22,682] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 10:51:53.025506+00:00 [scheduled]> in ORM
[2020-07-22 16:22:22,837] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.980 seconds
[2020-07-22 16:22:59,352] {scheduler_job.py:153} INFO - Started process (PID=572512) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:22:59,359] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:22:59,359] {logging_mixin.py:112} INFO - [2020-07-22 16:22:59,359] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:22:59,373] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:22:59,604] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:23:00,016] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:13:00+00:00: scheduled__2020-07-20T06:13:00+00:00, externally triggered: False>
[2020-07-22 16:23:00,030] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:12:00+00:00: scheduled__2020-07-20T06:12:00+00:00, externally triggered: False>
[2020-07-22 16:23:00,062] {logging_mixin.py:112} INFO - [2020-07-22 16:23:00,062] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:12:00+00:00: scheduled__2020-07-20T06:12:00+00:00, externally triggered: False> successful
[2020-07-22 16:23:00,245] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:13:00+00:00: scheduled__2020-07-20T06:13:00+00:00, externally triggered: False>
[2020-07-22 16:23:00,255] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 10:51:53.025506+00:00: manual__2020-07-22T10:51:53.025506+00:00, externally triggered: True>
[2020-07-22 16:23:00,264] {logging_mixin.py:112} INFO - [2020-07-22 16:23:00,263] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-22 10:51:53.025506+00:00: manual__2020-07-22T10:51:53.025506+00:00, externally triggered: True> successful
[2020-07-22 16:23:00,383] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:23:00,391] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:13:00+00:00 [scheduled]> in ORM
[2020-07-22 16:23:00,590] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.238 seconds
[2020-07-22 16:23:23,695] {scheduler_job.py:153} INFO - Started process (PID=573018) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:23:23,699] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:23:23,700] {logging_mixin.py:112} INFO - [2020-07-22 16:23:23,700] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:23:23,709] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:23:23,822] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:23:24,132] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:14:00+00:00: scheduled__2020-07-20T06:14:00+00:00, externally triggered: False>
[2020-07-22 16:23:24,137] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:13:00+00:00: scheduled__2020-07-20T06:13:00+00:00, externally triggered: False>
[2020-07-22 16:23:24,144] {logging_mixin.py:112} INFO - [2020-07-22 16:23:24,144] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:13:00+00:00: scheduled__2020-07-20T06:13:00+00:00, externally triggered: False> successful
[2020-07-22 16:23:24,435] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:14:00+00:00: scheduled__2020-07-20T06:14:00+00:00, externally triggered: False>
[2020-07-22 16:23:24,464] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:23:24,474] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:14:00+00:00 [scheduled]> in ORM
[2020-07-22 16:23:24,689] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.993 seconds
[2020-07-22 16:23:48,120] {scheduler_job.py:153} INFO - Started process (PID=573598) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:23:48,124] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:23:48,124] {logging_mixin.py:112} INFO - [2020-07-22 16:23:48,124] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:23:48,133] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:23:48,245] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:23:48,552] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:15:00+00:00: scheduled__2020-07-20T06:15:00+00:00, externally triggered: False>
[2020-07-22 16:23:48,559] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:14:00+00:00: scheduled__2020-07-20T06:14:00+00:00, externally triggered: False>
[2020-07-22 16:23:48,578] {logging_mixin.py:112} INFO - [2020-07-22 16:23:48,578] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:14:00+00:00: scheduled__2020-07-20T06:14:00+00:00, externally triggered: False> successful
[2020-07-22 16:23:48,702] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:15:00+00:00: scheduled__2020-07-20T06:15:00+00:00, externally triggered: False>
[2020-07-22 16:23:48,712] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 10:53:39.555461+00:00: manual__2020-07-22T10:53:39.555461+00:00, externally triggered: True>
[2020-07-22 16:23:48,728] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:23:48,733] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:15:00+00:00 [scheduled]> in ORM
[2020-07-22 16:23:48,738] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 10:53:39.555461+00:00 [scheduled]> in ORM
[2020-07-22 16:23:48,902] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.781 seconds
[2020-07-22 16:24:30,904] {scheduler_job.py:153} INFO - Started process (PID=574475) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:24:30,907] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:24:30,907] {logging_mixin.py:112} INFO - [2020-07-22 16:24:30,907] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:24:30,917] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:24:31,057] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:24:31,344] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:16:00+00:00: scheduled__2020-07-20T06:16:00+00:00, externally triggered: False>
[2020-07-22 16:24:31,349] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:15:00+00:00: scheduled__2020-07-20T06:15:00+00:00, externally triggered: False>
[2020-07-22 16:24:31,363] {logging_mixin.py:112} INFO - [2020-07-22 16:24:31,363] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:15:00+00:00: scheduled__2020-07-20T06:15:00+00:00, externally triggered: False> successful
[2020-07-22 16:24:31,471] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:16:00+00:00: scheduled__2020-07-20T06:16:00+00:00, externally triggered: False>
[2020-07-22 16:24:31,483] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 10:53:39.555461+00:00: manual__2020-07-22T10:53:39.555461+00:00, externally triggered: True>
[2020-07-22 16:24:31,491] {logging_mixin.py:112} INFO - [2020-07-22 16:24:31,491] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-22 10:53:39.555461+00:00: manual__2020-07-22T10:53:39.555461+00:00, externally triggered: True> successful
[2020-07-22 16:24:31,611] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:24:31,617] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:16:00+00:00 [scheduled]> in ORM
[2020-07-22 16:24:31,814] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.910 seconds
[2020-07-22 16:24:55,023] {scheduler_job.py:153} INFO - Started process (PID=574953) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:24:55,027] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:24:55,028] {logging_mixin.py:112} INFO - [2020-07-22 16:24:55,027] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:24:55,042] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:24:55,187] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:24:55,586] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:17:00+00:00: scheduled__2020-07-20T06:17:00+00:00, externally triggered: False>
[2020-07-22 16:24:55,591] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:16:00+00:00: scheduled__2020-07-20T06:16:00+00:00, externally triggered: False>
[2020-07-22 16:24:55,605] {logging_mixin.py:112} INFO - [2020-07-22 16:24:55,605] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:16:00+00:00: scheduled__2020-07-20T06:16:00+00:00, externally triggered: False> successful
[2020-07-22 16:24:55,753] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:17:00+00:00: scheduled__2020-07-20T06:17:00+00:00, externally triggered: False>
[2020-07-22 16:24:55,784] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:24:55,791] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:17:00+00:00 [scheduled]> in ORM
[2020-07-22 16:24:55,971] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.948 seconds
[2020-07-22 16:25:26,348] {scheduler_job.py:153} INFO - Started process (PID=575617) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:25:26,351] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:25:26,352] {logging_mixin.py:112} INFO - [2020-07-22 16:25:26,351] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:25:26,362] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:25:26,513] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:25:26,883] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:18:00+00:00: scheduled__2020-07-20T06:18:00+00:00, externally triggered: False>
[2020-07-22 16:25:26,886] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:17:00+00:00: scheduled__2020-07-20T06:17:00+00:00, externally triggered: False>
[2020-07-22 16:25:26,901] {logging_mixin.py:112} INFO - [2020-07-22 16:25:26,900] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:17:00+00:00: scheduled__2020-07-20T06:17:00+00:00, externally triggered: False> successful
[2020-07-22 16:25:27,007] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:18:00+00:00: scheduled__2020-07-20T06:18:00+00:00, externally triggered: False>
[2020-07-22 16:25:27,026] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:25:27,031] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:18:00+00:00 [scheduled]> in ORM
[2020-07-22 16:25:27,248] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.901 seconds
[2020-07-22 16:25:50,436] {scheduler_job.py:153} INFO - Started process (PID=576175) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:25:50,441] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:25:50,442] {logging_mixin.py:112} INFO - [2020-07-22 16:25:50,441] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:25:50,457] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:25:50,573] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:25:50,898] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:19:00+00:00: scheduled__2020-07-20T06:19:00+00:00, externally triggered: False>
[2020-07-22 16:25:50,905] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:18:00+00:00: scheduled__2020-07-20T06:18:00+00:00, externally triggered: False>
[2020-07-22 16:25:50,923] {logging_mixin.py:112} INFO - [2020-07-22 16:25:50,923] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:18:00+00:00: scheduled__2020-07-20T06:18:00+00:00, externally triggered: False> successful
[2020-07-22 16:25:51,063] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:19:00+00:00: scheduled__2020-07-20T06:19:00+00:00, externally triggered: False>
[2020-07-22 16:25:51,086] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:25:51,090] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:19:00+00:00 [scheduled]> in ORM
[2020-07-22 16:25:51,238] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.802 seconds
[2020-07-22 16:26:14,416] {scheduler_job.py:153} INFO - Started process (PID=576669) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:26:14,446] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:26:14,447] {logging_mixin.py:112} INFO - [2020-07-22 16:26:14,447] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:26:14,536] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:26:14,754] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:26:15,115] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:20:00+00:00: scheduled__2020-07-20T06:20:00+00:00, externally triggered: False>
[2020-07-22 16:26:15,118] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:19:00+00:00: scheduled__2020-07-20T06:19:00+00:00, externally triggered: False>
[2020-07-22 16:26:15,133] {logging_mixin.py:112} INFO - [2020-07-22 16:26:15,133] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:19:00+00:00: scheduled__2020-07-20T06:19:00+00:00, externally triggered: False> successful
[2020-07-22 16:26:15,264] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:20:00+00:00: scheduled__2020-07-20T06:20:00+00:00, externally triggered: False>
[2020-07-22 16:26:15,289] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:26:15,295] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:20:00+00:00 [scheduled]> in ORM
[2020-07-22 16:26:15,496] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.080 seconds
[2020-07-22 16:27:02,896] {scheduler_job.py:153} INFO - Started process (PID=577571) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:27:02,899] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:27:02,899] {logging_mixin.py:112} INFO - [2020-07-22 16:27:02,899] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:27:02,909] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:27:03,052] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:27:03,525] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:21:00+00:00: scheduled__2020-07-20T06:21:00+00:00, externally triggered: False>
[2020-07-22 16:27:03,529] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:20:00+00:00: scheduled__2020-07-20T06:20:00+00:00, externally triggered: False>
[2020-07-22 16:27:03,540] {logging_mixin.py:112} INFO - [2020-07-22 16:27:03,540] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:20:00+00:00: scheduled__2020-07-20T06:20:00+00:00, externally triggered: False> successful
[2020-07-22 16:27:03,710] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:21:00+00:00: scheduled__2020-07-20T06:21:00+00:00, externally triggered: False>
[2020-07-22 16:27:03,724] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 10:56:38.741278+00:00: manual__2020-07-22T10:56:38.741278+00:00, externally triggered: True>
[2020-07-22 16:27:03,741] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:27:03,745] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:21:00+00:00 [scheduled]> in ORM
[2020-07-22 16:27:03,750] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 10:56:38.741278+00:00 [scheduled]> in ORM
[2020-07-22 16:27:03,932] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.037 seconds
[2020-07-22 16:27:41,067] {scheduler_job.py:153} INFO - Started process (PID=578376) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:27:41,071] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:27:41,071] {logging_mixin.py:112} INFO - [2020-07-22 16:27:41,071] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:27:41,082] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:27:41,203] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:27:41,523] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:22:00+00:00: scheduled__2020-07-20T06:22:00+00:00, externally triggered: False>
[2020-07-22 16:27:41,527] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:21:00+00:00: scheduled__2020-07-20T06:21:00+00:00, externally triggered: False>
[2020-07-22 16:27:41,536] {logging_mixin.py:112} INFO - [2020-07-22 16:27:41,536] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:21:00+00:00: scheduled__2020-07-20T06:21:00+00:00, externally triggered: False> successful
[2020-07-22 16:27:41,722] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:22:00+00:00: scheduled__2020-07-20T06:22:00+00:00, externally triggered: False>
[2020-07-22 16:27:41,737] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 10:56:38.741278+00:00: manual__2020-07-22T10:56:38.741278+00:00, externally triggered: True>
[2020-07-22 16:27:41,748] {logging_mixin.py:112} INFO - [2020-07-22 16:27:41,748] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-22 10:56:38.741278+00:00: manual__2020-07-22T10:56:38.741278+00:00, externally triggered: True> successful
[2020-07-22 16:27:41,895] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:27:41,935] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:22:00+00:00 [scheduled]> in ORM
[2020-07-22 16:27:42,134] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.067 seconds
[2020-07-22 16:28:13,907] {scheduler_job.py:153} INFO - Started process (PID=579045) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:28:13,913] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:28:13,913] {logging_mixin.py:112} INFO - [2020-07-22 16:28:13,913] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:28:13,933] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:28:14,127] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:28:14,618] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:23:00+00:00: scheduled__2020-07-20T06:23:00+00:00, externally triggered: False>
[2020-07-22 16:28:14,635] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:22:00+00:00: scheduled__2020-07-20T06:22:00+00:00, externally triggered: False>
[2020-07-22 16:28:14,673] {logging_mixin.py:112} INFO - [2020-07-22 16:28:14,673] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:22:00+00:00: scheduled__2020-07-20T06:22:00+00:00, externally triggered: False> successful
[2020-07-22 16:28:14,801] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:23:00+00:00: scheduled__2020-07-20T06:23:00+00:00, externally triggered: False>
[2020-07-22 16:28:14,846] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:28:14,863] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:23:00+00:00 [scheduled]> in ORM
[2020-07-22 16:28:15,045] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.138 seconds
[2020-07-22 16:28:38,587] {scheduler_job.py:153} INFO - Started process (PID=579573) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:28:38,591] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:28:38,592] {logging_mixin.py:112} INFO - [2020-07-22 16:28:38,592] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:28:38,603] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:28:38,727] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:28:39,167] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:24:00+00:00: scheduled__2020-07-20T06:24:00+00:00, externally triggered: False>
[2020-07-22 16:28:39,200] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:23:00+00:00: scheduled__2020-07-20T06:23:00+00:00, externally triggered: False>
[2020-07-22 16:28:39,220] {logging_mixin.py:112} INFO - [2020-07-22 16:28:39,220] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:23:00+00:00: scheduled__2020-07-20T06:23:00+00:00, externally triggered: False> successful
[2020-07-22 16:28:39,336] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:24:00+00:00: scheduled__2020-07-20T06:24:00+00:00, externally triggered: False>
[2020-07-22 16:28:39,363] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:28:39,371] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:24:00+00:00 [scheduled]> in ORM
[2020-07-22 16:28:39,571] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.983 seconds
[2020-07-22 16:29:09,587] {scheduler_job.py:153} INFO - Started process (PID=580250) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:29:09,591] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:29:09,592] {logging_mixin.py:112} INFO - [2020-07-22 16:29:09,591] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:29:09,624] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:29:09,873] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:29:10,163] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:25:00+00:00: scheduled__2020-07-20T06:25:00+00:00, externally triggered: False>
[2020-07-22 16:29:10,168] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:24:00+00:00: scheduled__2020-07-20T06:24:00+00:00, externally triggered: False>
[2020-07-22 16:29:10,204] {logging_mixin.py:112} INFO - [2020-07-22 16:29:10,204] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:24:00+00:00: scheduled__2020-07-20T06:24:00+00:00, externally triggered: False> successful
[2020-07-22 16:29:10,326] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:25:00+00:00: scheduled__2020-07-20T06:25:00+00:00, externally triggered: False>
[2020-07-22 16:29:10,372] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:29:10,379] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:25:00+00:00 [scheduled]> in ORM
[2020-07-22 16:29:10,625] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.038 seconds
[2020-07-22 16:29:48,949] {scheduler_job.py:153} INFO - Started process (PID=581071) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:29:48,954] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:29:48,955] {logging_mixin.py:112} INFO - [2020-07-22 16:29:48,955] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:29:48,964] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:29:49,110] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:29:49,454] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:26:00+00:00: scheduled__2020-07-20T06:26:00+00:00, externally triggered: False>
[2020-07-22 16:29:49,460] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:25:00+00:00: scheduled__2020-07-20T06:25:00+00:00, externally triggered: False>
[2020-07-22 16:29:49,471] {logging_mixin.py:112} INFO - [2020-07-22 16:29:49,471] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:25:00+00:00: scheduled__2020-07-20T06:25:00+00:00, externally triggered: False> successful
[2020-07-22 16:29:49,628] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:26:00+00:00: scheduled__2020-07-20T06:26:00+00:00, externally triggered: False>
[2020-07-22 16:29:49,641] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 10:59:21.598398+00:00: manual__2020-07-22T10:59:21.598398+00:00, externally triggered: True>
[2020-07-22 16:29:49,657] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:29:49,661] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:26:00+00:00 [scheduled]> in ORM
[2020-07-22 16:29:49,665] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 10:59:21.598398+00:00 [scheduled]> in ORM
[2020-07-22 16:29:49,828] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.879 seconds
[2020-07-22 16:30:36,524] {scheduler_job.py:153} INFO - Started process (PID=582153) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:30:36,527] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:30:36,527] {logging_mixin.py:112} INFO - [2020-07-22 16:30:36,527] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:30:36,538] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:30:36,986] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:30:37,315] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:27:00+00:00: scheduled__2020-07-20T06:27:00+00:00, externally triggered: False>
[2020-07-22 16:30:37,319] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:26:00+00:00: scheduled__2020-07-20T06:26:00+00:00, externally triggered: False>
[2020-07-22 16:30:37,329] {logging_mixin.py:112} INFO - [2020-07-22 16:30:37,329] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:26:00+00:00: scheduled__2020-07-20T06:26:00+00:00, externally triggered: False> successful
[2020-07-22 16:30:37,441] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:27:00+00:00: scheduled__2020-07-20T06:27:00+00:00, externally triggered: False>
[2020-07-22 16:30:37,457] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 10:59:21.598398+00:00: manual__2020-07-22T10:59:21.598398+00:00, externally triggered: True>
[2020-07-22 16:30:37,465] {logging_mixin.py:112} INFO - [2020-07-22 16:30:37,464] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-22 10:59:21.598398+00:00: manual__2020-07-22T10:59:21.598398+00:00, externally triggered: True> successful
[2020-07-22 16:30:37,582] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:30:37,588] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:27:00+00:00 [scheduled]> in ORM
[2020-07-22 16:30:37,743] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.219 seconds
[2020-07-22 16:31:11,702] {scheduler_job.py:153} INFO - Started process (PID=582882) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:31:11,715] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:31:11,731] {logging_mixin.py:112} INFO - [2020-07-22 16:31:11,731] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:31:11,810] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:31:12,040] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:31:12,399] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:28:00+00:00: scheduled__2020-07-20T06:28:00+00:00, externally triggered: False>
[2020-07-22 16:31:12,430] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:27:00+00:00: scheduled__2020-07-20T06:27:00+00:00, externally triggered: False>
[2020-07-22 16:31:12,455] {logging_mixin.py:112} INFO - [2020-07-22 16:31:12,455] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:27:00+00:00: scheduled__2020-07-20T06:27:00+00:00, externally triggered: False> successful
[2020-07-22 16:31:12,620] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:28:00+00:00: scheduled__2020-07-20T06:28:00+00:00, externally triggered: False>
[2020-07-22 16:31:12,713] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:31:12,730] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:28:00+00:00 [scheduled]> in ORM
[2020-07-22 16:31:12,997] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.295 seconds
[2020-07-22 16:32:01,835] {scheduler_job.py:153} INFO - Started process (PID=583845) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:32:01,856] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:32:01,856] {logging_mixin.py:112} INFO - [2020-07-22 16:32:01,856] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:32:01,873] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:32:02,390] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:32:02,904] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:29:00+00:00: scheduled__2020-07-20T06:29:00+00:00, externally triggered: False>
[2020-07-22 16:32:02,920] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:28:00+00:00: scheduled__2020-07-20T06:28:00+00:00, externally triggered: False>
[2020-07-22 16:32:02,970] {logging_mixin.py:112} INFO - [2020-07-22 16:32:02,969] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:28:00+00:00: scheduled__2020-07-20T06:28:00+00:00, externally triggered: False> successful
[2020-07-22 16:32:03,111] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:29:00+00:00: scheduled__2020-07-20T06:29:00+00:00, externally triggered: False>
[2020-07-22 16:32:03,175] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:32:03,200] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:29:00+00:00 [scheduled]> in ORM
[2020-07-22 16:32:03,366] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.534 seconds
[2020-07-22 16:32:52,618] {scheduler_job.py:153} INFO - Started process (PID=584835) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:32:52,648] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:32:52,649] {logging_mixin.py:112} INFO - [2020-07-22 16:32:52,649] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:32:52,699] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:32:52,860] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:32:53,161] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:30:00+00:00: scheduled__2020-07-20T06:30:00+00:00, externally triggered: False>
[2020-07-22 16:32:53,174] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:29:00+00:00: scheduled__2020-07-20T06:29:00+00:00, externally triggered: False>
[2020-07-22 16:32:53,192] {logging_mixin.py:112} INFO - [2020-07-22 16:32:53,192] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:29:00+00:00: scheduled__2020-07-20T06:29:00+00:00, externally triggered: False> successful
[2020-07-22 16:32:53,335] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:30:00+00:00: scheduled__2020-07-20T06:30:00+00:00, externally triggered: False>
[2020-07-22 16:32:53,353] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 11:02:29.899911+00:00: manual__2020-07-22T11:02:29.899911+00:00, externally triggered: True>
[2020-07-22 16:32:53,385] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:32:53,398] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:30:00+00:00 [scheduled]> in ORM
[2020-07-22 16:32:53,409] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 11:02:29.899911+00:00 [scheduled]> in ORM
[2020-07-22 16:32:53,647] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.030 seconds
[2020-07-22 16:34:23,316] {scheduler_job.py:153} INFO - Started process (PID=586619) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:34:23,318] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:34:23,319] {logging_mixin.py:112} INFO - [2020-07-22 16:34:23,319] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:34:23,329] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:34:23,484] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:34:23,812] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:31:00+00:00: scheduled__2020-07-20T06:31:00+00:00, externally triggered: False>
[2020-07-22 16:34:23,816] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:30:00+00:00: scheduled__2020-07-20T06:30:00+00:00, externally triggered: False>
[2020-07-22 16:34:23,825] {logging_mixin.py:112} INFO - [2020-07-22 16:34:23,825] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:30:00+00:00: scheduled__2020-07-20T06:30:00+00:00, externally triggered: False> successful
[2020-07-22 16:34:23,951] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:31:00+00:00: scheduled__2020-07-20T06:31:00+00:00, externally triggered: False>
[2020-07-22 16:34:23,973] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 11:02:29.899911+00:00: manual__2020-07-22T11:02:29.899911+00:00, externally triggered: True>
[2020-07-22 16:34:23,994] {logging_mixin.py:112} INFO - [2020-07-22 16:34:23,994] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-22 11:02:29.899911+00:00: manual__2020-07-22T11:02:29.899911+00:00, externally triggered: True> successful
[2020-07-22 16:34:24,160] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:34:24,169] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:31:00+00:00 [scheduled]> in ORM
[2020-07-22 16:34:24,340] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.024 seconds
[2020-07-22 16:35:14,085] {scheduler_job.py:153} INFO - Started process (PID=587611) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:35:14,089] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:35:14,089] {logging_mixin.py:112} INFO - [2020-07-22 16:35:14,089] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:35:14,102] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:35:14,262] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:35:14,630] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:32:00+00:00: scheduled__2020-07-20T06:32:00+00:00, externally triggered: False>
[2020-07-22 16:35:14,636] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:31:00+00:00: scheduled__2020-07-20T06:31:00+00:00, externally triggered: False>
[2020-07-22 16:35:14,651] {logging_mixin.py:112} INFO - [2020-07-22 16:35:14,651] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:31:00+00:00: scheduled__2020-07-20T06:31:00+00:00, externally triggered: False> successful
[2020-07-22 16:35:14,776] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:32:00+00:00: scheduled__2020-07-20T06:32:00+00:00, externally triggered: False>
[2020-07-22 16:35:14,800] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:35:14,807] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:32:00+00:00 [scheduled]> in ORM
[2020-07-22 16:35:15,010] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.925 seconds
[2020-07-22 16:36:25,587] {scheduler_job.py:153} INFO - Started process (PID=589100) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:36:25,590] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:36:25,590] {logging_mixin.py:112} INFO - [2020-07-22 16:36:25,590] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:36:25,600] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:36:25,704] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:36:26,441] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:33:00+00:00: scheduled__2020-07-20T06:33:00+00:00, externally triggered: False>
[2020-07-22 16:36:26,447] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:32:00+00:00: scheduled__2020-07-20T06:32:00+00:00, externally triggered: False>
[2020-07-22 16:36:26,462] {logging_mixin.py:112} INFO - [2020-07-22 16:36:26,462] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:32:00+00:00: scheduled__2020-07-20T06:32:00+00:00, externally triggered: False> successful
[2020-07-22 16:36:26,623] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:33:00+00:00: scheduled__2020-07-20T06:33:00+00:00, externally triggered: False>
[2020-07-22 16:36:26,640] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:36:26,644] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:33:00+00:00 [scheduled]> in ORM
[2020-07-22 16:36:26,777] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.190 seconds
[2020-07-22 16:37:05,286] {scheduler_job.py:153} INFO - Started process (PID=589945) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:37:05,296] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:37:05,297] {logging_mixin.py:112} INFO - [2020-07-22 16:37:05,296] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:37:05,316] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:37:05,455] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:37:05,816] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:34:00+00:00: scheduled__2020-07-20T06:34:00+00:00, externally triggered: False>
[2020-07-22 16:37:05,820] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:33:00+00:00: scheduled__2020-07-20T06:33:00+00:00, externally triggered: False>
[2020-07-22 16:37:05,828] {logging_mixin.py:112} INFO - [2020-07-22 16:37:05,828] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:33:00+00:00: scheduled__2020-07-20T06:33:00+00:00, externally triggered: False> successful
[2020-07-22 16:37:05,947] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:34:00+00:00: scheduled__2020-07-20T06:34:00+00:00, externally triggered: False>
[2020-07-22 16:37:05,967] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:37:05,971] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:34:00+00:00 [scheduled]> in ORM
[2020-07-22 16:37:06,111] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.825 seconds
[2020-07-22 16:37:55,908] {scheduler_job.py:153} INFO - Started process (PID=590966) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:37:55,912] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:37:55,913] {logging_mixin.py:112} INFO - [2020-07-22 16:37:55,913] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:37:55,923] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:37:56,082] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:37:56,472] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:35:00+00:00: scheduled__2020-07-20T06:35:00+00:00, externally triggered: False>
[2020-07-22 16:37:56,476] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:34:00+00:00: scheduled__2020-07-20T06:34:00+00:00, externally triggered: False>
[2020-07-22 16:37:56,489] {logging_mixin.py:112} INFO - [2020-07-22 16:37:56,489] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:34:00+00:00: scheduled__2020-07-20T06:34:00+00:00, externally triggered: False> successful
[2020-07-22 16:37:56,616] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:35:00+00:00: scheduled__2020-07-20T06:35:00+00:00, externally triggered: False>
[2020-07-22 16:37:56,633] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:37:56,637] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:35:00+00:00 [scheduled]> in ORM
[2020-07-22 16:37:56,772] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.864 seconds
[2020-07-22 16:38:35,595] {scheduler_job.py:153} INFO - Started process (PID=591810) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:38:35,601] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:38:35,601] {logging_mixin.py:112} INFO - [2020-07-22 16:38:35,601] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:38:35,611] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:38:35,722] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:38:36,057] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:36:00+00:00: scheduled__2020-07-20T06:36:00+00:00, externally triggered: False>
[2020-07-22 16:38:36,062] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:35:00+00:00: scheduled__2020-07-20T06:35:00+00:00, externally triggered: False>
[2020-07-22 16:38:36,070] {logging_mixin.py:112} INFO - [2020-07-22 16:38:36,070] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:35:00+00:00: scheduled__2020-07-20T06:35:00+00:00, externally triggered: False> successful
[2020-07-22 16:38:36,195] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:36:00+00:00: scheduled__2020-07-20T06:36:00+00:00, externally triggered: False>
[2020-07-22 16:38:36,216] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:38:36,226] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:36:00+00:00 [scheduled]> in ORM
[2020-07-22 16:38:36,407] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.813 seconds
[2020-07-22 16:39:15,511] {scheduler_job.py:153} INFO - Started process (PID=592691) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:39:15,514] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:39:15,515] {logging_mixin.py:112} INFO - [2020-07-22 16:39:15,515] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:39:15,527] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:39:16,073] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:39:16,415] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:37:00+00:00: scheduled__2020-07-20T06:37:00+00:00, externally triggered: False>
[2020-07-22 16:39:16,418] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:36:00+00:00: scheduled__2020-07-20T06:36:00+00:00, externally triggered: False>
[2020-07-22 16:39:16,431] {logging_mixin.py:112} INFO - [2020-07-22 16:39:16,430] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:36:00+00:00: scheduled__2020-07-20T06:36:00+00:00, externally triggered: False> successful
[2020-07-22 16:39:16,608] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:37:00+00:00: scheduled__2020-07-20T06:37:00+00:00, externally triggered: False>
[2020-07-22 16:39:16,626] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:39:16,630] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:37:00+00:00 [scheduled]> in ORM
[2020-07-22 16:39:16,790] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.279 seconds
[2020-07-22 16:39:55,642] {scheduler_job.py:153} INFO - Started process (PID=593539) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:39:55,646] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:39:55,647] {logging_mixin.py:112} INFO - [2020-07-22 16:39:55,647] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:39:55,658] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:39:55,818] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:39:56,112] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:38:00+00:00: scheduled__2020-07-20T06:38:00+00:00, externally triggered: False>
[2020-07-22 16:39:56,116] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:37:00+00:00: scheduled__2020-07-20T06:37:00+00:00, externally triggered: False>
[2020-07-22 16:39:56,127] {logging_mixin.py:112} INFO - [2020-07-22 16:39:56,126] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:37:00+00:00: scheduled__2020-07-20T06:37:00+00:00, externally triggered: False> successful
[2020-07-22 16:39:56,288] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:38:00+00:00: scheduled__2020-07-20T06:38:00+00:00, externally triggered: False>
[2020-07-22 16:39:56,299] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:39:56,303] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:38:00+00:00 [scheduled]> in ORM
[2020-07-22 16:39:56,444] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.802 seconds
[2020-07-22 16:40:35,926] {scheduler_job.py:153} INFO - Started process (PID=594402) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:40:35,929] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:40:35,930] {logging_mixin.py:112} INFO - [2020-07-22 16:40:35,929] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:40:35,941] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:40:36,096] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:40:36,391] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:39:00+00:00: scheduled__2020-07-20T06:39:00+00:00, externally triggered: False>
[2020-07-22 16:40:36,394] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:38:00+00:00: scheduled__2020-07-20T06:38:00+00:00, externally triggered: False>
[2020-07-22 16:40:36,401] {logging_mixin.py:112} INFO - [2020-07-22 16:40:36,401] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:38:00+00:00: scheduled__2020-07-20T06:38:00+00:00, externally triggered: False> successful
[2020-07-22 16:40:36,534] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:39:00+00:00: scheduled__2020-07-20T06:39:00+00:00, externally triggered: False>
[2020-07-22 16:40:36,565] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:40:36,588] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:39:00+00:00 [scheduled]> in ORM
[2020-07-22 16:40:36,745] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.819 seconds
[2020-07-22 16:41:16,003] {scheduler_job.py:153} INFO - Started process (PID=595245) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:41:16,006] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:41:16,007] {logging_mixin.py:112} INFO - [2020-07-22 16:41:16,007] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:41:16,016] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:41:16,155] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:41:16,521] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:40:00+00:00: scheduled__2020-07-20T06:40:00+00:00, externally triggered: False>
[2020-07-22 16:41:16,524] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:39:00+00:00: scheduled__2020-07-20T06:39:00+00:00, externally triggered: False>
[2020-07-22 16:41:16,532] {logging_mixin.py:112} INFO - [2020-07-22 16:41:16,532] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:39:00+00:00: scheduled__2020-07-20T06:39:00+00:00, externally triggered: False> successful
[2020-07-22 16:41:16,669] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:40:00+00:00: scheduled__2020-07-20T06:40:00+00:00, externally triggered: False>
[2020-07-22 16:41:16,690] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:41:16,694] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:40:00+00:00 [scheduled]> in ORM
[2020-07-22 16:41:16,882] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.878 seconds
[2020-07-22 16:41:55,958] {scheduler_job.py:153} INFO - Started process (PID=596125) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:41:55,961] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:41:55,962] {logging_mixin.py:112} INFO - [2020-07-22 16:41:55,961] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:41:55,972] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:41:56,130] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:41:56,513] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:41:00+00:00: scheduled__2020-07-20T06:41:00+00:00, externally triggered: False>
[2020-07-22 16:41:56,517] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:40:00+00:00: scheduled__2020-07-20T06:40:00+00:00, externally triggered: False>
[2020-07-22 16:41:56,524] {logging_mixin.py:112} INFO - [2020-07-22 16:41:56,524] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:40:00+00:00: scheduled__2020-07-20T06:40:00+00:00, externally triggered: False> successful
[2020-07-22 16:41:56,627] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:41:00+00:00: scheduled__2020-07-20T06:41:00+00:00, externally triggered: False>
[2020-07-22 16:41:56,642] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:41:56,647] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:41:00+00:00 [scheduled]> in ORM
[2020-07-22 16:41:56,783] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.825 seconds
[2020-07-22 16:42:36,108] {scheduler_job.py:153} INFO - Started process (PID=596979) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:42:36,112] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:42:36,112] {logging_mixin.py:112} INFO - [2020-07-22 16:42:36,112] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:42:36,122] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:42:36,413] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:42:36,777] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:42:00+00:00: scheduled__2020-07-20T06:42:00+00:00, externally triggered: False>
[2020-07-22 16:42:36,783] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:41:00+00:00: scheduled__2020-07-20T06:41:00+00:00, externally triggered: False>
[2020-07-22 16:42:36,795] {logging_mixin.py:112} INFO - [2020-07-22 16:42:36,794] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:41:00+00:00: scheduled__2020-07-20T06:41:00+00:00, externally triggered: False> successful
[2020-07-22 16:42:36,940] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:42:00+00:00: scheduled__2020-07-20T06:42:00+00:00, externally triggered: False>
[2020-07-22 16:42:36,964] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:42:36,972] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:42:00+00:00 [scheduled]> in ORM
[2020-07-22 16:42:37,152] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.043 seconds
[2020-07-22 16:43:16,744] {scheduler_job.py:153} INFO - Started process (PID=597852) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:43:16,750] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:43:16,751] {logging_mixin.py:112} INFO - [2020-07-22 16:43:16,750] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:43:16,763] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:43:16,869] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:43:17,173] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:43:00+00:00: scheduled__2020-07-20T06:43:00+00:00, externally triggered: False>
[2020-07-22 16:43:17,179] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:42:00+00:00: scheduled__2020-07-20T06:42:00+00:00, externally triggered: False>
[2020-07-22 16:43:17,187] {logging_mixin.py:112} INFO - [2020-07-22 16:43:17,187] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:42:00+00:00: scheduled__2020-07-20T06:42:00+00:00, externally triggered: False> successful
[2020-07-22 16:43:17,386] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:43:00+00:00: scheduled__2020-07-20T06:43:00+00:00, externally triggered: False>
[2020-07-22 16:43:17,407] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:43:17,414] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:43:00+00:00 [scheduled]> in ORM
[2020-07-22 16:43:17,552] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.808 seconds
[2020-07-22 16:44:02,431] {scheduler_job.py:153} INFO - Started process (PID=598793) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:44:02,434] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:44:02,435] {logging_mixin.py:112} INFO - [2020-07-22 16:44:02,435] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:44:02,444] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:44:02,553] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:44:02,874] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:44:00+00:00: scheduled__2020-07-20T06:44:00+00:00, externally triggered: False>
[2020-07-22 16:44:02,878] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:43:00+00:00: scheduled__2020-07-20T06:43:00+00:00, externally triggered: False>
[2020-07-22 16:44:02,885] {logging_mixin.py:112} INFO - [2020-07-22 16:44:02,885] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:43:00+00:00: scheduled__2020-07-20T06:43:00+00:00, externally triggered: False> successful
[2020-07-22 16:44:03,022] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:44:00+00:00: scheduled__2020-07-20T06:44:00+00:00, externally triggered: False>
[2020-07-22 16:44:03,041] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:44:03,047] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:44:00+00:00 [scheduled]> in ORM
[2020-07-22 16:44:03,222] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.791 seconds
[2020-07-22 16:44:42,317] {scheduler_job.py:153} INFO - Started process (PID=599632) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:44:42,320] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:44:42,321] {logging_mixin.py:112} INFO - [2020-07-22 16:44:42,320] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:44:42,331] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:44:42,484] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:44:42,864] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:45:00+00:00: scheduled__2020-07-20T06:45:00+00:00, externally triggered: False>
[2020-07-22 16:44:42,868] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:44:00+00:00: scheduled__2020-07-20T06:44:00+00:00, externally triggered: False>
[2020-07-22 16:44:42,876] {logging_mixin.py:112} INFO - [2020-07-22 16:44:42,876] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:44:00+00:00: scheduled__2020-07-20T06:44:00+00:00, externally triggered: False> successful
[2020-07-22 16:44:43,024] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:45:00+00:00: scheduled__2020-07-20T06:45:00+00:00, externally triggered: False>
[2020-07-22 16:44:43,044] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:44:43,047] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:45:00+00:00 [scheduled]> in ORM
[2020-07-22 16:44:43,202] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.885 seconds
[2020-07-22 16:45:22,712] {scheduler_job.py:153} INFO - Started process (PID=600539) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:45:22,715] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:45:22,716] {logging_mixin.py:112} INFO - [2020-07-22 16:45:22,716] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:45:22,728] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:45:22,885] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:45:23,231] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:46:00+00:00: scheduled__2020-07-20T06:46:00+00:00, externally triggered: False>
[2020-07-22 16:45:23,239] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:45:00+00:00: scheduled__2020-07-20T06:45:00+00:00, externally triggered: False>
[2020-07-22 16:45:23,256] {logging_mixin.py:112} INFO - [2020-07-22 16:45:23,256] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:45:00+00:00: scheduled__2020-07-20T06:45:00+00:00, externally triggered: False> successful
[2020-07-22 16:45:23,414] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:46:00+00:00: scheduled__2020-07-20T06:46:00+00:00, externally triggered: False>
[2020-07-22 16:45:23,436] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:45:23,446] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:46:00+00:00 [scheduled]> in ORM
[2020-07-22 16:45:23,602] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.891 seconds
[2020-07-22 16:46:02,851] {scheduler_job.py:153} INFO - Started process (PID=601410) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:46:02,856] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:46:02,856] {logging_mixin.py:112} INFO - [2020-07-22 16:46:02,856] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:46:02,867] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:46:03,070] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:46:03,478] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:47:00+00:00: scheduled__2020-07-20T06:47:00+00:00, externally triggered: False>
[2020-07-22 16:46:03,511] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:46:00+00:00: scheduled__2020-07-20T06:46:00+00:00, externally triggered: False>
[2020-07-22 16:46:03,521] {logging_mixin.py:112} INFO - [2020-07-22 16:46:03,521] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:46:00+00:00: scheduled__2020-07-20T06:46:00+00:00, externally triggered: False> successful
[2020-07-22 16:46:03,672] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:47:00+00:00: scheduled__2020-07-20T06:47:00+00:00, externally triggered: False>
[2020-07-22 16:46:03,690] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:46:03,694] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:47:00+00:00 [scheduled]> in ORM
[2020-07-22 16:46:03,844] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.993 seconds
[2020-07-22 16:47:05,362] {scheduler_job.py:153} INFO - Started process (PID=602630) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:47:05,387] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:47:05,388] {logging_mixin.py:112} INFO - [2020-07-22 16:47:05,388] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:47:05,539] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:47:05,755] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:47:06,203] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:48:00+00:00: scheduled__2020-07-20T06:48:00+00:00, externally triggered: False>
[2020-07-22 16:47:06,209] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:47:00+00:00: scheduled__2020-07-20T06:47:00+00:00, externally triggered: False>
[2020-07-22 16:47:06,239] {logging_mixin.py:112} INFO - [2020-07-22 16:47:06,238] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:47:00+00:00: scheduled__2020-07-20T06:47:00+00:00, externally triggered: False> successful
[2020-07-22 16:47:06,386] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:48:00+00:00: scheduled__2020-07-20T06:48:00+00:00, externally triggered: False>
[2020-07-22 16:47:06,435] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:47:06,473] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:48:00+00:00 [scheduled]> in ORM
[2020-07-22 16:47:06,685] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.323 seconds
[2020-07-22 16:48:26,824] {scheduler_job.py:153} INFO - Started process (PID=604028) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:48:26,872] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:48:26,873] {logging_mixin.py:112} INFO - [2020-07-22 16:48:26,872] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:48:26,968] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:48:27,299] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:48:27,649] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:49:00+00:00: scheduled__2020-07-20T06:49:00+00:00, externally triggered: False>
[2020-07-22 16:48:27,655] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:48:00+00:00: scheduled__2020-07-20T06:48:00+00:00, externally triggered: False>
[2020-07-22 16:48:27,668] {logging_mixin.py:112} INFO - [2020-07-22 16:48:27,667] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:48:00+00:00: scheduled__2020-07-20T06:48:00+00:00, externally triggered: False> successful
[2020-07-22 16:48:27,812] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:49:00+00:00: scheduled__2020-07-20T06:49:00+00:00, externally triggered: False>
[2020-07-22 16:48:27,854] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:48:27,862] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:49:00+00:00 [scheduled]> in ORM
[2020-07-22 16:48:28,000] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.177 seconds
[2020-07-22 16:49:20,323] {scheduler_job.py:153} INFO - Started process (PID=605059) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:49:20,327] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:49:20,327] {logging_mixin.py:112} INFO - [2020-07-22 16:49:20,327] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:49:20,339] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:49:20,983] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:49:21,326] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:50:00+00:00: scheduled__2020-07-20T06:50:00+00:00, externally triggered: False>
[2020-07-22 16:49:21,331] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:49:00+00:00: scheduled__2020-07-20T06:49:00+00:00, externally triggered: False>
[2020-07-22 16:49:21,340] {logging_mixin.py:112} INFO - [2020-07-22 16:49:21,339] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:49:00+00:00: scheduled__2020-07-20T06:49:00+00:00, externally triggered: False> successful
[2020-07-22 16:49:21,460] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:50:00+00:00: scheduled__2020-07-20T06:50:00+00:00, externally triggered: False>
[2020-07-22 16:49:21,488] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:49:21,497] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:50:00+00:00 [scheduled]> in ORM
[2020-07-22 16:49:21,682] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.359 seconds
[2020-07-22 16:50:05,870] {scheduler_job.py:153} INFO - Started process (PID=606012) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:50:05,873] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:50:05,874] {logging_mixin.py:112} INFO - [2020-07-22 16:50:05,874] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:50:05,885] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:50:06,003] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:50:06,322] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:51:00+00:00: scheduled__2020-07-20T06:51:00+00:00, externally triggered: False>
[2020-07-22 16:50:06,330] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:50:00+00:00: scheduled__2020-07-20T06:50:00+00:00, externally triggered: False>
[2020-07-22 16:50:06,344] {logging_mixin.py:112} INFO - [2020-07-22 16:50:06,343] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:50:00+00:00: scheduled__2020-07-20T06:50:00+00:00, externally triggered: False> successful
[2020-07-22 16:50:06,495] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:51:00+00:00: scheduled__2020-07-20T06:51:00+00:00, externally triggered: False>
[2020-07-22 16:50:06,594] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:50:06,605] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:51:00+00:00 [scheduled]> in ORM
[2020-07-22 16:50:06,761] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.891 seconds
[2020-07-22 16:51:02,069] {scheduler_job.py:153} INFO - Started process (PID=607078) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:51:02,073] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:51:02,074] {logging_mixin.py:112} INFO - [2020-07-22 16:51:02,073] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:51:02,089] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:51:02,241] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:51:02,587] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:52:00+00:00: scheduled__2020-07-20T06:52:00+00:00, externally triggered: False>
[2020-07-22 16:51:02,591] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:51:00+00:00: scheduled__2020-07-20T06:51:00+00:00, externally triggered: False>
[2020-07-22 16:51:02,598] {logging_mixin.py:112} INFO - [2020-07-22 16:51:02,598] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:51:00+00:00: scheduled__2020-07-20T06:51:00+00:00, externally triggered: False> successful
[2020-07-22 16:51:02,753] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:52:00+00:00: scheduled__2020-07-20T06:52:00+00:00, externally triggered: False>
[2020-07-22 16:51:02,772] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:51:02,776] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:52:00+00:00 [scheduled]> in ORM
[2020-07-22 16:51:03,189] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.120 seconds
[2020-07-22 16:52:16,267] {scheduler_job.py:153} INFO - Started process (PID=608468) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:52:16,302] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:52:16,303] {logging_mixin.py:112} INFO - [2020-07-22 16:52:16,302] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:52:16,375] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:52:16,629] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:52:17,049] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:53:00+00:00: scheduled__2020-07-20T06:53:00+00:00, externally triggered: False>
[2020-07-22 16:52:17,064] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:52:00+00:00: scheduled__2020-07-20T06:52:00+00:00, externally triggered: False>
[2020-07-22 16:52:17,083] {logging_mixin.py:112} INFO - [2020-07-22 16:52:17,083] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:52:00+00:00: scheduled__2020-07-20T06:52:00+00:00, externally triggered: False> successful
[2020-07-22 16:52:17,190] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:53:00+00:00: scheduled__2020-07-20T06:53:00+00:00, externally triggered: False>
[2020-07-22 16:52:17,220] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:52:17,225] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:53:00+00:00 [scheduled]> in ORM
[2020-07-22 16:52:17,407] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.140 seconds
[2020-07-22 16:53:21,870] {scheduler_job.py:153} INFO - Started process (PID=609709) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:53:21,898] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:53:21,899] {logging_mixin.py:112} INFO - [2020-07-22 16:53:21,899] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:53:21,923] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:53:22,146] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:53:22,428] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:54:00+00:00: scheduled__2020-07-20T06:54:00+00:00, externally triggered: False>
[2020-07-22 16:53:22,431] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:53:00+00:00: scheduled__2020-07-20T06:53:00+00:00, externally triggered: False>
[2020-07-22 16:53:22,440] {logging_mixin.py:112} INFO - [2020-07-22 16:53:22,439] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:53:00+00:00: scheduled__2020-07-20T06:53:00+00:00, externally triggered: False> successful
[2020-07-22 16:53:22,570] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:54:00+00:00: scheduled__2020-07-20T06:54:00+00:00, externally triggered: False>
[2020-07-22 16:53:22,595] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:53:22,604] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:54:00+00:00 [scheduled]> in ORM
[2020-07-22 16:53:22,748] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.877 seconds
[2020-07-22 16:54:34,997] {scheduler_job.py:153} INFO - Started process (PID=610984) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:54:35,012] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:54:35,013] {logging_mixin.py:112} INFO - [2020-07-22 16:54:35,013] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:54:35,037] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:54:35,206] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:54:35,624] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:55:00+00:00: scheduled__2020-07-20T06:55:00+00:00, externally triggered: False>
[2020-07-22 16:54:35,646] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:54:00+00:00: scheduled__2020-07-20T06:54:00+00:00, externally triggered: False>
[2020-07-22 16:54:35,670] {logging_mixin.py:112} INFO - [2020-07-22 16:54:35,670] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:54:00+00:00: scheduled__2020-07-20T06:54:00+00:00, externally triggered: False> successful
[2020-07-22 16:54:35,818] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:55:00+00:00: scheduled__2020-07-20T06:55:00+00:00, externally triggered: False>
[2020-07-22 16:54:35,933] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:54:35,950] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:55:00+00:00 [scheduled]> in ORM
[2020-07-22 16:54:36,095] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.098 seconds
[2020-07-22 16:55:39,281] {scheduler_job.py:153} INFO - Started process (PID=612151) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:55:39,328] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:55:39,328] {logging_mixin.py:112} INFO - [2020-07-22 16:55:39,328] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:55:39,379] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:55:39,661] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:55:39,989] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:56:00+00:00: scheduled__2020-07-20T06:56:00+00:00, externally triggered: False>
[2020-07-22 16:55:39,996] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:55:00+00:00: scheduled__2020-07-20T06:55:00+00:00, externally triggered: False>
[2020-07-22 16:55:40,008] {logging_mixin.py:112} INFO - [2020-07-22 16:55:40,008] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:55:00+00:00: scheduled__2020-07-20T06:55:00+00:00, externally triggered: False> successful
[2020-07-22 16:55:40,144] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:56:00+00:00: scheduled__2020-07-20T06:56:00+00:00, externally triggered: False>
[2020-07-22 16:55:40,186] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:55:40,193] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:56:00+00:00 [scheduled]> in ORM
[2020-07-22 16:55:40,388] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.107 seconds
[2020-07-22 16:56:53,495] {scheduler_job.py:153} INFO - Started process (PID=613522) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:56:53,499] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:56:53,500] {logging_mixin.py:112} INFO - [2020-07-22 16:56:53,500] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:56:53,512] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:56:53,704] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:56:54,060] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:57:00+00:00: scheduled__2020-07-20T06:57:00+00:00, externally triggered: False>
[2020-07-22 16:56:54,064] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:56:00+00:00: scheduled__2020-07-20T06:56:00+00:00, externally triggered: False>
[2020-07-22 16:56:54,075] {logging_mixin.py:112} INFO - [2020-07-22 16:56:54,075] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:56:00+00:00: scheduled__2020-07-20T06:56:00+00:00, externally triggered: False> successful
[2020-07-22 16:56:54,180] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:57:00+00:00: scheduled__2020-07-20T06:57:00+00:00, externally triggered: False>
[2020-07-22 16:56:54,198] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:56:54,203] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:57:00+00:00 [scheduled]> in ORM
[2020-07-22 16:56:54,346] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.851 seconds
[2020-07-22 16:57:24,632] {scheduler_job.py:153} INFO - Started process (PID=614161) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:57:24,635] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:57:24,636] {logging_mixin.py:112} INFO - [2020-07-22 16:57:24,636] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:57:24,646] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:57:24,785] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:57:25,112] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:58:00+00:00: scheduled__2020-07-20T06:58:00+00:00, externally triggered: False>
[2020-07-22 16:57:25,116] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:57:00+00:00: scheduled__2020-07-20T06:57:00+00:00, externally triggered: False>
[2020-07-22 16:57:25,135] {logging_mixin.py:112} INFO - [2020-07-22 16:57:25,134] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:57:00+00:00: scheduled__2020-07-20T06:57:00+00:00, externally triggered: False> failed
[2020-07-22 16:57:25,282] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:58:00+00:00: scheduled__2020-07-20T06:58:00+00:00, externally triggered: False>
[2020-07-22 16:57:25,308] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:57:25,316] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:58:00+00:00 [scheduled]> in ORM
[2020-07-22 16:57:25,468] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.837 seconds
[2020-07-22 16:57:50,104] {scheduler_job.py:153} INFO - Started process (PID=614750) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:57:50,108] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:57:50,108] {logging_mixin.py:112} INFO - [2020-07-22 16:57:50,108] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:57:50,121] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:57:50,318] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:57:50,679] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T06:59:00+00:00: scheduled__2020-07-20T06:59:00+00:00, externally triggered: False>
[2020-07-22 16:57:50,685] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:58:00+00:00: scheduled__2020-07-20T06:58:00+00:00, externally triggered: False>
[2020-07-22 16:57:50,698] {logging_mixin.py:112} INFO - [2020-07-22 16:57:50,698] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:58:00+00:00: scheduled__2020-07-20T06:58:00+00:00, externally triggered: False> failed
[2020-07-22 16:57:50,838] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:59:00+00:00: scheduled__2020-07-20T06:59:00+00:00, externally triggered: False>
[2020-07-22 16:57:50,854] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:57:50,858] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 06:59:00+00:00 [scheduled]> in ORM
[2020-07-22 16:57:51,003] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.899 seconds
[2020-07-22 16:58:14,845] {scheduler_job.py:153} INFO - Started process (PID=615202) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:58:14,848] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:58:14,849] {logging_mixin.py:112} INFO - [2020-07-22 16:58:14,849] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:58:14,861] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:58:15,060] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:58:15,367] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:00:00+00:00: scheduled__2020-07-20T07:00:00+00:00, externally triggered: False>
[2020-07-22 16:58:15,373] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 06:59:00+00:00: scheduled__2020-07-20T06:59:00+00:00, externally triggered: False>
[2020-07-22 16:58:15,387] {logging_mixin.py:112} INFO - [2020-07-22 16:58:15,387] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 06:59:00+00:00: scheduled__2020-07-20T06:59:00+00:00, externally triggered: False> failed
[2020-07-22 16:58:15,505] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:00:00+00:00: scheduled__2020-07-20T07:00:00+00:00, externally triggered: False>
[2020-07-22 16:58:15,523] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:58:15,527] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:00:00+00:00 [scheduled]> in ORM
[2020-07-22 16:58:15,673] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.828 seconds
[2020-07-22 16:58:44,131] {scheduler_job.py:153} INFO - Started process (PID=615850) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:58:44,135] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:58:44,135] {logging_mixin.py:112} INFO - [2020-07-22 16:58:44,135] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:58:44,145] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:58:44,325] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:58:44,669] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:01:00+00:00: scheduled__2020-07-20T07:01:00+00:00, externally triggered: False>
[2020-07-22 16:58:44,675] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:00:00+00:00: scheduled__2020-07-20T07:00:00+00:00, externally triggered: False>
[2020-07-22 16:58:44,689] {logging_mixin.py:112} INFO - [2020-07-22 16:58:44,689] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:00:00+00:00: scheduled__2020-07-20T07:00:00+00:00, externally triggered: False> failed
[2020-07-22 16:58:44,914] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:01:00+00:00: scheduled__2020-07-20T07:01:00+00:00, externally triggered: False>
[2020-07-22 16:58:44,927] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:58:44,934] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:01:00+00:00 [scheduled]> in ORM
[2020-07-22 16:58:45,085] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.954 seconds
[2020-07-22 16:59:08,216] {scheduler_job.py:153} INFO - Started process (PID=616357) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:59:08,220] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:59:08,221] {logging_mixin.py:112} INFO - [2020-07-22 16:59:08,221] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:59:08,273] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:59:08,449] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:59:08,793] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:02:00+00:00: scheduled__2020-07-20T07:02:00+00:00, externally triggered: False>
[2020-07-22 16:59:08,811] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:01:00+00:00: scheduled__2020-07-20T07:01:00+00:00, externally triggered: False>
[2020-07-22 16:59:08,828] {logging_mixin.py:112} INFO - [2020-07-22 16:59:08,828] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:01:00+00:00: scheduled__2020-07-20T07:01:00+00:00, externally triggered: False> failed
[2020-07-22 16:59:08,929] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:02:00+00:00: scheduled__2020-07-20T07:02:00+00:00, externally triggered: False>
[2020-07-22 16:59:08,952] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:59:08,961] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:02:00+00:00 [scheduled]> in ORM
[2020-07-22 16:59:09,169] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.953 seconds
[2020-07-22 16:59:33,903] {scheduler_job.py:153} INFO - Started process (PID=616919) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:59:33,908] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 16:59:33,910] {logging_mixin.py:112} INFO - [2020-07-22 16:59:33,909] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:59:33,926] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 16:59:34,167] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 16:59:34,843] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:03:00+00:00: scheduled__2020-07-20T07:03:00+00:00, externally triggered: False>
[2020-07-22 16:59:34,848] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:02:00+00:00: scheduled__2020-07-20T07:02:00+00:00, externally triggered: False>
[2020-07-22 16:59:34,859] {logging_mixin.py:112} INFO - [2020-07-22 16:59:34,859] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:02:00+00:00: scheduled__2020-07-20T07:02:00+00:00, externally triggered: False> failed
[2020-07-22 16:59:34,964] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:03:00+00:00: scheduled__2020-07-20T07:03:00+00:00, externally triggered: False>
[2020-07-22 16:59:34,979] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 16:59:34,984] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:03:00+00:00 [scheduled]> in ORM
[2020-07-22 16:59:35,132] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.229 seconds
[2020-07-22 17:00:00,533] {scheduler_job.py:153} INFO - Started process (PID=617543) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:00:00,536] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:00:00,537] {logging_mixin.py:112} INFO - [2020-07-22 17:00:00,537] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:00:00,548] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:00:00,690] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:00:01,203] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:04:00+00:00: scheduled__2020-07-20T07:04:00+00:00, externally triggered: False>
[2020-07-22 17:00:01,208] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:03:00+00:00: scheduled__2020-07-20T07:03:00+00:00, externally triggered: False>
[2020-07-22 17:00:01,221] {logging_mixin.py:112} INFO - [2020-07-22 17:00:01,221] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:03:00+00:00: scheduled__2020-07-20T07:03:00+00:00, externally triggered: False> failed
[2020-07-22 17:00:01,343] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:04:00+00:00: scheduled__2020-07-20T07:04:00+00:00, externally triggered: False>
[2020-07-22 17:00:01,359] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:00:01,363] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:04:00+00:00 [scheduled]> in ORM
[2020-07-22 17:00:01,499] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.966 seconds
[2020-07-22 17:00:24,775] {scheduler_job.py:153} INFO - Started process (PID=618076) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:00:24,779] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:00:24,780] {logging_mixin.py:112} INFO - [2020-07-22 17:00:24,780] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:00:24,790] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:00:24,939] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:00:25,295] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:05:00+00:00: scheduled__2020-07-20T07:05:00+00:00, externally triggered: False>
[2020-07-22 17:00:25,299] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:04:00+00:00: scheduled__2020-07-20T07:04:00+00:00, externally triggered: False>
[2020-07-22 17:00:25,306] {logging_mixin.py:112} INFO - [2020-07-22 17:00:25,306] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:04:00+00:00: scheduled__2020-07-20T07:04:00+00:00, externally triggered: False> failed
[2020-07-22 17:00:25,466] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:05:00+00:00: scheduled__2020-07-20T07:05:00+00:00, externally triggered: False>
[2020-07-22 17:00:25,488] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:00:25,495] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:05:00+00:00 [scheduled]> in ORM
[2020-07-22 17:00:25,655] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.880 seconds
[2020-07-22 17:00:55,413] {scheduler_job.py:153} INFO - Started process (PID=618741) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:00:55,416] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:00:55,417] {logging_mixin.py:112} INFO - [2020-07-22 17:00:55,417] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:00:55,427] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:00:55,577] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:00:55,902] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:06:00+00:00: scheduled__2020-07-20T07:06:00+00:00, externally triggered: False>
[2020-07-22 17:00:55,909] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:05:00+00:00: scheduled__2020-07-20T07:05:00+00:00, externally triggered: False>
[2020-07-22 17:00:55,922] {logging_mixin.py:112} INFO - [2020-07-22 17:00:55,922] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:05:00+00:00: scheduled__2020-07-20T07:05:00+00:00, externally triggered: False> failed
[2020-07-22 17:00:56,045] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:06:00+00:00: scheduled__2020-07-20T07:06:00+00:00, externally triggered: False>
[2020-07-22 17:00:56,065] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:00:56,071] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:06:00+00:00 [scheduled]> in ORM
[2020-07-22 17:00:56,212] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.800 seconds
[2020-07-22 17:01:19,758] {scheduler_job.py:153} INFO - Started process (PID=619196) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:01:19,762] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:01:19,762] {logging_mixin.py:112} INFO - [2020-07-22 17:01:19,762] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:01:19,773] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:01:20,242] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:01:20,584] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:07:00+00:00: scheduled__2020-07-20T07:07:00+00:00, externally triggered: False>
[2020-07-22 17:01:20,590] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:06:00+00:00: scheduled__2020-07-20T07:06:00+00:00, externally triggered: False>
[2020-07-22 17:01:20,598] {logging_mixin.py:112} INFO - [2020-07-22 17:01:20,598] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:06:00+00:00: scheduled__2020-07-20T07:06:00+00:00, externally triggered: False> failed
[2020-07-22 17:01:20,713] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:07:00+00:00: scheduled__2020-07-20T07:07:00+00:00, externally triggered: False>
[2020-07-22 17:01:20,745] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:01:20,754] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:07:00+00:00 [scheduled]> in ORM
[2020-07-22 17:01:20,922] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.164 seconds
[2020-07-22 17:01:50,639] {scheduler_job.py:153} INFO - Started process (PID=619852) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:01:50,644] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:01:50,645] {logging_mixin.py:112} INFO - [2020-07-22 17:01:50,644] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:01:50,655] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:01:50,873] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:01:51,264] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:08:00+00:00: scheduled__2020-07-20T07:08:00+00:00, externally triggered: False>
[2020-07-22 17:01:51,268] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:07:00+00:00: scheduled__2020-07-20T07:07:00+00:00, externally triggered: False>
[2020-07-22 17:01:51,282] {logging_mixin.py:112} INFO - [2020-07-22 17:01:51,281] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:07:00+00:00: scheduled__2020-07-20T07:07:00+00:00, externally triggered: False> failed
[2020-07-22 17:01:51,391] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:08:00+00:00: scheduled__2020-07-20T07:08:00+00:00, externally triggered: False>
[2020-07-22 17:01:51,440] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:01:51,445] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:08:00+00:00 [scheduled]> in ORM
[2020-07-22 17:01:51,601] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.962 seconds
[2020-07-22 17:02:24,753] {scheduler_job.py:153} INFO - Started process (PID=620567) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:02:24,757] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:02:24,758] {logging_mixin.py:112} INFO - [2020-07-22 17:02:24,757] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:02:24,775] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:02:24,935] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:02:25,268] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:09:00+00:00: scheduled__2020-07-20T07:09:00+00:00, externally triggered: False>
[2020-07-22 17:02:25,274] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:08:00+00:00: scheduled__2020-07-20T07:08:00+00:00, externally triggered: False>
[2020-07-22 17:02:25,288] {logging_mixin.py:112} INFO - [2020-07-22 17:02:25,287] {dagrun.py:309} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:08:00+00:00: scheduled__2020-07-20T07:08:00+00:00, externally triggered: False> failed
[2020-07-22 17:02:25,426] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:09:00+00:00: scheduled__2020-07-20T07:09:00+00:00, externally triggered: False>
[2020-07-22 17:02:25,548] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:02:25,589] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:09:00+00:00 [scheduled]> in ORM
[2020-07-22 17:02:25,769] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.017 seconds
[2020-07-22 17:03:27,751] {scheduler_job.py:153} INFO - Started process (PID=621766) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:03:27,755] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:03:27,755] {logging_mixin.py:112} INFO - [2020-07-22 17:03:27,755] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:03:27,766] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:03:27,894] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:03:28,259] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:10:00+00:00: scheduled__2020-07-20T07:10:00+00:00, externally triggered: False>
[2020-07-22 17:03:28,264] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:09:00+00:00: scheduled__2020-07-20T07:09:00+00:00, externally triggered: False>
[2020-07-22 17:03:28,273] {logging_mixin.py:112} INFO - [2020-07-22 17:03:28,273] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:09:00+00:00: scheduled__2020-07-20T07:09:00+00:00, externally triggered: False> successful
[2020-07-22 17:03:28,384] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:10:00+00:00: scheduled__2020-07-20T07:10:00+00:00, externally triggered: False>
[2020-07-22 17:03:28,394] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 11:33:25.454943+00:00: manual__2020-07-22T11:33:25.454943+00:00, externally triggered: True>
[2020-07-22 17:03:28,413] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:03:28,418] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:10:00+00:00 [scheduled]> in ORM
[2020-07-22 17:03:28,423] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-22 11:33:25.454943+00:00 [scheduled]> in ORM
[2020-07-22 17:03:28,564] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.814 seconds
[2020-07-22 17:05:01,663] {scheduler_job.py:153} INFO - Started process (PID=623564) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:05:01,666] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:05:01,666] {logging_mixin.py:112} INFO - [2020-07-22 17:05:01,666] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:05:01,677] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:05:01,838] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:05:02,162] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:11:00+00:00: scheduled__2020-07-20T07:11:00+00:00, externally triggered: False>
[2020-07-22 17:05:02,166] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:10:00+00:00: scheduled__2020-07-20T07:10:00+00:00, externally triggered: False>
[2020-07-22 17:05:02,173] {logging_mixin.py:112} INFO - [2020-07-22 17:05:02,173] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:10:00+00:00: scheduled__2020-07-20T07:10:00+00:00, externally triggered: False> successful
[2020-07-22 17:05:02,277] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:11:00+00:00: scheduled__2020-07-20T07:11:00+00:00, externally triggered: False>
[2020-07-22 17:05:02,291] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-22 11:33:25.454943+00:00: manual__2020-07-22T11:33:25.454943+00:00, externally triggered: True>
[2020-07-22 17:05:02,299] {logging_mixin.py:112} INFO - [2020-07-22 17:05:02,299] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-22 11:33:25.454943+00:00: manual__2020-07-22T11:33:25.454943+00:00, externally triggered: True> successful
[2020-07-22 17:05:02,460] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:05:02,464] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:11:00+00:00 [scheduled]> in ORM
[2020-07-22 17:05:03,142] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.480 seconds
[2020-07-22 17:05:41,815] {scheduler_job.py:153} INFO - Started process (PID=624448) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:05:41,819] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:05:41,820] {logging_mixin.py:112} INFO - [2020-07-22 17:05:41,819] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:05:41,830] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:05:42,003] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:05:42,304] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:12:00+00:00: scheduled__2020-07-20T07:12:00+00:00, externally triggered: False>
[2020-07-22 17:05:42,308] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:11:00+00:00: scheduled__2020-07-20T07:11:00+00:00, externally triggered: False>
[2020-07-22 17:05:42,317] {logging_mixin.py:112} INFO - [2020-07-22 17:05:42,317] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:11:00+00:00: scheduled__2020-07-20T07:11:00+00:00, externally triggered: False> successful
[2020-07-22 17:05:42,457] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:12:00+00:00: scheduled__2020-07-20T07:12:00+00:00, externally triggered: False>
[2020-07-22 17:05:42,490] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:05:42,504] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:12:00+00:00 [scheduled]> in ORM
[2020-07-22 17:05:42,691] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.876 seconds
[2020-07-22 17:06:40,039] {scheduler_job.py:153} INFO - Started process (PID=625784) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:06:40,045] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:06:40,046] {logging_mixin.py:112} INFO - [2020-07-22 17:06:40,046] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:06:40,064] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:06:40,246] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:06:40,553] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:13:00+00:00: scheduled__2020-07-20T07:13:00+00:00, externally triggered: False>
[2020-07-22 17:06:40,559] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:12:00+00:00: scheduled__2020-07-20T07:12:00+00:00, externally triggered: False>
[2020-07-22 17:06:40,575] {logging_mixin.py:112} INFO - [2020-07-22 17:06:40,575] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:12:00+00:00: scheduled__2020-07-20T07:12:00+00:00, externally triggered: False> successful
[2020-07-22 17:06:40,715] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:13:00+00:00: scheduled__2020-07-20T07:13:00+00:00, externally triggered: False>
[2020-07-22 17:06:40,742] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:06:40,750] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:13:00+00:00 [scheduled]> in ORM
[2020-07-22 17:06:40,891] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.852 seconds
[2020-07-22 17:07:39,316] {scheduler_job.py:153} INFO - Started process (PID=627206) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:07:39,319] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:07:39,320] {logging_mixin.py:112} INFO - [2020-07-22 17:07:39,320] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:07:39,331] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:07:39,504] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:07:39,935] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:14:00+00:00: scheduled__2020-07-20T07:14:00+00:00, externally triggered: False>
[2020-07-22 17:07:39,941] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:13:00+00:00: scheduled__2020-07-20T07:13:00+00:00, externally triggered: False>
[2020-07-22 17:07:39,949] {logging_mixin.py:112} INFO - [2020-07-22 17:07:39,949] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:13:00+00:00: scheduled__2020-07-20T07:13:00+00:00, externally triggered: False> successful
[2020-07-22 17:07:40,165] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:14:00+00:00: scheduled__2020-07-20T07:14:00+00:00, externally triggered: False>
[2020-07-22 17:07:40,193] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:07:40,200] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:14:00+00:00 [scheduled]> in ORM
[2020-07-22 17:07:40,396] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.081 seconds
[2020-07-22 17:08:31,454] {scheduler_job.py:153} INFO - Started process (PID=628266) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:08:31,458] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:08:31,458] {logging_mixin.py:112} INFO - [2020-07-22 17:08:31,458] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:08:31,468] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:08:32,754] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:08:33,603] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:15:00+00:00: scheduled__2020-07-20T07:15:00+00:00, externally triggered: False>
[2020-07-22 17:08:33,608] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:14:00+00:00: scheduled__2020-07-20T07:14:00+00:00, externally triggered: False>
[2020-07-22 17:08:33,616] {logging_mixin.py:112} INFO - [2020-07-22 17:08:33,616] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:14:00+00:00: scheduled__2020-07-20T07:14:00+00:00, externally triggered: False> successful
[2020-07-22 17:08:33,975] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:15:00+00:00: scheduled__2020-07-20T07:15:00+00:00, externally triggered: False>
[2020-07-22 17:08:34,628] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:08:34,632] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:15:00+00:00 [scheduled]> in ORM
[2020-07-22 17:08:34,898] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 3.445 seconds
[2020-07-22 17:09:17,097] {scheduler_job.py:153} INFO - Started process (PID=629241) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:09:17,100] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:09:17,101] {logging_mixin.py:112} INFO - [2020-07-22 17:09:17,101] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:09:17,110] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:09:17,285] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:09:17,651] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:16:00+00:00: scheduled__2020-07-20T07:16:00+00:00, externally triggered: False>
[2020-07-22 17:09:17,655] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:15:00+00:00: scheduled__2020-07-20T07:15:00+00:00, externally triggered: False>
[2020-07-22 17:09:17,664] {logging_mixin.py:112} INFO - [2020-07-22 17:09:17,664] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:15:00+00:00: scheduled__2020-07-20T07:15:00+00:00, externally triggered: False> successful
[2020-07-22 17:09:17,755] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:16:00+00:00: scheduled__2020-07-20T07:16:00+00:00, externally triggered: False>
[2020-07-22 17:09:17,777] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:09:17,783] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:16:00+00:00 [scheduled]> in ORM
[2020-07-22 17:09:17,945] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.848 seconds
[2020-07-22 17:10:02,031] {scheduler_job.py:153} INFO - Started process (PID=630207) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:10:02,035] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:10:02,036] {logging_mixin.py:112} INFO - [2020-07-22 17:10:02,035] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:10:02,044] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:10:02,208] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:10:02,517] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:17:00+00:00: scheduled__2020-07-20T07:17:00+00:00, externally triggered: False>
[2020-07-22 17:10:02,521] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:16:00+00:00: scheduled__2020-07-20T07:16:00+00:00, externally triggered: False>
[2020-07-22 17:10:02,530] {logging_mixin.py:112} INFO - [2020-07-22 17:10:02,529] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:16:00+00:00: scheduled__2020-07-20T07:16:00+00:00, externally triggered: False> successful
[2020-07-22 17:10:02,635] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:17:00+00:00: scheduled__2020-07-20T07:17:00+00:00, externally triggered: False>
[2020-07-22 17:10:02,652] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:10:02,659] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:17:00+00:00 [scheduled]> in ORM
[2020-07-22 17:10:02,868] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.838 seconds
[2020-07-22 17:10:41,703] {scheduler_job.py:153} INFO - Started process (PID=631117) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:10:41,706] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:10:41,707] {logging_mixin.py:112} INFO - [2020-07-22 17:10:41,707] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:10:41,720] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:10:41,883] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:10:42,197] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:18:00+00:00: scheduled__2020-07-20T07:18:00+00:00, externally triggered: False>
[2020-07-22 17:10:42,201] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:17:00+00:00: scheduled__2020-07-20T07:17:00+00:00, externally triggered: False>
[2020-07-22 17:10:42,209] {logging_mixin.py:112} INFO - [2020-07-22 17:10:42,209] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:17:00+00:00: scheduled__2020-07-20T07:17:00+00:00, externally triggered: False> successful
[2020-07-22 17:10:42,314] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:18:00+00:00: scheduled__2020-07-20T07:18:00+00:00, externally triggered: False>
[2020-07-22 17:10:42,331] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:10:42,337] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:18:00+00:00 [scheduled]> in ORM
[2020-07-22 17:10:42,502] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.799 seconds
[2020-07-22 17:11:21,578] {scheduler_job.py:153} INFO - Started process (PID=632054) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:11:21,581] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:11:21,581] {logging_mixin.py:112} INFO - [2020-07-22 17:11:21,581] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:11:21,590] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:11:21,714] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:11:22,115] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:19:00+00:00: scheduled__2020-07-20T07:19:00+00:00, externally triggered: False>
[2020-07-22 17:11:22,119] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:18:00+00:00: scheduled__2020-07-20T07:18:00+00:00, externally triggered: False>
[2020-07-22 17:11:22,126] {logging_mixin.py:112} INFO - [2020-07-22 17:11:22,126] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:18:00+00:00: scheduled__2020-07-20T07:18:00+00:00, externally triggered: False> successful
[2020-07-22 17:11:22,261] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:19:00+00:00: scheduled__2020-07-20T07:19:00+00:00, externally triggered: False>
[2020-07-22 17:11:22,281] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:11:22,288] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:19:00+00:00 [scheduled]> in ORM
[2020-07-22 17:11:22,417] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.838 seconds
[2020-07-22 17:12:01,629] {scheduler_job.py:153} INFO - Started process (PID=632930) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:12:01,634] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:12:01,634] {logging_mixin.py:112} INFO - [2020-07-22 17:12:01,634] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:12:01,645] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:12:01,770] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:12:02,047] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:20:00+00:00: scheduled__2020-07-20T07:20:00+00:00, externally triggered: False>
[2020-07-22 17:12:02,053] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:19:00+00:00: scheduled__2020-07-20T07:19:00+00:00, externally triggered: False>
[2020-07-22 17:12:02,060] {logging_mixin.py:112} INFO - [2020-07-22 17:12:02,060] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:19:00+00:00: scheduled__2020-07-20T07:19:00+00:00, externally triggered: False> successful
[2020-07-22 17:12:02,188] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:20:00+00:00: scheduled__2020-07-20T07:20:00+00:00, externally triggered: False>
[2020-07-22 17:12:02,207] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:12:02,211] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:20:00+00:00 [scheduled]> in ORM
[2020-07-22 17:12:02,350] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.721 seconds
[2020-07-22 17:12:41,170] {scheduler_job.py:153} INFO - Started process (PID=633780) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:12:41,175] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:12:41,176] {logging_mixin.py:112} INFO - [2020-07-22 17:12:41,176] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:12:41,190] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:12:41,395] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:12:41,682] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:21:00+00:00: scheduled__2020-07-20T07:21:00+00:00, externally triggered: False>
[2020-07-22 17:12:41,686] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:20:00+00:00: scheduled__2020-07-20T07:20:00+00:00, externally triggered: False>
[2020-07-22 17:12:41,694] {logging_mixin.py:112} INFO - [2020-07-22 17:12:41,694] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:20:00+00:00: scheduled__2020-07-20T07:20:00+00:00, externally triggered: False> successful
[2020-07-22 17:12:41,797] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:21:00+00:00: scheduled__2020-07-20T07:21:00+00:00, externally triggered: False>
[2020-07-22 17:12:41,818] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:12:41,822] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:21:00+00:00 [scheduled]> in ORM
[2020-07-22 17:12:41,965] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.795 seconds
[2020-07-22 17:13:21,179] {scheduler_job.py:153} INFO - Started process (PID=634675) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:13:21,182] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:13:21,183] {logging_mixin.py:112} INFO - [2020-07-22 17:13:21,182] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:13:21,193] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:13:21,291] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:13:21,650] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:22:00+00:00: scheduled__2020-07-20T07:22:00+00:00, externally triggered: False>
[2020-07-22 17:13:21,653] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:21:00+00:00: scheduled__2020-07-20T07:21:00+00:00, externally triggered: False>
[2020-07-22 17:13:21,661] {logging_mixin.py:112} INFO - [2020-07-22 17:13:21,661] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:21:00+00:00: scheduled__2020-07-20T07:21:00+00:00, externally triggered: False> successful
[2020-07-22 17:13:22,177] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:22:00+00:00: scheduled__2020-07-20T07:22:00+00:00, externally triggered: False>
[2020-07-22 17:13:22,197] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:13:22,200] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:22:00+00:00 [scheduled]> in ORM
[2020-07-22 17:13:22,422] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.243 seconds
[2020-07-22 17:14:00,873] {scheduler_job.py:153} INFO - Started process (PID=635523) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:14:00,877] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:14:00,878] {logging_mixin.py:112} INFO - [2020-07-22 17:14:00,878] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:14:00,889] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:14:01,108] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:14:01,436] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:23:00+00:00: scheduled__2020-07-20T07:23:00+00:00, externally triggered: False>
[2020-07-22 17:14:01,439] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:22:00+00:00: scheduled__2020-07-20T07:22:00+00:00, externally triggered: False>
[2020-07-22 17:14:01,447] {logging_mixin.py:112} INFO - [2020-07-22 17:14:01,447] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:22:00+00:00: scheduled__2020-07-20T07:22:00+00:00, externally triggered: False> successful
[2020-07-22 17:14:01,571] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:23:00+00:00: scheduled__2020-07-20T07:23:00+00:00, externally triggered: False>
[2020-07-22 17:14:01,587] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:14:01,591] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:23:00+00:00 [scheduled]> in ORM
[2020-07-22 17:14:01,733] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.860 seconds
[2020-07-22 17:14:40,407] {scheduler_job.py:153} INFO - Started process (PID=636372) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:14:40,410] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:14:40,411] {logging_mixin.py:112} INFO - [2020-07-22 17:14:40,411] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:14:40,421] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:14:40,571] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:14:40,899] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:24:00+00:00: scheduled__2020-07-20T07:24:00+00:00, externally triggered: False>
[2020-07-22 17:14:40,902] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:23:00+00:00: scheduled__2020-07-20T07:23:00+00:00, externally triggered: False>
[2020-07-22 17:14:40,909] {logging_mixin.py:112} INFO - [2020-07-22 17:14:40,909] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:23:00+00:00: scheduled__2020-07-20T07:23:00+00:00, externally triggered: False> successful
[2020-07-22 17:14:41,014] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:24:00+00:00: scheduled__2020-07-20T07:24:00+00:00, externally triggered: False>
[2020-07-22 17:14:41,032] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:14:41,038] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:24:00+00:00 [scheduled]> in ORM
[2020-07-22 17:14:41,180] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.773 seconds
[2020-07-22 17:15:25,656] {scheduler_job.py:153} INFO - Started process (PID=637317) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:15:25,659] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:15:25,660] {logging_mixin.py:112} INFO - [2020-07-22 17:15:25,660] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:15:25,670] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:15:25,840] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:15:26,203] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:25:00+00:00: scheduled__2020-07-20T07:25:00+00:00, externally triggered: False>
[2020-07-22 17:15:26,208] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:24:00+00:00: scheduled__2020-07-20T07:24:00+00:00, externally triggered: False>
[2020-07-22 17:15:26,217] {logging_mixin.py:112} INFO - [2020-07-22 17:15:26,217] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:24:00+00:00: scheduled__2020-07-20T07:24:00+00:00, externally triggered: False> successful
[2020-07-22 17:15:26,339] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:25:00+00:00: scheduled__2020-07-20T07:25:00+00:00, externally triggered: False>
[2020-07-22 17:15:26,356] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:15:26,360] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:25:00+00:00 [scheduled]> in ORM
[2020-07-22 17:15:26,549] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.894 seconds
[2020-07-22 17:16:05,514] {scheduler_job.py:153} INFO - Started process (PID=638162) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:16:05,519] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:16:05,519] {logging_mixin.py:112} INFO - [2020-07-22 17:16:05,519] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:16:05,528] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:16:05,660] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:16:06,035] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:26:00+00:00: scheduled__2020-07-20T07:26:00+00:00, externally triggered: False>
[2020-07-22 17:16:06,039] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:25:00+00:00: scheduled__2020-07-20T07:25:00+00:00, externally triggered: False>
[2020-07-22 17:16:06,046] {logging_mixin.py:112} INFO - [2020-07-22 17:16:06,046] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:25:00+00:00: scheduled__2020-07-20T07:25:00+00:00, externally triggered: False> successful
[2020-07-22 17:16:06,162] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:26:00+00:00: scheduled__2020-07-20T07:26:00+00:00, externally triggered: False>
[2020-07-22 17:16:06,183] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:16:06,187] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:26:00+00:00 [scheduled]> in ORM
[2020-07-22 17:16:06,330] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.816 seconds
[2020-07-22 17:16:45,130] {scheduler_job.py:153} INFO - Started process (PID=639018) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:16:45,133] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:16:45,134] {logging_mixin.py:112} INFO - [2020-07-22 17:16:45,134] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:16:45,144] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:16:45,299] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:16:45,664] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:27:00+00:00: scheduled__2020-07-20T07:27:00+00:00, externally triggered: False>
[2020-07-22 17:16:45,670] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:26:00+00:00: scheduled__2020-07-20T07:26:00+00:00, externally triggered: False>
[2020-07-22 17:16:45,685] {logging_mixin.py:112} INFO - [2020-07-22 17:16:45,685] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:26:00+00:00: scheduled__2020-07-20T07:26:00+00:00, externally triggered: False> successful
[2020-07-22 17:16:45,775] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:27:00+00:00: scheduled__2020-07-20T07:27:00+00:00, externally triggered: False>
[2020-07-22 17:16:45,795] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:16:45,799] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:27:00+00:00 [scheduled]> in ORM
[2020-07-22 17:16:45,942] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.812 seconds
[2020-07-22 17:17:24,917] {scheduler_job.py:153} INFO - Started process (PID=639883) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:17:24,922] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:17:24,922] {logging_mixin.py:112} INFO - [2020-07-22 17:17:24,922] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:17:24,934] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:17:25,120] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:17:25,517] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:28:00+00:00: scheduled__2020-07-20T07:28:00+00:00, externally triggered: False>
[2020-07-22 17:17:25,524] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:27:00+00:00: scheduled__2020-07-20T07:27:00+00:00, externally triggered: False>
[2020-07-22 17:17:25,540] {logging_mixin.py:112} INFO - [2020-07-22 17:17:25,539] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:27:00+00:00: scheduled__2020-07-20T07:27:00+00:00, externally triggered: False> successful
[2020-07-22 17:17:25,644] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:28:00+00:00: scheduled__2020-07-20T07:28:00+00:00, externally triggered: False>
[2020-07-22 17:17:25,663] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:17:25,667] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:28:00+00:00 [scheduled]> in ORM
[2020-07-22 17:17:25,823] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.906 seconds
[2020-07-22 17:18:11,391] {scheduler_job.py:153} INFO - Started process (PID=640963) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:18:11,396] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:18:11,397] {logging_mixin.py:112} INFO - [2020-07-22 17:18:11,396] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:18:11,423] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:18:11,560] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:18:11,930] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:29:00+00:00: scheduled__2020-07-20T07:29:00+00:00, externally triggered: False>
[2020-07-22 17:18:11,937] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:28:00+00:00: scheduled__2020-07-20T07:28:00+00:00, externally triggered: False>
[2020-07-22 17:18:11,950] {logging_mixin.py:112} INFO - [2020-07-22 17:18:11,950] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:28:00+00:00: scheduled__2020-07-20T07:28:00+00:00, externally triggered: False> successful
[2020-07-22 17:18:12,079] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:29:00+00:00: scheduled__2020-07-20T07:29:00+00:00, externally triggered: False>
[2020-07-22 17:18:12,099] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:18:12,107] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:29:00+00:00 [scheduled]> in ORM
[2020-07-22 17:18:12,357] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.965 seconds
[2020-07-22 17:19:07,064] {scheduler_job.py:153} INFO - Started process (PID=642068) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:19:07,071] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:19:07,072] {logging_mixin.py:112} INFO - [2020-07-22 17:19:07,072] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:19:07,111] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:19:07,269] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:19:08,245] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:30:00+00:00: scheduled__2020-07-20T07:30:00+00:00, externally triggered: False>
[2020-07-22 17:19:08,252] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:29:00+00:00: scheduled__2020-07-20T07:29:00+00:00, externally triggered: False>
[2020-07-22 17:19:08,268] {logging_mixin.py:112} INFO - [2020-07-22 17:19:08,268] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:29:00+00:00: scheduled__2020-07-20T07:29:00+00:00, externally triggered: False> successful
[2020-07-22 17:19:08,404] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:30:00+00:00: scheduled__2020-07-20T07:30:00+00:00, externally triggered: False>
[2020-07-22 17:19:08,423] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:19:08,427] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:30:00+00:00 [scheduled]> in ORM
[2020-07-22 17:19:08,571] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.508 seconds
[2020-07-22 17:19:53,132] {scheduler_job.py:153} INFO - Started process (PID=643006) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:19:53,136] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:19:53,137] {logging_mixin.py:112} INFO - [2020-07-22 17:19:53,136] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:19:53,147] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:19:53,260] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:19:53,545] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:31:00+00:00: scheduled__2020-07-20T07:31:00+00:00, externally triggered: False>
[2020-07-22 17:19:53,550] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:30:00+00:00: scheduled__2020-07-20T07:30:00+00:00, externally triggered: False>
[2020-07-22 17:19:53,558] {logging_mixin.py:112} INFO - [2020-07-22 17:19:53,557] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:30:00+00:00: scheduled__2020-07-20T07:30:00+00:00, externally triggered: False> successful
[2020-07-22 17:19:53,673] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:31:00+00:00: scheduled__2020-07-20T07:31:00+00:00, externally triggered: False>
[2020-07-22 17:19:53,690] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:19:53,693] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:31:00+00:00 [scheduled]> in ORM
[2020-07-22 17:19:53,881] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.749 seconds
[2020-07-22 17:20:32,672] {scheduler_job.py:153} INFO - Started process (PID=643850) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:20:32,675] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:20:32,675] {logging_mixin.py:112} INFO - [2020-07-22 17:20:32,675] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:20:32,684] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:20:32,878] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:20:33,193] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:32:00+00:00: scheduled__2020-07-20T07:32:00+00:00, externally triggered: False>
[2020-07-22 17:20:33,197] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:31:00+00:00: scheduled__2020-07-20T07:31:00+00:00, externally triggered: False>
[2020-07-22 17:20:33,204] {logging_mixin.py:112} INFO - [2020-07-22 17:20:33,204] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:31:00+00:00: scheduled__2020-07-20T07:31:00+00:00, externally triggered: False> successful
[2020-07-22 17:20:33,330] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:32:00+00:00: scheduled__2020-07-20T07:32:00+00:00, externally triggered: False>
[2020-07-22 17:20:33,349] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:20:33,352] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:32:00+00:00 [scheduled]> in ORM
[2020-07-22 17:20:33,521] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.849 seconds
[2020-07-22 17:21:14,277] {scheduler_job.py:153} INFO - Started process (PID=644765) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:21:14,280] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:21:14,280] {logging_mixin.py:112} INFO - [2020-07-22 17:21:14,280] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:21:14,290] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:21:14,405] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:21:14,783] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:33:00+00:00: scheduled__2020-07-20T07:33:00+00:00, externally triggered: False>
[2020-07-22 17:21:14,787] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:32:00+00:00: scheduled__2020-07-20T07:32:00+00:00, externally triggered: False>
[2020-07-22 17:21:14,796] {logging_mixin.py:112} INFO - [2020-07-22 17:21:14,796] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:32:00+00:00: scheduled__2020-07-20T07:32:00+00:00, externally triggered: False> successful
[2020-07-22 17:21:15,009] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:33:00+00:00: scheduled__2020-07-20T07:33:00+00:00, externally triggered: False>
[2020-07-22 17:21:15,022] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:21:15,026] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:33:00+00:00 [scheduled]> in ORM
[2020-07-22 17:21:15,176] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.899 seconds
[2020-07-22 17:21:54,664] {scheduler_job.py:153} INFO - Started process (PID=645626) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:21:54,667] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:21:54,667] {logging_mixin.py:112} INFO - [2020-07-22 17:21:54,667] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:21:54,678] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:21:54,949] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:21:55,308] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:34:00+00:00: scheduled__2020-07-20T07:34:00+00:00, externally triggered: False>
[2020-07-22 17:21:55,313] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:33:00+00:00: scheduled__2020-07-20T07:33:00+00:00, externally triggered: False>
[2020-07-22 17:21:55,321] {logging_mixin.py:112} INFO - [2020-07-22 17:21:55,321] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:33:00+00:00: scheduled__2020-07-20T07:33:00+00:00, externally triggered: False> successful
[2020-07-22 17:21:55,445] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:34:00+00:00: scheduled__2020-07-20T07:34:00+00:00, externally triggered: False>
[2020-07-22 17:21:55,463] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:21:55,467] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:34:00+00:00 [scheduled]> in ORM
[2020-07-22 17:21:55,612] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.949 seconds
[2020-07-22 17:22:45,165] {scheduler_job.py:153} INFO - Started process (PID=646749) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:22:45,169] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:22:45,169] {logging_mixin.py:112} INFO - [2020-07-22 17:22:45,169] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:22:45,178] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:22:45,355] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:22:45,871] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:35:00+00:00: scheduled__2020-07-20T07:35:00+00:00, externally triggered: False>
[2020-07-22 17:22:45,875] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:34:00+00:00: scheduled__2020-07-20T07:34:00+00:00, externally triggered: False>
[2020-07-22 17:22:45,885] {logging_mixin.py:112} INFO - [2020-07-22 17:22:45,885] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:34:00+00:00: scheduled__2020-07-20T07:34:00+00:00, externally triggered: False> successful
[2020-07-22 17:22:45,991] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:35:00+00:00: scheduled__2020-07-20T07:35:00+00:00, externally triggered: False>
[2020-07-22 17:22:46,004] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:22:46,008] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:35:00+00:00 [scheduled]> in ORM
[2020-07-22 17:22:46,156] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.992 seconds
[2020-07-22 17:23:26,093] {scheduler_job.py:153} INFO - Started process (PID=647647) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:23:26,097] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:23:26,097] {logging_mixin.py:112} INFO - [2020-07-22 17:23:26,097] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:23:26,109] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:23:26,279] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:23:26,573] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:36:00+00:00: scheduled__2020-07-20T07:36:00+00:00, externally triggered: False>
[2020-07-22 17:23:26,578] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:35:00+00:00: scheduled__2020-07-20T07:35:00+00:00, externally triggered: False>
[2020-07-22 17:23:26,591] {logging_mixin.py:112} INFO - [2020-07-22 17:23:26,591] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:35:00+00:00: scheduled__2020-07-20T07:35:00+00:00, externally triggered: False> successful
[2020-07-22 17:23:26,693] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:36:00+00:00: scheduled__2020-07-20T07:36:00+00:00, externally triggered: False>
[2020-07-22 17:23:26,705] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:23:26,710] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:36:00+00:00 [scheduled]> in ORM
[2020-07-22 17:23:26,859] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.766 seconds
[2020-07-22 17:24:10,764] {scheduler_job.py:153} INFO - Started process (PID=648575) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:24:10,769] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:24:10,769] {logging_mixin.py:112} INFO - [2020-07-22 17:24:10,769] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:24:10,779] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:24:10,902] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:24:11,247] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:37:00+00:00: scheduled__2020-07-20T07:37:00+00:00, externally triggered: False>
[2020-07-22 17:24:11,251] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:36:00+00:00: scheduled__2020-07-20T07:36:00+00:00, externally triggered: False>
[2020-07-22 17:24:11,261] {logging_mixin.py:112} INFO - [2020-07-22 17:24:11,260] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:36:00+00:00: scheduled__2020-07-20T07:36:00+00:00, externally triggered: False> successful
[2020-07-22 17:24:11,417] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:37:00+00:00: scheduled__2020-07-20T07:37:00+00:00, externally triggered: False>
[2020-07-22 17:24:11,431] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:24:11,436] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:37:00+00:00 [scheduled]> in ORM
[2020-07-22 17:24:11,605] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.840 seconds
[2020-07-22 17:24:56,799] {scheduler_job.py:153} INFO - Started process (PID=649536) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:24:56,805] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:24:56,805] {logging_mixin.py:112} INFO - [2020-07-22 17:24:56,805] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:24:56,815] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:24:56,982] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:24:57,430] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:38:00+00:00: scheduled__2020-07-20T07:38:00+00:00, externally triggered: False>
[2020-07-22 17:24:57,434] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:37:00+00:00: scheduled__2020-07-20T07:37:00+00:00, externally triggered: False>
[2020-07-22 17:24:57,442] {logging_mixin.py:112} INFO - [2020-07-22 17:24:57,442] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:37:00+00:00: scheduled__2020-07-20T07:37:00+00:00, externally triggered: False> successful
[2020-07-22 17:24:57,575] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:38:00+00:00: scheduled__2020-07-20T07:38:00+00:00, externally triggered: False>
[2020-07-22 17:24:57,589] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:24:57,593] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:38:00+00:00 [scheduled]> in ORM
[2020-07-22 17:24:57,752] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.952 seconds
[2020-07-22 17:25:42,042] {scheduler_job.py:153} INFO - Started process (PID=650570) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:25:42,046] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:25:42,046] {logging_mixin.py:112} INFO - [2020-07-22 17:25:42,046] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:25:42,055] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:25:42,225] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:25:42,507] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:39:00+00:00: scheduled__2020-07-20T07:39:00+00:00, externally triggered: False>
[2020-07-22 17:25:42,512] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:38:00+00:00: scheduled__2020-07-20T07:38:00+00:00, externally triggered: False>
[2020-07-22 17:25:42,519] {logging_mixin.py:112} INFO - [2020-07-22 17:25:42,519] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:38:00+00:00: scheduled__2020-07-20T07:38:00+00:00, externally triggered: False> successful
[2020-07-22 17:25:42,633] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:39:00+00:00: scheduled__2020-07-20T07:39:00+00:00, externally triggered: False>
[2020-07-22 17:25:42,650] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:25:42,654] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:39:00+00:00 [scheduled]> in ORM
[2020-07-22 17:25:42,800] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.758 seconds
[2020-07-22 17:26:40,057] {scheduler_job.py:153} INFO - Started process (PID=651723) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:26:40,060] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:26:40,061] {logging_mixin.py:112} INFO - [2020-07-22 17:26:40,061] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:26:40,071] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:26:40,323] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:26:40,793] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:40:00+00:00: scheduled__2020-07-20T07:40:00+00:00, externally triggered: False>
[2020-07-22 17:26:40,797] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:39:00+00:00: scheduled__2020-07-20T07:39:00+00:00, externally triggered: False>
[2020-07-22 17:26:40,811] {logging_mixin.py:112} INFO - [2020-07-22 17:26:40,810] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:39:00+00:00: scheduled__2020-07-20T07:39:00+00:00, externally triggered: False> successful
[2020-07-22 17:26:41,002] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:40:00+00:00: scheduled__2020-07-20T07:40:00+00:00, externally triggered: False>
[2020-07-22 17:26:41,047] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:26:41,063] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:40:00+00:00 [scheduled]> in ORM
[2020-07-22 17:26:41,226] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.168 seconds
[2020-07-22 17:27:20,196] {scheduler_job.py:153} INFO - Started process (PID=652602) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:27:20,201] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:27:20,202] {logging_mixin.py:112} INFO - [2020-07-22 17:27:20,202] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:27:20,212] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:27:20,616] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:27:20,895] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:41:00+00:00: scheduled__2020-07-20T07:41:00+00:00, externally triggered: False>
[2020-07-22 17:27:20,900] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:40:00+00:00: scheduled__2020-07-20T07:40:00+00:00, externally triggered: False>
[2020-07-22 17:27:20,908] {logging_mixin.py:112} INFO - [2020-07-22 17:27:20,908] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:40:00+00:00: scheduled__2020-07-20T07:40:00+00:00, externally triggered: False> successful
[2020-07-22 17:27:21,248] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:41:00+00:00: scheduled__2020-07-20T07:41:00+00:00, externally triggered: False>
[2020-07-22 17:27:21,265] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:27:21,269] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:41:00+00:00 [scheduled]> in ORM
[2020-07-22 17:27:21,428] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.232 seconds
[2020-07-22 17:28:01,493] {scheduler_job.py:153} INFO - Started process (PID=653471) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:28:01,498] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:28:01,499] {logging_mixin.py:112} INFO - [2020-07-22 17:28:01,498] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:28:01,508] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:28:01,675] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:28:01,965] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:42:00+00:00: scheduled__2020-07-20T07:42:00+00:00, externally triggered: False>
[2020-07-22 17:28:01,972] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:41:00+00:00: scheduled__2020-07-20T07:41:00+00:00, externally triggered: False>
[2020-07-22 17:28:01,980] {logging_mixin.py:112} INFO - [2020-07-22 17:28:01,980] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:41:00+00:00: scheduled__2020-07-20T07:41:00+00:00, externally triggered: False> successful
[2020-07-22 17:28:02,128] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:42:00+00:00: scheduled__2020-07-20T07:42:00+00:00, externally triggered: False>
[2020-07-22 17:28:02,142] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:28:02,148] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:42:00+00:00 [scheduled]> in ORM
[2020-07-22 17:28:02,329] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.836 seconds
[2020-07-22 17:28:36,281] {scheduler_job.py:153} INFO - Started process (PID=654254) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:28:36,284] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:28:36,284] {logging_mixin.py:112} INFO - [2020-07-22 17:28:36,284] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:28:36,294] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:28:36,460] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:28:36,775] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:43:00+00:00: scheduled__2020-07-20T07:43:00+00:00, externally triggered: False>
[2020-07-22 17:28:36,779] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:42:00+00:00: scheduled__2020-07-20T07:42:00+00:00, externally triggered: False>
[2020-07-22 17:28:36,788] {logging_mixin.py:112} INFO - [2020-07-22 17:28:36,787] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:42:00+00:00: scheduled__2020-07-20T07:42:00+00:00, externally triggered: False> successful
[2020-07-22 17:28:36,896] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:43:00+00:00: scheduled__2020-07-20T07:43:00+00:00, externally triggered: False>
[2020-07-22 17:28:36,910] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:28:36,914] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:43:00+00:00 [scheduled]> in ORM
[2020-07-22 17:28:37,097] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.816 seconds
[2020-07-22 17:29:10,500] {scheduler_job.py:153} INFO - Started process (PID=655045) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:29:10,504] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:29:10,505] {logging_mixin.py:112} INFO - [2020-07-22 17:29:10,505] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:29:10,522] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:29:10,666] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:29:10,944] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:44:00+00:00: scheduled__2020-07-20T07:44:00+00:00, externally triggered: False>
[2020-07-22 17:29:10,947] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:43:00+00:00: scheduled__2020-07-20T07:43:00+00:00, externally triggered: False>
[2020-07-22 17:29:10,955] {logging_mixin.py:112} INFO - [2020-07-22 17:29:10,955] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:43:00+00:00: scheduled__2020-07-20T07:43:00+00:00, externally triggered: False> successful
[2020-07-22 17:29:11,065] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:44:00+00:00: scheduled__2020-07-20T07:44:00+00:00, externally triggered: False>
[2020-07-22 17:29:11,084] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:29:11,088] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:44:00+00:00 [scheduled]> in ORM
[2020-07-22 17:29:11,229] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.730 seconds
[2020-07-22 17:29:44,569] {scheduler_job.py:153} INFO - Started process (PID=655763) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:29:44,578] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:29:44,579] {logging_mixin.py:112} INFO - [2020-07-22 17:29:44,579] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:29:44,606] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:29:44,821] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:29:45,215] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:45:00+00:00: scheduled__2020-07-20T07:45:00+00:00, externally triggered: False>
[2020-07-22 17:29:45,222] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:44:00+00:00: scheduled__2020-07-20T07:44:00+00:00, externally triggered: False>
[2020-07-22 17:29:45,242] {logging_mixin.py:112} INFO - [2020-07-22 17:29:45,242] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:44:00+00:00: scheduled__2020-07-20T07:44:00+00:00, externally triggered: False> successful
[2020-07-22 17:29:45,344] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:45:00+00:00: scheduled__2020-07-20T07:45:00+00:00, externally triggered: False>
[2020-07-22 17:29:45,359] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:29:45,364] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:45:00+00:00 [scheduled]> in ORM
[2020-07-22 17:29:45,510] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.941 seconds
[2020-07-22 17:30:24,414] {scheduler_job.py:153} INFO - Started process (PID=656633) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:30:24,421] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:30:24,422] {logging_mixin.py:112} INFO - [2020-07-22 17:30:24,422] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:30:24,442] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:30:24,560] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:30:24,876] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:46:00+00:00: scheduled__2020-07-20T07:46:00+00:00, externally triggered: False>
[2020-07-22 17:30:24,881] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:45:00+00:00: scheduled__2020-07-20T07:45:00+00:00, externally triggered: False>
[2020-07-22 17:30:24,895] {logging_mixin.py:112} INFO - [2020-07-22 17:30:24,895] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:45:00+00:00: scheduled__2020-07-20T07:45:00+00:00, externally triggered: False> successful
[2020-07-22 17:30:25,001] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:46:00+00:00: scheduled__2020-07-20T07:46:00+00:00, externally triggered: False>
[2020-07-22 17:30:25,015] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:30:25,020] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:46:00+00:00 [scheduled]> in ORM
[2020-07-22 17:30:25,168] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.754 seconds
[2020-07-22 17:31:10,140] {scheduler_job.py:153} INFO - Started process (PID=657624) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:31:10,150] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:31:10,157] {logging_mixin.py:112} INFO - [2020-07-22 17:31:10,156] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:31:10,230] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:31:10,591] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:31:11,084] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:47:00+00:00: scheduled__2020-07-20T07:47:00+00:00, externally triggered: False>
[2020-07-22 17:31:11,101] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:46:00+00:00: scheduled__2020-07-20T07:46:00+00:00, externally triggered: False>
[2020-07-22 17:31:11,118] {logging_mixin.py:112} INFO - [2020-07-22 17:31:11,118] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:46:00+00:00: scheduled__2020-07-20T07:46:00+00:00, externally triggered: False> successful
[2020-07-22 17:31:11,211] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:47:00+00:00: scheduled__2020-07-20T07:47:00+00:00, externally triggered: False>
[2020-07-22 17:31:11,294] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:31:11,320] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:47:00+00:00 [scheduled]> in ORM
[2020-07-22 17:31:11,540] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.400 seconds
[2020-07-22 17:31:48,213] {scheduler_job.py:153} INFO - Started process (PID=658435) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:31:48,216] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:31:48,216] {logging_mixin.py:112} INFO - [2020-07-22 17:31:48,216] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:31:48,226] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:31:48,383] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:31:48,673] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:48:00+00:00: scheduled__2020-07-20T07:48:00+00:00, externally triggered: False>
[2020-07-22 17:31:48,677] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:47:00+00:00: scheduled__2020-07-20T07:47:00+00:00, externally triggered: False>
[2020-07-22 17:31:48,684] {logging_mixin.py:112} INFO - [2020-07-22 17:31:48,684] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:47:00+00:00: scheduled__2020-07-20T07:47:00+00:00, externally triggered: False> successful
[2020-07-22 17:31:48,787] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:48:00+00:00: scheduled__2020-07-20T07:48:00+00:00, externally triggered: False>
[2020-07-22 17:31:48,806] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:31:48,813] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:48:00+00:00 [scheduled]> in ORM
[2020-07-22 17:31:48,952] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.739 seconds
[2020-07-22 17:32:34,365] {scheduler_job.py:153} INFO - Started process (PID=659461) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:32:34,369] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:32:34,369] {logging_mixin.py:112} INFO - [2020-07-22 17:32:34,369] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:32:34,378] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:32:34,574] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:32:34,957] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:49:00+00:00: scheduled__2020-07-20T07:49:00+00:00, externally triggered: False>
[2020-07-22 17:32:34,963] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:48:00+00:00: scheduled__2020-07-20T07:48:00+00:00, externally triggered: False>
[2020-07-22 17:32:34,970] {logging_mixin.py:112} INFO - [2020-07-22 17:32:34,970] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:48:00+00:00: scheduled__2020-07-20T07:48:00+00:00, externally triggered: False> successful
[2020-07-22 17:32:35,097] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:49:00+00:00: scheduled__2020-07-20T07:49:00+00:00, externally triggered: False>
[2020-07-22 17:32:35,120] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:32:35,126] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:49:00+00:00 [scheduled]> in ORM
[2020-07-22 17:32:35,298] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.934 seconds
[2020-07-22 17:33:20,713] {scheduler_job.py:153} INFO - Started process (PID=660409) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:33:20,716] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:33:20,717] {logging_mixin.py:112} INFO - [2020-07-22 17:33:20,717] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:33:20,731] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:33:20,859] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:33:21,212] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:50:00+00:00: scheduled__2020-07-20T07:50:00+00:00, externally triggered: False>
[2020-07-22 17:33:21,218] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:49:00+00:00: scheduled__2020-07-20T07:49:00+00:00, externally triggered: False>
[2020-07-22 17:33:21,232] {logging_mixin.py:112} INFO - [2020-07-22 17:33:21,231] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:49:00+00:00: scheduled__2020-07-20T07:49:00+00:00, externally triggered: False> successful
[2020-07-22 17:33:21,407] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:50:00+00:00: scheduled__2020-07-20T07:50:00+00:00, externally triggered: False>
[2020-07-22 17:33:21,438] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:33:21,447] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:50:00+00:00 [scheduled]> in ORM
[2020-07-22 17:33:21,711] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.999 seconds
[2020-07-22 17:34:02,427] {scheduler_job.py:153} INFO - Started process (PID=661281) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:34:02,430] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:34:02,431] {logging_mixin.py:112} INFO - [2020-07-22 17:34:02,431] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:34:02,441] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:34:02,553] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:34:02,911] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:51:00+00:00: scheduled__2020-07-20T07:51:00+00:00, externally triggered: False>
[2020-07-22 17:34:02,914] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:50:00+00:00: scheduled__2020-07-20T07:50:00+00:00, externally triggered: False>
[2020-07-22 17:34:02,922] {logging_mixin.py:112} INFO - [2020-07-22 17:34:02,922] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:50:00+00:00: scheduled__2020-07-20T07:50:00+00:00, externally triggered: False> successful
[2020-07-22 17:34:03,028] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:51:00+00:00: scheduled__2020-07-20T07:51:00+00:00, externally triggered: False>
[2020-07-22 17:34:03,045] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:34:03,049] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:51:00+00:00 [scheduled]> in ORM
[2020-07-22 17:34:03,195] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.768 seconds
[2020-07-22 17:34:47,467] {scheduler_job.py:153} INFO - Started process (PID=662241) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:34:47,471] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:34:47,472] {logging_mixin.py:112} INFO - [2020-07-22 17:34:47,472] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:34:47,482] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:34:47,603] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:34:48,004] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:52:00+00:00: scheduled__2020-07-20T07:52:00+00:00, externally triggered: False>
[2020-07-22 17:34:48,010] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:51:00+00:00: scheduled__2020-07-20T07:51:00+00:00, externally triggered: False>
[2020-07-22 17:34:48,025] {logging_mixin.py:112} INFO - [2020-07-22 17:34:48,025] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:51:00+00:00: scheduled__2020-07-20T07:51:00+00:00, externally triggered: False> successful
[2020-07-22 17:34:48,204] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:52:00+00:00: scheduled__2020-07-20T07:52:00+00:00, externally triggered: False>
[2020-07-22 17:34:48,223] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:34:48,226] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:52:00+00:00 [scheduled]> in ORM
[2020-07-22 17:34:48,371] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.904 seconds
[2020-07-22 17:35:27,235] {scheduler_job.py:153} INFO - Started process (PID=663105) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:35:27,238] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:35:27,239] {logging_mixin.py:112} INFO - [2020-07-22 17:35:27,239] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:35:27,250] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:35:27,399] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:35:27,671] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:53:00+00:00: scheduled__2020-07-20T07:53:00+00:00, externally triggered: False>
[2020-07-22 17:35:27,676] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:52:00+00:00: scheduled__2020-07-20T07:52:00+00:00, externally triggered: False>
[2020-07-22 17:35:27,684] {logging_mixin.py:112} INFO - [2020-07-22 17:35:27,684] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:52:00+00:00: scheduled__2020-07-20T07:52:00+00:00, externally triggered: False> successful
[2020-07-22 17:35:27,826] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:53:00+00:00: scheduled__2020-07-20T07:53:00+00:00, externally triggered: False>
[2020-07-22 17:35:27,839] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:35:27,844] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:53:00+00:00 [scheduled]> in ORM
[2020-07-22 17:35:27,990] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.755 seconds
[2020-07-22 17:36:07,297] {scheduler_job.py:153} INFO - Started process (PID=663953) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:36:07,300] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:36:07,301] {logging_mixin.py:112} INFO - [2020-07-22 17:36:07,301] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:36:07,313] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:36:07,519] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:36:07,821] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:54:00+00:00: scheduled__2020-07-20T07:54:00+00:00, externally triggered: False>
[2020-07-22 17:36:07,825] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:53:00+00:00: scheduled__2020-07-20T07:53:00+00:00, externally triggered: False>
[2020-07-22 17:36:07,832] {logging_mixin.py:112} INFO - [2020-07-22 17:36:07,832] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:53:00+00:00: scheduled__2020-07-20T07:53:00+00:00, externally triggered: False> successful
[2020-07-22 17:36:07,937] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:54:00+00:00: scheduled__2020-07-20T07:54:00+00:00, externally triggered: False>
[2020-07-22 17:36:07,956] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:36:07,960] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:54:00+00:00 [scheduled]> in ORM
[2020-07-22 17:36:08,105] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.808 seconds
[2020-07-22 17:36:47,766] {scheduler_job.py:153} INFO - Started process (PID=664838) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:36:47,771] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:36:47,772] {logging_mixin.py:112} INFO - [2020-07-22 17:36:47,771] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:36:47,781] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:36:47,924] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:36:48,245] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:55:00+00:00: scheduled__2020-07-20T07:55:00+00:00, externally triggered: False>
[2020-07-22 17:36:48,248] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:54:00+00:00: scheduled__2020-07-20T07:54:00+00:00, externally triggered: False>
[2020-07-22 17:36:48,256] {logging_mixin.py:112} INFO - [2020-07-22 17:36:48,256] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:54:00+00:00: scheduled__2020-07-20T07:54:00+00:00, externally triggered: False> successful
[2020-07-22 17:36:48,359] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:55:00+00:00: scheduled__2020-07-20T07:55:00+00:00, externally triggered: False>
[2020-07-22 17:36:48,379] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:36:48,383] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:55:00+00:00 [scheduled]> in ORM
[2020-07-22 17:36:48,516] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.750 seconds
[2020-07-22 17:37:32,795] {scheduler_job.py:153} INFO - Started process (PID=665741) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:37:32,800] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:37:32,801] {logging_mixin.py:112} INFO - [2020-07-22 17:37:32,800] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:37:32,816] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:37:32,997] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:37:33,275] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:56:00+00:00: scheduled__2020-07-20T07:56:00+00:00, externally triggered: False>
[2020-07-22 17:37:33,279] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:55:00+00:00: scheduled__2020-07-20T07:55:00+00:00, externally triggered: False>
[2020-07-22 17:37:33,286] {logging_mixin.py:112} INFO - [2020-07-22 17:37:33,285] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:55:00+00:00: scheduled__2020-07-20T07:55:00+00:00, externally triggered: False> successful
[2020-07-22 17:37:33,380] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:56:00+00:00: scheduled__2020-07-20T07:56:00+00:00, externally triggered: False>
[2020-07-22 17:37:33,398] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:37:33,402] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:56:00+00:00 [scheduled]> in ORM
[2020-07-22 17:37:33,559] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.764 seconds
[2020-07-22 17:38:13,018] {scheduler_job.py:153} INFO - Started process (PID=666590) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:38:13,023] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:38:13,023] {logging_mixin.py:112} INFO - [2020-07-22 17:38:13,023] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:38:13,036] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:38:13,188] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:38:13,464] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:57:00+00:00: scheduled__2020-07-20T07:57:00+00:00, externally triggered: False>
[2020-07-22 17:38:13,470] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:56:00+00:00: scheduled__2020-07-20T07:56:00+00:00, externally triggered: False>
[2020-07-22 17:38:13,483] {logging_mixin.py:112} INFO - [2020-07-22 17:38:13,482] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:56:00+00:00: scheduled__2020-07-20T07:56:00+00:00, externally triggered: False> successful
[2020-07-22 17:38:13,647] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:57:00+00:00: scheduled__2020-07-20T07:57:00+00:00, externally triggered: False>
[2020-07-22 17:38:13,665] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:38:13,669] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:57:00+00:00 [scheduled]> in ORM
[2020-07-22 17:38:13,804] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.785 seconds
[2020-07-22 17:38:53,683] {scheduler_job.py:153} INFO - Started process (PID=667473) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:38:53,689] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:38:53,690] {logging_mixin.py:112} INFO - [2020-07-22 17:38:53,690] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:38:53,700] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:38:53,833] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:38:54,154] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:58:00+00:00: scheduled__2020-07-20T07:58:00+00:00, externally triggered: False>
[2020-07-22 17:38:54,157] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:57:00+00:00: scheduled__2020-07-20T07:57:00+00:00, externally triggered: False>
[2020-07-22 17:38:54,165] {logging_mixin.py:112} INFO - [2020-07-22 17:38:54,165] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:57:00+00:00: scheduled__2020-07-20T07:57:00+00:00, externally triggered: False> successful
[2020-07-22 17:38:54,258] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:58:00+00:00: scheduled__2020-07-20T07:58:00+00:00, externally triggered: False>
[2020-07-22 17:38:54,274] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:38:54,279] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:58:00+00:00 [scheduled]> in ORM
[2020-07-22 17:38:54,436] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.753 seconds
[2020-07-22 17:39:33,796] {scheduler_job.py:153} INFO - Started process (PID=668324) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:39:33,800] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:39:33,800] {logging_mixin.py:112} INFO - [2020-07-22 17:39:33,800] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:39:33,809] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:39:34,014] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:39:34,331] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T07:59:00+00:00: scheduled__2020-07-20T07:59:00+00:00, externally triggered: False>
[2020-07-22 17:39:34,339] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:58:00+00:00: scheduled__2020-07-20T07:58:00+00:00, externally triggered: False>
[2020-07-22 17:39:34,348] {logging_mixin.py:112} INFO - [2020-07-22 17:39:34,348] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:58:00+00:00: scheduled__2020-07-20T07:58:00+00:00, externally triggered: False> successful
[2020-07-22 17:39:34,458] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:59:00+00:00: scheduled__2020-07-20T07:59:00+00:00, externally triggered: False>
[2020-07-22 17:39:34,477] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:39:34,481] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 07:59:00+00:00 [scheduled]> in ORM
[2020-07-22 17:39:34,636] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.840 seconds
[2020-07-22 17:40:13,693] {scheduler_job.py:153} INFO - Started process (PID=669171) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:40:13,696] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:40:13,696] {logging_mixin.py:112} INFO - [2020-07-22 17:40:13,696] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:40:13,706] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:40:13,831] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:40:14,209] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:00:00+00:00: scheduled__2020-07-20T08:00:00+00:00, externally triggered: False>
[2020-07-22 17:40:14,213] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 07:59:00+00:00: scheduled__2020-07-20T07:59:00+00:00, externally triggered: False>
[2020-07-22 17:40:14,221] {logging_mixin.py:112} INFO - [2020-07-22 17:40:14,220] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 07:59:00+00:00: scheduled__2020-07-20T07:59:00+00:00, externally triggered: False> successful
[2020-07-22 17:40:14,369] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:00:00+00:00: scheduled__2020-07-20T08:00:00+00:00, externally triggered: False>
[2020-07-22 17:40:14,388] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:40:14,392] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:00:00+00:00 [scheduled]> in ORM
[2020-07-22 17:40:14,534] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.841 seconds
[2020-07-22 17:40:47,987] {scheduler_job.py:153} INFO - Started process (PID=669942) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:40:47,990] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:40:47,990] {logging_mixin.py:112} INFO - [2020-07-22 17:40:47,990] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:40:47,999] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:40:48,211] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:40:48,521] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:01:00+00:00: scheduled__2020-07-20T08:01:00+00:00, externally triggered: False>
[2020-07-22 17:40:48,525] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:00:00+00:00: scheduled__2020-07-20T08:00:00+00:00, externally triggered: False>
[2020-07-22 17:40:48,532] {logging_mixin.py:112} INFO - [2020-07-22 17:40:48,532] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:00:00+00:00: scheduled__2020-07-20T08:00:00+00:00, externally triggered: False> successful
[2020-07-22 17:40:48,636] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:01:00+00:00: scheduled__2020-07-20T08:01:00+00:00, externally triggered: False>
[2020-07-22 17:40:48,653] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:40:48,657] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:01:00+00:00 [scheduled]> in ORM
[2020-07-22 17:40:48,801] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.814 seconds
[2020-07-22 17:41:22,725] {scheduler_job.py:153} INFO - Started process (PID=670747) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:41:22,729] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:41:22,730] {logging_mixin.py:112} INFO - [2020-07-22 17:41:22,730] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:41:22,752] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:41:22,878] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:41:23,221] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:02:00+00:00: scheduled__2020-07-20T08:02:00+00:00, externally triggered: False>
[2020-07-22 17:41:23,225] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:01:00+00:00: scheduled__2020-07-20T08:01:00+00:00, externally triggered: False>
[2020-07-22 17:41:23,232] {logging_mixin.py:112} INFO - [2020-07-22 17:41:23,232] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:01:00+00:00: scheduled__2020-07-20T08:01:00+00:00, externally triggered: False> successful
[2020-07-22 17:41:23,336] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:02:00+00:00: scheduled__2020-07-20T08:02:00+00:00, externally triggered: False>
[2020-07-22 17:41:23,354] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:41:23,358] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:02:00+00:00 [scheduled]> in ORM
[2020-07-22 17:41:23,503] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.779 seconds
[2020-07-22 17:41:56,834] {scheduler_job.py:153} INFO - Started process (PID=671476) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:41:56,839] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:41:56,839] {logging_mixin.py:112} INFO - [2020-07-22 17:41:56,839] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:41:56,848] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:41:56,962] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:41:57,329] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:03:00+00:00: scheduled__2020-07-20T08:03:00+00:00, externally triggered: False>
[2020-07-22 17:41:57,335] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:02:00+00:00: scheduled__2020-07-20T08:02:00+00:00, externally triggered: False>
[2020-07-22 17:41:57,348] {logging_mixin.py:112} INFO - [2020-07-22 17:41:57,347] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:02:00+00:00: scheduled__2020-07-20T08:02:00+00:00, externally triggered: False> successful
[2020-07-22 17:41:57,503] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:03:00+00:00: scheduled__2020-07-20T08:03:00+00:00, externally triggered: False>
[2020-07-22 17:41:57,523] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:41:57,530] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:03:00+00:00 [scheduled]> in ORM
[2020-07-22 17:41:57,679] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.845 seconds
[2020-07-22 17:42:33,221] {scheduler_job.py:153} INFO - Started process (PID=672278) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:42:33,225] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:42:33,226] {logging_mixin.py:112} INFO - [2020-07-22 17:42:33,225] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:42:33,240] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:42:33,358] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:42:33,651] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:04:00+00:00: scheduled__2020-07-20T08:04:00+00:00, externally triggered: False>
[2020-07-22 17:42:33,656] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:03:00+00:00: scheduled__2020-07-20T08:03:00+00:00, externally triggered: False>
[2020-07-22 17:42:33,667] {logging_mixin.py:112} INFO - [2020-07-22 17:42:33,667] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:03:00+00:00: scheduled__2020-07-20T08:03:00+00:00, externally triggered: False> successful
[2020-07-22 17:42:33,763] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:04:00+00:00: scheduled__2020-07-20T08:04:00+00:00, externally triggered: False>
[2020-07-22 17:42:33,792] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:42:33,802] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:04:00+00:00 [scheduled]> in ORM
[2020-07-22 17:42:33,990] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.769 seconds
[2020-07-22 17:43:13,745] {scheduler_job.py:153} INFO - Started process (PID=673100) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:43:13,748] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:43:13,749] {logging_mixin.py:112} INFO - [2020-07-22 17:43:13,749] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:43:13,765] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:43:13,890] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:43:14,258] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:05:00+00:00: scheduled__2020-07-20T08:05:00+00:00, externally triggered: False>
[2020-07-22 17:43:14,262] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:04:00+00:00: scheduled__2020-07-20T08:04:00+00:00, externally triggered: False>
[2020-07-22 17:43:14,270] {logging_mixin.py:112} INFO - [2020-07-22 17:43:14,269] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:04:00+00:00: scheduled__2020-07-20T08:04:00+00:00, externally triggered: False> successful
[2020-07-22 17:43:14,371] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:05:00+00:00: scheduled__2020-07-20T08:05:00+00:00, externally triggered: False>
[2020-07-22 17:43:14,389] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:43:14,393] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:05:00+00:00 [scheduled]> in ORM
[2020-07-22 17:43:14,524] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.779 seconds
[2020-07-22 17:43:53,990] {scheduler_job.py:153} INFO - Started process (PID=673941) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:43:53,994] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:43:53,994] {logging_mixin.py:112} INFO - [2020-07-22 17:43:53,994] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:43:54,004] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:43:54,151] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:43:54,495] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:06:00+00:00: scheduled__2020-07-20T08:06:00+00:00, externally triggered: False>
[2020-07-22 17:43:54,499] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:05:00+00:00: scheduled__2020-07-20T08:05:00+00:00, externally triggered: False>
[2020-07-22 17:43:54,508] {logging_mixin.py:112} INFO - [2020-07-22 17:43:54,508] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:05:00+00:00: scheduled__2020-07-20T08:05:00+00:00, externally triggered: False> successful
[2020-07-22 17:43:54,638] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:06:00+00:00: scheduled__2020-07-20T08:06:00+00:00, externally triggered: False>
[2020-07-22 17:43:54,658] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:43:54,661] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:06:00+00:00 [scheduled]> in ORM
[2020-07-22 17:43:54,804] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.814 seconds
[2020-07-22 17:44:34,567] {scheduler_job.py:153} INFO - Started process (PID=674825) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:44:34,571] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:44:34,572] {logging_mixin.py:112} INFO - [2020-07-22 17:44:34,572] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:44:34,584] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:44:34,734] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:44:35,062] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:07:00+00:00: scheduled__2020-07-20T08:07:00+00:00, externally triggered: False>
[2020-07-22 17:44:35,066] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:06:00+00:00: scheduled__2020-07-20T08:06:00+00:00, externally triggered: False>
[2020-07-22 17:44:35,078] {logging_mixin.py:112} INFO - [2020-07-22 17:44:35,078] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:06:00+00:00: scheduled__2020-07-20T08:06:00+00:00, externally triggered: False> successful
[2020-07-22 17:44:35,172] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:07:00+00:00: scheduled__2020-07-20T08:07:00+00:00, externally triggered: False>
[2020-07-22 17:44:35,191] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:44:35,197] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:07:00+00:00 [scheduled]> in ORM
[2020-07-22 17:44:35,361] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.794 seconds
[2020-07-22 17:45:14,361] {scheduler_job.py:153} INFO - Started process (PID=675673) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:45:14,366] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:45:14,366] {logging_mixin.py:112} INFO - [2020-07-22 17:45:14,366] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:45:14,376] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:45:14,537] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:45:14,891] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:08:00+00:00: scheduled__2020-07-20T08:08:00+00:00, externally triggered: False>
[2020-07-22 17:45:14,894] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:07:00+00:00: scheduled__2020-07-20T08:07:00+00:00, externally triggered: False>
[2020-07-22 17:45:14,903] {logging_mixin.py:112} INFO - [2020-07-22 17:45:14,902] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:07:00+00:00: scheduled__2020-07-20T08:07:00+00:00, externally triggered: False> successful
[2020-07-22 17:45:15,006] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:08:00+00:00: scheduled__2020-07-20T08:08:00+00:00, externally triggered: False>
[2020-07-22 17:45:15,025] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:45:15,029] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:08:00+00:00 [scheduled]> in ORM
[2020-07-22 17:45:15,172] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.811 seconds
[2020-07-22 17:45:59,339] {scheduler_job.py:153} INFO - Started process (PID=676593) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:45:59,346] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:45:59,347] {logging_mixin.py:112} INFO - [2020-07-22 17:45:59,347] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:45:59,370] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:45:59,543] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:46:00,474] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:09:00+00:00: scheduled__2020-07-20T08:09:00+00:00, externally triggered: False>
[2020-07-22 17:46:00,478] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:08:00+00:00: scheduled__2020-07-20T08:08:00+00:00, externally triggered: False>
[2020-07-22 17:46:00,486] {logging_mixin.py:112} INFO - [2020-07-22 17:46:00,486] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:08:00+00:00: scheduled__2020-07-20T08:08:00+00:00, externally triggered: False> successful
[2020-07-22 17:46:00,595] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:09:00+00:00: scheduled__2020-07-20T08:09:00+00:00, externally triggered: False>
[2020-07-22 17:46:00,610] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:46:00,614] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:09:00+00:00 [scheduled]> in ORM
[2020-07-22 17:46:00,775] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.436 seconds
[2020-07-22 17:46:45,342] {scheduler_job.py:153} INFO - Started process (PID=677546) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:46:45,345] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:46:45,345] {logging_mixin.py:112} INFO - [2020-07-22 17:46:45,345] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:46:45,355] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:46:45,453] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:46:45,858] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:10:00+00:00: scheduled__2020-07-20T08:10:00+00:00, externally triggered: False>
[2020-07-22 17:46:45,865] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:09:00+00:00: scheduled__2020-07-20T08:09:00+00:00, externally triggered: False>
[2020-07-22 17:46:45,877] {logging_mixin.py:112} INFO - [2020-07-22 17:46:45,877] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:09:00+00:00: scheduled__2020-07-20T08:09:00+00:00, externally triggered: False> successful
[2020-07-22 17:46:45,986] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:10:00+00:00: scheduled__2020-07-20T08:10:00+00:00, externally triggered: False>
[2020-07-22 17:46:46,011] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:46:46,021] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:10:00+00:00 [scheduled]> in ORM
[2020-07-22 17:46:46,165] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.823 seconds
[2020-07-22 17:47:30,562] {scheduler_job.py:153} INFO - Started process (PID=678458) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:47:30,567] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:47:30,567] {logging_mixin.py:112} INFO - [2020-07-22 17:47:30,567] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:47:30,577] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:47:30,727] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:47:31,199] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:11:00+00:00: scheduled__2020-07-20T08:11:00+00:00, externally triggered: False>
[2020-07-22 17:47:31,203] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:10:00+00:00: scheduled__2020-07-20T08:10:00+00:00, externally triggered: False>
[2020-07-22 17:47:31,210] {logging_mixin.py:112} INFO - [2020-07-22 17:47:31,210] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:10:00+00:00: scheduled__2020-07-20T08:10:00+00:00, externally triggered: False> successful
[2020-07-22 17:47:31,320] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:11:00+00:00: scheduled__2020-07-20T08:11:00+00:00, externally triggered: False>
[2020-07-22 17:47:31,339] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:47:31,342] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:11:00+00:00 [scheduled]> in ORM
[2020-07-22 17:47:31,475] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.913 seconds
[2020-07-22 17:48:11,174] {scheduler_job.py:153} INFO - Started process (PID=679338) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:48:11,179] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:48:11,180] {logging_mixin.py:112} INFO - [2020-07-22 17:48:11,180] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:48:11,189] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:48:11,317] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:48:11,591] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:12:00+00:00: scheduled__2020-07-20T08:12:00+00:00, externally triggered: False>
[2020-07-22 17:48:11,597] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:11:00+00:00: scheduled__2020-07-20T08:11:00+00:00, externally triggered: False>
[2020-07-22 17:48:11,610] {logging_mixin.py:112} INFO - [2020-07-22 17:48:11,610] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:11:00+00:00: scheduled__2020-07-20T08:11:00+00:00, externally triggered: False> successful
[2020-07-22 17:48:11,743] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:12:00+00:00: scheduled__2020-07-20T08:12:00+00:00, externally triggered: False>
[2020-07-22 17:48:11,761] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:48:11,765] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:12:00+00:00 [scheduled]> in ORM
[2020-07-22 17:48:11,906] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.733 seconds
[2020-07-22 17:48:50,734] {scheduler_job.py:153} INFO - Started process (PID=680182) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:48:50,737] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:48:50,737] {logging_mixin.py:112} INFO - [2020-07-22 17:48:50,737] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:48:50,747] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:48:50,896] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:48:51,184] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:13:00+00:00: scheduled__2020-07-20T08:13:00+00:00, externally triggered: False>
[2020-07-22 17:48:51,188] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:12:00+00:00: scheduled__2020-07-20T08:12:00+00:00, externally triggered: False>
[2020-07-22 17:48:51,197] {logging_mixin.py:112} INFO - [2020-07-22 17:48:51,196] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:12:00+00:00: scheduled__2020-07-20T08:12:00+00:00, externally triggered: False> successful
[2020-07-22 17:48:51,332] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:13:00+00:00: scheduled__2020-07-20T08:13:00+00:00, externally triggered: False>
[2020-07-22 17:48:51,354] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:48:51,361] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:13:00+00:00 [scheduled]> in ORM
[2020-07-22 17:48:51,553] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.819 seconds
[2020-07-22 17:49:36,718] {scheduler_job.py:153} INFO - Started process (PID=681126) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:49:36,723] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:49:36,724] {logging_mixin.py:112} INFO - [2020-07-22 17:49:36,724] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:49:36,741] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:49:36,897] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:49:37,216] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:14:00+00:00: scheduled__2020-07-20T08:14:00+00:00, externally triggered: False>
[2020-07-22 17:49:37,226] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:13:00+00:00: scheduled__2020-07-20T08:13:00+00:00, externally triggered: False>
[2020-07-22 17:49:37,246] {logging_mixin.py:112} INFO - [2020-07-22 17:49:37,246] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:13:00+00:00: scheduled__2020-07-20T08:13:00+00:00, externally triggered: False> successful
[2020-07-22 17:49:37,368] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:14:00+00:00: scheduled__2020-07-20T08:14:00+00:00, externally triggered: False>
[2020-07-22 17:49:37,391] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:49:37,397] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:14:00+00:00 [scheduled]> in ORM
[2020-07-22 17:49:37,556] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.838 seconds
[2020-07-22 17:50:16,541] {scheduler_job.py:153} INFO - Started process (PID=681976) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:50:16,546] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:50:16,546] {logging_mixin.py:112} INFO - [2020-07-22 17:50:16,546] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:50:16,557] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:50:16,705] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:50:17,007] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:15:00+00:00: scheduled__2020-07-20T08:15:00+00:00, externally triggered: False>
[2020-07-22 17:50:17,012] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:14:00+00:00: scheduled__2020-07-20T08:14:00+00:00, externally triggered: False>
[2020-07-22 17:50:17,027] {logging_mixin.py:112} INFO - [2020-07-22 17:50:17,027] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:14:00+00:00: scheduled__2020-07-20T08:14:00+00:00, externally triggered: False> successful
[2020-07-22 17:50:17,179] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:15:00+00:00: scheduled__2020-07-20T08:15:00+00:00, externally triggered: False>
[2020-07-22 17:50:17,199] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:50:17,203] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:15:00+00:00 [scheduled]> in ORM
[2020-07-22 17:50:17,357] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.815 seconds
[2020-07-22 17:50:56,243] {scheduler_job.py:153} INFO - Started process (PID=682826) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:50:56,247] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:50:56,247] {logging_mixin.py:112} INFO - [2020-07-22 17:50:56,247] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:50:56,258] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:50:56,462] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:50:56,754] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:16:00+00:00: scheduled__2020-07-20T08:16:00+00:00, externally triggered: False>
[2020-07-22 17:50:56,758] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:15:00+00:00: scheduled__2020-07-20T08:15:00+00:00, externally triggered: False>
[2020-07-22 17:50:56,766] {logging_mixin.py:112} INFO - [2020-07-22 17:50:56,766] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:15:00+00:00: scheduled__2020-07-20T08:15:00+00:00, externally triggered: False> successful
[2020-07-22 17:50:56,868] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:16:00+00:00: scheduled__2020-07-20T08:16:00+00:00, externally triggered: False>
[2020-07-22 17:50:56,888] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:50:56,892] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:16:00+00:00 [scheduled]> in ORM
[2020-07-22 17:50:57,036] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.793 seconds
[2020-07-22 17:51:31,000] {scheduler_job.py:153} INFO - Started process (PID=683634) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:51:31,006] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:51:31,006] {logging_mixin.py:112} INFO - [2020-07-22 17:51:31,006] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:51:31,016] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:51:31,133] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:51:31,443] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:17:00+00:00: scheduled__2020-07-20T08:17:00+00:00, externally triggered: False>
[2020-07-22 17:51:31,448] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:16:00+00:00: scheduled__2020-07-20T08:16:00+00:00, externally triggered: False>
[2020-07-22 17:51:31,456] {logging_mixin.py:112} INFO - [2020-07-22 17:51:31,455] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:16:00+00:00: scheduled__2020-07-20T08:16:00+00:00, externally triggered: False> successful
[2020-07-22 17:51:31,558] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:17:00+00:00: scheduled__2020-07-20T08:17:00+00:00, externally triggered: False>
[2020-07-22 17:51:31,578] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:51:31,583] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:17:00+00:00 [scheduled]> in ORM
[2020-07-22 17:51:31,725] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.725 seconds
[2020-07-22 17:52:10,649] {scheduler_job.py:153} INFO - Started process (PID=684505) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:52:10,652] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:52:10,652] {logging_mixin.py:112} INFO - [2020-07-22 17:52:10,652] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:52:10,662] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:52:10,772] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:52:11,110] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:18:00+00:00: scheduled__2020-07-20T08:18:00+00:00, externally triggered: False>
[2020-07-22 17:52:11,116] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:17:00+00:00: scheduled__2020-07-20T08:17:00+00:00, externally triggered: False>
[2020-07-22 17:52:11,123] {logging_mixin.py:112} INFO - [2020-07-22 17:52:11,123] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:17:00+00:00: scheduled__2020-07-20T08:17:00+00:00, externally triggered: False> successful
[2020-07-22 17:52:11,237] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:18:00+00:00: scheduled__2020-07-20T08:18:00+00:00, externally triggered: False>
[2020-07-22 17:52:11,256] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:52:11,260] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:18:00+00:00 [scheduled]> in ORM
[2020-07-22 17:52:11,415] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.767 seconds
[2020-07-22 17:52:45,626] {scheduler_job.py:153} INFO - Started process (PID=685269) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:52:45,631] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:52:45,631] {logging_mixin.py:112} INFO - [2020-07-22 17:52:45,631] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:52:45,646] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:52:45,872] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:52:46,276] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:19:00+00:00: scheduled__2020-07-20T08:19:00+00:00, externally triggered: False>
[2020-07-22 17:52:46,281] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:18:00+00:00: scheduled__2020-07-20T08:18:00+00:00, externally triggered: False>
[2020-07-22 17:52:46,301] {logging_mixin.py:112} INFO - [2020-07-22 17:52:46,301] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:18:00+00:00: scheduled__2020-07-20T08:18:00+00:00, externally triggered: False> successful
[2020-07-22 17:52:46,448] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:19:00+00:00: scheduled__2020-07-20T08:19:00+00:00, externally triggered: False>
[2020-07-22 17:52:46,471] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:52:46,478] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:19:00+00:00 [scheduled]> in ORM
[2020-07-22 17:52:46,625] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.000 seconds
[2020-07-22 17:53:21,440] {scheduler_job.py:153} INFO - Started process (PID=686046) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:53:21,444] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:53:21,444] {logging_mixin.py:112} INFO - [2020-07-22 17:53:21,444] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:53:21,455] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:53:21,575] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:53:22,014] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:20:00+00:00: scheduled__2020-07-20T08:20:00+00:00, externally triggered: False>
[2020-07-22 17:53:22,020] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:19:00+00:00: scheduled__2020-07-20T08:19:00+00:00, externally triggered: False>
[2020-07-22 17:53:22,042] {logging_mixin.py:112} INFO - [2020-07-22 17:53:22,041] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:19:00+00:00: scheduled__2020-07-20T08:19:00+00:00, externally triggered: False> successful
[2020-07-22 17:53:22,149] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:20:00+00:00: scheduled__2020-07-20T08:20:00+00:00, externally triggered: False>
[2020-07-22 17:53:22,197] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:53:22,207] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:20:00+00:00 [scheduled]> in ORM
[2020-07-22 17:53:22,361] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.921 seconds
[2020-07-22 17:54:01,931] {scheduler_job.py:153} INFO - Started process (PID=686884) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:54:01,937] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:54:01,938] {logging_mixin.py:112} INFO - [2020-07-22 17:54:01,938] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:54:01,951] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:54:02,074] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:54:02,355] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:21:00+00:00: scheduled__2020-07-20T08:21:00+00:00, externally triggered: False>
[2020-07-22 17:54:02,361] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:20:00+00:00: scheduled__2020-07-20T08:20:00+00:00, externally triggered: False>
[2020-07-22 17:54:02,374] {logging_mixin.py:112} INFO - [2020-07-22 17:54:02,374] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:20:00+00:00: scheduled__2020-07-20T08:20:00+00:00, externally triggered: False> successful
[2020-07-22 17:54:02,540] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:21:00+00:00: scheduled__2020-07-20T08:21:00+00:00, externally triggered: False>
[2020-07-22 17:54:02,563] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:54:02,569] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:21:00+00:00 [scheduled]> in ORM
[2020-07-22 17:54:02,770] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.839 seconds
[2020-07-22 17:54:42,793] {scheduler_job.py:153} INFO - Started process (PID=687743) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:54:42,797] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:54:42,798] {logging_mixin.py:112} INFO - [2020-07-22 17:54:42,797] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:54:42,807] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:54:42,951] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:54:43,382] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:22:00+00:00: scheduled__2020-07-20T08:22:00+00:00, externally triggered: False>
[2020-07-22 17:54:43,388] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:21:00+00:00: scheduled__2020-07-20T08:21:00+00:00, externally triggered: False>
[2020-07-22 17:54:43,395] {logging_mixin.py:112} INFO - [2020-07-22 17:54:43,395] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:21:00+00:00: scheduled__2020-07-20T08:21:00+00:00, externally triggered: False> successful
[2020-07-22 17:54:43,507] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:22:00+00:00: scheduled__2020-07-20T08:22:00+00:00, externally triggered: False>
[2020-07-22 17:54:43,527] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:54:43,532] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:22:00+00:00 [scheduled]> in ORM
[2020-07-22 17:54:43,675] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.882 seconds
[2020-07-22 17:55:27,900] {scheduler_job.py:153} INFO - Started process (PID=688699) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:55:27,903] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:55:27,904] {logging_mixin.py:112} INFO - [2020-07-22 17:55:27,904] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:55:27,914] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:55:28,038] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:55:28,348] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:23:00+00:00: scheduled__2020-07-20T08:23:00+00:00, externally triggered: False>
[2020-07-22 17:55:28,352] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:22:00+00:00: scheduled__2020-07-20T08:22:00+00:00, externally triggered: False>
[2020-07-22 17:55:28,359] {logging_mixin.py:112} INFO - [2020-07-22 17:55:28,359] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:22:00+00:00: scheduled__2020-07-20T08:22:00+00:00, externally triggered: False> successful
[2020-07-22 17:55:28,686] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:23:00+00:00: scheduled__2020-07-20T08:23:00+00:00, externally triggered: False>
[2020-07-22 17:55:28,705] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:55:28,710] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:23:00+00:00 [scheduled]> in ORM
[2020-07-22 17:55:28,957] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.057 seconds
[2020-07-22 17:56:13,143] {scheduler_job.py:153} INFO - Started process (PID=689710) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:56:13,146] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:56:13,147] {logging_mixin.py:112} INFO - [2020-07-22 17:56:13,147] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:56:13,157] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:56:13,404] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:56:14,403] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:24:00+00:00: scheduled__2020-07-20T08:24:00+00:00, externally triggered: False>
[2020-07-22 17:56:14,412] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:23:00+00:00: scheduled__2020-07-20T08:23:00+00:00, externally triggered: False>
[2020-07-22 17:56:14,426] {logging_mixin.py:112} INFO - [2020-07-22 17:56:14,425] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:23:00+00:00: scheduled__2020-07-20T08:23:00+00:00, externally triggered: False> successful
[2020-07-22 17:56:14,754] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:24:00+00:00: scheduled__2020-07-20T08:24:00+00:00, externally triggered: False>
[2020-07-22 17:56:14,782] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:56:14,795] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:24:00+00:00 [scheduled]> in ORM
[2020-07-22 17:56:15,226] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.083 seconds
[2020-07-22 17:56:48,768] {scheduler_job.py:153} INFO - Started process (PID=690479) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:56:48,772] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:56:48,772] {logging_mixin.py:112} INFO - [2020-07-22 17:56:48,772] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:56:48,782] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:56:48,995] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:56:49,629] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:25:00+00:00: scheduled__2020-07-20T08:25:00+00:00, externally triggered: False>
[2020-07-22 17:56:49,633] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:24:00+00:00: scheduled__2020-07-20T08:24:00+00:00, externally triggered: False>
[2020-07-22 17:56:49,640] {logging_mixin.py:112} INFO - [2020-07-22 17:56:49,640] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:24:00+00:00: scheduled__2020-07-20T08:24:00+00:00, externally triggered: False> successful
[2020-07-22 17:56:49,877] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:25:00+00:00: scheduled__2020-07-20T08:25:00+00:00, externally triggered: False>
[2020-07-22 17:56:49,896] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:56:49,900] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:25:00+00:00 [scheduled]> in ORM
[2020-07-22 17:56:50,100] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.332 seconds
[2020-07-22 17:57:23,838] {scheduler_job.py:153} INFO - Started process (PID=691225) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:57:23,842] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:57:23,843] {logging_mixin.py:112} INFO - [2020-07-22 17:57:23,842] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:57:23,853] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:57:23,983] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:57:24,342] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:26:00+00:00: scheduled__2020-07-20T08:26:00+00:00, externally triggered: False>
[2020-07-22 17:57:24,346] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:25:00+00:00: scheduled__2020-07-20T08:25:00+00:00, externally triggered: False>
[2020-07-22 17:57:24,354] {logging_mixin.py:112} INFO - [2020-07-22 17:57:24,354] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:25:00+00:00: scheduled__2020-07-20T08:25:00+00:00, externally triggered: False> successful
[2020-07-22 17:57:24,490] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:26:00+00:00: scheduled__2020-07-20T08:26:00+00:00, externally triggered: False>
[2020-07-22 17:57:24,507] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:57:24,511] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:26:00+00:00 [scheduled]> in ORM
[2020-07-22 17:57:24,667] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.829 seconds
[2020-07-22 17:57:59,175] {scheduler_job.py:153} INFO - Started process (PID=691940) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:57:59,178] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:57:59,178] {logging_mixin.py:112} INFO - [2020-07-22 17:57:59,178] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:57:59,188] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:57:59,377] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:57:59,859] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:27:00+00:00: scheduled__2020-07-20T08:27:00+00:00, externally triggered: False>
[2020-07-22 17:57:59,863] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:26:00+00:00: scheduled__2020-07-20T08:26:00+00:00, externally triggered: False>
[2020-07-22 17:57:59,870] {logging_mixin.py:112} INFO - [2020-07-22 17:57:59,870] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:26:00+00:00: scheduled__2020-07-20T08:26:00+00:00, externally triggered: False> successful
[2020-07-22 17:57:59,979] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:27:00+00:00: scheduled__2020-07-20T08:27:00+00:00, externally triggered: False>
[2020-07-22 17:58:00,000] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:58:00,005] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:27:00+00:00 [scheduled]> in ORM
[2020-07-22 17:58:00,146] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.971 seconds
[2020-07-22 17:58:33,390] {scheduler_job.py:153} INFO - Started process (PID=692631) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:58:33,394] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:58:33,395] {logging_mixin.py:112} INFO - [2020-07-22 17:58:33,395] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:58:33,407] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:58:33,547] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:58:34,047] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:28:00+00:00: scheduled__2020-07-20T08:28:00+00:00, externally triggered: False>
[2020-07-22 17:58:34,056] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:27:00+00:00: scheduled__2020-07-20T08:27:00+00:00, externally triggered: False>
[2020-07-22 17:58:34,073] {logging_mixin.py:112} INFO - [2020-07-22 17:58:34,073] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:27:00+00:00: scheduled__2020-07-20T08:27:00+00:00, externally triggered: False> successful
[2020-07-22 17:58:34,291] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:28:00+00:00: scheduled__2020-07-20T08:28:00+00:00, externally triggered: False>
[2020-07-22 17:58:34,323] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:58:34,330] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:28:00+00:00 [scheduled]> in ORM
[2020-07-22 17:58:34,471] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.081 seconds
[2020-07-22 17:59:19,354] {scheduler_job.py:153} INFO - Started process (PID=693536) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:59:19,357] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:59:19,358] {logging_mixin.py:112} INFO - [2020-07-22 17:59:19,357] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:59:19,368] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:59:19,530] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:59:19,904] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:29:00+00:00: scheduled__2020-07-20T08:29:00+00:00, externally triggered: False>
[2020-07-22 17:59:19,910] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:28:00+00:00: scheduled__2020-07-20T08:28:00+00:00, externally triggered: False>
[2020-07-22 17:59:19,918] {logging_mixin.py:112} INFO - [2020-07-22 17:59:19,918] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:28:00+00:00: scheduled__2020-07-20T08:28:00+00:00, externally triggered: False> successful
[2020-07-22 17:59:20,071] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:29:00+00:00: scheduled__2020-07-20T08:29:00+00:00, externally triggered: False>
[2020-07-22 17:59:20,089] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:59:20,093] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:29:00+00:00 [scheduled]> in ORM
[2020-07-22 17:59:20,226] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.872 seconds
[2020-07-22 17:59:54,284] {scheduler_job.py:153} INFO - Started process (PID=694266) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:59:54,287] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 17:59:54,288] {logging_mixin.py:112} INFO - [2020-07-22 17:59:54,288] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:59:54,298] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 17:59:54,418] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 17:59:54,735] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:30:00+00:00: scheduled__2020-07-20T08:30:00+00:00, externally triggered: False>
[2020-07-22 17:59:54,740] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:29:00+00:00: scheduled__2020-07-20T08:29:00+00:00, externally triggered: False>
[2020-07-22 17:59:54,747] {logging_mixin.py:112} INFO - [2020-07-22 17:59:54,747] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:29:00+00:00: scheduled__2020-07-20T08:29:00+00:00, externally triggered: False> successful
[2020-07-22 17:59:54,894] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:30:00+00:00: scheduled__2020-07-20T08:30:00+00:00, externally triggered: False>
[2020-07-22 17:59:54,912] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 17:59:54,916] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:30:00+00:00 [scheduled]> in ORM
[2020-07-22 17:59:55,061] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.776 seconds
[2020-07-22 18:00:29,082] {scheduler_job.py:153} INFO - Started process (PID=695020) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:00:29,086] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:00:29,087] {logging_mixin.py:112} INFO - [2020-07-22 18:00:29,087] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:00:29,098] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:00:29,319] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:00:29,672] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:31:00+00:00: scheduled__2020-07-20T08:31:00+00:00, externally triggered: False>
[2020-07-22 18:00:29,676] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:30:00+00:00: scheduled__2020-07-20T08:30:00+00:00, externally triggered: False>
[2020-07-22 18:00:29,691] {logging_mixin.py:112} INFO - [2020-07-22 18:00:29,691] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:30:00+00:00: scheduled__2020-07-20T08:30:00+00:00, externally triggered: False> successful
[2020-07-22 18:00:29,806] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:31:00+00:00: scheduled__2020-07-20T08:31:00+00:00, externally triggered: False>
[2020-07-22 18:00:29,868] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:00:29,875] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:31:00+00:00 [scheduled]> in ORM
[2020-07-22 18:00:30,319] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.237 seconds
[2020-07-22 18:01:10,756] {scheduler_job.py:153} INFO - Started process (PID=695884) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:01:10,759] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:01:10,760] {logging_mixin.py:112} INFO - [2020-07-22 18:01:10,760] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:01:10,770] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:01:10,925] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:01:11,414] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:32:00+00:00: scheduled__2020-07-20T08:32:00+00:00, externally triggered: False>
[2020-07-22 18:01:11,420] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:31:00+00:00: scheduled__2020-07-20T08:31:00+00:00, externally triggered: False>
[2020-07-22 18:01:11,433] {logging_mixin.py:112} INFO - [2020-07-22 18:01:11,433] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:31:00+00:00: scheduled__2020-07-20T08:31:00+00:00, externally triggered: False> successful
[2020-07-22 18:01:11,674] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:32:00+00:00: scheduled__2020-07-20T08:32:00+00:00, externally triggered: False>
[2020-07-22 18:01:11,701] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:01:11,706] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:32:00+00:00 [scheduled]> in ORM
[2020-07-22 18:01:11,889] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.134 seconds
[2020-07-22 18:01:45,213] {scheduler_job.py:153} INFO - Started process (PID=696628) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:01:45,216] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:01:45,216] {logging_mixin.py:112} INFO - [2020-07-22 18:01:45,216] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:01:45,226] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:01:45,384] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:01:45,702] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:33:00+00:00: scheduled__2020-07-20T08:33:00+00:00, externally triggered: False>
[2020-07-22 18:01:45,706] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:32:00+00:00: scheduled__2020-07-20T08:32:00+00:00, externally triggered: False>
[2020-07-22 18:01:45,715] {logging_mixin.py:112} INFO - [2020-07-22 18:01:45,714] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:32:00+00:00: scheduled__2020-07-20T08:32:00+00:00, externally triggered: False> successful
[2020-07-22 18:01:45,808] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:33:00+00:00: scheduled__2020-07-20T08:33:00+00:00, externally triggered: False>
[2020-07-22 18:01:45,824] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:01:45,828] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:33:00+00:00 [scheduled]> in ORM
[2020-07-22 18:01:45,975] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.762 seconds
[2020-07-22 18:02:25,640] {scheduler_job.py:153} INFO - Started process (PID=697454) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:02:25,644] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:02:25,645] {logging_mixin.py:112} INFO - [2020-07-22 18:02:25,644] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:02:25,660] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:02:25,849] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:02:26,259] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:34:00+00:00: scheduled__2020-07-20T08:34:00+00:00, externally triggered: False>
[2020-07-22 18:02:26,264] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:33:00+00:00: scheduled__2020-07-20T08:33:00+00:00, externally triggered: False>
[2020-07-22 18:02:26,272] {logging_mixin.py:112} INFO - [2020-07-22 18:02:26,272] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:33:00+00:00: scheduled__2020-07-20T08:33:00+00:00, externally triggered: False> successful
[2020-07-22 18:02:26,364] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:34:00+00:00: scheduled__2020-07-20T08:34:00+00:00, externally triggered: False>
[2020-07-22 18:02:26,380] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:02:26,385] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:34:00+00:00 [scheduled]> in ORM
[2020-07-22 18:02:26,521] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.880 seconds
[2020-07-22 18:03:05,505] {scheduler_job.py:153} INFO - Started process (PID=699130) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:03:05,511] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:03:05,512] {logging_mixin.py:112} INFO - [2020-07-22 18:03:05,512] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:03:05,528] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:03:05,813] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:03:06,216] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:35:00+00:00: scheduled__2020-07-20T08:35:00+00:00, externally triggered: False>
[2020-07-22 18:03:06,222] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:34:00+00:00: scheduled__2020-07-20T08:34:00+00:00, externally triggered: False>
[2020-07-22 18:03:06,234] {logging_mixin.py:112} INFO - [2020-07-22 18:03:06,234] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:34:00+00:00: scheduled__2020-07-20T08:34:00+00:00, externally triggered: False> successful
[2020-07-22 18:03:06,377] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:35:00+00:00: scheduled__2020-07-20T08:35:00+00:00, externally triggered: False>
[2020-07-22 18:03:06,425] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:03:06,443] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:35:00+00:00 [scheduled]> in ORM
[2020-07-22 18:03:06,622] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.117 seconds
[2020-07-22 18:03:46,539] {scheduler_job.py:153} INFO - Started process (PID=699928) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:03:46,544] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:03:46,545] {logging_mixin.py:112} INFO - [2020-07-22 18:03:46,545] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:03:46,564] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:03:46,710] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:03:46,999] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:36:00+00:00: scheduled__2020-07-20T08:36:00+00:00, externally triggered: False>
[2020-07-22 18:03:47,005] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:35:00+00:00: scheduled__2020-07-20T08:35:00+00:00, externally triggered: False>
[2020-07-22 18:03:47,021] {logging_mixin.py:112} INFO - [2020-07-22 18:03:47,020] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:35:00+00:00: scheduled__2020-07-20T08:35:00+00:00, externally triggered: False> successful
[2020-07-22 18:03:47,190] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:36:00+00:00: scheduled__2020-07-20T08:36:00+00:00, externally triggered: False>
[2020-07-22 18:03:47,218] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:03:47,224] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:36:00+00:00 [scheduled]> in ORM
[2020-07-22 18:03:47,378] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.839 seconds
[2020-07-22 18:04:26,343] {scheduler_job.py:153} INFO - Started process (PID=700691) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:04:26,347] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:04:26,347] {logging_mixin.py:112} INFO - [2020-07-22 18:04:26,347] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:04:26,358] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:04:26,475] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:04:26,750] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:37:00+00:00: scheduled__2020-07-20T08:37:00+00:00, externally triggered: False>
[2020-07-22 18:04:26,756] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:36:00+00:00: scheduled__2020-07-20T08:36:00+00:00, externally triggered: False>
[2020-07-22 18:04:26,778] {logging_mixin.py:112} INFO - [2020-07-22 18:04:26,778] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:36:00+00:00: scheduled__2020-07-20T08:36:00+00:00, externally triggered: False> successful
[2020-07-22 18:04:26,879] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:37:00+00:00: scheduled__2020-07-20T08:37:00+00:00, externally triggered: False>
[2020-07-22 18:04:26,893] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:04:26,897] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:37:00+00:00 [scheduled]> in ORM
[2020-07-22 18:04:27,056] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.713 seconds
[2020-07-22 18:05:01,821] {scheduler_job.py:153} INFO - Started process (PID=701395) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:05:01,826] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:05:01,826] {logging_mixin.py:112} INFO - [2020-07-22 18:05:01,826] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:05:01,835] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:05:02,032] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:05:02,405] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:38:00+00:00: scheduled__2020-07-20T08:38:00+00:00, externally triggered: False>
[2020-07-22 18:05:02,410] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:37:00+00:00: scheduled__2020-07-20T08:37:00+00:00, externally triggered: False>
[2020-07-22 18:05:02,424] {logging_mixin.py:112} INFO - [2020-07-22 18:05:02,424] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:37:00+00:00: scheduled__2020-07-20T08:37:00+00:00, externally triggered: False> successful
[2020-07-22 18:05:03,459] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:38:00+00:00: scheduled__2020-07-20T08:38:00+00:00, externally triggered: False>
[2020-07-22 18:05:03,472] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:05:03,479] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:38:00+00:00 [scheduled]> in ORM
[2020-07-22 18:05:03,626] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.806 seconds
[2020-07-22 18:05:36,166] {scheduler_job.py:153} INFO - Started process (PID=702128) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:05:36,170] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:05:36,170] {logging_mixin.py:112} INFO - [2020-07-22 18:05:36,170] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:05:36,179] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:05:36,293] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:05:36,557] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:39:00+00:00: scheduled__2020-07-20T08:39:00+00:00, externally triggered: False>
[2020-07-22 18:05:36,561] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:38:00+00:00: scheduled__2020-07-20T08:38:00+00:00, externally triggered: False>
[2020-07-22 18:05:36,570] {logging_mixin.py:112} INFO - [2020-07-22 18:05:36,570] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:38:00+00:00: scheduled__2020-07-20T08:38:00+00:00, externally triggered: False> successful
[2020-07-22 18:05:36,662] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:39:00+00:00: scheduled__2020-07-20T08:39:00+00:00, externally triggered: False>
[2020-07-22 18:05:36,679] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:05:36,683] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:39:00+00:00 [scheduled]> in ORM
[2020-07-22 18:05:36,815] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.649 seconds
[2020-07-22 18:06:10,661] {scheduler_job.py:153} INFO - Started process (PID=702826) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:06:10,665] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:06:10,666] {logging_mixin.py:112} INFO - [2020-07-22 18:06:10,665] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:06:10,675] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:06:10,797] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:06:11,093] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:40:00+00:00: scheduled__2020-07-20T08:40:00+00:00, externally triggered: False>
[2020-07-22 18:06:11,099] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:39:00+00:00: scheduled__2020-07-20T08:39:00+00:00, externally triggered: False>
[2020-07-22 18:06:11,106] {logging_mixin.py:112} INFO - [2020-07-22 18:06:11,106] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:39:00+00:00: scheduled__2020-07-20T08:39:00+00:00, externally triggered: False> successful
[2020-07-22 18:06:11,232] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:40:00+00:00: scheduled__2020-07-20T08:40:00+00:00, externally triggered: False>
[2020-07-22 18:06:11,262] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:06:11,270] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:40:00+00:00 [scheduled]> in ORM
[2020-07-22 18:06:11,487] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.826 seconds
[2020-07-22 18:07:07,166] {scheduler_job.py:153} INFO - Started process (PID=703952) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:07:07,175] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:07:07,175] {logging_mixin.py:112} INFO - [2020-07-22 18:07:07,175] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:07:07,202] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:07:07,583] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:07:07,887] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:41:00+00:00: scheduled__2020-07-20T08:41:00+00:00, externally triggered: False>
[2020-07-22 18:07:07,892] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:40:00+00:00: scheduled__2020-07-20T08:40:00+00:00, externally triggered: False>
[2020-07-22 18:07:07,899] {logging_mixin.py:112} INFO - [2020-07-22 18:07:07,899] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:40:00+00:00: scheduled__2020-07-20T08:40:00+00:00, externally triggered: False> successful
[2020-07-22 18:07:08,024] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:41:00+00:00: scheduled__2020-07-20T08:41:00+00:00, externally triggered: False>
[2020-07-22 18:07:08,045] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:07:08,053] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:41:00+00:00 [scheduled]> in ORM
[2020-07-22 18:07:08,225] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.058 seconds
[2020-07-22 18:07:48,044] {scheduler_job.py:153} INFO - Started process (PID=704717) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:07:48,048] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:07:48,049] {logging_mixin.py:112} INFO - [2020-07-22 18:07:48,048] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:07:48,064] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:07:48,292] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:07:48,589] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:42:00+00:00: scheduled__2020-07-20T08:42:00+00:00, externally triggered: False>
[2020-07-22 18:07:48,593] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:41:00+00:00: scheduled__2020-07-20T08:41:00+00:00, externally triggered: False>
[2020-07-22 18:07:48,600] {logging_mixin.py:112} INFO - [2020-07-22 18:07:48,600] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:41:00+00:00: scheduled__2020-07-20T08:41:00+00:00, externally triggered: False> successful
[2020-07-22 18:07:48,705] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:42:00+00:00: scheduled__2020-07-20T08:42:00+00:00, externally triggered: False>
[2020-07-22 18:07:48,722] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:07:48,728] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:42:00+00:00 [scheduled]> in ORM
[2020-07-22 18:07:48,960] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.916 seconds
[2020-07-22 18:08:27,764] {scheduler_job.py:153} INFO - Started process (PID=706155) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:08:27,768] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:08:27,769] {logging_mixin.py:112} INFO - [2020-07-22 18:08:27,769] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:08:27,784] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:08:27,918] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:08:28,212] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:43:00+00:00: scheduled__2020-07-20T08:43:00+00:00, externally triggered: False>
[2020-07-22 18:08:28,218] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:42:00+00:00: scheduled__2020-07-20T08:42:00+00:00, externally triggered: False>
[2020-07-22 18:08:28,225] {logging_mixin.py:112} INFO - [2020-07-22 18:08:28,225] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:42:00+00:00: scheduled__2020-07-20T08:42:00+00:00, externally triggered: False> successful
[2020-07-22 18:08:28,363] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:43:00+00:00: scheduled__2020-07-20T08:43:00+00:00, externally triggered: False>
[2020-07-22 18:08:28,390] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:08:28,397] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:43:00+00:00 [scheduled]> in ORM
[2020-07-22 18:08:28,578] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.814 seconds
[2020-07-22 18:09:02,708] {scheduler_job.py:153} INFO - Started process (PID=706829) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:09:02,711] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:09:02,711] {logging_mixin.py:112} INFO - [2020-07-22 18:09:02,711] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:09:02,721] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:09:02,871] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:09:03,193] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:44:00+00:00: scheduled__2020-07-20T08:44:00+00:00, externally triggered: False>
[2020-07-22 18:09:03,198] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:43:00+00:00: scheduled__2020-07-20T08:43:00+00:00, externally triggered: False>
[2020-07-22 18:09:03,207] {logging_mixin.py:112} INFO - [2020-07-22 18:09:03,206] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:43:00+00:00: scheduled__2020-07-20T08:43:00+00:00, externally triggered: False> successful
[2020-07-22 18:09:03,343] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:44:00+00:00: scheduled__2020-07-20T08:44:00+00:00, externally triggered: False>
[2020-07-22 18:09:03,363] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:09:03,367] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:44:00+00:00 [scheduled]> in ORM
[2020-07-22 18:09:03,543] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.836 seconds
[2020-07-22 18:09:42,555] {scheduler_job.py:153} INFO - Started process (PID=707564) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:09:42,558] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:09:42,558] {logging_mixin.py:112} INFO - [2020-07-22 18:09:42,558] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:09:42,568] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:09:42,721] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:09:43,013] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:45:00+00:00: scheduled__2020-07-20T08:45:00+00:00, externally triggered: False>
[2020-07-22 18:09:43,017] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:44:00+00:00: scheduled__2020-07-20T08:44:00+00:00, externally triggered: False>
[2020-07-22 18:09:43,026] {logging_mixin.py:112} INFO - [2020-07-22 18:09:43,026] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:44:00+00:00: scheduled__2020-07-20T08:44:00+00:00, externally triggered: False> successful
[2020-07-22 18:09:43,646] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:45:00+00:00: scheduled__2020-07-20T08:45:00+00:00, externally triggered: False>
[2020-07-22 18:09:43,700] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:09:43,705] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:45:00+00:00 [scheduled]> in ORM
[2020-07-22 18:09:44,000] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.445 seconds
[2020-07-22 18:10:16,907] {scheduler_job.py:153} INFO - Started process (PID=708263) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:10:16,910] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:10:16,910] {logging_mixin.py:112} INFO - [2020-07-22 18:10:16,910] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:10:16,922] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:10:17,077] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:10:17,510] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:46:00+00:00: scheduled__2020-07-20T08:46:00+00:00, externally triggered: False>
[2020-07-22 18:10:17,517] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:45:00+00:00: scheduled__2020-07-20T08:45:00+00:00, externally triggered: False>
[2020-07-22 18:10:17,531] {logging_mixin.py:112} INFO - [2020-07-22 18:10:17,531] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:45:00+00:00: scheduled__2020-07-20T08:45:00+00:00, externally triggered: False> successful
[2020-07-22 18:10:17,726] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:46:00+00:00: scheduled__2020-07-20T08:46:00+00:00, externally triggered: False>
[2020-07-22 18:10:17,743] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:10:17,747] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:46:00+00:00 [scheduled]> in ORM
[2020-07-22 18:10:17,915] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.009 seconds
[2020-07-22 18:10:51,192] {scheduler_job.py:153} INFO - Started process (PID=708964) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:10:51,196] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:10:51,197] {logging_mixin.py:112} INFO - [2020-07-22 18:10:51,197] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:10:51,206] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:10:51,357] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:10:51,701] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:47:00+00:00: scheduled__2020-07-20T08:47:00+00:00, externally triggered: False>
[2020-07-22 18:10:51,705] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:46:00+00:00: scheduled__2020-07-20T08:46:00+00:00, externally triggered: False>
[2020-07-22 18:10:51,712] {logging_mixin.py:112} INFO - [2020-07-22 18:10:51,712] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:46:00+00:00: scheduled__2020-07-20T08:46:00+00:00, externally triggered: False> successful
[2020-07-22 18:10:51,838] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:47:00+00:00: scheduled__2020-07-20T08:47:00+00:00, externally triggered: False>
[2020-07-22 18:10:51,857] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:10:51,861] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:47:00+00:00 [scheduled]> in ORM
[2020-07-22 18:10:52,017] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.825 seconds
[2020-07-22 18:11:25,891] {scheduler_job.py:153} INFO - Started process (PID=709678) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:11:25,894] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:11:25,895] {logging_mixin.py:112} INFO - [2020-07-22 18:11:25,894] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:11:25,904] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:11:26,076] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:11:26,419] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:48:00+00:00: scheduled__2020-07-20T08:48:00+00:00, externally triggered: False>
[2020-07-22 18:11:26,423] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:47:00+00:00: scheduled__2020-07-20T08:47:00+00:00, externally triggered: False>
[2020-07-22 18:11:26,431] {logging_mixin.py:112} INFO - [2020-07-22 18:11:26,431] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:47:00+00:00: scheduled__2020-07-20T08:47:00+00:00, externally triggered: False> successful
[2020-07-22 18:11:26,585] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:48:00+00:00: scheduled__2020-07-20T08:48:00+00:00, externally triggered: False>
[2020-07-22 18:11:26,609] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:11:26,621] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:48:00+00:00 [scheduled]> in ORM
[2020-07-22 18:11:26,849] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.958 seconds
[2020-07-22 18:12:04,108] {scheduler_job.py:153} INFO - Started process (PID=710460) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:12:04,111] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:12:04,111] {logging_mixin.py:112} INFO - [2020-07-22 18:12:04,111] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:12:04,120] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:12:04,390] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:12:04,725] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:49:00+00:00: scheduled__2020-07-20T08:49:00+00:00, externally triggered: False>
[2020-07-22 18:12:04,732] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:48:00+00:00: scheduled__2020-07-20T08:48:00+00:00, externally triggered: False>
[2020-07-22 18:12:04,739] {logging_mixin.py:112} INFO - [2020-07-22 18:12:04,738] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:48:00+00:00: scheduled__2020-07-20T08:48:00+00:00, externally triggered: False> successful
[2020-07-22 18:12:04,865] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:49:00+00:00: scheduled__2020-07-20T08:49:00+00:00, externally triggered: False>
[2020-07-22 18:12:04,883] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:12:04,886] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:49:00+00:00 [scheduled]> in ORM
[2020-07-22 18:12:05,118] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.010 seconds
[2020-07-22 18:12:39,349] {scheduler_job.py:153} INFO - Started process (PID=711440) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:12:39,353] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:12:39,353] {logging_mixin.py:112} INFO - [2020-07-22 18:12:39,353] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:12:39,364] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:12:39,518] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:12:39,862] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:50:00+00:00: scheduled__2020-07-20T08:50:00+00:00, externally triggered: False>
[2020-07-22 18:12:39,868] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:49:00+00:00: scheduled__2020-07-20T08:49:00+00:00, externally triggered: False>
[2020-07-22 18:12:39,886] {logging_mixin.py:112} INFO - [2020-07-22 18:12:39,885] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:49:00+00:00: scheduled__2020-07-20T08:49:00+00:00, externally triggered: False> successful
[2020-07-22 18:12:40,044] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:50:00+00:00: scheduled__2020-07-20T08:50:00+00:00, externally triggered: False>
[2020-07-22 18:12:40,058] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:12:40,062] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:50:00+00:00 [scheduled]> in ORM
[2020-07-22 18:12:40,222] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.873 seconds
[2020-07-22 18:13:19,437] {scheduler_job.py:153} INFO - Started process (PID=712761) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:13:19,440] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:13:19,441] {logging_mixin.py:112} INFO - [2020-07-22 18:13:19,441] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:13:19,451] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:13:19,622] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:13:19,953] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:51:00+00:00: scheduled__2020-07-20T08:51:00+00:00, externally triggered: False>
[2020-07-22 18:13:19,957] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:50:00+00:00: scheduled__2020-07-20T08:50:00+00:00, externally triggered: False>
[2020-07-22 18:13:19,964] {logging_mixin.py:112} INFO - [2020-07-22 18:13:19,964] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:50:00+00:00: scheduled__2020-07-20T08:50:00+00:00, externally triggered: False> successful
[2020-07-22 18:13:20,102] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:51:00+00:00: scheduled__2020-07-20T08:51:00+00:00, externally triggered: False>
[2020-07-22 18:13:20,121] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:13:20,124] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:51:00+00:00 [scheduled]> in ORM
[2020-07-22 18:13:20,269] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.833 seconds
[2020-07-22 18:13:54,291] {scheduler_job.py:153} INFO - Started process (PID=713468) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:13:54,294] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:13:54,294] {logging_mixin.py:112} INFO - [2020-07-22 18:13:54,294] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:13:54,304] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:13:54,591] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:13:54,885] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:52:00+00:00: scheduled__2020-07-20T08:52:00+00:00, externally triggered: False>
[2020-07-22 18:13:54,890] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:51:00+00:00: scheduled__2020-07-20T08:51:00+00:00, externally triggered: False>
[2020-07-22 18:13:54,901] {logging_mixin.py:112} INFO - [2020-07-22 18:13:54,901] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:51:00+00:00: scheduled__2020-07-20T08:51:00+00:00, externally triggered: False> successful
[2020-07-22 18:13:55,082] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:52:00+00:00: scheduled__2020-07-20T08:52:00+00:00, externally triggered: False>
[2020-07-22 18:13:55,105] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:13:55,114] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:52:00+00:00 [scheduled]> in ORM
[2020-07-22 18:13:55,292] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.001 seconds
[2020-07-22 18:14:28,958] {scheduler_job.py:153} INFO - Started process (PID=714196) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:14:28,963] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:14:28,963] {logging_mixin.py:112} INFO - [2020-07-22 18:14:28,963] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:14:28,973] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:14:29,105] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:14:29,487] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:53:00+00:00: scheduled__2020-07-20T08:53:00+00:00, externally triggered: False>
[2020-07-22 18:14:29,491] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:52:00+00:00: scheduled__2020-07-20T08:52:00+00:00, externally triggered: False>
[2020-07-22 18:14:29,499] {logging_mixin.py:112} INFO - [2020-07-22 18:14:29,499] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:52:00+00:00: scheduled__2020-07-20T08:52:00+00:00, externally triggered: False> successful
[2020-07-22 18:14:29,706] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:53:00+00:00: scheduled__2020-07-20T08:53:00+00:00, externally triggered: False>
[2020-07-22 18:14:29,725] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:14:29,730] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:53:00+00:00 [scheduled]> in ORM
[2020-07-22 18:14:29,884] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.926 seconds
[2020-07-22 18:15:08,837] {scheduler_job.py:153} INFO - Started process (PID=715538) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:15:08,841] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:15:08,841] {logging_mixin.py:112} INFO - [2020-07-22 18:15:08,841] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:15:08,863] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:15:09,038] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:15:09,404] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:54:00+00:00: scheduled__2020-07-20T08:54:00+00:00, externally triggered: False>
[2020-07-22 18:15:09,407] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:53:00+00:00: scheduled__2020-07-20T08:53:00+00:00, externally triggered: False>
[2020-07-22 18:15:09,415] {logging_mixin.py:112} INFO - [2020-07-22 18:15:09,415] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:53:00+00:00: scheduled__2020-07-20T08:53:00+00:00, externally triggered: False> successful
[2020-07-22 18:15:09,553] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:54:00+00:00: scheduled__2020-07-20T08:54:00+00:00, externally triggered: False>
[2020-07-22 18:15:09,570] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:15:09,573] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:54:00+00:00 [scheduled]> in ORM
[2020-07-22 18:15:09,732] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.895 seconds
[2020-07-22 18:15:48,936] {scheduler_job.py:153} INFO - Started process (PID=716293) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:15:48,939] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:15:48,940] {logging_mixin.py:112} INFO - [2020-07-22 18:15:48,940] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:15:48,952] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:15:49,106] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:15:49,466] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:55:00+00:00: scheduled__2020-07-20T08:55:00+00:00, externally triggered: False>
[2020-07-22 18:15:49,471] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:54:00+00:00: scheduled__2020-07-20T08:54:00+00:00, externally triggered: False>
[2020-07-22 18:15:49,479] {logging_mixin.py:112} INFO - [2020-07-22 18:15:49,479] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:54:00+00:00: scheduled__2020-07-20T08:54:00+00:00, externally triggered: False> successful
[2020-07-22 18:15:49,610] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:55:00+00:00: scheduled__2020-07-20T08:55:00+00:00, externally triggered: False>
[2020-07-22 18:15:49,633] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:15:49,642] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:55:00+00:00 [scheduled]> in ORM
[2020-07-22 18:15:49,805] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.869 seconds
[2020-07-22 18:16:29,308] {scheduler_job.py:153} INFO - Started process (PID=717127) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:16:29,312] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:16:29,314] {logging_mixin.py:112} INFO - [2020-07-22 18:16:29,314] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:16:29,334] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:16:29,575] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:16:29,967] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:56:00+00:00: scheduled__2020-07-20T08:56:00+00:00, externally triggered: False>
[2020-07-22 18:16:29,972] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:55:00+00:00: scheduled__2020-07-20T08:55:00+00:00, externally triggered: False>
[2020-07-22 18:16:29,980] {logging_mixin.py:112} INFO - [2020-07-22 18:16:29,980] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:55:00+00:00: scheduled__2020-07-20T08:55:00+00:00, externally triggered: False> successful
[2020-07-22 18:16:30,113] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:56:00+00:00: scheduled__2020-07-20T08:56:00+00:00, externally triggered: False>
[2020-07-22 18:16:30,141] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:16:30,149] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:56:00+00:00 [scheduled]> in ORM
[2020-07-22 18:16:30,328] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.021 seconds
[2020-07-22 18:17:10,757] {scheduler_job.py:153} INFO - Started process (PID=717905) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:17:10,760] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:17:10,761] {logging_mixin.py:112} INFO - [2020-07-22 18:17:10,761] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:17:10,772] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:17:10,912] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:17:11,242] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:57:00+00:00: scheduled__2020-07-20T08:57:00+00:00, externally triggered: False>
[2020-07-22 18:17:11,247] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:56:00+00:00: scheduled__2020-07-20T08:56:00+00:00, externally triggered: False>
[2020-07-22 18:17:11,259] {logging_mixin.py:112} INFO - [2020-07-22 18:17:11,259] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:56:00+00:00: scheduled__2020-07-20T08:56:00+00:00, externally triggered: False> successful
[2020-07-22 18:17:11,447] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:57:00+00:00: scheduled__2020-07-20T08:57:00+00:00, externally triggered: False>
[2020-07-22 18:17:11,459] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:17:11,465] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:57:00+00:00 [scheduled]> in ORM
[2020-07-22 18:17:11,631] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.875 seconds
[2020-07-22 18:17:45,651] {scheduler_job.py:153} INFO - Started process (PID=718598) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:17:45,655] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:17:45,656] {logging_mixin.py:112} INFO - [2020-07-22 18:17:45,655] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:17:45,666] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:17:45,884] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:17:46,221] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:58:00+00:00: scheduled__2020-07-20T08:58:00+00:00, externally triggered: False>
[2020-07-22 18:17:46,225] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:57:00+00:00: scheduled__2020-07-20T08:57:00+00:00, externally triggered: False>
[2020-07-22 18:17:46,234] {logging_mixin.py:112} INFO - [2020-07-22 18:17:46,233] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:57:00+00:00: scheduled__2020-07-20T08:57:00+00:00, externally triggered: False> successful
[2020-07-22 18:17:46,371] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:58:00+00:00: scheduled__2020-07-20T08:58:00+00:00, externally triggered: False>
[2020-07-22 18:17:46,403] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:17:46,411] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:58:00+00:00 [scheduled]> in ORM
[2020-07-22 18:17:46,574] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.923 seconds
[2020-07-22 18:18:25,292] {scheduler_job.py:153} INFO - Started process (PID=719361) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:18:25,296] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:18:25,297] {logging_mixin.py:112} INFO - [2020-07-22 18:18:25,297] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:18:25,307] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:18:25,509] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:18:25,861] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T08:59:00+00:00: scheduled__2020-07-20T08:59:00+00:00, externally triggered: False>
[2020-07-22 18:18:25,865] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:58:00+00:00: scheduled__2020-07-20T08:58:00+00:00, externally triggered: False>
[2020-07-22 18:18:25,873] {logging_mixin.py:112} INFO - [2020-07-22 18:18:25,873] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:58:00+00:00: scheduled__2020-07-20T08:58:00+00:00, externally triggered: False> successful
[2020-07-22 18:18:26,018] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:59:00+00:00: scheduled__2020-07-20T08:59:00+00:00, externally triggered: False>
[2020-07-22 18:18:26,037] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:18:26,041] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 08:59:00+00:00 [scheduled]> in ORM
[2020-07-22 18:18:26,200] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.909 seconds
[2020-07-22 18:19:05,837] {scheduler_job.py:153} INFO - Started process (PID=720147) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:19:05,840] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:19:05,840] {logging_mixin.py:112} INFO - [2020-07-22 18:19:05,840] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:19:05,851] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:19:05,983] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:19:06,404] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:00:00+00:00: scheduled__2020-07-20T09:00:00+00:00, externally triggered: False>
[2020-07-22 18:19:06,409] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 08:59:00+00:00: scheduled__2020-07-20T08:59:00+00:00, externally triggered: False>
[2020-07-22 18:19:06,416] {logging_mixin.py:112} INFO - [2020-07-22 18:19:06,416] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 08:59:00+00:00: scheduled__2020-07-20T08:59:00+00:00, externally triggered: False> successful
[2020-07-22 18:19:06,575] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:00:00+00:00: scheduled__2020-07-20T09:00:00+00:00, externally triggered: False>
[2020-07-22 18:19:06,594] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:19:06,598] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:00:00+00:00 [scheduled]> in ORM
[2020-07-22 18:19:06,758] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.921 seconds
[2020-07-22 18:19:40,554] {scheduler_job.py:153} INFO - Started process (PID=720825) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:19:40,558] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:19:40,558] {logging_mixin.py:112} INFO - [2020-07-22 18:19:40,558] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:19:40,567] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:19:40,707] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:19:41,109] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:01:00+00:00: scheduled__2020-07-20T09:01:00+00:00, externally triggered: False>
[2020-07-22 18:19:41,115] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:00:00+00:00: scheduled__2020-07-20T09:00:00+00:00, externally triggered: False>
[2020-07-22 18:19:41,122] {logging_mixin.py:112} INFO - [2020-07-22 18:19:41,122] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:00:00+00:00: scheduled__2020-07-20T09:00:00+00:00, externally triggered: False> successful
[2020-07-22 18:19:41,265] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:01:00+00:00: scheduled__2020-07-20T09:01:00+00:00, externally triggered: False>
[2020-07-22 18:19:41,285] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:19:41,289] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:01:00+00:00 [scheduled]> in ORM
[2020-07-22 18:19:41,604] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.050 seconds
[2020-07-22 18:20:20,061] {scheduler_job.py:153} INFO - Started process (PID=721597) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:20:20,066] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:20:20,066] {logging_mixin.py:112} INFO - [2020-07-22 18:20:20,066] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:20:20,076] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:20:20,196] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:20:20,600] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:02:00+00:00: scheduled__2020-07-20T09:02:00+00:00, externally triggered: False>
[2020-07-22 18:20:20,604] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:01:00+00:00: scheduled__2020-07-20T09:01:00+00:00, externally triggered: False>
[2020-07-22 18:20:20,612] {logging_mixin.py:112} INFO - [2020-07-22 18:20:20,612] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:01:00+00:00: scheduled__2020-07-20T09:01:00+00:00, externally triggered: False> successful
[2020-07-22 18:20:20,756] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:02:00+00:00: scheduled__2020-07-20T09:02:00+00:00, externally triggered: False>
[2020-07-22 18:20:20,775] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:20:20,779] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:02:00+00:00 [scheduled]> in ORM
[2020-07-22 18:20:20,950] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.889 seconds
[2020-07-22 18:21:00,027] {scheduler_job.py:153} INFO - Started process (PID=722348) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:21:00,034] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:21:00,035] {logging_mixin.py:112} INFO - [2020-07-22 18:21:00,035] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:21:00,048] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:21:00,200] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:21:00,539] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:03:00+00:00: scheduled__2020-07-20T09:03:00+00:00, externally triggered: False>
[2020-07-22 18:21:00,543] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:02:00+00:00: scheduled__2020-07-20T09:02:00+00:00, externally triggered: False>
[2020-07-22 18:21:00,551] {logging_mixin.py:112} INFO - [2020-07-22 18:21:00,551] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:02:00+00:00: scheduled__2020-07-20T09:02:00+00:00, externally triggered: False> successful
[2020-07-22 18:21:00,691] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:03:00+00:00: scheduled__2020-07-20T09:03:00+00:00, externally triggered: False>
[2020-07-22 18:21:00,710] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:21:00,714] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:03:00+00:00 [scheduled]> in ORM
[2020-07-22 18:21:00,875] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.848 seconds
[2020-07-22 18:21:34,669] {scheduler_job.py:153} INFO - Started process (PID=723099) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:21:34,673] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:21:34,673] {logging_mixin.py:112} INFO - [2020-07-22 18:21:34,673] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:21:34,683] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:21:35,172] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:21:35,502] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:04:00+00:00: scheduled__2020-07-20T09:04:00+00:00, externally triggered: False>
[2020-07-22 18:21:35,508] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:03:00+00:00: scheduled__2020-07-20T09:03:00+00:00, externally triggered: False>
[2020-07-22 18:21:35,522] {logging_mixin.py:112} INFO - [2020-07-22 18:21:35,521] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:03:00+00:00: scheduled__2020-07-20T09:03:00+00:00, externally triggered: False> successful
[2020-07-22 18:21:35,704] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:04:00+00:00: scheduled__2020-07-20T09:04:00+00:00, externally triggered: False>
[2020-07-22 18:21:35,723] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:21:35,727] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:04:00+00:00 [scheduled]> in ORM
[2020-07-22 18:21:35,920] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.251 seconds
[2020-07-22 18:22:09,207] {scheduler_job.py:153} INFO - Started process (PID=723793) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:22:09,210] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:22:09,211] {logging_mixin.py:112} INFO - [2020-07-22 18:22:09,211] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:22:09,220] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:22:09,343] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:22:09,722] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:05:00+00:00: scheduled__2020-07-20T09:05:00+00:00, externally triggered: False>
[2020-07-22 18:22:09,726] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:04:00+00:00: scheduled__2020-07-20T09:04:00+00:00, externally triggered: False>
[2020-07-22 18:22:09,734] {logging_mixin.py:112} INFO - [2020-07-22 18:22:09,734] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:04:00+00:00: scheduled__2020-07-20T09:04:00+00:00, externally triggered: False> successful
[2020-07-22 18:22:09,861] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:05:00+00:00: scheduled__2020-07-20T09:05:00+00:00, externally triggered: False>
[2020-07-22 18:22:09,879] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:22:09,882] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:05:00+00:00 [scheduled]> in ORM
[2020-07-22 18:22:10,042] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.835 seconds
[2020-07-22 18:22:48,899] {scheduler_job.py:153} INFO - Started process (PID=724580) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:22:48,905] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:22:48,906] {logging_mixin.py:112} INFO - [2020-07-22 18:22:48,906] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:22:48,916] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:22:49,037] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:22:49,841] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:06:00+00:00: scheduled__2020-07-20T09:06:00+00:00, externally triggered: False>
[2020-07-22 18:22:49,846] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:05:00+00:00: scheduled__2020-07-20T09:05:00+00:00, externally triggered: False>
[2020-07-22 18:22:49,853] {logging_mixin.py:112} INFO - [2020-07-22 18:22:49,853] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:05:00+00:00: scheduled__2020-07-20T09:05:00+00:00, externally triggered: False> successful
[2020-07-22 18:22:50,310] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:06:00+00:00: scheduled__2020-07-20T09:06:00+00:00, externally triggered: False>
[2020-07-22 18:22:50,330] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:22:50,334] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:06:00+00:00 [scheduled]> in ORM
[2020-07-22 18:22:50,502] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.603 seconds
[2020-07-22 18:23:28,822] {scheduler_job.py:153} INFO - Started process (PID=725365) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:23:28,825] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:23:28,825] {logging_mixin.py:112} INFO - [2020-07-22 18:23:28,825] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:23:28,836] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:23:28,982] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:23:29,320] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:07:00+00:00: scheduled__2020-07-20T09:07:00+00:00, externally triggered: False>
[2020-07-22 18:23:29,326] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:06:00+00:00: scheduled__2020-07-20T09:06:00+00:00, externally triggered: False>
[2020-07-22 18:23:29,342] {logging_mixin.py:112} INFO - [2020-07-22 18:23:29,342] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:06:00+00:00: scheduled__2020-07-20T09:06:00+00:00, externally triggered: False> successful
[2020-07-22 18:23:29,553] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:07:00+00:00: scheduled__2020-07-20T09:07:00+00:00, externally triggered: False>
[2020-07-22 18:23:29,575] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:23:29,579] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:07:00+00:00 [scheduled]> in ORM
[2020-07-22 18:23:29,747] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.926 seconds
[2020-07-22 18:24:09,527] {scheduler_job.py:153} INFO - Started process (PID=726142) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:24:09,530] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:24:09,531] {logging_mixin.py:112} INFO - [2020-07-22 18:24:09,531] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:24:09,541] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:24:09,697] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:24:10,467] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:08:00+00:00: scheduled__2020-07-20T09:08:00+00:00, externally triggered: False>
[2020-07-22 18:24:10,470] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:07:00+00:00: scheduled__2020-07-20T09:07:00+00:00, externally triggered: False>
[2020-07-22 18:24:10,478] {logging_mixin.py:112} INFO - [2020-07-22 18:24:10,478] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:07:00+00:00: scheduled__2020-07-20T09:07:00+00:00, externally triggered: False> successful
[2020-07-22 18:24:10,610] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:08:00+00:00: scheduled__2020-07-20T09:08:00+00:00, externally triggered: False>
[2020-07-22 18:24:10,629] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:24:10,633] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:08:00+00:00 [scheduled]> in ORM
[2020-07-22 18:24:10,803] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.276 seconds
[2020-07-22 18:24:49,644] {scheduler_job.py:153} INFO - Started process (PID=726905) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:24:49,647] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:24:49,648] {logging_mixin.py:112} INFO - [2020-07-22 18:24:49,648] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:24:49,658] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:24:49,833] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:24:50,239] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:09:00+00:00: scheduled__2020-07-20T09:09:00+00:00, externally triggered: False>
[2020-07-22 18:24:50,243] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:08:00+00:00: scheduled__2020-07-20T09:08:00+00:00, externally triggered: False>
[2020-07-22 18:24:50,251] {logging_mixin.py:112} INFO - [2020-07-22 18:24:50,251] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:08:00+00:00: scheduled__2020-07-20T09:08:00+00:00, externally triggered: False> successful
[2020-07-22 18:24:50,379] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:09:00+00:00: scheduled__2020-07-20T09:09:00+00:00, externally triggered: False>
[2020-07-22 18:24:50,397] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:24:50,400] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:09:00+00:00 [scheduled]> in ORM
[2020-07-22 18:24:50,550] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.906 seconds
[2020-07-22 18:25:29,346] {scheduler_job.py:153} INFO - Started process (PID=727702) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:25:29,349] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:25:29,350] {logging_mixin.py:112} INFO - [2020-07-22 18:25:29,349] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:25:29,359] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:25:29,617] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:25:30,005] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:10:00+00:00: scheduled__2020-07-20T09:10:00+00:00, externally triggered: False>
[2020-07-22 18:25:30,009] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:09:00+00:00: scheduled__2020-07-20T09:09:00+00:00, externally triggered: False>
[2020-07-22 18:25:30,018] {logging_mixin.py:112} INFO - [2020-07-22 18:25:30,017] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:09:00+00:00: scheduled__2020-07-20T09:09:00+00:00, externally triggered: False> successful
[2020-07-22 18:25:30,158] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:10:00+00:00: scheduled__2020-07-20T09:10:00+00:00, externally triggered: False>
[2020-07-22 18:25:30,176] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:25:30,180] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:10:00+00:00 [scheduled]> in ORM
[2020-07-22 18:25:30,353] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.007 seconds
[2020-07-22 18:26:04,051] {scheduler_job.py:153} INFO - Started process (PID=728407) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:26:04,056] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:26:04,057] {logging_mixin.py:112} INFO - [2020-07-22 18:26:04,056] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:26:04,069] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:26:04,212] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:26:04,527] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:11:00+00:00: scheduled__2020-07-20T09:11:00+00:00, externally triggered: False>
[2020-07-22 18:26:04,532] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:10:00+00:00: scheduled__2020-07-20T09:10:00+00:00, externally triggered: False>
[2020-07-22 18:26:04,539] {logging_mixin.py:112} INFO - [2020-07-22 18:26:04,539] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:10:00+00:00: scheduled__2020-07-20T09:10:00+00:00, externally triggered: False> successful
[2020-07-22 18:26:04,659] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:11:00+00:00: scheduled__2020-07-20T09:11:00+00:00, externally triggered: False>
[2020-07-22 18:26:04,680] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:26:04,683] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:11:00+00:00 [scheduled]> in ORM
[2020-07-22 18:26:04,862] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.811 seconds
[2020-07-22 18:26:43,793] {scheduler_job.py:153} INFO - Started process (PID=729195) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:26:43,799] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:26:43,801] {logging_mixin.py:112} INFO - [2020-07-22 18:26:43,801] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:26:43,823] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:26:44,188] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:26:44,672] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:12:00+00:00: scheduled__2020-07-20T09:12:00+00:00, externally triggered: False>
[2020-07-22 18:26:44,690] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:11:00+00:00: scheduled__2020-07-20T09:11:00+00:00, externally triggered: False>
[2020-07-22 18:26:44,716] {logging_mixin.py:112} INFO - [2020-07-22 18:26:44,715] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:11:00+00:00: scheduled__2020-07-20T09:11:00+00:00, externally triggered: False> successful
[2020-07-22 18:26:44,917] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:12:00+00:00: scheduled__2020-07-20T09:12:00+00:00, externally triggered: False>
[2020-07-22 18:26:44,946] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:26:44,954] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:12:00+00:00 [scheduled]> in ORM
[2020-07-22 18:26:45,224] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.431 seconds
[2020-07-22 18:27:39,873] {scheduler_job.py:153} INFO - Started process (PID=730328) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:27:39,880] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:27:39,881] {logging_mixin.py:112} INFO - [2020-07-22 18:27:39,881] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:27:39,900] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:27:40,039] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:27:40,485] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:13:00+00:00: scheduled__2020-07-20T09:13:00+00:00, externally triggered: False>
[2020-07-22 18:27:40,490] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:12:00+00:00: scheduled__2020-07-20T09:12:00+00:00, externally triggered: False>
[2020-07-22 18:27:40,498] {logging_mixin.py:112} INFO - [2020-07-22 18:27:40,497] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:12:00+00:00: scheduled__2020-07-20T09:12:00+00:00, externally triggered: False> successful
[2020-07-22 18:27:40,631] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:13:00+00:00: scheduled__2020-07-20T09:13:00+00:00, externally triggered: False>
[2020-07-22 18:27:40,661] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:27:40,670] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:13:00+00:00 [scheduled]> in ORM
[2020-07-22 18:27:40,837] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.964 seconds
[2020-07-22 18:28:31,315] {scheduler_job.py:153} INFO - Started process (PID=731660) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:28:31,322] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:28:31,322] {logging_mixin.py:112} INFO - [2020-07-22 18:28:31,322] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:28:31,348] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:28:31,650] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:28:32,322] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:14:00+00:00: scheduled__2020-07-20T09:14:00+00:00, externally triggered: False>
[2020-07-22 18:28:32,333] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:13:00+00:00: scheduled__2020-07-20T09:13:00+00:00, externally triggered: False>
[2020-07-22 18:28:32,359] {logging_mixin.py:112} INFO - [2020-07-22 18:28:32,359] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:13:00+00:00: scheduled__2020-07-20T09:13:00+00:00, externally triggered: False> successful
[2020-07-22 18:28:32,521] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:14:00+00:00: scheduled__2020-07-20T09:14:00+00:00, externally triggered: False>
[2020-07-22 18:28:32,547] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:28:32,555] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:14:00+00:00 [scheduled]> in ORM
[2020-07-22 18:28:32,762] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.447 seconds
[2020-07-22 18:29:23,322] {scheduler_job.py:153} INFO - Started process (PID=733305) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:29:23,326] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:29:23,327] {logging_mixin.py:112} INFO - [2020-07-22 18:29:23,326] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:29:23,346] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:29:23,479] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:29:23,827] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:15:00+00:00: scheduled__2020-07-20T09:15:00+00:00, externally triggered: False>
[2020-07-22 18:29:23,833] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:14:00+00:00: scheduled__2020-07-20T09:14:00+00:00, externally triggered: False>
[2020-07-22 18:29:23,849] {logging_mixin.py:112} INFO - [2020-07-22 18:29:23,849] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:14:00+00:00: scheduled__2020-07-20T09:14:00+00:00, externally triggered: False> successful
[2020-07-22 18:29:24,045] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:15:00+00:00: scheduled__2020-07-20T09:15:00+00:00, externally triggered: False>
[2020-07-22 18:29:24,063] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:29:24,070] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:15:00+00:00 [scheduled]> in ORM
[2020-07-22 18:29:24,240] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.919 seconds
[2020-07-22 18:30:15,509] {scheduler_job.py:153} INFO - Started process (PID=734245) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:30:15,515] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:30:15,516] {logging_mixin.py:112} INFO - [2020-07-22 18:30:15,515] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:30:15,537] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:30:15,717] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:30:16,144] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:16:00+00:00: scheduled__2020-07-20T09:16:00+00:00, externally triggered: False>
[2020-07-22 18:30:16,149] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:15:00+00:00: scheduled__2020-07-20T09:15:00+00:00, externally triggered: False>
[2020-07-22 18:30:16,159] {logging_mixin.py:112} INFO - [2020-07-22 18:30:16,158] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:15:00+00:00: scheduled__2020-07-20T09:15:00+00:00, externally triggered: False> successful
[2020-07-22 18:30:16,359] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:16:00+00:00: scheduled__2020-07-20T09:16:00+00:00, externally triggered: False>
[2020-07-22 18:30:16,379] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:30:16,383] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:16:00+00:00 [scheduled]> in ORM
[2020-07-22 18:30:16,687] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.178 seconds
[2020-07-22 18:31:00,859] {scheduler_job.py:153} INFO - Started process (PID=735131) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:31:00,869] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:31:00,870] {logging_mixin.py:112} INFO - [2020-07-22 18:31:00,870] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:31:00,890] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:31:01,128] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:31:01,540] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:17:00+00:00: scheduled__2020-07-20T09:17:00+00:00, externally triggered: False>
[2020-07-22 18:31:01,550] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:16:00+00:00: scheduled__2020-07-20T09:16:00+00:00, externally triggered: False>
[2020-07-22 18:31:01,571] {logging_mixin.py:112} INFO - [2020-07-22 18:31:01,571] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:16:00+00:00: scheduled__2020-07-20T09:16:00+00:00, externally triggered: False> successful
[2020-07-22 18:31:01,728] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:17:00+00:00: scheduled__2020-07-20T09:17:00+00:00, externally triggered: False>
[2020-07-22 18:31:01,780] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:31:01,786] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:17:00+00:00 [scheduled]> in ORM
[2020-07-22 18:31:01,963] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.104 seconds
[2020-07-22 18:31:41,140] {scheduler_job.py:153} INFO - Started process (PID=736278) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:31:41,144] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:31:41,145] {logging_mixin.py:112} INFO - [2020-07-22 18:31:41,145] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:31:41,155] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:31:41,392] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:31:41,743] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:18:00+00:00: scheduled__2020-07-20T09:18:00+00:00, externally triggered: False>
[2020-07-22 18:31:41,746] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:17:00+00:00: scheduled__2020-07-20T09:17:00+00:00, externally triggered: False>
[2020-07-22 18:31:41,755] {logging_mixin.py:112} INFO - [2020-07-22 18:31:41,755] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:17:00+00:00: scheduled__2020-07-20T09:17:00+00:00, externally triggered: False> successful
[2020-07-22 18:31:41,907] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:18:00+00:00: scheduled__2020-07-20T09:18:00+00:00, externally triggered: False>
[2020-07-22 18:31:41,926] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:31:41,930] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:18:00+00:00 [scheduled]> in ORM
[2020-07-22 18:31:42,080] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.940 seconds
[2020-07-22 18:32:21,484] {scheduler_job.py:153} INFO - Started process (PID=737398) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:32:21,488] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:32:21,489] {logging_mixin.py:112} INFO - [2020-07-22 18:32:21,489] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:32:21,510] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:32:21,780] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:32:22,284] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:19:00+00:00: scheduled__2020-07-20T09:19:00+00:00, externally triggered: False>
[2020-07-22 18:32:22,291] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:18:00+00:00: scheduled__2020-07-20T09:18:00+00:00, externally triggered: False>
[2020-07-22 18:32:22,299] {logging_mixin.py:112} INFO - [2020-07-22 18:32:22,298] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:18:00+00:00: scheduled__2020-07-20T09:18:00+00:00, externally triggered: False> successful
[2020-07-22 18:32:22,530] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:19:00+00:00: scheduled__2020-07-20T09:19:00+00:00, externally triggered: False>
[2020-07-22 18:32:22,565] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:32:22,574] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:19:00+00:00 [scheduled]> in ORM
[2020-07-22 18:32:22,880] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.396 seconds
[2020-07-22 18:33:26,088] {scheduler_job.py:153} INFO - Started process (PID=738806) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:33:26,092] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:33:26,092] {logging_mixin.py:112} INFO - [2020-07-22 18:33:26,092] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:33:26,103] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:33:26,292] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:33:26,751] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:20:00+00:00: scheduled__2020-07-20T09:20:00+00:00, externally triggered: False>
[2020-07-22 18:33:26,756] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:19:00+00:00: scheduled__2020-07-20T09:19:00+00:00, externally triggered: False>
[2020-07-22 18:33:26,763] {logging_mixin.py:112} INFO - [2020-07-22 18:33:26,763] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:19:00+00:00: scheduled__2020-07-20T09:19:00+00:00, externally triggered: False> successful
[2020-07-22 18:33:26,889] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:20:00+00:00: scheduled__2020-07-20T09:20:00+00:00, externally triggered: False>
[2020-07-22 18:33:26,909] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:33:26,913] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:20:00+00:00 [scheduled]> in ORM
[2020-07-22 18:33:27,075] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.987 seconds
[2020-07-22 18:34:06,297] {scheduler_job.py:153} INFO - Started process (PID=739597) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:34:06,301] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:34:06,302] {logging_mixin.py:112} INFO - [2020-07-22 18:34:06,302] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:34:06,312] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:34:06,464] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:34:06,808] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:21:00+00:00: scheduled__2020-07-20T09:21:00+00:00, externally triggered: False>
[2020-07-22 18:34:06,816] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:20:00+00:00: scheduled__2020-07-20T09:20:00+00:00, externally triggered: False>
[2020-07-22 18:34:06,827] {logging_mixin.py:112} INFO - [2020-07-22 18:34:06,826] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:20:00+00:00: scheduled__2020-07-20T09:20:00+00:00, externally triggered: False> successful
[2020-07-22 18:34:07,012] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:21:00+00:00: scheduled__2020-07-20T09:21:00+00:00, externally triggered: False>
[2020-07-22 18:34:07,033] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:34:07,039] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:21:00+00:00 [scheduled]> in ORM
[2020-07-22 18:34:07,229] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.933 seconds
[2020-07-22 18:34:46,192] {scheduler_job.py:153} INFO - Started process (PID=740353) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:34:46,195] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:34:46,196] {logging_mixin.py:112} INFO - [2020-07-22 18:34:46,196] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:34:46,206] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:34:46,444] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:34:46,861] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:22:00+00:00: scheduled__2020-07-20T09:22:00+00:00, externally triggered: False>
[2020-07-22 18:34:46,865] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:21:00+00:00: scheduled__2020-07-20T09:21:00+00:00, externally triggered: False>
[2020-07-22 18:34:46,875] {logging_mixin.py:112} INFO - [2020-07-22 18:34:46,874] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:21:00+00:00: scheduled__2020-07-20T09:21:00+00:00, externally triggered: False> successful
[2020-07-22 18:34:47,297] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:22:00+00:00: scheduled__2020-07-20T09:22:00+00:00, externally triggered: False>
[2020-07-22 18:34:47,318] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:34:47,322] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:22:00+00:00 [scheduled]> in ORM
[2020-07-22 18:34:47,473] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.281 seconds
[2020-07-22 18:35:32,624] {scheduler_job.py:153} INFO - Started process (PID=741267) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:35:32,628] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:35:32,628] {logging_mixin.py:112} INFO - [2020-07-22 18:35:32,628] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:35:32,639] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:35:32,762] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:35:33,492] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:23:00+00:00: scheduled__2020-07-20T09:23:00+00:00, externally triggered: False>
[2020-07-22 18:35:33,504] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:22:00+00:00: scheduled__2020-07-20T09:22:00+00:00, externally triggered: False>
[2020-07-22 18:35:33,526] {logging_mixin.py:112} INFO - [2020-07-22 18:35:33,526] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:22:00+00:00: scheduled__2020-07-20T09:22:00+00:00, externally triggered: False> successful
[2020-07-22 18:35:33,716] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:23:00+00:00: scheduled__2020-07-20T09:23:00+00:00, externally triggered: False>
[2020-07-22 18:35:33,776] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:35:33,790] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:23:00+00:00 [scheduled]> in ORM
[2020-07-22 18:35:34,721] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 2.097 seconds
[2020-07-22 18:36:13,276] {scheduler_job.py:153} INFO - Started process (PID=742059) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:36:13,280] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:36:13,280] {logging_mixin.py:112} INFO - [2020-07-22 18:36:13,280] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:36:13,291] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:36:13,436] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:36:13,772] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:24:00+00:00: scheduled__2020-07-20T09:24:00+00:00, externally triggered: False>
[2020-07-22 18:36:13,776] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:23:00+00:00: scheduled__2020-07-20T09:23:00+00:00, externally triggered: False>
[2020-07-22 18:36:13,784] {logging_mixin.py:112} INFO - [2020-07-22 18:36:13,784] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:23:00+00:00: scheduled__2020-07-20T09:23:00+00:00, externally triggered: False> successful
[2020-07-22 18:36:13,906] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:24:00+00:00: scheduled__2020-07-20T09:24:00+00:00, externally triggered: False>
[2020-07-22 18:36:13,924] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:36:13,928] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:24:00+00:00 [scheduled]> in ORM
[2020-07-22 18:36:14,078] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.802 seconds
[2020-07-22 18:36:47,694] {scheduler_job.py:153} INFO - Started process (PID=742739) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:36:47,698] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:36:47,699] {logging_mixin.py:112} INFO - [2020-07-22 18:36:47,698] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:36:47,709] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:36:47,945] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:36:48,296] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:25:00+00:00: scheduled__2020-07-20T09:25:00+00:00, externally triggered: False>
[2020-07-22 18:36:48,299] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:24:00+00:00: scheduled__2020-07-20T09:24:00+00:00, externally triggered: False>
[2020-07-22 18:36:48,307] {logging_mixin.py:112} INFO - [2020-07-22 18:36:48,307] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:24:00+00:00: scheduled__2020-07-20T09:24:00+00:00, externally triggered: False> successful
[2020-07-22 18:36:48,441] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:25:00+00:00: scheduled__2020-07-20T09:25:00+00:00, externally triggered: False>
[2020-07-22 18:36:48,460] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:36:48,464] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:25:00+00:00 [scheduled]> in ORM
[2020-07-22 18:36:48,624] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.930 seconds
[2020-07-22 18:37:22,464] {scheduler_job.py:153} INFO - Started process (PID=743460) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:37:22,467] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:37:22,467] {logging_mixin.py:112} INFO - [2020-07-22 18:37:22,467] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:37:22,476] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:37:22,604] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:37:22,943] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:26:00+00:00: scheduled__2020-07-20T09:26:00+00:00, externally triggered: False>
[2020-07-22 18:37:22,949] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:25:00+00:00: scheduled__2020-07-20T09:25:00+00:00, externally triggered: False>
[2020-07-22 18:37:22,956] {logging_mixin.py:112} INFO - [2020-07-22 18:37:22,956] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:25:00+00:00: scheduled__2020-07-20T09:25:00+00:00, externally triggered: False> successful
[2020-07-22 18:37:23,098] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:26:00+00:00: scheduled__2020-07-20T09:26:00+00:00, externally triggered: False>
[2020-07-22 18:37:23,118] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:37:23,122] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:26:00+00:00 [scheduled]> in ORM
[2020-07-22 18:37:23,270] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.807 seconds
[2020-07-22 18:37:56,903] {scheduler_job.py:153} INFO - Started process (PID=744134) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:37:56,908] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:37:56,909] {logging_mixin.py:112} INFO - [2020-07-22 18:37:56,909] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:37:56,919] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:37:57,108] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:37:57,522] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:27:00+00:00: scheduled__2020-07-20T09:27:00+00:00, externally triggered: False>
[2020-07-22 18:37:57,526] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:26:00+00:00: scheduled__2020-07-20T09:26:00+00:00, externally triggered: False>
[2020-07-22 18:37:57,533] {logging_mixin.py:112} INFO - [2020-07-22 18:37:57,533] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:26:00+00:00: scheduled__2020-07-20T09:26:00+00:00, externally triggered: False> successful
[2020-07-22 18:37:57,666] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:27:00+00:00: scheduled__2020-07-20T09:27:00+00:00, externally triggered: False>
[2020-07-22 18:37:57,683] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:37:57,686] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:27:00+00:00 [scheduled]> in ORM
[2020-07-22 18:37:57,835] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.932 seconds
[2020-07-22 18:38:31,515] {scheduler_job.py:153} INFO - Started process (PID=744815) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:38:31,518] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:38:31,519] {logging_mixin.py:112} INFO - [2020-07-22 18:38:31,518] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:38:31,528] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:38:31,651] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:38:31,967] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:28:00+00:00: scheduled__2020-07-20T09:28:00+00:00, externally triggered: False>
[2020-07-22 18:38:31,971] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:27:00+00:00: scheduled__2020-07-20T09:27:00+00:00, externally triggered: False>
[2020-07-22 18:38:31,978] {logging_mixin.py:112} INFO - [2020-07-22 18:38:31,978] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:27:00+00:00: scheduled__2020-07-20T09:27:00+00:00, externally triggered: False> successful
[2020-07-22 18:38:32,111] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:28:00+00:00: scheduled__2020-07-20T09:28:00+00:00, externally triggered: False>
[2020-07-22 18:38:32,128] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:38:32,132] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:28:00+00:00 [scheduled]> in ORM
[2020-07-22 18:38:32,328] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.813 seconds
[2020-07-22 18:39:05,692] {scheduler_job.py:153} INFO - Started process (PID=746181) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:39:05,697] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:39:05,697] {logging_mixin.py:112} INFO - [2020-07-22 18:39:05,697] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:39:05,707] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:39:05,862] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:39:06,271] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:29:00+00:00: scheduled__2020-07-20T09:29:00+00:00, externally triggered: False>
[2020-07-22 18:39:06,274] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:28:00+00:00: scheduled__2020-07-20T09:28:00+00:00, externally triggered: False>
[2020-07-22 18:39:06,281] {logging_mixin.py:112} INFO - [2020-07-22 18:39:06,281] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:28:00+00:00: scheduled__2020-07-20T09:28:00+00:00, externally triggered: False> successful
[2020-07-22 18:39:06,415] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:29:00+00:00: scheduled__2020-07-20T09:29:00+00:00, externally triggered: False>
[2020-07-22 18:39:06,433] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:39:06,437] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:29:00+00:00 [scheduled]> in ORM
[2020-07-22 18:39:06,587] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.895 seconds
[2020-07-22 18:39:40,638] {scheduler_job.py:153} INFO - Started process (PID=747553) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:39:40,642] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:39:40,642] {logging_mixin.py:112} INFO - [2020-07-22 18:39:40,642] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:39:40,653] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:39:40,844] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:39:41,506] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:30:00+00:00: scheduled__2020-07-20T09:30:00+00:00, externally triggered: False>
[2020-07-22 18:39:41,513] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:29:00+00:00: scheduled__2020-07-20T09:29:00+00:00, externally triggered: False>
[2020-07-22 18:39:41,529] {logging_mixin.py:112} INFO - [2020-07-22 18:39:41,528] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:29:00+00:00: scheduled__2020-07-20T09:29:00+00:00, externally triggered: False> successful
[2020-07-22 18:39:41,889] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:30:00+00:00: scheduled__2020-07-20T09:30:00+00:00, externally triggered: False>
[2020-07-22 18:39:41,915] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:39:41,920] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:30:00+00:00 [scheduled]> in ORM
[2020-07-22 18:39:42,101] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 1.464 seconds
[2020-07-22 18:40:21,326] {scheduler_job.py:153} INFO - Started process (PID=748365) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:40:21,330] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:40:21,331] {logging_mixin.py:112} INFO - [2020-07-22 18:40:21,331] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:40:21,365] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:40:21,569] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:40:21,901] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:31:00+00:00: scheduled__2020-07-20T09:31:00+00:00, externally triggered: False>
[2020-07-22 18:40:21,910] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:30:00+00:00: scheduled__2020-07-20T09:30:00+00:00, externally triggered: False>
[2020-07-22 18:40:21,935] {logging_mixin.py:112} INFO - [2020-07-22 18:40:21,935] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:30:00+00:00: scheduled__2020-07-20T09:30:00+00:00, externally triggered: False> successful
[2020-07-22 18:40:22,071] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:31:00+00:00: scheduled__2020-07-20T09:31:00+00:00, externally triggered: False>
[2020-07-22 18:40:22,092] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:40:22,097] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:31:00+00:00 [scheduled]> in ORM
[2020-07-22 18:40:22,241] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.916 seconds
[2020-07-22 18:41:19,765] {scheduler_job.py:153} INFO - Started process (PID=750700) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:41:19,768] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:41:19,769] {logging_mixin.py:112} INFO - [2020-07-22 18:41:19,769] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:41:19,780] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:41:19,916] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:41:20,255] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:32:00+00:00: scheduled__2020-07-20T09:32:00+00:00, externally triggered: False>
[2020-07-22 18:41:20,264] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:31:00+00:00: scheduled__2020-07-20T09:31:00+00:00, externally triggered: False>
[2020-07-22 18:41:20,277] {logging_mixin.py:112} INFO - [2020-07-22 18:41:20,277] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:31:00+00:00: scheduled__2020-07-20T09:31:00+00:00, externally triggered: False> successful
[2020-07-22 18:41:20,479] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:32:00+00:00: scheduled__2020-07-20T09:32:00+00:00, externally triggered: False>
[2020-07-22 18:41:20,499] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:41:20,503] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:32:00+00:00 [scheduled]> in ORM
[2020-07-22 18:41:20,661] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.896 seconds
[2020-07-22 18:42:06,286] {scheduler_job.py:153} INFO - Started process (PID=751592) to work on /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:42:06,289] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/spark_submit_operator.py for tasks to queue
[2020-07-22 18:42:06,290] {logging_mixin.py:112} INFO - [2020-07-22 18:42:06,289] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:42:06,299] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['submit_data']) retrieved from /home/bhakti/airflow/dags/spark_submit_operator.py
[2020-07-22 18:42:06,495] {scheduler_job.py:1284} INFO - Processing submit_data
[2020-07-22 18:42:06,829] {scheduler_job.py:1294} INFO - Created <DagRun submit_data @ 2020-07-20T09:33:00+00:00: scheduled__2020-07-20T09:33:00+00:00, externally triggered: False>
[2020-07-22 18:42:06,836] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:32:00+00:00: scheduled__2020-07-20T09:32:00+00:00, externally triggered: False>
[2020-07-22 18:42:06,851] {logging_mixin.py:112} INFO - [2020-07-22 18:42:06,850] {dagrun.py:318} INFO - Marking run <DagRun submit_data @ 2020-07-20 09:32:00+00:00: scheduled__2020-07-20T09:32:00+00:00, externally triggered: False> successful
[2020-07-22 18:42:06,996] {scheduler_job.py:759} INFO - Examining DAG run <DagRun submit_data @ 2020-07-20 09:33:00+00:00: scheduled__2020-07-20T09:33:00+00:00, externally triggered: False>
[2020-07-22 18:42:07,021] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: submit_data> because no tasks in DAG have SLAs
[2020-07-22 18:42:07,028] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: submit_data.spark_submit 2020-07-20 09:33:00+00:00 [scheduled]> in ORM
[2020-07-22 18:42:07,233] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/spark_submit_operator.py took 0.947 seconds
