[2020-07-18 12:15:13,475] {scheduler_job.py:153} INFO - Started process (PID=9103) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:15:13,479] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:15:13,479] {logging_mixin.py:112} INFO - [2020-07-18 12:15:13,479] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:15:13,487] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:15:13,667] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:15:13,996] {scheduler_job.py:1294} INFO - Created <DagRun storing_data @ 2020-07-17 00:00:00+00:00: scheduled__2020-07-17T00:00:00+00:00, externally triggered: False>
[2020-07-18 12:15:14,000] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-17 00:00:00+00:00: scheduled__2020-07-17T00:00:00+00:00, externally triggered: False>
[2020-07-18 12:15:14,012] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:15:14,016] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-17 00:00:00+00:00 [scheduled]> in ORM
[2020-07-18 12:15:14,020] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.csv_to_db2 2020-07-17 00:00:00+00:00 [scheduled]> in ORM
[2020-07-18 12:15:14,025] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-17 00:00:00+00:00 [scheduled]> in ORM
[2020-07-18 12:15:14,190] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.715 seconds
[2020-07-18 12:16:47,476] {scheduler_job.py:153} INFO - Started process (PID=9855) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:16:47,479] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:16:47,480] {logging_mixin.py:112} INFO - [2020-07-18 12:16:47,479] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:16:47,488] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:16:47,703] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:16:47,723] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-17 00:00:00+00:00: scheduled__2020-07-17T00:00:00+00:00, externally triggered: False>
[2020-07-18 12:16:47,746] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:16:47,750] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-17 00:00:00+00:00 [scheduled]> in ORM
[2020-07-18 12:16:47,756] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.csv_to_db2 2020-07-17 00:00:00+00:00 [scheduled]> in ORM
[2020-07-18 12:16:47,767] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-17 00:00:00+00:00 [scheduled]> in ORM
[2020-07-18 12:16:47,917] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.441 seconds
[2020-07-18 12:18:21,959] {scheduler_job.py:153} INFO - Started process (PID=10278) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:18:21,963] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:18:21,963] {logging_mixin.py:112} INFO - [2020-07-18 12:18:21,963] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:18:21,973] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:18:22,478] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:18:22,496] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-17 00:00:00+00:00: scheduled__2020-07-17T00:00:00+00:00, externally triggered: False>
[2020-07-18 12:18:22,519] {logging_mixin.py:112} INFO - [2020-07-18 12:18:22,519] {dagrun.py:309} INFO - Marking run <DagRun storing_data @ 2020-07-17 00:00:00+00:00: scheduled__2020-07-17T00:00:00+00:00, externally triggered: False> failed
[2020-07-18 12:18:22,655] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:18:22,659] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.700 seconds
[2020-07-18 12:19:20,013] {scheduler_job.py:153} INFO - Started process (PID=10702) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:19:20,016] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:19:20,017] {logging_mixin.py:112} INFO - [2020-07-18 12:19:20,016] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:19:20,025] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:19:20,341] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:19:20,373] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:19:20,379] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.366 seconds
[2020-07-18 12:20:18,077] {scheduler_job.py:153} INFO - Started process (PID=11078) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:20:18,080] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:20:18,080] {logging_mixin.py:112} INFO - [2020-07-18 12:20:18,080] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:20:18,089] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:20:18,798] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:20:18,814] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:20:18,818] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.741 seconds
[2020-07-18 12:21:16,137] {scheduler_job.py:153} INFO - Started process (PID=11361) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:21:16,142] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:21:16,142] {logging_mixin.py:112} INFO - [2020-07-18 12:21:16,142] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:21:16,153] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:21:16,343] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:21:16,359] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:21:16,362] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.225 seconds
[2020-07-18 12:22:14,388] {scheduler_job.py:153} INFO - Started process (PID=11845) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:22:14,391] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:22:14,392] {logging_mixin.py:112} INFO - [2020-07-18 12:22:14,392] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:22:14,400] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:22:14,523] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:22:14,539] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 06:51:26.466442+00:00: manual__2020-07-18T06:51:26.466442+00:00, externally triggered: True>
[2020-07-18 12:22:14,556] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:22:14,560] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 06:51:26.466442+00:00 [scheduled]> in ORM
[2020-07-18 12:22:14,564] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.csv_to_db2 2020-07-18 06:51:26.466442+00:00 [scheduled]> in ORM
[2020-07-18 12:22:14,568] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 06:51:26.466442+00:00 [scheduled]> in ORM
[2020-07-18 12:22:14,706] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.319 seconds
[2020-07-18 12:23:48,628] {scheduler_job.py:153} INFO - Started process (PID=12429) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:23:48,632] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:23:48,632] {logging_mixin.py:112} INFO - [2020-07-18 12:23:48,632] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:23:48,641] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:23:48,769] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:23:48,785] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 06:51:26.466442+00:00: manual__2020-07-18T06:51:26.466442+00:00, externally triggered: True>
[2020-07-18 12:23:48,800] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:23:48,804] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 06:51:26.466442+00:00 [scheduled]> in ORM
[2020-07-18 12:23:48,809] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.csv_to_db2 2020-07-18 06:51:26.466442+00:00 [scheduled]> in ORM
[2020-07-18 12:23:48,814] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 06:51:26.466442+00:00 [scheduled]> in ORM
[2020-07-18 12:23:48,966] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.338 seconds
[2020-07-18 12:25:24,155] {scheduler_job.py:153} INFO - Started process (PID=13596) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:25:24,160] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:25:24,160] {logging_mixin.py:112} INFO - [2020-07-18 12:25:24,160] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:25:24,170] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:25:24,293] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:25:24,307] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 06:51:26.466442+00:00: manual__2020-07-18T06:51:26.466442+00:00, externally triggered: True>
[2020-07-18 12:25:24,317] {logging_mixin.py:112} INFO - [2020-07-18 12:25:24,317] {dagrun.py:309} INFO - Marking run <DagRun storing_data @ 2020-07-18 06:51:26.466442+00:00: manual__2020-07-18T06:51:26.466442+00:00, externally triggered: True> failed
[2020-07-18 12:25:24,425] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:25:24,430] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.275 seconds
[2020-07-18 12:26:22,209] {scheduler_job.py:153} INFO - Started process (PID=14172) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:26:22,212] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:26:22,212] {logging_mixin.py:112} INFO - [2020-07-18 12:26:22,212] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:26:22,221] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:26:22,533] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:26:22,578] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:26:22,583] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.375 seconds
[2020-07-18 12:27:20,278] {scheduler_job.py:153} INFO - Started process (PID=15348) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:27:20,285] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:27:20,286] {logging_mixin.py:112} INFO - [2020-07-18 12:27:20,286] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:27:20,300] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:27:20,631] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:27:20,660] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 06:57:05.124584+00:00: manual__2020-07-18T06:57:05.124584+00:00, externally triggered: True>
[2020-07-18 12:27:20,693] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:27:20,702] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 06:57:05.124584+00:00 [scheduled]> in ORM
[2020-07-18 12:27:20,711] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.csv_to_db2 2020-07-18 06:57:05.124584+00:00 [scheduled]> in ORM
[2020-07-18 12:27:20,722] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 06:57:05.124584+00:00 [scheduled]> in ORM
[2020-07-18 12:27:20,899] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.621 seconds
[2020-07-18 12:28:55,950] {scheduler_job.py:153} INFO - Started process (PID=17144) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:28:55,953] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:28:55,953] {logging_mixin.py:112} INFO - [2020-07-18 12:28:55,953] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:28:55,963] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:28:56,110] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:28:56,133] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 06:57:05.124584+00:00: manual__2020-07-18T06:57:05.124584+00:00, externally triggered: True>
[2020-07-18 12:28:56,155] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:28:56,163] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 06:57:05.124584+00:00 [scheduled]> in ORM
[2020-07-18 12:28:56,312] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.362 seconds
[2020-07-18 12:30:05,562] {scheduler_job.py:153} INFO - Started process (PID=18250) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:30:05,567] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:30:05,568] {logging_mixin.py:112} INFO - [2020-07-18 12:30:05,567] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:30:05,579] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:30:05,792] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:30:05,807] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 06:57:05.124584+00:00: manual__2020-07-18T06:57:05.124584+00:00, externally triggered: True>
[2020-07-18 12:30:05,817] {logging_mixin.py:112} INFO - [2020-07-18 12:30:05,817] {dagrun.py:309} INFO - Marking run <DagRun storing_data @ 2020-07-18 06:57:05.124584+00:00: manual__2020-07-18T06:57:05.124584+00:00, externally triggered: True> failed
[2020-07-18 12:30:05,934] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:30:05,940] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.378 seconds
[2020-07-18 12:31:03,617] {scheduler_job.py:153} INFO - Started process (PID=19225) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:31:03,619] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:31:03,620] {logging_mixin.py:112} INFO - [2020-07-18 12:31:03,620] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:31:03,629] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:31:03,924] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:31:03,939] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:31:03,942] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.326 seconds
[2020-07-18 12:32:01,678] {scheduler_job.py:153} INFO - Started process (PID=20097) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:32:01,681] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:32:01,681] {logging_mixin.py:112} INFO - [2020-07-18 12:32:01,681] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:32:01,690] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:32:01,949] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:32:01,964] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:32:01,967] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.290 seconds
[2020-07-18 12:32:59,737] {scheduler_job.py:153} INFO - Started process (PID=21122) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:32:59,743] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:32:59,743] {logging_mixin.py:112} INFO - [2020-07-18 12:32:59,743] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:32:59,751] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:33:00,617] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:33:00,634] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:33:00,637] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.900 seconds
[2020-07-18 12:33:57,789] {scheduler_job.py:153} INFO - Started process (PID=22071) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:33:57,794] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:33:57,843] {logging_mixin.py:112} INFO - [2020-07-18 12:33:57,843] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:33:57,855] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:33:58,087] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:33:58,110] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:33:58,114] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.324 seconds
[2020-07-18 12:34:55,848] {scheduler_job.py:153} INFO - Started process (PID=23164) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:34:55,852] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:34:55,852] {logging_mixin.py:112} INFO - [2020-07-18 12:34:55,852] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:34:55,861] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:34:56,016] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:34:56,032] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:34:56,035] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.187 seconds
[2020-07-18 12:35:54,092] {scheduler_job.py:153} INFO - Started process (PID=24220) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:35:54,095] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:35:54,095] {logging_mixin.py:112} INFO - [2020-07-18 12:35:54,095] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:35:54,103] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:35:54,552] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:35:54,567] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:35:54,569] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.478 seconds
[2020-07-18 12:36:52,389] {scheduler_job.py:153} INFO - Started process (PID=25281) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:36:52,392] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:36:52,392] {logging_mixin.py:112} INFO - [2020-07-18 12:36:52,392] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:36:52,402] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:36:52,673] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:36:52,689] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:36:52,692] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.303 seconds
[2020-07-18 12:37:50,454] {scheduler_job.py:153} INFO - Started process (PID=26284) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:37:50,457] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:37:50,457] {logging_mixin.py:112} INFO - [2020-07-18 12:37:50,457] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:37:50,466] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:37:50,647] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:37:50,663] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:37:50,666] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.213 seconds
[2020-07-18 12:38:48,516] {scheduler_job.py:153} INFO - Started process (PID=27225) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:38:48,520] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:38:48,520] {logging_mixin.py:112} INFO - [2020-07-18 12:38:48,520] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:38:48,528] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:38:48,668] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:38:48,690] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:38:48,693] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.177 seconds
[2020-07-18 12:39:47,428] {scheduler_job.py:153} INFO - Started process (PID=28223) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:39:47,430] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:39:47,431] {logging_mixin.py:112} INFO - [2020-07-18 12:39:47,431] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:39:47,440] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:39:47,567] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:39:47,581] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:39:47,585] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.157 seconds
[2020-07-18 12:40:45,296] {scheduler_job.py:153} INFO - Started process (PID=29087) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:40:45,299] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:40:45,300] {logging_mixin.py:112} INFO - [2020-07-18 12:40:45,300] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:40:45,308] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:40:45,468] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:40:45,489] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:40:45,495] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.199 seconds
[2020-07-18 12:41:43,355] {scheduler_job.py:153} INFO - Started process (PID=30167) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:41:43,360] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:41:43,361] {logging_mixin.py:112} INFO - [2020-07-18 12:41:43,361] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:41:43,374] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:41:44,046] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:41:44,062] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:41:44,065] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.710 seconds
[2020-07-18 12:42:41,654] {scheduler_job.py:153} INFO - Started process (PID=31055) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:42:41,656] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:42:41,657] {logging_mixin.py:112} INFO - [2020-07-18 12:42:41,657] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:42:41,666] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:42:41,780] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:42:41,795] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 07:12:32.264735+00:00: manual__2020-07-18T07:12:32.264735+00:00, externally triggered: True>
[2020-07-18 12:42:41,810] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:42:41,814] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 07:12:32.264735+00:00 [scheduled]> in ORM
[2020-07-18 12:42:41,820] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.csv_to_db2 2020-07-18 07:12:32.264735+00:00 [scheduled]> in ORM
[2020-07-18 12:42:41,824] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 07:12:32.264735+00:00 [scheduled]> in ORM
[2020-07-18 12:42:42,055] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.401 seconds
[2020-07-18 12:44:16,109] {scheduler_job.py:153} INFO - Started process (PID=32695) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:44:16,112] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:44:16,112] {logging_mixin.py:112} INFO - [2020-07-18 12:44:16,112] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:44:16,122] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:44:16,280] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:44:16,296] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 07:12:32.264735+00:00: manual__2020-07-18T07:12:32.264735+00:00, externally triggered: True>
[2020-07-18 12:44:16,307] {logging_mixin.py:112} INFO - [2020-07-18 12:44:16,307] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 07:12:32.264735+00:00: manual__2020-07-18T07:12:32.264735+00:00, externally triggered: True> successful
[2020-07-18 12:44:16,442] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:44:16,449] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.340 seconds
[2020-07-18 12:45:14,165] {scheduler_job.py:153} INFO - Started process (PID=33726) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:45:14,168] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:45:14,168] {logging_mixin.py:112} INFO - [2020-07-18 12:45:14,168] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:45:14,177] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:45:14,471] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:45:14,488] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:45:14,492] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.327 seconds
[2020-07-18 12:46:12,223] {scheduler_job.py:153} INFO - Started process (PID=34620) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:46:12,227] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:46:12,228] {logging_mixin.py:112} INFO - [2020-07-18 12:46:12,228] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:46:12,243] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:46:12,408] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:46:12,434] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:46:12,440] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-18 12:47:10,945] {scheduler_job.py:153} INFO - Started process (PID=35615) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:47:10,949] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:47:10,949] {logging_mixin.py:112} INFO - [2020-07-18 12:47:10,949] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:47:10,959] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:47:11,170] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:47:11,192] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:47:11,198] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.252 seconds
[2020-07-18 12:48:09,754] {scheduler_job.py:153} INFO - Started process (PID=36529) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:48:09,758] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:48:09,759] {logging_mixin.py:112} INFO - [2020-07-18 12:48:09,759] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:48:09,777] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:48:10,100] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:48:10,118] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:48:10,121] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.368 seconds
[2020-07-18 12:49:07,077] {scheduler_job.py:153} INFO - Started process (PID=37496) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:49:07,080] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:49:07,081] {logging_mixin.py:112} INFO - [2020-07-18 12:49:07,080] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:49:07,089] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:49:07,212] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:49:07,227] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:49:07,230] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.153 seconds
[2020-07-18 12:50:05,821] {scheduler_job.py:153} INFO - Started process (PID=38535) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:50:05,824] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:50:05,825] {logging_mixin.py:112} INFO - [2020-07-18 12:50:05,824] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:50:05,833] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:50:05,980] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:50:06,001] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:50:06,007] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.186 seconds
[2020-07-18 12:51:04,016] {scheduler_job.py:153} INFO - Started process (PID=39397) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:51:04,019] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:51:04,020] {logging_mixin.py:112} INFO - [2020-07-18 12:51:04,020] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:51:04,034] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:51:04,143] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:51:04,164] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:51:04,167] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.151 seconds
[2020-07-18 12:52:01,931] {scheduler_job.py:153} INFO - Started process (PID=40380) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:52:01,934] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:52:01,935] {logging_mixin.py:112} INFO - [2020-07-18 12:52:01,934] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:52:01,944] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:52:02,099] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:52:02,133] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:52:02,139] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.207 seconds
[2020-07-18 12:53:00,018] {scheduler_job.py:153} INFO - Started process (PID=41277) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:53:00,023] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:53:00,023] {logging_mixin.py:112} INFO - [2020-07-18 12:53:00,023] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:53:00,037] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:53:00,204] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:53:00,220] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:53:00,223] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.205 seconds
[2020-07-18 12:53:58,660] {scheduler_job.py:153} INFO - Started process (PID=42389) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:53:58,664] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:53:58,664] {logging_mixin.py:112} INFO - [2020-07-18 12:53:58,664] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:53:58,672] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:53:59,480] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:53:59,496] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:53:59,499] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.840 seconds
[2020-07-18 12:54:56,524] {scheduler_job.py:153} INFO - Started process (PID=43249) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:54:56,527] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:54:56,528] {logging_mixin.py:112} INFO - [2020-07-18 12:54:56,528] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:54:56,537] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:54:56,691] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:54:56,708] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:54:56,712] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.188 seconds
[2020-07-18 12:55:54,588] {scheduler_job.py:153} INFO - Started process (PID=44277) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:55:54,592] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:55:54,592] {logging_mixin.py:112} INFO - [2020-07-18 12:55:54,592] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:55:54,602] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:55:54,732] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:55:54,750] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:55:54,753] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.165 seconds
[2020-07-18 12:56:52,789] {scheduler_job.py:153} INFO - Started process (PID=45277) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:56:52,793] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:56:52,794] {logging_mixin.py:112} INFO - [2020-07-18 12:56:52,794] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:56:52,809] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:56:52,947] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:56:52,984] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:56:52,989] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.201 seconds
[2020-07-18 12:57:50,706] {scheduler_job.py:153} INFO - Started process (PID=46133) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:57:50,710] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:57:50,710] {logging_mixin.py:112} INFO - [2020-07-18 12:57:50,710] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:57:50,719] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:57:50,952] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:57:50,970] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 07:27:48.730539+00:00: manual__2020-07-18T07:27:48.730539+00:00, externally triggered: True>
[2020-07-18 12:57:50,992] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:57:50,998] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 07:27:48.730539+00:00 [scheduled]> in ORM
[2020-07-18 12:57:51,004] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.csv_to_db2 2020-07-18 07:27:48.730539+00:00 [scheduled]> in ORM
[2020-07-18 12:57:51,008] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 07:27:48.730539+00:00 [scheduled]> in ORM
[2020-07-18 12:57:51,188] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.482 seconds
[2020-07-18 12:59:25,726] {scheduler_job.py:153} INFO - Started process (PID=47811) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:59:25,729] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 12:59:25,730] {logging_mixin.py:112} INFO - [2020-07-18 12:59:25,729] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:59:25,739] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 12:59:26,362] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 12:59:26,391] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 07:27:48.730539+00:00: manual__2020-07-18T07:27:48.730539+00:00, externally triggered: True>
[2020-07-18 12:59:26,420] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 12:59:26,426] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 07:27:48.730539+00:00 [scheduled]> in ORM
[2020-07-18 12:59:26,590] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.864 seconds
[2020-07-18 13:00:35,985] {scheduler_job.py:153} INFO - Started process (PID=49019) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:00:35,988] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:00:35,989] {logging_mixin.py:112} INFO - [2020-07-18 13:00:35,989] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:00:35,998] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:00:36,162] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:00:36,179] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 07:27:48.730539+00:00: manual__2020-07-18T07:27:48.730539+00:00, externally triggered: True>
[2020-07-18 13:00:36,196] {logging_mixin.py:112} INFO - [2020-07-18 13:00:36,195] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 07:27:48.730539+00:00: manual__2020-07-18T07:27:48.730539+00:00, externally triggered: True> successful
[2020-07-18 13:00:36,354] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:00:36,359] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.374 seconds
[2020-07-18 13:01:34,036] {scheduler_job.py:153} INFO - Started process (PID=49905) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:01:34,040] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:01:34,040] {logging_mixin.py:112} INFO - [2020-07-18 13:01:34,040] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:01:34,049] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:01:34,365] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:01:34,402] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:01:34,410] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.374 seconds
[2020-07-18 13:02:32,099] {scheduler_job.py:153} INFO - Started process (PID=50929) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:02:32,102] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:02:32,102] {logging_mixin.py:112} INFO - [2020-07-18 13:02:32,102] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:02:32,113] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:02:32,240] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:02:32,260] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:02:32,265] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.167 seconds
[2020-07-18 13:03:30,155] {scheduler_job.py:153} INFO - Started process (PID=51818) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:03:30,160] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:03:30,160] {logging_mixin.py:112} INFO - [2020-07-18 13:03:30,160] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:03:30,171] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:03:30,324] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:03:30,339] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:03:30,342] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.187 seconds
[2020-07-18 13:04:28,413] {scheduler_job.py:153} INFO - Started process (PID=52783) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:04:28,422] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:04:28,424] {logging_mixin.py:112} INFO - [2020-07-18 13:04:28,424] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:04:28,450] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:04:28,633] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:04:28,665] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:04:28,672] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.260 seconds
[2020-07-18 13:05:26,273] {scheduler_job.py:153} INFO - Started process (PID=53652) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:05:26,276] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:05:26,276] {logging_mixin.py:112} INFO - [2020-07-18 13:05:26,276] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:05:26,286] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:05:26,408] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:05:26,426] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:05:26,429] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.156 seconds
[2020-07-18 13:06:24,464] {scheduler_job.py:153} INFO - Started process (PID=54659) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:06:24,467] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:06:24,468] {logging_mixin.py:112} INFO - [2020-07-18 13:06:24,468] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:06:24,479] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:06:24,605] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:06:24,633] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:06:24,639] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.175 seconds
[2020-07-18 13:07:22,523] {scheduler_job.py:153} INFO - Started process (PID=55548) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:07:22,530] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:07:22,530] {logging_mixin.py:112} INFO - [2020-07-18 13:07:22,530] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:07:22,539] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:07:22,769] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:07:22,784] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:07:22,787] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.264 seconds
[2020-07-18 13:08:20,571] {scheduler_job.py:153} INFO - Started process (PID=56547) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:08:20,574] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:08:20,575] {logging_mixin.py:112} INFO - [2020-07-18 13:08:20,575] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:08:20,584] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:08:20,705] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:08:20,723] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:08:20,727] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.155 seconds
[2020-07-18 13:09:18,636] {scheduler_job.py:153} INFO - Started process (PID=57549) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:09:18,639] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:09:18,640] {logging_mixin.py:112} INFO - [2020-07-18 13:09:18,640] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:09:18,650] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:09:18,826] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:09:18,853] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:09:18,859] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.223 seconds
[2020-07-18 13:10:16,703] {scheduler_job.py:153} INFO - Started process (PID=58393) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:10:16,708] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:10:16,709] {logging_mixin.py:112} INFO - [2020-07-18 13:10:16,709] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:10:16,722] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:10:17,068] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:10:17,084] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:10:17,087] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.384 seconds
[2020-07-18 13:11:14,750] {scheduler_job.py:153} INFO - Started process (PID=59414) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:11:14,754] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:11:14,754] {logging_mixin.py:112} INFO - [2020-07-18 13:11:14,754] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:11:14,765] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:11:14,961] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:11:14,990] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 07:40:20.359788+00:00: manual__2020-07-18T07:40:20.359788+00:00, externally triggered: True>
[2020-07-18 13:11:15,021] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:11:15,029] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 07:40:20.359788+00:00 [scheduled]> in ORM
[2020-07-18 13:11:15,039] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.csv_to_db2 2020-07-18 07:40:20.359788+00:00 [scheduled]> in ORM
[2020-07-18 13:11:15,047] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 07:40:20.359788+00:00 [scheduled]> in ORM
[2020-07-18 13:11:15,196] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.446 seconds
[2020-07-18 13:12:49,511] {scheduler_job.py:153} INFO - Started process (PID=61118) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:12:49,515] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:12:49,515] {logging_mixin.py:112} INFO - [2020-07-18 13:12:49,515] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:12:49,525] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:12:49,694] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:12:49,709] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 07:40:20.359788+00:00: manual__2020-07-18T07:40:20.359788+00:00, externally triggered: True>
[2020-07-18 13:12:49,720] {logging_mixin.py:112} INFO - [2020-07-18 13:12:49,720] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 07:40:20.359788+00:00: manual__2020-07-18T07:40:20.359788+00:00, externally triggered: True> successful
[2020-07-18 13:12:49,821] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:12:49,829] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.318 seconds
[2020-07-18 13:13:47,563] {scheduler_job.py:153} INFO - Started process (PID=62018) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:13:47,567] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:13:47,567] {logging_mixin.py:112} INFO - [2020-07-18 13:13:47,567] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:13:47,575] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:13:47,832] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:13:47,847] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:13:47,850] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.287 seconds
[2020-07-18 13:18:38,366] {scheduler_job.py:153} INFO - Started process (PID=63224) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:18:38,379] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:18:38,380] {logging_mixin.py:112} INFO - [2020-07-18 13:18:38,380] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:18:38,425] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:18:38,693] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:18:38,785] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:18:38,798] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.432 seconds
[2020-07-18 13:19:37,128] {scheduler_job.py:153} INFO - Started process (PID=64274) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:19:37,135] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:19:37,136] {logging_mixin.py:112} INFO - [2020-07-18 13:19:37,136] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:19:37,156] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:19:37,309] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:19:37,339] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:19:37,342] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.214 seconds
[2020-07-18 13:20:35,703] {scheduler_job.py:153} INFO - Started process (PID=65336) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:20:35,707] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:20:35,707] {logging_mixin.py:112} INFO - [2020-07-18 13:20:35,707] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:20:35,720] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:20:36,034] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:20:36,053] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:20:36,057] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.354 seconds
[2020-07-18 13:21:33,821] {scheduler_job.py:153} INFO - Started process (PID=66422) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:21:33,837] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:21:33,842] {logging_mixin.py:112} INFO - [2020-07-18 13:21:33,842] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:21:33,904] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:21:34,124] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:21:34,213] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:21:34,229] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.408 seconds
[2020-07-18 13:22:31,826] {scheduler_job.py:153} INFO - Started process (PID=67719) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:22:31,832] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:22:31,832] {logging_mixin.py:112} INFO - [2020-07-18 13:22:31,832] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:22:31,846] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:22:31,960] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:22:31,977] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:22:31,980] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.155 seconds
[2020-07-18 13:23:30,171] {scheduler_job.py:153} INFO - Started process (PID=68662) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:23:30,182] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:23:30,183] {logging_mixin.py:112} INFO - [2020-07-18 13:23:30,183] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:23:30,199] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:23:30,381] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:23:30,420] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:23:30,426] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.255 seconds
[2020-07-18 13:24:27,938] {scheduler_job.py:153} INFO - Started process (PID=69881) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:24:27,941] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:24:27,942] {logging_mixin.py:112} INFO - [2020-07-18 13:24:27,942] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:24:27,957] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:24:28,066] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:24:28,085] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:24:28,088] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.150 seconds
[2020-07-18 13:25:26,003] {scheduler_job.py:153} INFO - Started process (PID=70972) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:25:26,007] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:25:26,008] {logging_mixin.py:112} INFO - [2020-07-18 13:25:26,007] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:25:26,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:25:26,995] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:25:27,012] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:25:27,015] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.011 seconds
[2020-07-18 13:26:24,063] {scheduler_job.py:153} INFO - Started process (PID=72013) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:26:24,066] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:26:24,067] {logging_mixin.py:112} INFO - [2020-07-18 13:26:24,067] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:26:24,076] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:26:24,414] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:26:24,430] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:26:24,433] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.370 seconds
[2020-07-18 13:27:22,135] {scheduler_job.py:153} INFO - Started process (PID=72915) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:27:22,139] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:27:22,139] {logging_mixin.py:112} INFO - [2020-07-18 13:27:22,139] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:27:22,148] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:27:22,285] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:27:22,300] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:27:22,303] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.168 seconds
[2020-07-18 13:28:20,191] {scheduler_job.py:153} INFO - Started process (PID=73955) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:28:20,195] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:28:20,196] {logging_mixin.py:112} INFO - [2020-07-18 13:28:20,196] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:28:20,207] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:28:20,415] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:28:20,434] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:28:20,439] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.248 seconds
[2020-07-18 13:29:18,499] {scheduler_job.py:153} INFO - Started process (PID=74898) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:29:18,503] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:29:18,503] {logging_mixin.py:112} INFO - [2020-07-18 13:29:18,503] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:29:18,518] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:29:18,642] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:29:18,668] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:29:18,671] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.172 seconds
[2020-07-18 13:30:16,474] {scheduler_job.py:153} INFO - Started process (PID=76098) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:30:16,477] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:30:16,477] {logging_mixin.py:112} INFO - [2020-07-18 13:30:16,477] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:30:16,486] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:30:16,646] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:30:16,677] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:30:16,681] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.207 seconds
[2020-07-18 13:31:14,531] {scheduler_job.py:153} INFO - Started process (PID=77105) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:31:14,535] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:31:14,536] {logging_mixin.py:112} INFO - [2020-07-18 13:31:14,536] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:31:14,545] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:31:14,687] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:31:14,712] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:31:14,717] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.185 seconds
[2020-07-18 13:32:12,584] {scheduler_job.py:153} INFO - Started process (PID=78101) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:32:12,587] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:32:12,587] {logging_mixin.py:112} INFO - [2020-07-18 13:32:12,587] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:32:12,596] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:32:12,868] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:32:12,883] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:32:12,886] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.302 seconds
[2020-07-18 13:33:10,644] {scheduler_job.py:153} INFO - Started process (PID=79124) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:33:10,649] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:33:10,649] {logging_mixin.py:112} INFO - [2020-07-18 13:33:10,649] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:33:10,659] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:33:11,103] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:33:11,127] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:33:11,130] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.487 seconds
[2020-07-18 13:34:09,007] {scheduler_job.py:153} INFO - Started process (PID=80035) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:34:09,010] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:34:09,011] {logging_mixin.py:112} INFO - [2020-07-18 13:34:09,011] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:34:09,020] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:34:09,187] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:34:09,206] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:34:09,209] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.202 seconds
[2020-07-18 13:35:07,648] {scheduler_job.py:153} INFO - Started process (PID=81075) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:35:07,652] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:35:07,652] {logging_mixin.py:112} INFO - [2020-07-18 13:35:07,652] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:35:07,661] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:35:07,928] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:35:07,949] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:35:07,954] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.305 seconds
[2020-07-18 13:36:05,710] {scheduler_job.py:153} INFO - Started process (PID=81964) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:36:05,713] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:36:05,714] {logging_mixin.py:112} INFO - [2020-07-18 13:36:05,714] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:36:05,723] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:36:05,953] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:36:05,967] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:36:05,970] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.261 seconds
[2020-07-18 13:37:03,766] {scheduler_job.py:153} INFO - Started process (PID=82991) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:37:03,769] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:37:03,769] {logging_mixin.py:112} INFO - [2020-07-18 13:37:03,769] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:37:03,778] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:37:03,890] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:37:03,905] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:37:03,908] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.143 seconds
[2020-07-18 13:38:01,823] {scheduler_job.py:153} INFO - Started process (PID=83879) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:38:01,827] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:38:01,828] {logging_mixin.py:112} INFO - [2020-07-18 13:38:01,828] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:38:01,837] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:38:02,077] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:38:02,092] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:38:02,095] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.271 seconds
[2020-07-18 13:38:59,881] {scheduler_job.py:153} INFO - Started process (PID=84888) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:38:59,885] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:38:59,885] {logging_mixin.py:112} INFO - [2020-07-18 13:38:59,885] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:38:59,893] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:39:00,034] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:39:00,056] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:39:00,059] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.178 seconds
[2020-07-18 13:39:57,939] {scheduler_job.py:153} INFO - Started process (PID=85824) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:39:57,942] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:39:57,942] {logging_mixin.py:112} INFO - [2020-07-18 13:39:57,942] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:39:57,952] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:39:58,127] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:39:58,152] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:39:58,155] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.217 seconds
[2020-07-18 13:40:56,360] {scheduler_job.py:153} INFO - Started process (PID=86891) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:40:56,364] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:40:56,365] {logging_mixin.py:112} INFO - [2020-07-18 13:40:56,365] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:40:56,374] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:40:56,689] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:40:56,722] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:40:56,726] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.365 seconds
[2020-07-18 13:41:55,028] {scheduler_job.py:153} INFO - Started process (PID=87916) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:41:55,031] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:41:55,032] {logging_mixin.py:112} INFO - [2020-07-18 13:41:55,032] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:41:55,041] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:41:55,151] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:41:55,168] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:41:55,171] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.143 seconds
[2020-07-18 13:42:53,088] {scheduler_job.py:153} INFO - Started process (PID=88808) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:42:53,092] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:42:53,092] {logging_mixin.py:112} INFO - [2020-07-18 13:42:53,092] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:42:53,102] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:42:53,240] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:42:53,255] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:42:53,258] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.170 seconds
[2020-07-18 13:43:51,646] {scheduler_job.py:153} INFO - Started process (PID=89854) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:43:51,650] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:43:51,651] {logging_mixin.py:112} INFO - [2020-07-18 13:43:51,651] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:43:51,660] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:43:52,006] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:43:52,021] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:43:52,024] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.378 seconds
[2020-07-18 13:44:49,704] {scheduler_job.py:153} INFO - Started process (PID=90756) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:44:49,707] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:44:49,708] {logging_mixin.py:112} INFO - [2020-07-18 13:44:49,708] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:44:49,717] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:44:49,841] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:44:49,895] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:44:49,902] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.197 seconds
[2020-07-18 13:45:47,768] {scheduler_job.py:153} INFO - Started process (PID=91806) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:45:47,771] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:45:47,772] {logging_mixin.py:112} INFO - [2020-07-18 13:45:47,772] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:45:47,781] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:45:47,895] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:45:47,911] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:45:47,914] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.146 seconds
[2020-07-18 13:46:45,831] {scheduler_job.py:153} INFO - Started process (PID=92735) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:46:45,836] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:46:45,837] {logging_mixin.py:112} INFO - [2020-07-18 13:46:45,837] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:46:45,853] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:46:46,138] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:46:46,155] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:46:46,159] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.327 seconds
[2020-07-18 13:47:43,884] {scheduler_job.py:153} INFO - Started process (PID=93900) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:47:43,887] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:47:43,888] {logging_mixin.py:112} INFO - [2020-07-18 13:47:43,888] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:47:43,897] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:47:44,063] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:47:44,079] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:47:44,082] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.198 seconds
[2020-07-18 13:48:42,213] {scheduler_job.py:153} INFO - Started process (PID=94873) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:48:42,216] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:48:42,216] {logging_mixin.py:112} INFO - [2020-07-18 13:48:42,216] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:48:42,225] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:48:43,380] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:48:43,405] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:48:43,408] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.195 seconds
[2020-07-18 13:49:40,464] {scheduler_job.py:153} INFO - Started process (PID=95859) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:49:40,468] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:49:40,468] {logging_mixin.py:112} INFO - [2020-07-18 13:49:40,468] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:49:40,477] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:49:40,734] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:49:40,762] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:49:40,769] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.305 seconds
[2020-07-18 13:50:38,796] {scheduler_job.py:153} INFO - Started process (PID=96932) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:50:38,800] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:50:38,800] {logging_mixin.py:112} INFO - [2020-07-18 13:50:38,800] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:50:38,809] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:50:38,920] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:50:38,935] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:50:38,938] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.142 seconds
[2020-07-18 13:51:36,854] {scheduler_job.py:153} INFO - Started process (PID=97841) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:51:36,859] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:51:36,860] {logging_mixin.py:112} INFO - [2020-07-18 13:51:36,860] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:51:36,877] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:51:37,170] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:51:37,188] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:51:37,191] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.337 seconds
[2020-07-18 13:52:34,912] {scheduler_job.py:153} INFO - Started process (PID=98856) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:52:34,915] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:52:34,915] {logging_mixin.py:112} INFO - [2020-07-18 13:52:34,915] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:52:34,925] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:52:35,179] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:52:35,195] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:52:35,198] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.286 seconds
[2020-07-18 13:53:32,973] {scheduler_job.py:153} INFO - Started process (PID=99745) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:53:32,979] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:53:32,980] {logging_mixin.py:112} INFO - [2020-07-18 13:53:32,980] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:53:32,993] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:53:33,184] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:53:33,231] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:53:33,239] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.266 seconds
[2020-07-18 13:55:18,792] {scheduler_job.py:153} INFO - Started process (PID=101531) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:55:18,796] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:55:18,796] {logging_mixin.py:112} INFO - [2020-07-18 13:55:18,796] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:55:18,804] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:55:18,961] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:55:18,976] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 08:24:42.079299+00:00: manual__2020-07-18T08:24:42.079299+00:00, externally triggered: True>
[2020-07-18 13:55:18,989] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:55:18,993] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 08:24:42.079299+00:00 [scheduled]> in ORM
[2020-07-18 13:55:19,124] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.332 seconds
[2020-07-18 13:56:28,990] {scheduler_job.py:153} INFO - Started process (PID=102793) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:56:28,993] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:56:28,994] {logging_mixin.py:112} INFO - [2020-07-18 13:56:28,994] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:56:29,003] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:56:29,141] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:56:29,168] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 08:24:42.079299+00:00: manual__2020-07-18T08:24:42.079299+00:00, externally triggered: True>
[2020-07-18 13:56:29,178] {logging_mixin.py:112} INFO - [2020-07-18 13:56:29,178] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 08:24:42.079299+00:00: manual__2020-07-18T08:24:42.079299+00:00, externally triggered: True> successful
[2020-07-18 13:56:29,432] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:56:29,438] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.449 seconds
[2020-07-18 13:57:27,042] {scheduler_job.py:153} INFO - Started process (PID=103684) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:57:27,045] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:57:27,046] {logging_mixin.py:112} INFO - [2020-07-18 13:57:27,045] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:57:27,055] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:57:27,844] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:57:27,859] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:57:27,863] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.820 seconds
[2020-07-18 13:58:25,550] {scheduler_job.py:153} INFO - Started process (PID=104703) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:58:25,554] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:58:25,554] {logging_mixin.py:112} INFO - [2020-07-18 13:58:25,554] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:58:25,569] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:58:25,731] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:58:25,766] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:58:25,772] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.222 seconds
[2020-07-18 13:59:23,614] {scheduler_job.py:153} INFO - Started process (PID=105741) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:59:23,619] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 13:59:23,620] {logging_mixin.py:112} INFO - [2020-07-18 13:59:23,620] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:59:23,634] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 13:59:23,854] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 13:59:23,869] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 13:59:23,872] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.258 seconds
[2020-07-18 14:00:21,677] {scheduler_job.py:153} INFO - Started process (PID=106647) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:00:21,680] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:00:21,680] {logging_mixin.py:112} INFO - [2020-07-18 14:00:21,680] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:00:21,891] {logging_mixin.py:112} INFO - <class 'str'>
[2020-07-18 14:00:21,892] {logging_mixin.py:112} INFO - 123
[2020-07-18 14:00:21,899] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:00:22,014] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:00:22,037] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 08:29:53.412413+00:00: manual__2020-07-18T08:29:53.412413+00:00, externally triggered: True>
[2020-07-18 14:00:22,058] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:00:22,064] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 08:29:53.412413+00:00 [scheduled]> in ORM
[2020-07-18 14:00:22,192] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.515 seconds
[2020-07-18 14:01:32,961] {scheduler_job.py:153} INFO - Started process (PID=107889) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:01:32,964] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:01:32,964] {logging_mixin.py:112} INFO - [2020-07-18 14:01:32,964] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:01:33,029] {logging_mixin.py:112} INFO - <class 'str'>
[2020-07-18 14:01:33,029] {logging_mixin.py:112} INFO - 123
[2020-07-18 14:01:33,033] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:01:33,697] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:01:33,712] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 08:29:53.412413+00:00: manual__2020-07-18T08:29:53.412413+00:00, externally triggered: True>
[2020-07-18 14:01:33,721] {logging_mixin.py:112} INFO - [2020-07-18 14:01:33,721] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 08:29:53.412413+00:00: manual__2020-07-18T08:29:53.412413+00:00, externally triggered: True> successful
[2020-07-18 14:01:34,501] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:01:34,506] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.545 seconds
[2020-07-18 14:02:31,018] {scheduler_job.py:153} INFO - Started process (PID=108777) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:02:31,021] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:02:31,021] {logging_mixin.py:112} INFO - [2020-07-18 14:02:31,021] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:02:31,287] {logging_mixin.py:112} INFO - <class 'str'>
[2020-07-18 14:02:31,288] {logging_mixin.py:112} INFO - 123
[2020-07-18 14:02:31,294] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:02:31,413] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:02:31,428] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:02:31,431] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.413 seconds
[2020-07-18 14:03:29,075] {scheduler_job.py:153} INFO - Started process (PID=109819) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:03:29,078] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:03:29,079] {logging_mixin.py:112} INFO - [2020-07-18 14:03:29,079] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:03:29,151] {logging_mixin.py:112} INFO - <class 'str'>
[2020-07-18 14:03:29,158] {logging_mixin.py:112} INFO - 123
[2020-07-18 14:03:29,170] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:03:29,347] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:03:29,418] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:03:29,442] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.367 seconds
[2020-07-18 14:04:27,131] {scheduler_job.py:153} INFO - Started process (PID=110702) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:04:27,134] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:04:27,134] {logging_mixin.py:112} INFO - [2020-07-18 14:04:27,134] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:04:27,201] {logging_mixin.py:112} INFO - <class 'str'>
[2020-07-18 14:04:27,201] {logging_mixin.py:112} INFO - 123
[2020-07-18 14:04:27,207] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:04:27,362] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:04:27,378] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:04:27,381] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.250 seconds
[2020-07-18 14:05:25,327] {scheduler_job.py:153} INFO - Started process (PID=111746) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:05:25,332] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:05:25,332] {logging_mixin.py:112} INFO - [2020-07-18 14:05:25,332] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:05:25,453] {logging_mixin.py:112} INFO - <class 'str'>
[2020-07-18 14:05:25,454] {logging_mixin.py:112} INFO - 123
[2020-07-18 14:05:25,461] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:05:25,577] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:05:25,596] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:05:25,598] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.271 seconds
[2020-07-18 14:06:23,249] {scheduler_job.py:153} INFO - Started process (PID=112777) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:06:23,254] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:06:23,254] {logging_mixin.py:112} INFO - [2020-07-18 14:06:23,254] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:06:23,315] {logging_mixin.py:112} INFO - <class 'str'>
[2020-07-18 14:06:23,316] {logging_mixin.py:112} INFO - 123
[2020-07-18 14:06:23,320] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:06:23,438] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:06:23,483] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:06:23,488] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.239 seconds
[2020-07-18 14:07:21,315] {scheduler_job.py:153} INFO - Started process (PID=113668) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:07:21,319] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:07:21,319] {logging_mixin.py:112} INFO - [2020-07-18 14:07:21,319] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:07:21,463] {logging_mixin.py:112} INFO - [2020-07-18 14:07:21,415] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 9, in <module>
    db_name = Variable.get('db_name')
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable db_name does not exist'
[2020-07-18 14:07:21,463] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:07:21,569] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.255 seconds
[2020-07-18 14:08:20,861] {scheduler_job.py:153} INFO - Started process (PID=114713) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:08:20,864] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:08:20,865] {logging_mixin.py:112} INFO - [2020-07-18 14:08:20,864] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:08:21,090] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:08:21,248] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:08:21,289] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:08:21,381] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.520 seconds
[2020-07-18 14:09:18,978] {scheduler_job.py:153} INFO - Started process (PID=115611) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:09:18,985] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:09:18,986] {logging_mixin.py:112} INFO - [2020-07-18 14:09:18,986] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:09:19,153] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:09:19,332] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:09:19,351] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:09:19,355] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.377 seconds
[2020-07-18 14:10:17,036] {scheduler_job.py:153} INFO - Started process (PID=116606) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:10:17,040] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:10:17,040] {logging_mixin.py:112} INFO - [2020-07-18 14:10:17,040] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:10:17,105] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:10:17,301] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:10:17,315] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 08:39:58.450641+00:00: manual__2020-07-18T08:39:58.450641+00:00, externally triggered: True>
[2020-07-18 14:10:17,328] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:10:17,332] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 08:39:58.450641+00:00 [scheduled]> in ORM
[2020-07-18 14:10:17,534] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.498 seconds
[2020-07-18 14:11:28,044] {scheduler_job.py:153} INFO - Started process (PID=117762) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:11:28,049] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:11:28,049] {logging_mixin.py:112} INFO - [2020-07-18 14:11:28,049] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:11:28,135] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:11:28,273] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:11:28,294] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 08:39:58.450641+00:00: manual__2020-07-18T08:39:58.450641+00:00, externally triggered: True>
[2020-07-18 14:11:28,307] {logging_mixin.py:112} INFO - [2020-07-18 14:11:28,307] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 08:39:58.450641+00:00: manual__2020-07-18T08:39:58.450641+00:00, externally triggered: True> successful
[2020-07-18 14:11:28,525] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 08:41:20.496132+00:00: manual__2020-07-18T08:41:20.496132+00:00, externally triggered: True>
[2020-07-18 14:11:28,563] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:11:28,568] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 08:41:20.496132+00:00 [scheduled]> in ORM
[2020-07-18 14:11:28,751] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.706 seconds
[2020-07-18 14:12:39,485] {scheduler_job.py:153} INFO - Started process (PID=118984) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:12:39,491] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:12:39,492] {logging_mixin.py:112} INFO - [2020-07-18 14:12:39,491] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:12:39,596] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:12:39,777] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:12:39,805] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 08:41:20.496132+00:00: manual__2020-07-18T08:41:20.496132+00:00, externally triggered: True>
[2020-07-18 14:12:39,826] {logging_mixin.py:112} INFO - [2020-07-18 14:12:39,826] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 08:41:20.496132+00:00: manual__2020-07-18T08:41:20.496132+00:00, externally triggered: True> successful
[2020-07-18 14:12:39,918] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:12:39,923] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.438 seconds
[2020-07-18 14:13:37,555] {scheduler_job.py:153} INFO - Started process (PID=120006) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:13:37,559] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:13:37,560] {logging_mixin.py:112} INFO - [2020-07-18 14:13:37,560] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:13:37,808] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:13:37,924] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:13:37,939] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 08:43:05.930380+00:00: manual__2020-07-18T08:43:05.930380+00:00, externally triggered: True>
[2020-07-18 14:13:37,952] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:13:37,955] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 08:43:05.930380+00:00 [scheduled]> in ORM
[2020-07-18 14:13:38,298] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.743 seconds
[2020-07-18 14:14:47,181] {scheduler_job.py:153} INFO - Started process (PID=121069) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:14:47,185] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:14:47,186] {logging_mixin.py:112} INFO - [2020-07-18 14:14:47,186] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:14:47,304] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:14:47,429] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:14:47,457] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 08:43:05.930380+00:00: manual__2020-07-18T08:43:05.930380+00:00, externally triggered: True>
[2020-07-18 14:14:47,473] {logging_mixin.py:112} INFO - [2020-07-18 14:14:47,473] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 08:43:05.930380+00:00: manual__2020-07-18T08:43:05.930380+00:00, externally triggered: True> successful
[2020-07-18 14:14:47,569] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:14:47,575] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.394 seconds
[2020-07-18 14:15:45,297] {scheduler_job.py:153} INFO - Started process (PID=122125) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:15:45,300] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:15:45,301] {logging_mixin.py:112} INFO - [2020-07-18 14:15:45,301] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:15:45,560] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:15:45,675] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:15:45,690] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:15:45,693] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.396 seconds
[2020-07-18 14:16:43,360] {scheduler_job.py:153} INFO - Started process (PID=123032) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:16:43,364] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:16:43,364] {logging_mixin.py:112} INFO - [2020-07-18 14:16:43,364] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:16:43,435] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:16:43,541] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:16:43,557] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:16:43,560] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.200 seconds
[2020-07-18 14:17:41,418] {scheduler_job.py:153} INFO - Started process (PID=124044) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:17:41,421] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:17:41,421] {logging_mixin.py:112} INFO - [2020-07-18 14:17:41,421] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:17:41,501] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:17:41,758] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:17:41,784] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:17:41,788] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.370 seconds
[2020-07-18 14:18:39,611] {scheduler_job.py:153} INFO - Started process (PID=125092) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:18:39,614] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 14:18:39,614] {logging_mixin.py:112} INFO - [2020-07-18 14:18:39,614] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:18:39,683] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 14:18:39,785] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 14:18:39,800] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 08:48:05.564283+00:00: manual__2020-07-18T08:48:05.564283+00:00, externally triggered: True>
[2020-07-18 14:18:39,815] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 14:18:39,819] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 08:48:05.564283+00:00 [scheduled]> in ORM
[2020-07-18 14:18:39,939] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.328 seconds
[2020-07-18 16:40:38,227] {scheduler_job.py:153} INFO - Started process (PID=132804) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:40:38,230] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:40:38,230] {logging_mixin.py:112} INFO - [2020-07-18 16:40:38,230] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:40:38,455] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:40:38,640] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:40:38,655] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 08:48:05.564283+00:00: manual__2020-07-18T08:48:05.564283+00:00, externally triggered: True>
[2020-07-18 16:40:38,664] {logging_mixin.py:112} INFO - [2020-07-18 16:40:38,664] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 08:48:05.564283+00:00: manual__2020-07-18T08:48:05.564283+00:00, externally triggered: True> successful
[2020-07-18 16:40:38,771] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:40:38,777] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.550 seconds
[2020-07-18 16:41:36,291] {scheduler_job.py:153} INFO - Started process (PID=133648) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:41:36,293] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:41:36,294] {logging_mixin.py:112} INFO - [2020-07-18 16:41:36,294] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:41:36,358] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:41:36,520] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:41:36,535] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:41:36,537] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.247 seconds
[2020-07-18 16:42:34,348] {scheduler_job.py:153} INFO - Started process (PID=134523) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:42:34,352] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:42:34,353] {logging_mixin.py:112} INFO - [2020-07-18 16:42:34,352] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:42:34,534] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:42:34,645] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:42:34,665] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:42:34,668] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.320 seconds
[2020-07-18 16:43:32,540] {scheduler_job.py:153} INFO - Started process (PID=135434) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:43:32,543] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:43:32,544] {logging_mixin.py:112} INFO - [2020-07-18 16:43:32,544] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:43:32,635] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:43:32,753] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:43:32,768] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:43:32,771] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.231 seconds
[2020-07-18 16:44:30,464] {scheduler_job.py:153} INFO - Started process (PID=136355) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:44:30,468] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:44:30,469] {logging_mixin.py:112} INFO - [2020-07-18 16:44:30,468] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:44:30,540] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:44:30,657] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:44:30,673] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:44:30,677] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.213 seconds
[2020-07-18 16:45:28,516] {scheduler_job.py:153} INFO - Started process (PID=137195) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:45:28,520] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:45:28,521] {logging_mixin.py:112} INFO - [2020-07-18 16:45:28,520] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:45:28,588] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:45:28,727] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:45:28,743] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:45:28,746] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.231 seconds
[2020-07-18 16:46:26,576] {scheduler_job.py:153} INFO - Started process (PID=138073) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:46:26,580] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:46:26,581] {logging_mixin.py:112} INFO - [2020-07-18 16:46:26,580] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:46:26,830] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:46:26,944] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:46:26,970] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:46:26,973] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.397 seconds
[2020-07-18 16:47:24,635] {scheduler_job.py:153} INFO - Started process (PID=138925) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:47:24,638] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:47:24,639] {logging_mixin.py:112} INFO - [2020-07-18 16:47:24,639] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:47:24,702] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:47:24,920] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:47:24,957] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:16:59.697286+00:00: manual__2020-07-18T11:16:59.697286+00:00, externally triggered: True>
[2020-07-18 16:47:24,985] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:47:24,993] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 11:16:59.697286+00:00 [scheduled]> in ORM
[2020-07-18 16:47:24,998] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.csv_to_db2 2020-07-18 11:16:59.697286+00:00 [scheduled]> in ORM
[2020-07-18 16:47:25,005] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 11:16:59.697286+00:00 [scheduled]> in ORM
[2020-07-18 16:47:25,168] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.533 seconds
[2020-07-18 16:48:59,611] {scheduler_job.py:153} INFO - Started process (PID=140518) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:48:59,615] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:48:59,615] {logging_mixin.py:112} INFO - [2020-07-18 16:48:59,615] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:48:59,726] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:48:59,862] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:48:59,884] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:16:59.697286+00:00: manual__2020-07-18T11:16:59.697286+00:00, externally triggered: True>
[2020-07-18 16:48:59,904] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:48:59,909] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 11:16:59.697286+00:00 [scheduled]> in ORM
[2020-07-18 16:49:00,025] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.414 seconds
[2020-07-18 16:50:09,320] {scheduler_job.py:153} INFO - Started process (PID=141651) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:50:09,323] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:50:09,323] {logging_mixin.py:112} INFO - [2020-07-18 16:50:09,323] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:50:09,386] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:50:09,554] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:50:09,575] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:16:59.697286+00:00: manual__2020-07-18T11:16:59.697286+00:00, externally triggered: True>
[2020-07-18 16:50:09,584] {logging_mixin.py:112} INFO - [2020-07-18 16:50:09,584] {dagrun.py:309} INFO - Marking run <DagRun storing_data @ 2020-07-18 11:16:59.697286+00:00: manual__2020-07-18T11:16:59.697286+00:00, externally triggered: True> failed
[2020-07-18 16:50:09,753] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:50:09,758] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.438 seconds
[2020-07-18 16:51:07,395] {scheduler_job.py:153} INFO - Started process (PID=142700) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:51:07,399] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:51:07,400] {logging_mixin.py:112} INFO - [2020-07-18 16:51:07,399] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:51:07,737] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:51:07,925] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:51:07,999] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:51:08,004] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.609 seconds
[2020-07-18 16:52:05,727] {scheduler_job.py:153} INFO - Started process (PID=143727) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:52:05,733] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:52:05,734] {logging_mixin.py:112} INFO - [2020-07-18 16:52:05,734] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:52:06,183] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:52:06,324] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:52:06,349] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:52:06,354] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.627 seconds
[2020-07-18 16:53:03,777] {scheduler_job.py:153} INFO - Started process (PID=144639) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:53:03,781] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:53:03,782] {logging_mixin.py:112} INFO - [2020-07-18 16:53:03,782] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:53:03,847] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:53:03,964] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:53:03,979] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:22:10.434824+00:00: manual__2020-07-18T11:22:10.434824+00:00, externally triggered: True>
[2020-07-18 16:53:03,993] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:53:03,999] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 11:22:10.434824+00:00 [scheduled]> in ORM
[2020-07-18 16:53:04,005] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.csv_to_db2 2020-07-18 11:22:10.434824+00:00 [scheduled]> in ORM
[2020-07-18 16:53:04,011] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 11:22:10.434824+00:00 [scheduled]> in ORM
[2020-07-18 16:53:04,164] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.387 seconds
[2020-07-18 16:54:41,089] {scheduler_job.py:153} INFO - Started process (PID=146372) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:54:41,094] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:54:41,095] {logging_mixin.py:112} INFO - [2020-07-18 16:54:41,095] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:54:41,165] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:54:41,271] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:54:41,286] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:22:10.434824+00:00: manual__2020-07-18T11:22:10.434824+00:00, externally triggered: True>
[2020-07-18 16:54:41,300] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:54:41,303] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 11:22:10.434824+00:00 [scheduled]> in ORM
[2020-07-18 16:54:41,428] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.339 seconds
[2020-07-18 16:55:50,822] {scheduler_job.py:153} INFO - Started process (PID=147639) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:55:50,826] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:55:50,826] {logging_mixin.py:112} INFO - [2020-07-18 16:55:50,826] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:55:51,041] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:55:51,323] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:55:51,344] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:22:10.434824+00:00: manual__2020-07-18T11:22:10.434824+00:00, externally triggered: True>
[2020-07-18 16:55:51,349] {logging_mixin.py:112} INFO - [2020-07-18 16:55:51,349] {dagrun.py:374} WARNING - Failed to get task '<TaskInstance: storing_data.db1_to_csv 2020-07-18 11:22:10.434824+00:00 [failed]>' for dag '<DAG: storing_data>'. Marking it as removed.
[2020-07-18 16:55:51,349] {logging_mixin.py:112} INFO - [2020-07-18 16:55:51,349] {dagrun.py:374} WARNING - Failed to get task '<TaskInstance: storing_data.csv_to_db2 2020-07-18 11:22:10.434824+00:00 [success]>' for dag '<DAG: storing_data>'. Marking it as removed.
[2020-07-18 16:55:51,534] {logging_mixin.py:112} INFO - [2020-07-18 16:55:51,534] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 11:22:10.434824+00:00: manual__2020-07-18T11:22:10.434824+00:00, externally triggered: True> successful
[2020-07-18 16:55:51,640] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:25:50.702983+00:00: manual__2020-07-18T11:25:50.702983+00:00, externally triggered: True>
[2020-07-18 16:55:51,654] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:55:51,659] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 11:25:50.702983+00:00 [scheduled]> in ORM
[2020-07-18 16:55:51,798] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.976 seconds
[2020-07-18 16:57:00,821] {scheduler_job.py:153} INFO - Started process (PID=148873) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:57:00,825] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:57:00,826] {logging_mixin.py:112} INFO - [2020-07-18 16:57:00,825] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:57:00,893] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:57:01,028] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:57:01,061] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:25:50.702983+00:00: manual__2020-07-18T11:25:50.702983+00:00, externally triggered: True>
[2020-07-18 16:57:01,088] {logging_mixin.py:112} INFO - [2020-07-18 16:57:01,088] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 11:25:50.702983+00:00: manual__2020-07-18T11:25:50.702983+00:00, externally triggered: True> successful
[2020-07-18 16:57:01,242] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:57:01,248] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.427 seconds
[2020-07-18 16:57:58,895] {scheduler_job.py:153} INFO - Started process (PID=149861) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:57:58,898] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:57:58,898] {logging_mixin.py:112} INFO - [2020-07-18 16:57:58,898] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:57:59,195] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:57:59,309] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:57:59,338] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:57:59,342] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.447 seconds
[2020-07-18 16:58:57,521] {scheduler_job.py:153} INFO - Started process (PID=150900) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:58:57,524] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:58:57,524] {logging_mixin.py:112} INFO - [2020-07-18 16:58:57,524] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:58:57,592] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:58:57,738] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:58:57,772] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:58:57,777] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.257 seconds
[2020-07-18 16:59:55,580] {scheduler_job.py:153} INFO - Started process (PID=151767) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:59:55,584] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 16:59:55,585] {logging_mixin.py:112} INFO - [2020-07-18 16:59:55,585] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:59:55,683] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 16:59:56,661] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 16:59:56,695] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:29:21.864769+00:00: manual__2020-07-18T11:29:21.864769+00:00, externally triggered: True>
[2020-07-18 16:59:57,061] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 16:59:57,069] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 11:29:21.864769+00:00 [scheduled]> in ORM
[2020-07-18 16:59:57,208] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.628 seconds
[2020-07-18 17:01:06,677] {scheduler_job.py:153} INFO - Started process (PID=153019) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:01:06,683] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:01:06,684] {logging_mixin.py:112} INFO - [2020-07-18 17:01:06,684] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:01:06,838] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:01:07,081] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:01:07,096] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:29:21.864769+00:00: manual__2020-07-18T11:29:21.864769+00:00, externally triggered: True>
[2020-07-18 17:01:07,106] {logging_mixin.py:112} INFO - [2020-07-18 17:01:07,105] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 11:29:21.864769+00:00: manual__2020-07-18T11:29:21.864769+00:00, externally triggered: True> successful
[2020-07-18 17:01:07,238] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:01:07,240] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.563 seconds
[2020-07-18 17:02:04,719] {scheduler_job.py:153} INFO - Started process (PID=153952) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:02:04,722] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:02:04,723] {logging_mixin.py:112} INFO - [2020-07-18 17:02:04,723] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:02:05,972] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:02:06,357] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:02:06,391] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:02:06,420] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.702 seconds
[2020-07-18 17:03:02,922] {scheduler_job.py:153} INFO - Started process (PID=154996) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:03:02,927] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:03:02,927] {logging_mixin.py:112} INFO - [2020-07-18 17:03:02,927] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:03:02,991] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:03:03,137] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:03:03,153] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:03:03,156] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.233 seconds
[2020-07-18 17:04:00,976] {scheduler_job.py:153} INFO - Started process (PID=156073) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:04:00,980] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:04:00,980] {logging_mixin.py:112} INFO - [2020-07-18 17:04:00,980] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:04:01,064] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:04:01,263] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:04:01,278] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:04:01,281] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.305 seconds
[2020-07-18 17:04:59,249] {scheduler_job.py:153} INFO - Started process (PID=156993) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:04:59,253] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:04:59,253] {logging_mixin.py:112} INFO - [2020-07-18 17:04:59,253] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:04:59,315] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:04:59,434] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:04:59,450] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:04:59,452] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.203 seconds
[2020-07-18 17:05:57,103] {scheduler_job.py:153} INFO - Started process (PID=158014) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:05:57,106] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:05:57,106] {logging_mixin.py:112} INFO - [2020-07-18 17:05:57,106] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:05:57,176] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:05:57,315] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:05:57,349] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:05:57,355] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.253 seconds
[2020-07-18 17:06:55,389] {scheduler_job.py:153} INFO - Started process (PID=158904) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:06:55,393] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:06:55,393] {logging_mixin.py:112} INFO - [2020-07-18 17:06:55,393] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:06:55,465] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:06:55,590] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:06:55,609] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:06:55,613] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.224 seconds
[2020-07-18 17:07:53,761] {scheduler_job.py:153} INFO - Started process (PID=159987) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:07:53,763] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:07:53,764] {logging_mixin.py:112} INFO - [2020-07-18 17:07:53,764] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:07:54,968] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:07:55,380] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:07:55,401] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:07:55,404] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.643 seconds
[2020-07-18 17:08:51,976] {scheduler_job.py:153} INFO - Started process (PID=160859) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:08:51,982] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:08:51,982] {logging_mixin.py:112} INFO - [2020-07-18 17:08:51,982] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:08:52,055] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:08:52,203] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:08:52,226] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:37:59.216823+00:00: manual__2020-07-18T11:37:59.216823+00:00, externally triggered: True>
[2020-07-18 17:08:52,246] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:08:52,252] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 11:37:59.216823+00:00 [scheduled]> in ORM
[2020-07-18 17:08:52,391] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.415 seconds
[2020-07-18 17:10:01,983] {scheduler_job.py:153} INFO - Started process (PID=162090) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:10:01,987] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:10:01,987] {logging_mixin.py:112} INFO - [2020-07-18 17:10:01,987] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:10:02,099] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:10:02,266] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:10:02,296] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:37:59.216823+00:00: manual__2020-07-18T11:37:59.216823+00:00, externally triggered: True>
[2020-07-18 17:10:02,315] {logging_mixin.py:112} INFO - [2020-07-18 17:10:02,315] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 11:37:59.216823+00:00: manual__2020-07-18T11:37:59.216823+00:00, externally triggered: True> successful
[2020-07-18 17:10:02,472] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:10:02,478] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.495 seconds
[2020-07-18 17:11:00,038] {scheduler_job.py:153} INFO - Started process (PID=163142) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:11:00,041] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:11:00,042] {logging_mixin.py:112} INFO - [2020-07-18 17:11:00,042] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:11:00,269] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:11:00,379] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:11:00,396] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:11:00,401] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.362 seconds
[2020-07-18 17:11:58,099] {scheduler_job.py:153} INFO - Started process (PID=164045) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:11:58,102] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:11:58,102] {logging_mixin.py:112} INFO - [2020-07-18 17:11:58,102] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:11:58,166] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:11:58,259] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:11:58,274] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:41:13.426829+00:00: manual__2020-07-18T11:41:13.426829+00:00, externally triggered: True>
[2020-07-18 17:11:58,287] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:11:58,291] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 11:41:13.426829+00:00 [scheduled]> in ORM
[2020-07-18 17:11:58,415] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.316 seconds
[2020-07-18 17:13:08,582] {scheduler_job.py:153} INFO - Started process (PID=165274) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:13:08,589] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:13:08,589] {logging_mixin.py:112} INFO - [2020-07-18 17:13:08,589] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:13:08,667] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:13:08,798] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:13:08,814] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:41:13.426829+00:00: manual__2020-07-18T11:41:13.426829+00:00, externally triggered: True>
[2020-07-18 17:13:08,829] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:13:08,834] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 11:41:13.426829+00:00 [scheduled]> in ORM
[2020-07-18 17:13:08,974] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.392 seconds
[2020-07-18 17:14:18,566] {scheduler_job.py:153} INFO - Started process (PID=166402) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:14:18,570] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:14:18,571] {logging_mixin.py:112} INFO - [2020-07-18 17:14:18,571] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:14:18,638] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:14:18,751] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:14:18,766] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 11:41:13.426829+00:00: manual__2020-07-18T11:41:13.426829+00:00, externally triggered: True>
[2020-07-18 17:14:18,775] {logging_mixin.py:112} INFO - [2020-07-18 17:14:18,774] {dagrun.py:309} INFO - Marking run <DagRun storing_data @ 2020-07-18 11:41:13.426829+00:00: manual__2020-07-18T11:41:13.426829+00:00, externally triggered: True> failed
[2020-07-18 17:14:18,892] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:14:18,898] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.332 seconds
[2020-07-18 17:15:16,626] {scheduler_job.py:153} INFO - Started process (PID=167424) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:15:16,628] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:15:16,629] {logging_mixin.py:112} INFO - [2020-07-18 17:15:16,629] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:15:16,938] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:15:17,053] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:15:17,068] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:15:17,070] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.445 seconds
[2020-07-18 17:16:14,686] {scheduler_job.py:153} INFO - Started process (PID=168375) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:16:14,758] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:16:14,758] {logging_mixin.py:112} INFO - [2020-07-18 17:16:14,758] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:16:14,825] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:16:15,799] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:16:15,814] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:16:15,816] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.130 seconds
[2020-07-18 17:17:12,746] {scheduler_job.py:153} INFO - Started process (PID=169423) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:17:12,748] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:17:12,749] {logging_mixin.py:112} INFO - [2020-07-18 17:17:12,749] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:17:12,811] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:17:12,936] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:17:12,952] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:17:12,954] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.209 seconds
[2020-07-18 17:18:10,801] {scheduler_job.py:153} INFO - Started process (PID=170587) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:18:10,804] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:18:10,805] {logging_mixin.py:112} INFO - [2020-07-18 17:18:10,804] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:18:11,109] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:18:11,248] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:18:11,275] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:18:11,279] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.478 seconds
[2020-07-18 17:19:08,855] {scheduler_job.py:153} INFO - Started process (PID=171585) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:19:08,859] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:19:08,859] {logging_mixin.py:112} INFO - [2020-07-18 17:19:08,859] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:19:08,937] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:19:09,074] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:19:09,091] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:19:09,093] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.239 seconds
[2020-07-18 17:20:06,915] {scheduler_job.py:153} INFO - Started process (PID=172618) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:20:06,918] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:20:06,918] {logging_mixin.py:112} INFO - [2020-07-18 17:20:06,918] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:20:06,982] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:20:07,120] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:20:07,135] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:20:07,138] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.223 seconds
[2020-07-18 17:21:04,966] {scheduler_job.py:153} INFO - Started process (PID=173516) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:21:04,969] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:21:04,970] {logging_mixin.py:112} INFO - [2020-07-18 17:21:04,970] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:21:05,178] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:21:05,360] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:21:05,376] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:21:05,379] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.412 seconds
[2020-07-18 17:22:03,024] {scheduler_job.py:153} INFO - Started process (PID=174522) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:22:03,028] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:22:03,028] {logging_mixin.py:112} INFO - [2020-07-18 17:22:03,028] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:22:03,105] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:22:03,232] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:22:03,249] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:22:03,252] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.228 seconds
[2020-07-18 17:23:01,080] {scheduler_job.py:153} INFO - Started process (PID=175454) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:23:01,085] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:23:01,085] {logging_mixin.py:112} INFO - [2020-07-18 17:23:01,085] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:23:01,150] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:23:01,276] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:23:01,292] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:23:01,294] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.214 seconds
[2020-07-18 17:23:59,776] {scheduler_job.py:153} INFO - Started process (PID=176474) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:23:59,779] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:23:59,779] {logging_mixin.py:112} INFO - [2020-07-18 17:23:59,779] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:23:59,842] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:23:59,955] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:23:59,971] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:23:59,973] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.198 seconds
[2020-07-18 17:24:57,187] {scheduler_job.py:153} INFO - Started process (PID=177345) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:24:57,191] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:24:57,191] {logging_mixin.py:112} INFO - [2020-07-18 17:24:57,191] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:24:57,255] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:24:57,430] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:24:57,459] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:24:57,464] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.277 seconds
[2020-07-18 17:25:55,418] {scheduler_job.py:153} INFO - Started process (PID=178357) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:25:55,422] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:25:55,423] {logging_mixin.py:112} INFO - [2020-07-18 17:25:55,423] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:25:55,487] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:25:55,584] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:25:55,604] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:25:55,607] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.189 seconds
[2020-07-18 17:26:53,483] {scheduler_job.py:153} INFO - Started process (PID=179363) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:26:53,488] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:26:53,489] {logging_mixin.py:112} INFO - [2020-07-18 17:26:53,489] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:26:53,903] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:26:54,022] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:26:54,041] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:26:54,046] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.563 seconds
[2020-07-18 17:27:51,534] {scheduler_job.py:153} INFO - Started process (PID=180264) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:27:51,540] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:27:51,541] {logging_mixin.py:112} INFO - [2020-07-18 17:27:51,541] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:27:51,604] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:27:51,727] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:27:51,742] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:27:51,745] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.211 seconds
[2020-07-18 17:28:49,597] {scheduler_job.py:153} INFO - Started process (PID=181269) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:28:49,600] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:28:49,601] {logging_mixin.py:112} INFO - [2020-07-18 17:28:49,601] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:28:49,668] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:28:49,888] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:28:49,904] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:28:49,906] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.309 seconds
[2020-07-18 17:29:47,652] {scheduler_job.py:153} INFO - Started process (PID=182151) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:29:47,655] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:29:47,655] {logging_mixin.py:112} INFO - [2020-07-18 17:29:47,655] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:29:47,981] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:29:48,107] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:29:48,126] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:29:48,129] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.477 seconds
[2020-07-18 17:30:45,851] {scheduler_job.py:153} INFO - Started process (PID=183128) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:30:45,856] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:30:45,857] {logging_mixin.py:112} INFO - [2020-07-18 17:30:45,857] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:30:45,923] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:30:46,031] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:30:46,046] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:00:27.311315+00:00: manual__2020-07-18T12:00:27.311315+00:00, externally triggered: True>
[2020-07-18 17:30:46,058] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:30:46,062] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 12:00:27.311315+00:00 [scheduled]> in ORM
[2020-07-18 17:30:46,197] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.346 seconds
[2020-07-18 17:35:29,188] {scheduler_job.py:153} INFO - Started process (PID=187611) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:35:29,191] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:35:29,192] {logging_mixin.py:112} INFO - [2020-07-18 17:35:29,192] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:35:29,305] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:35:29,511] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:35:29,538] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:00:27.311315+00:00: manual__2020-07-18T12:00:27.311315+00:00, externally triggered: True>
[2020-07-18 17:35:29,557] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:05:03.412679+00:00: manual__2020-07-18T12:05:03.412679+00:00, externally triggered: True>
[2020-07-18 17:35:29,577] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:35:29,581] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 12:00:27.311315+00:00 [scheduled]> in ORM
[2020-07-18 17:35:29,586] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 12:05:03.412679+00:00 [scheduled]> in ORM
[2020-07-18 17:35:29,706] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.518 seconds
[2020-07-18 17:40:17,741] {scheduler_job.py:153} INFO - Started process (PID=192344) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:40:17,745] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:40:17,746] {logging_mixin.py:112} INFO - [2020-07-18 17:40:17,746] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:40:17,911] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:40:18,030] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:40:18,057] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:00:27.311315+00:00: manual__2020-07-18T12:00:27.311315+00:00, externally triggered: True>
[2020-07-18 17:40:18,073] {logging_mixin.py:112} INFO - [2020-07-18 17:40:18,073] {dagrun.py:309} INFO - Marking run <DagRun storing_data @ 2020-07-18 12:00:27.311315+00:00: manual__2020-07-18T12:00:27.311315+00:00, externally triggered: True> failed
[2020-07-18 17:40:18,202] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:05:03.412679+00:00: manual__2020-07-18T12:05:03.412679+00:00, externally triggered: True>
[2020-07-18 17:40:18,214] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:09:55.480162+00:00: manual__2020-07-18T12:09:55.480162+00:00, externally triggered: True>
[2020-07-18 17:40:18,237] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:40:18,242] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 12:05:03.412679+00:00 [scheduled]> in ORM
[2020-07-18 17:40:18,251] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 12:09:55.480162+00:00 [scheduled]> in ORM
[2020-07-18 17:40:18,395] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.655 seconds
[2020-07-18 17:41:39,855] {scheduler_job.py:153} INFO - Started process (PID=193767) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:41:39,858] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:41:39,859] {logging_mixin.py:112} INFO - [2020-07-18 17:41:39,859] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:41:39,965] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:41:40,167] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:41:40,184] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:05:03.412679+00:00: manual__2020-07-18T12:05:03.412679+00:00, externally triggered: True>
[2020-07-18 17:41:40,193] {logging_mixin.py:112} INFO - [2020-07-18 17:41:40,193] {dagrun.py:309} INFO - Marking run <DagRun storing_data @ 2020-07-18 12:05:03.412679+00:00: manual__2020-07-18T12:05:03.412679+00:00, externally triggered: True> failed
[2020-07-18 17:41:40,364] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:09:55.480162+00:00: manual__2020-07-18T12:09:55.480162+00:00, externally triggered: True>
[2020-07-18 17:41:40,376] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:41:40,380] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 12:09:55.480162+00:00 [scheduled]> in ORM
[2020-07-18 17:41:40,544] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.689 seconds
[2020-07-18 17:42:49,632] {scheduler_job.py:153} INFO - Started process (PID=194989) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:42:49,636] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:42:49,637] {logging_mixin.py:112} INFO - [2020-07-18 17:42:49,637] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:42:49,699] {logging_mixin.py:112} INFO - [2020-07-18 17:42:49,697] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 11, in <module>
    mysql_host = Variable.get()
TypeError: get() missing 1 required positional argument: 'key'
[2020-07-18 17:42:49,699] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:42:49,825] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.192 seconds
[2020-07-18 17:43:47,809] {scheduler_job.py:153} INFO - Started process (PID=195876) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:43:47,811] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:43:47,812] {logging_mixin.py:112} INFO - [2020-07-18 17:43:47,812] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:43:48,060] {logging_mixin.py:112} INFO - [2020-07-18 17:43:48,058] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 11, in <module>
    mysql_host = Variable.get()
TypeError: get() missing 1 required positional argument: 'key'
[2020-07-18 17:43:48,060] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:43:48,152] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.344 seconds
[2020-07-18 17:44:45,871] {scheduler_job.py:153} INFO - Started process (PID=196884) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:44:45,877] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:44:45,878] {logging_mixin.py:112} INFO - [2020-07-18 17:44:45,878] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:44:45,976] {logging_mixin.py:112} INFO - [2020-07-18 17:44:45,974] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 11, in <module>
    mysql_host = Variable.get()
TypeError: get() missing 1 required positional argument: 'key'
[2020-07-18 17:44:45,976] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:44:46,069] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.198 seconds
[2020-07-18 17:45:43,931] {scheduler_job.py:153} INFO - Started process (PID=197743) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:45:43,936] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:45:43,938] {logging_mixin.py:112} INFO - [2020-07-18 17:45:43,938] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:45:44,000] {logging_mixin.py:112} INFO - [2020-07-18 17:45:43,998] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 11, in <module>
    mysql_host = Variable.get()
TypeError: get() missing 1 required positional argument: 'key'
[2020-07-18 17:45:44,000] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:45:44,114] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.184 seconds
[2020-07-18 17:46:43,195] {scheduler_job.py:153} INFO - Started process (PID=198771) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:46:43,199] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:46:43,199] {logging_mixin.py:112} INFO - [2020-07-18 17:46:43,199] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:46:43,267] {logging_mixin.py:112} INFO - [2020-07-18 17:46:43,264] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 11, in <module>
    mysql_host = Variable.get()
TypeError: get() missing 1 required positional argument: 'key'
[2020-07-18 17:46:43,267] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:46:43,338] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.143 seconds
[2020-07-18 17:47:40,191] {scheduler_job.py:153} INFO - Started process (PID=199609) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:47:40,196] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:47:40,196] {logging_mixin.py:112} INFO - [2020-07-18 17:47:40,196] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:47:40,270] {logging_mixin.py:112} INFO - [2020-07-18 17:47:40,268] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 11, in <module>
    mysql_host = Variable.get()
TypeError: get() missing 1 required positional argument: 'key'
[2020-07-18 17:47:40,270] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:47:40,427] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.236 seconds
[2020-07-18 17:48:39,591] {scheduler_job.py:153} INFO - Started process (PID=200649) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:48:39,594] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:48:39,595] {logging_mixin.py:112} INFO - [2020-07-18 17:48:39,594] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:48:39,714] {logging_mixin.py:112} INFO - [2020-07-18 17:48:39,711] {dagbag.py:239} ERROR - Failed to import: /home/bhakti/airflow/dags/task_3_bash_operator.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/bhakti/airflow/dags/task_3_bash_operator.py", line 11, in <module>
    mysql_host = Variable.get()
TypeError: get() missing 1 required positional argument: 'key'
[2020-07-18 17:48:39,714] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:48:39,857] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.266 seconds
[2020-07-18 17:49:37,878] {scheduler_job.py:153} INFO - Started process (PID=201633) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:49:37,881] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:49:37,881] {logging_mixin.py:112} INFO - [2020-07-18 17:49:37,881] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:49:38,022] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:49:38,626] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:49:38,731] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:09:55.480162+00:00: manual__2020-07-18T12:09:55.480162+00:00, externally triggered: True>
[2020-07-18 17:49:38,750] {logging_mixin.py:112} INFO - [2020-07-18 17:49:38,750] {dagrun.py:309} INFO - Marking run <DagRun storing_data @ 2020-07-18 12:09:55.480162+00:00: manual__2020-07-18T12:09:55.480162+00:00, externally triggered: True> failed
[2020-07-18 17:49:39,208] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:49:39,359] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.481 seconds
[2020-07-18 17:50:35,706] {scheduler_job.py:153} INFO - Started process (PID=202506) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:50:35,709] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:50:35,710] {logging_mixin.py:112} INFO - [2020-07-18 17:50:35,709] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:50:35,782] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:50:35,890] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:50:35,909] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:50:35,912] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.207 seconds
[2020-07-18 17:51:33,768] {scheduler_job.py:153} INFO - Started process (PID=203434) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:51:33,771] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:51:33,771] {logging_mixin.py:112} INFO - [2020-07-18 17:51:33,771] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:51:33,843] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:51:34,048] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:51:34,079] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:51:34,084] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.316 seconds
[2020-07-18 17:52:32,010] {scheduler_job.py:153} INFO - Started process (PID=204370) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:52:32,015] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:52:32,015] {logging_mixin.py:112} INFO - [2020-07-18 17:52:32,015] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:52:32,098] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:52:32,249] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:52:32,275] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:21:55.773671+00:00: manual__2020-07-18T12:21:55.773671+00:00, externally triggered: True>
[2020-07-18 17:52:32,293] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:52:32,299] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 12:21:55.773671+00:00 [scheduled]> in ORM
[2020-07-18 17:52:32,452] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.442 seconds
[2020-07-18 17:53:42,186] {scheduler_job.py:153} INFO - Started process (PID=205585) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:53:42,190] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:53:42,191] {logging_mixin.py:112} INFO - [2020-07-18 17:53:42,191] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:53:42,289] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:53:42,479] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:53:42,505] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:21:55.773671+00:00: manual__2020-07-18T12:21:55.773671+00:00, externally triggered: True>
[2020-07-18 17:53:42,519] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:53:42,523] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 12:21:55.773671+00:00 [scheduled]> in ORM
[2020-07-18 17:53:42,636] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.451 seconds
[2020-07-18 17:54:52,720] {scheduler_job.py:153} INFO - Started process (PID=206688) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:54:52,724] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:54:52,725] {logging_mixin.py:112} INFO - [2020-07-18 17:54:52,725] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:54:52,797] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:54:52,925] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:54:52,941] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:21:55.773671+00:00: manual__2020-07-18T12:21:55.773671+00:00, externally triggered: True>
[2020-07-18 17:54:52,950] {logging_mixin.py:112} INFO - [2020-07-18 17:54:52,950] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 12:21:55.773671+00:00: manual__2020-07-18T12:21:55.773671+00:00, externally triggered: True> successful
[2020-07-18 17:54:53,055] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:54:53,061] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.341 seconds
[2020-07-18 17:55:50,819] {scheduler_job.py:153} INFO - Started process (PID=207689) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:55:50,822] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:55:50,823] {logging_mixin.py:112} INFO - [2020-07-18 17:55:50,823] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:55:51,096] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:55:51,282] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:55:51,297] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:55:51,300] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.481 seconds
[2020-07-18 17:56:48,879] {scheduler_job.py:153} INFO - Started process (PID=208699) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:56:48,883] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:56:48,884] {logging_mixin.py:112} INFO - [2020-07-18 17:56:48,884] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:56:48,990] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:56:49,123] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:56:49,139] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:56:49,142] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.263 seconds
[2020-07-18 17:57:46,940] {scheduler_job.py:153} INFO - Started process (PID=209560) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:57:46,943] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:57:46,944] {logging_mixin.py:112} INFO - [2020-07-18 17:57:46,943] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:57:47,015] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:57:47,178] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:57:47,199] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:57:47,203] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.264 seconds
[2020-07-18 17:58:45,134] {scheduler_job.py:153} INFO - Started process (PID=210667) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:58:45,137] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:58:45,137] {logging_mixin.py:112} INFO - [2020-07-18 17:58:45,137] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:58:45,207] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:58:45,329] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:58:45,344] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:58:45,347] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.213 seconds
[2020-07-18 17:59:43,053] {scheduler_job.py:153} INFO - Started process (PID=211557) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:59:43,059] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 17:59:43,060] {logging_mixin.py:112} INFO - [2020-07-18 17:59:43,059] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:59:43,222] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 17:59:43,409] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 17:59:43,464] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 17:59:43,470] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.418 seconds
[2020-07-18 18:00:41,105] {scheduler_job.py:153} INFO - Started process (PID=212540) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:00:41,109] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:00:41,109] {logging_mixin.py:112} INFO - [2020-07-18 18:00:41,109] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:00:41,203] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:00:41,360] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:00:41,396] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:00:41,400] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.295 seconds
[2020-07-18 18:01:39,166] {scheduler_job.py:153} INFO - Started process (PID=213423) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:01:39,170] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:01:39,171] {logging_mixin.py:112} INFO - [2020-07-18 18:01:39,171] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:01:39,430] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:01:39,540] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:01:39,562] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:01:39,566] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.400 seconds
[2020-07-18 18:02:37,221] {scheduler_job.py:153} INFO - Started process (PID=214452) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:02:37,225] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:02:37,225] {logging_mixin.py:112} INFO - [2020-07-18 18:02:37,225] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:02:37,296] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:02:37,418] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:02:37,434] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:02:37,436] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.216 seconds
[2020-07-18 18:03:35,276] {scheduler_job.py:153} INFO - Started process (PID=215314) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:03:35,280] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:03:35,281] {logging_mixin.py:112} INFO - [2020-07-18 18:03:35,281] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:03:35,384] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:03:35,559] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:03:35,581] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:03:35,585] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.309 seconds
[2020-07-18 18:04:33,582] {scheduler_job.py:153} INFO - Started process (PID=216326) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:04:33,586] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:04:33,587] {logging_mixin.py:112} INFO - [2020-07-18 18:04:33,586] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:04:33,694] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:04:33,910] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:04:33,948] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:04:33,953] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.371 seconds
[2020-07-18 18:05:31,397] {scheduler_job.py:153} INFO - Started process (PID=217337) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:05:31,400] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:05:31,401] {logging_mixin.py:112} INFO - [2020-07-18 18:05:31,401] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:05:31,481] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:05:31,741] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:05:31,758] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:05:31,762] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.364 seconds
[2020-07-18 18:06:29,458] {scheduler_job.py:153} INFO - Started process (PID=218198) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:06:29,462] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:06:29,463] {logging_mixin.py:112} INFO - [2020-07-18 18:06:29,462] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:06:29,594] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:06:29,755] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:06:29,780] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:06:29,783] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.325 seconds
[2020-07-18 18:07:27,950] {scheduler_job.py:153} INFO - Started process (PID=219236) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:07:27,953] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:07:27,954] {logging_mixin.py:112} INFO - [2020-07-18 18:07:27,954] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:07:28,758] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:07:28,867] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:07:28,882] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:07:28,884] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.934 seconds
[2020-07-18 18:09:02,862] {scheduler_job.py:153} INFO - Started process (PID=220793) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:09:02,868] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:09:02,868] {logging_mixin.py:112} INFO - [2020-07-18 18:09:02,868] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:09:03,038] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:09:03,231] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:09:03,247] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:38:14.487969+00:00: manual__2020-07-18T12:38:14.487969+00:00, externally triggered: True>
[2020-07-18 18:09:03,264] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:09:03,268] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 12:38:14.487969+00:00 [scheduled]> in ORM
[2020-07-18 18:09:03,272] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.csv_to_db2 2020-07-18 12:38:14.487969+00:00 [scheduled]> in ORM
[2020-07-18 18:09:03,276] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 12:38:14.487969+00:00 [scheduled]> in ORM
[2020-07-18 18:09:03,494] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.632 seconds
[2020-07-18 18:10:38,351] {scheduler_job.py:153} INFO - Started process (PID=222270) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:10:38,355] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:10:38,355] {logging_mixin.py:112} INFO - [2020-07-18 18:10:38,355] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:10:38,462] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:10:38,573] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:10:38,588] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:38:14.487969+00:00: manual__2020-07-18T12:38:14.487969+00:00, externally triggered: True>
[2020-07-18 18:10:38,598] {logging_mixin.py:112} INFO - [2020-07-18 18:10:38,598] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 12:38:14.487969+00:00: manual__2020-07-18T12:38:14.487969+00:00, externally triggered: True> successful
[2020-07-18 18:10:38,707] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:10:38,715] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.363 seconds
[2020-07-18 18:11:36,409] {scheduler_job.py:153} INFO - Started process (PID=223258) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:11:36,412] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:11:36,413] {logging_mixin.py:112} INFO - [2020-07-18 18:11:36,413] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:11:37,456] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:11:37,568] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:11:37,584] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:11:37,586] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 1.177 seconds
[2020-07-18 18:12:34,462] {scheduler_job.py:153} INFO - Started process (PID=224282) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:12:34,466] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:12:34,466] {logging_mixin.py:112} INFO - [2020-07-18 18:12:34,466] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:12:34,542] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:12:34,744] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:12:34,768] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:12:34,771] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.309 seconds
[2020-07-18 18:13:32,522] {scheduler_job.py:153} INFO - Started process (PID=225244) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:13:32,526] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:13:32,526] {logging_mixin.py:112} INFO - [2020-07-18 18:13:32,526] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:13:32,609] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:13:32,704] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:13:32,728] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:13:32,732] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.210 seconds
[2020-07-18 18:14:30,982] {scheduler_job.py:153} INFO - Started process (PID=226256) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:14:30,987] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:14:30,987] {logging_mixin.py:112} INFO - [2020-07-18 18:14:30,987] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:14:31,298] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:14:31,413] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:14:31,429] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:14:31,431] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.449 seconds
[2020-07-18 18:15:29,033] {scheduler_job.py:153} INFO - Started process (PID=227171) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:15:29,039] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:15:29,040] {logging_mixin.py:112} INFO - [2020-07-18 18:15:29,040] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:15:29,129] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:15:29,263] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:15:29,279] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:15:29,281] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.248 seconds
[2020-07-18 18:16:27,475] {scheduler_job.py:153} INFO - Started process (PID=228179) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:16:27,479] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:16:27,480] {logging_mixin.py:112} INFO - [2020-07-18 18:16:27,479] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:16:27,555] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:16:27,734] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:16:27,757] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:16:27,761] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.286 seconds
[2020-07-18 18:17:25,525] {scheduler_job.py:153} INFO - Started process (PID=229065) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:17:25,542] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:17:25,542] {logging_mixin.py:112} INFO - [2020-07-18 18:17:25,542] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:17:25,860] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:17:25,983] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:17:26,006] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:17:26,010] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.485 seconds
[2020-07-18 18:18:23,591] {scheduler_job.py:153} INFO - Started process (PID=230083) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:18:23,595] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:18:23,596] {logging_mixin.py:112} INFO - [2020-07-18 18:18:23,595] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:18:23,670] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:18:23,914] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:18:23,929] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:47:38.829179+00:00: manual__2020-07-18T12:47:38.829179+00:00, externally triggered: True>
[2020-07-18 18:18:23,943] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:18:23,947] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 12:47:38.829179+00:00 [scheduled]> in ORM
[2020-07-18 18:18:23,951] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.csv_to_db2 2020-07-18 12:47:38.829179+00:00 [scheduled]> in ORM
[2020-07-18 18:18:23,955] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 12:47:38.829179+00:00 [scheduled]> in ORM
[2020-07-18 18:18:24,153] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.563 seconds
[2020-07-18 18:20:03,009] {scheduler_job.py:153} INFO - Started process (PID=231734) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:20:03,012] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:20:03,013] {logging_mixin.py:112} INFO - [2020-07-18 18:20:03,013] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:20:03,089] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:20:03,196] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:20:03,216] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:47:38.829179+00:00: manual__2020-07-18T12:47:38.829179+00:00, externally triggered: True>
[2020-07-18 18:20:03,226] {logging_mixin.py:112} INFO - [2020-07-18 18:20:03,226] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 12:47:38.829179+00:00: manual__2020-07-18T12:47:38.829179+00:00, externally triggered: True> successful
[2020-07-18 18:20:03,325] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:20:03,331] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.323 seconds
[2020-07-18 18:21:01,075] {scheduler_job.py:153} INFO - Started process (PID=232594) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:21:01,079] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:21:01,080] {logging_mixin.py:112} INFO - [2020-07-18 18:21:01,080] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:21:01,367] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:21:01,527] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:21:01,560] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:21:01,565] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.491 seconds
[2020-07-18 18:21:59,129] {scheduler_job.py:153} INFO - Started process (PID=233598) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:21:59,133] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:21:59,134] {logging_mixin.py:112} INFO - [2020-07-18 18:21:59,134] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:21:59,213] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:21:59,351] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:21:59,366] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:21:59,369] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.240 seconds
[2020-07-18 18:22:57,187] {scheduler_job.py:153} INFO - Started process (PID=234470) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:22:57,190] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:22:57,190] {logging_mixin.py:112} INFO - [2020-07-18 18:22:57,190] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:22:57,280] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:22:57,430] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:22:57,445] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:22:57,448] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.261 seconds
[2020-07-18 18:23:55,361] {scheduler_job.py:153} INFO - Started process (PID=235474) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:23:55,364] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:23:55,365] {logging_mixin.py:112} INFO - [2020-07-18 18:23:55,364] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:23:55,627] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:23:55,736] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:23:55,756] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:23:55,759] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.398 seconds
[2020-07-18 18:24:53,417] {scheduler_job.py:153} INFO - Started process (PID=236347) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:24:53,421] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:24:53,422] {logging_mixin.py:112} INFO - [2020-07-18 18:24:53,422] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:24:53,563] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:24:53,759] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:24:53,774] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:54:26.232614+00:00: manual__2020-07-18T12:54:26.232614+00:00, externally triggered: True>
[2020-07-18 18:24:53,789] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:24:53,793] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.db1_to_csv 2020-07-18 12:54:26.232614+00:00 [scheduled]> in ORM
[2020-07-18 18:24:53,797] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.csv_to_db2 2020-07-18 12:54:26.232614+00:00 [scheduled]> in ORM
[2020-07-18 18:24:53,801] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: storing_data.mysql_status 2020-07-18 12:54:26.232614+00:00 [scheduled]> in ORM
[2020-07-18 18:24:54,052] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.635 seconds
[2020-07-18 18:26:29,601] {scheduler_job.py:153} INFO - Started process (PID=238034) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:26:29,604] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:26:29,605] {logging_mixin.py:112} INFO - [2020-07-18 18:26:29,605] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:26:29,692] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:26:29,804] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:26:29,821] {scheduler_job.py:759} INFO - Examining DAG run <DagRun storing_data @ 2020-07-18 12:54:26.232614+00:00: manual__2020-07-18T12:54:26.232614+00:00, externally triggered: True>
[2020-07-18 18:26:29,832] {logging_mixin.py:112} INFO - [2020-07-18 18:26:29,832] {dagrun.py:318} INFO - Marking run <DagRun storing_data @ 2020-07-18 12:54:26.232614+00:00: manual__2020-07-18T12:54:26.232614+00:00, externally triggered: True> successful
[2020-07-18 18:26:29,952] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:26:29,959] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.358 seconds
[2020-07-18 18:27:27,662] {scheduler_job.py:153} INFO - Started process (PID=239031) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:27:27,665] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:27:27,665] {logging_mixin.py:112} INFO - [2020-07-18 18:27:27,665] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:27:27,878] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:27:27,990] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:27:28,005] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:27:28,008] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.346 seconds
[2020-07-18 18:28:25,722] {scheduler_job.py:153} INFO - Started process (PID=239951) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:28:25,726] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:28:25,727] {logging_mixin.py:112} INFO - [2020-07-18 18:28:25,727] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:28:25,847] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['storing_data']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:28:26,144] {scheduler_job.py:1284} INFO - Processing storing_data
[2020-07-18 18:28:26,160] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: storing_data> because no tasks in DAG have SLAs
[2020-07-18 18:28:26,162] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.441 seconds
[2020-07-18 18:29:24,302] {scheduler_job.py:153} INFO - Started process (PID=240927) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:29:24,306] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:29:24,306] {logging_mixin.py:112} INFO - [2020-07-18 18:29:24,306] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:29:24,376] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['mysql_operation']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:29:24,381] {logging_mixin.py:112} INFO - [2020-07-18 18:29:24,380] {dag.py:1501} INFO - Creating ORM DAG for mysql_operation
[2020-07-18 18:29:24,515] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.213 seconds
[2020-07-18 18:30:22,375] {scheduler_job.py:153} INFO - Started process (PID=241951) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:30:22,391] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:30:22,391] {logging_mixin.py:112} INFO - [2020-07-18 18:30:22,391] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:30:22,696] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['mysql_operation']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:30:22,796] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.421 seconds
[2020-07-18 18:31:20,421] {scheduler_job.py:153} INFO - Started process (PID=242839) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:31:20,425] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:31:20,425] {logging_mixin.py:112} INFO - [2020-07-18 18:31:20,425] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:31:20,552] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:31:20,563] {logging_mixin.py:112} INFO - [2020-07-18 18:31:20,562] {dag.py:1501} INFO - Creating ORM DAG for MYSQLDAG
[2020-07-18 18:31:20,681] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.260 seconds
[2020-07-18 18:32:31,123] {scheduler_job.py:153} INFO - Started process (PID=244022) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:32:31,126] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:32:31,126] {logging_mixin.py:112} INFO - [2020-07-18 18:32:31,126] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:32:31,403] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:32:31,575] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-18 18:32:31,894] {scheduler_job.py:1294} INFO - Created <DagRun MYSQLDAG @ 2020-07-17T00:00:00+00:00: scheduled__2020-07-17T00:00:00+00:00, externally triggered: False>
[2020-07-18 18:32:31,897] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-17 00:00:00+00:00: scheduled__2020-07-17T00:00:00+00:00, externally triggered: False>
[2020-07-18 18:32:31,905] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-18 13:02:25.907277+00:00: manual__2020-07-18T13:02:25.907277+00:00, externally triggered: True>
[2020-07-18 18:32:31,940] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-18 18:32:31,944] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.first_db_to_csv 2020-07-17 00:00:00+00:00 [scheduled]> in ORM
[2020-07-18 18:32:31,948] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.first_db_to_csv 2020-07-18 13:02:25.907277+00:00 [scheduled]> in ORM
[2020-07-18 18:32:32,118] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.996 seconds
[2020-07-18 18:33:53,655] {scheduler_job.py:153} INFO - Started process (PID=245510) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:33:53,658] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:33:53,658] {logging_mixin.py:112} INFO - [2020-07-18 18:33:53,658] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:33:53,736] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:33:53,926] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-18 18:33:53,941] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-17 00:00:00+00:00: scheduled__2020-07-17T00:00:00+00:00, externally triggered: False>
[2020-07-18 18:33:53,955] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-18 13:02:25.907277+00:00: manual__2020-07-18T13:02:25.907277+00:00, externally triggered: True>
[2020-07-18 18:33:53,990] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-18 18:33:53,994] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.csv_to_second_db 2020-07-17 00:00:00+00:00 [scheduled]> in ORM
[2020-07-18 18:33:53,998] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.csv_to_second_db 2020-07-18 13:02:25.907277+00:00 [scheduled]> in ORM
[2020-07-18 18:33:54,170] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.515 seconds
[2020-07-18 18:35:16,555] {scheduler_job.py:153} INFO - Started process (PID=246842) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:35:16,558] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:35:16,559] {logging_mixin.py:112} INFO - [2020-07-18 18:35:16,559] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:35:16,631] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:35:16,856] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-18 18:35:16,887] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-17 00:00:00+00:00: scheduled__2020-07-17T00:00:00+00:00, externally triggered: False>
[2020-07-18 18:35:16,904] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-18 13:02:25.907277+00:00: manual__2020-07-18T13:02:25.907277+00:00, externally triggered: True>
[2020-07-18 18:35:16,956] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-18 18:35:16,960] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.dump_second_upload_minio 2020-07-17 00:00:00+00:00 [scheduled]> in ORM
[2020-07-18 18:35:16,966] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: MYSQLDAG.dump_second_upload_minio 2020-07-18 13:02:25.907277+00:00 [scheduled]> in ORM
[2020-07-18 18:35:17,195] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.640 seconds
[2020-07-18 18:36:40,762] {scheduler_job.py:153} INFO - Started process (PID=248323) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:36:40,766] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:36:40,766] {logging_mixin.py:112} INFO - [2020-07-18 18:36:40,766] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:36:40,840] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:36:40,991] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-18 18:36:41,006] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-17 00:00:00+00:00: scheduled__2020-07-17T00:00:00+00:00, externally triggered: False>
[2020-07-18 18:36:41,015] {logging_mixin.py:112} INFO - [2020-07-18 18:36:41,015] {dagrun.py:318} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-17 00:00:00+00:00: scheduled__2020-07-17T00:00:00+00:00, externally triggered: False> successful
[2020-07-18 18:36:41,120] {scheduler_job.py:759} INFO - Examining DAG run <DagRun MYSQLDAG @ 2020-07-18 13:02:25.907277+00:00: manual__2020-07-18T13:02:25.907277+00:00, externally triggered: True>
[2020-07-18 18:36:41,131] {logging_mixin.py:112} INFO - [2020-07-18 18:36:41,131] {dagrun.py:318} INFO - Marking run <DagRun MYSQLDAG @ 2020-07-18 13:02:25.907277+00:00: manual__2020-07-18T13:02:25.907277+00:00, externally triggered: True> successful
[2020-07-18 18:36:41,286] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-18 18:36:41,289] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.527 seconds
[2020-07-18 18:37:40,079] {scheduler_job.py:153} INFO - Started process (PID=249321) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:37:40,082] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:37:40,082] {logging_mixin.py:112} INFO - [2020-07-18 18:37:40,082] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:37:40,337] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:37:40,460] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-18 18:37:40,475] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-18 18:37:40,478] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.399 seconds
[2020-07-18 18:38:38,143] {scheduler_job.py:153} INFO - Started process (PID=250220) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:38:38,150] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:38:38,150] {logging_mixin.py:112} INFO - [2020-07-18 18:38:38,150] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:38:38,240] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:38:38,386] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-18 18:38:38,401] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-18 18:38:38,404] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.260 seconds
[2020-07-18 18:39:36,195] {scheduler_job.py:153} INFO - Started process (PID=251218) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:39:36,199] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:39:36,200] {logging_mixin.py:112} INFO - [2020-07-18 18:39:36,200] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:39:36,281] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:39:36,376] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-18 18:39:36,394] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-18 18:39:36,396] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.202 seconds
[2020-07-18 18:40:34,445] {scheduler_job.py:153} INFO - Started process (PID=252100) to work on /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:40:34,448] {scheduler_job.py:1562} INFO - Processing file /home/bhakti/airflow/dags/task_3_bash_operator.py for tasks to queue
[2020-07-18 18:40:34,448] {logging_mixin.py:112} INFO - [2020-07-18 18:40:34,448] {dagbag.py:396} INFO - Filling up the DagBag from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:40:34,524] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['MYSQLDAG']) retrieved from /home/bhakti/airflow/dags/task_3_bash_operator.py
[2020-07-18 18:40:34,648] {scheduler_job.py:1284} INFO - Processing MYSQLDAG
[2020-07-18 18:40:34,671] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: MYSQLDAG> because no tasks in DAG have SLAs
[2020-07-18 18:40:34,674] {scheduler_job.py:161} INFO - Processing /home/bhakti/airflow/dags/task_3_bash_operator.py took 0.229 seconds
